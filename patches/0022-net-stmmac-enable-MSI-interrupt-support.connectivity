From 920d042c4584e84b6cd422c8037b61ebcdecc6ac Mon Sep 17 00:00:00 2001
From: "Wong, Vincent Por Yin" <vincent.por.yin.wong@intel.com>
Date: Sat, 15 Sep 2018 11:24:34 +0800
Subject: [PATCH 22/26] net: stmmac: enable MSI interrupt support

Add support for multi-interrupts using MSI. New ISRs are introduced to
increase efficiency. Legacy interrupts are still supported and is used
by default.

Improves upon <commitid> to make IRQ allocation more dynamic. Changed
the use of mutexes in interrupt handlers to spinlocks. Additional
bug fixes.

Signed-off-by: Wong, Vincent Por Yin <vincent.por.yin.wong@intel.com>
Signed-off-by: Voon Weifeng <weifeng.voon@intel.com>
---
 .../net/ethernet/stmicro/stmmac/dwmac4_dma.c  |   2 +
 .../net/ethernet/stmicro/stmmac/dwmac4_dma.h  |   2 +
 .../net/ethernet/stmicro/stmmac/dwmac4_lib.c  |   8 +
 drivers/net/ethernet/stmicro/stmmac/hwif.h    |   4 +
 drivers/net/ethernet/stmicro/stmmac/stmmac.h  |  15 +-
 .../net/ethernet/stmicro/stmmac/stmmac_main.c | 406 ++++++++++++++++--
 .../net/ethernet/stmicro/stmmac/stmmac_pci.c  |  26 +-
 .../ethernet/stmicro/stmmac/stmmac_platform.c |   2 -
 include/linux/stmmac.h                        |  21 +
 9 files changed, 434 insertions(+), 52 deletions(-)

diff --git a/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.c b/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.c
index 0f208e13da9f..ab028e5bb1a2 100644
--- a/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.c
+++ b/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.c
@@ -450,6 +450,7 @@ const struct stmmac_dma_ops dwmac4_dma_ops = {
 	.set_tx_ring_len = dwmac4_set_tx_ring_len,
 	.set_rx_tail_ptr = dwmac4_set_rx_tail_ptr,
 	.set_tx_tail_ptr = dwmac4_set_tx_tail_ptr,
+	.set_intr_mode = dwmac4_set_intr_mode,
 	.enable_tso = dwmac4_enable_tso,
 	.qmode = dwmac4_qmode,
 	.set_bfsize = dwmac4_set_bfsize,
@@ -478,6 +479,7 @@ const struct stmmac_dma_ops dwmac410_dma_ops = {
 	.set_tx_ring_len = dwmac4_set_tx_ring_len,
 	.set_rx_tail_ptr = dwmac4_set_rx_tail_ptr,
 	.set_tx_tail_ptr = dwmac4_set_tx_tail_ptr,
+	.set_intr_mode = dwmac4_set_intr_mode,
 	.enable_tso = dwmac4_enable_tso,
 	.qmode = dwmac4_qmode,
 	.set_bfsize = dwmac4_set_bfsize,
diff --git a/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.h b/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.h
index b66da0237d2a..fbdfa49eb43f 100644
--- a/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.h
+++ b/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.h
@@ -25,6 +25,7 @@
 
 /* DMA Bus Mode bitmap */
 #define DMA_BUS_MODE_SFT_RESET		BIT(0)
+#define DMA_BUS_MODE_INTR_MODE_01	BIT(16)
 
 /* DMA SYS Bus Mode bitmap */
 #define DMA_BUS_MODE_SPH		BIT(24)
@@ -195,5 +196,6 @@ void dwmac4_set_rx_ring_len(void __iomem *ioaddr, u32 len, u32 chan);
 void dwmac4_set_tx_ring_len(void __iomem *ioaddr, u32 len, u32 chan);
 void dwmac4_set_rx_tail_ptr(void __iomem *ioaddr, u32 tail_ptr, u32 chan);
 void dwmac4_set_tx_tail_ptr(void __iomem *ioaddr, u32 tail_ptr, u32 chan);
+void dwmac4_set_intr_mode(void __iomem *ioaddr);
 
 #endif /* __DWMAC4_DMA_H__ */
diff --git a/drivers/net/ethernet/stmicro/stmmac/dwmac4_lib.c b/drivers/net/ethernet/stmicro/stmmac/dwmac4_lib.c
index 85826524683c..11b1840a63cb 100644
--- a/drivers/net/ethernet/stmicro/stmmac/dwmac4_lib.c
+++ b/drivers/net/ethernet/stmicro/stmmac/dwmac4_lib.c
@@ -101,6 +101,14 @@ void dwmac4_set_rx_ring_len(void __iomem *ioaddr, u32 len, u32 chan)
 	writel(len, ioaddr + DMA_CHAN_RX_RING_LEN(chan));
 }
 
+void dwmac4_set_intr_mode(void __iomem *ioaddr)
+{
+	u32 value = readl(ioaddr + DMA_BUS_MODE);
+
+	value |= DMA_BUS_MODE_INTR_MODE_01;
+	writel(value, ioaddr + DMA_BUS_MODE);
+}
+
 void dwmac4_enable_dma_irq(void __iomem *ioaddr, u32 chan)
 {
 	writel(DMA_CHAN_INTR_DEFAULT_MASK, ioaddr +
diff --git a/drivers/net/ethernet/stmicro/stmmac/hwif.h b/drivers/net/ethernet/stmicro/stmmac/hwif.h
index b29896c313d5..b5d330e02cee 100644
--- a/drivers/net/ethernet/stmicro/stmmac/hwif.h
+++ b/drivers/net/ethernet/stmicro/stmmac/hwif.h
@@ -187,6 +187,8 @@ struct stmmac_dma_ops {
 	void (*enable_tso)(void __iomem *ioaddr, bool en, u32 chan);
 	void (*qmode)(void __iomem *ioaddr, u32 channel, u8 qmode);
 	void (*set_bfsize)(void __iomem *ioaddr, int bfsize, u32 chan);
+	/* Set the interrupt mode (if using MSI interrupts) */
+	void (*set_intr_mode)(void __iomem *ioaddr);
 };
 
 #define stmmac_reset(__priv, __args...) \
@@ -243,6 +245,8 @@ struct stmmac_dma_ops {
 	stmmac_do_void_callback(__priv, dma, qmode, __args)
 #define stmmac_set_dma_bfsize(__priv, __args...) \
 	stmmac_do_void_callback(__priv, dma, set_bfsize, __args)
+#define stmmac_set_intr_mode(__priv, __args...) \
+	stmmac_do_void_callback(__priv, dma, set_intr_mode, __args)
 
 struct mac_device_info;
 struct net_device;
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac.h b/drivers/net/ethernet/stmicro/stmmac/stmmac.h
index 8f0c701f2cd7..9db2db589db6 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac.h
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac.h
@@ -24,10 +24,15 @@
 struct stmmac_resources {
 	void __iomem *addr;
 	const char *mac;
+	int irq;
+	int rx_irq[MTL_MAX_RX_QUEUES];
+	int tx_irq[MTL_MAX_TX_QUEUES];
+	int mac_irq;
 	int wol_irq;
 	int lpi_irq;
+	int sfty_ue_irq;
+	int sfty_ce_irq;
 	int xpcs_irq;
-	int irq;
 };
 
 struct stmmac_tx_info {
@@ -128,6 +133,9 @@ struct stmmac_priv {
 	struct mac_device_info *hw;
 	int (*hwif_quirks)(struct stmmac_priv *priv);
 	struct mutex lock;
+	spinlock_t dma_chan_status_lock; /* dma status register */
+	spinlock_t dma_intr_enable_lock; /* dma intr enable register */
+	spinlock_t dma_operation_lock; /* dma operation register */
 
 	/* RX Queue */
 	struct stmmac_rx_queue rx_queue[MTL_MAX_RX_QUEUES];
@@ -178,6 +186,11 @@ struct stmmac_priv {
 	spinlock_t ptp_lock;
 	void __iomem *mmcaddr;
 	void __iomem *ptpaddr;
+	int mac_irq;
+	int sfty_ue_irq;
+	int sfty_ce_irq;
+	int rx_irq[MTL_MAX_RX_QUEUES];
+	int tx_irq[MTL_MAX_TX_QUEUES];
 
 #ifdef CONFIG_DEBUG_FS
 	struct dentry *dbgfs_dir;
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
index 3a7af108df84..6a94f10b14f6 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
@@ -104,6 +104,8 @@ module_param(chain_mode, int, 0444);
 MODULE_PARM_DESC(chain_mode, "To use chain instead of ring mode");
 
 static irqreturn_t stmmac_interrupt(int irq, void *dev_id);
+static irqreturn_t stmmac_msi_dma(int irq, void *dev_id);
+static irqreturn_t stmmac_msi_non_dma(int irq, void *dev_id);
 static irqreturn_t xpcs_interrupt(int irq, void *dev_id);
 
 #ifdef CONFIG_DEBUG_FS
@@ -2208,6 +2210,9 @@ static int stmmac_init_dma_engine(struct stmmac_priv *priv)
 		return ret;
 	}
 
+	if (!priv->plat->multi_msi_en)
+		stmmac_set_intr_mode(priv, priv->ioaddr);
+
 	/* DMA Configuration */
 	stmmac_dma_init(priv, priv->ioaddr, priv->plat->dma_cfg, atds);
 
@@ -2647,6 +2652,7 @@ static int stmmac_open(struct net_device *dev)
 	struct stmmac_priv *priv = netdev_priv(dev);
 	u32 chan;
 	int ret;
+	int i;
 
 	if (priv->hw->pcs != STMMAC_PCS_RGMII &&
 	    priv->hw->pcs != STMMAC_PCS_TBI &&
@@ -2693,48 +2699,151 @@ static int stmmac_open(struct net_device *dev)
 		phy_start(dev->phydev);
 
 	/* Request the IRQ lines */
-	ret = request_irq(dev->irq, stmmac_interrupt,
-			  IRQF_SHARED, dev->name, dev);
-	if (unlikely(ret < 0)) {
-		netdev_err(priv->dev,
-			   "%s: ERROR: allocating the IRQ %d (error: %d)\n",
-			   __func__, dev->irq, ret);
-		goto irq_error;
-	}
-
-	/* Request the Wake IRQ in case of another line is used for WoL */
-	if (priv->wol_irq != dev->irq) {
-		ret = request_irq(priv->wol_irq, stmmac_interrupt,
+	if (!priv->plat->multi_msi_en) {
+		ret = request_irq(dev->irq, stmmac_interrupt,
 				  IRQF_SHARED, dev->name, dev);
 		if (unlikely(ret < 0)) {
 			netdev_err(priv->dev,
-				   "%s: ERROR: allocating the WoL IRQ %d (%d)\n",
-				   __func__, priv->wol_irq, ret);
-			goto wolirq_error;
+				   "%s: ERROR: allocating IRQ %d (error: %d)\n",
+				   __func__, dev->irq, ret);
+			goto irq_error;
 		}
-	}
 
-	/* Request the IRQ lines */
-	if (priv->lpi_irq > 0) {
-		ret = request_irq(priv->lpi_irq, stmmac_interrupt, IRQF_SHARED,
-				  dev->name, dev);
-		if (unlikely(ret < 0)) {
+		/* Request the Wake IRQ in case of another line is used for WoL */
+		if (priv->wol_irq != dev->irq) {
+			ret = request_irq(priv->wol_irq, stmmac_interrupt,
+					  IRQF_SHARED, dev->name, dev);
+			if (unlikely(ret < 0)) {
+				netdev_err(priv->dev,
+					   "%s: ERROR: allocating the WoL IRQ %d (%d)\n",
+					   __func__, priv->wol_irq, ret);
+				goto wolirq_error;
+			}
+		}
+
+		/* Request the IRQ lines */
+		if (priv->lpi_irq > 0) {
+			ret = request_irq(priv->lpi_irq, stmmac_interrupt, IRQF_SHARED,
+					  dev->name, dev);
+			if (unlikely(ret < 0)) {
+				netdev_err(priv->dev,
+					   "%s: ERROR: allocating the LPI IRQ %d (%d)\n",
+					   __func__, priv->lpi_irq, ret);
+				goto lpiirq_error;
+			}
+		}
+
+		/* xPCS IRQ line */
+		if (priv->xpcs_irq > 0) {
+			ret = request_irq(priv->xpcs_irq, xpcs_interrupt, IRQF_SHARED,
+					  dev->name, dev);
+			if (unlikely(ret < 0)) {
+				netdev_err(priv->dev,
+					   "%s: ERROR: allocating the xPCS IRQ %d (%d)\n",
+					   __func__, priv->xpcs_irq, ret);
+				goto xpcsirq_error;
+			}
+		}
+	} else {
+		/* LPI IRQ lines */
+		if (priv->lpi_irq > 0) {
+			ret = request_irq(priv->lpi_irq, stmmac_msi_non_dma,
+					  0, dev->name, dev);
+			if (unlikely(ret < 0)) {
+				netdev_err(priv->dev,
+					   "%s: ERROR allocating IRQ %d (error: %d)\n",
+					   __func__, priv->lpi_irq, ret);
+				goto lpiirq_error;
+			}
+		}
+
+		/* xPCS IRQ line */
+		if (priv->xpcs_irq > 0) {
+			ret = request_irq(priv->xpcs_irq, xpcs_interrupt, 0,
+					  dev->name, dev);
+			if (unlikely(ret < 0)) {
+				netdev_err(priv->dev,
+					   "%s: ERROR allocating IRQ %d (error: %d)\n",
+					   __func__, priv->xpcs_irq, ret);
+				goto xpcsirq_error;
+			}
+		}
+
+		/* MAC IRQ lines */
+		if (priv->mac_irq > 0) {
+			ret = request_irq(priv->mac_irq, stmmac_msi_non_dma,
+					  0, dev->name, dev);
+			if (unlikely(ret < 0)) {
+				netdev_err(priv->dev,
+					   "%s: ERROR allocating IRQ %d (error: %d)\n",
+					   __func__, priv->mac_irq, ret);
+				goto macirq_error;
+			}
+		}
+
+		/* Safety correctable error IRQ line */
+		if (priv->sfty_ce_irq > 0) {
+			ret = request_irq(priv->sfty_ce_irq, stmmac_msi_non_dma,
+					  0, dev->name, dev);
+			if (unlikely(ret < 0)) {
+				netdev_err(priv->dev,
+					   "%s: ERROR allocating IRQ %d (error: %d)\n",
+					    __func__, priv->sfty_ce_irq, ret);
+				goto sfty_ce_irq_error;
+			}
+		}
+
+		/* Safety uncorrectable error IRQ line */
+		if (priv->sfty_ue_irq > 0) {
+			ret = request_irq(priv->sfty_ue_irq, stmmac_msi_non_dma,
+					  0, dev->name, dev);
+			if (unlikely(ret < 0)) {
+				netdev_err(priv->dev,
+					   "%s: ERROR allocating IRQ %d (error: %d)\n",
+					   __func__, priv->sfty_ue_irq, ret);
+				goto sfty_ue_irq_error;
+			}
+		}
+
+		/* MSI-style IRQs are handled by DMA and non-DMA ISRs */
+		/* Assign ISR to RX DMA IRQ lines */
+		for (i = 0; i < MTL_MAX_RX_QUEUES; i++) {
+			if (priv->rx_irq[i]) {
+				ret = request_irq(priv->rx_irq[i],
+						  stmmac_msi_dma,
+						  0,
+						  dev->name,
+						  dev);
+			if (unlikely(ret < 0))
+				break;
+			}
+		}
+
+		if (ret < 0) {
 			netdev_err(priv->dev,
-				   "%s: ERROR: allocating the LPI IRQ %d (%d)\n",
-				   __func__, priv->lpi_irq, ret);
-			goto lpiirq_error;
+				   "%s: ERROR: allocating IRQ %d (error: %d)\n",
+				   __func__, priv->rx_irq[i], ret);
+			goto rxirq_error;
 		}
-	}
 
-	/* xPCS IRQ line */
-	if (priv->xpcs_irq > 0) {
-		ret = request_irq(priv->xpcs_irq, xpcs_interrupt, IRQF_SHARED,
-				  dev->name, dev);
-		if (unlikely(ret < 0)) {
+		/* Assign ISR to TX DMA IRQ lines */
+		for (i = 0; i < MTL_MAX_TX_QUEUES; i++) {
+			if (priv->tx_irq[i]) {
+				ret = request_irq(priv->tx_irq[i],
+						  stmmac_msi_dma,
+						  0,
+						  dev->name,
+						  dev);
+			}
+			if (unlikely(ret < 0))
+				break;
+		}
+
+		if (ret < 0) {
 			netdev_err(priv->dev,
-				   "%s: ERROR: allocating the xPCS IRQ %d (%d)\n",
-				   __func__, priv->xpcs_irq, ret);
-			goto xpcsirq_error;
+				   "%s: ERROR: allocating IRQ %d (error: %d)\n",
+				   __func__, priv->tx_irq[i], ret);
+			goto txirq_error;
 		}
 	}
 
@@ -2743,15 +2852,34 @@ static int stmmac_open(struct net_device *dev)
 
 	return 0;
 
+txirq_error:
+	if (priv->tx_irq[0]) {
+		for (i = 0; i < MTL_MAX_TX_QUEUES; i++)
+			free_irq(priv->tx_irq[i], dev);
+	}
+rxirq_error:
+	if (priv->rx_irq[0]) {
+		for (i = 0; i < MTL_MAX_RX_QUEUES; i++)
+			free_irq(priv->rx_irq[i], dev);
+	}
+sfty_ue_irq_error:
+	if (priv->sfty_ue_irq)
+		free_irq(priv->sfty_ue_irq, dev);
+sfty_ce_irq_error:
+	if (priv->sfty_ce_irq)
+		free_irq(priv->sfty_ce_irq, dev);
+macirq_error:
+	if (priv->mac_irq)
+		free_irq(priv->mac_irq, dev);
 xpcsirq_error:
-	if (priv->lpi_irq > 0)
-		free_irq(priv->lpi_irq, dev);
-
+	if (priv->xpcs_irq)
+		free_irq(priv->xpcs_irq, dev);
 lpiirq_error:
-	if (priv->wol_irq != dev->irq)
-		free_irq(priv->wol_irq, dev);
+	if (priv->lpi_irq)
+		free_irq(priv->lpi_irq, dev);
 wolirq_error:
-	free_irq(dev->irq, dev);
+	if (priv->wol_irq != dev->irq && priv->wol_irq > 0)
+		free_irq(priv->wol_irq, dev);
 irq_error:
 	if (dev->phydev)
 		phy_stop(dev->phydev);
@@ -2779,6 +2907,7 @@ static int stmmac_release(struct net_device *dev)
 {
 	struct stmmac_priv *priv = netdev_priv(dev);
 	u32 chan;
+	int i;
 
 	if (priv->eee_enabled)
 		del_timer_sync(&priv->eee_ctrl_timer);
@@ -2797,11 +2926,32 @@ static int stmmac_release(struct net_device *dev)
 		del_timer_sync(&priv->tx_queue[chan].txtimer);
 
 	/* Free the IRQ lines */
-	free_irq(dev->irq, dev);
-	if (priv->wol_irq != dev->irq)
-		free_irq(priv->wol_irq, dev);
-	if (priv->lpi_irq > 0)
-		free_irq(priv->lpi_irq, dev);
+	if (!priv->plat->multi_msi_en)
+		free_irq(dev->irq, dev);
+	else {
+		if (priv->wol_irq != dev->irq  && priv->wol_irq > 0)
+			free_irq(priv->wol_irq, dev);
+		if (priv->lpi_irq > 0)
+			free_irq(priv->lpi_irq, dev);
+		if (priv->mac_irq > 0)
+			free_irq(priv->mac_irq, dev);
+		if (priv->xpcs_irq > 0)
+			free_irq(priv->xpcs_irq, dev);
+		if (priv->sfty_ue_irq > 0)
+			free_irq(priv->sfty_ue_irq, dev);
+		if (priv->sfty_ce_irq > 0)
+			free_irq(priv->sfty_ce_irq, dev);
+
+		if (priv->tx_irq[0] > 0) {
+			for (i = 0; i < priv->plat->tx_queues_to_use; i++)
+				free_irq(priv->tx_irq[i], dev);
+		}
+
+		if (priv->rx_irq[0] > 0) {
+			for (i = 0; i < priv->plat->rx_queues_to_use; i++)
+				free_irq(priv->rx_irq[i], dev);
+		}
+	}
 
 	/* Stop TX/RX DMA and clear the descriptors */
 	stmmac_stop_all_dma(priv);
@@ -3317,7 +3467,6 @@ static void stmmac_rx_vlan(struct net_device *dev, struct sk_buff *skb)
 	}
 }
 
-
 static inline int stmmac_rx_threshold_count(struct stmmac_rx_queue *rx_q)
 {
 	if (rx_q->rx_zeroc_thresh < STMMAC_RX_THRESH)
@@ -3748,6 +3897,160 @@ static int stmmac_set_features(struct net_device *netdev,
 	return 0;
 }
 
+/**
+ *  stmmac_msi_non_dma - same as main ISR but without dma interrupt handling
+ *  @irq: interrupt number.
+ *  @dev_id: to pass the net device pointer.
+ *  Description: ISR to service non-dma interrupts only when msi is available
+ *  It can call:
+ *  o Core interrupts to manage: remote wake-up, management counter, LPI
+ *    interrupts.
+ */
+static irqreturn_t stmmac_msi_non_dma(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *)dev_id;
+	struct stmmac_priv *priv = netdev_priv(dev);
+	u32 rx_cnt = priv->plat->rx_queues_to_use;
+	u32 tx_cnt = priv->plat->tx_queues_to_use;
+	u32 queues_count;
+	u32 queue;
+
+	queues_count = (rx_cnt > tx_cnt) ? rx_cnt : tx_cnt;
+
+	if (priv->irq_wake)
+		pm_wakeup_event(priv->device, 0);
+
+	if (unlikely(!dev)) {
+		netdev_err(priv->dev, "%s: invalid dev pointer\n", __func__);
+		return IRQ_NONE;
+	}
+
+	/* Check if adapter is up */
+	if (test_bit(STMMAC_DOWN, &priv->state))
+		return IRQ_HANDLED;
+
+	/* Check if a fatal error happened */
+	if (stmmac_safety_feat_interrupt(priv))
+		return IRQ_HANDLED;
+
+	/* To handle GMAC own interrupts */
+	if (priv->plat->has_gmac || priv->plat->has_gmac4) {
+		int status = stmmac_host_irq_status(priv, priv->hw,
+						    &priv->xstats);
+		int mtl_status;
+
+		if (unlikely(status)) {
+			/* For LPI we need to save the tx status */
+			if (status & CORE_IRQ_TX_PATH_IN_LPI_MODE)
+				priv->tx_path_in_lpi_mode = true;
+			if (status & CORE_IRQ_TX_PATH_EXIT_LPI_MODE)
+				priv->tx_path_in_lpi_mode = false;
+		}
+
+		for (queue = 0; queue < queues_count; queue++) {
+			struct stmmac_rx_queue *rx_q = &priv->rx_queue[queue];
+
+			mtl_status = stmmac_host_mtl_irq_status(priv, priv->hw,
+								queue);
+			if (mtl_status != -EINVAL)
+				status |= mtl_status;
+
+			if (status & CORE_IRQ_MTL_RX_OVERFLOW)
+				stmmac_set_rx_tail_ptr(priv, priv->ioaddr,
+						       rx_q->rx_tail_addr,
+						       queue);
+		}
+
+		if (priv->hw->tsn_cap & TSN_CAP_EST)
+			stmmac_est_irq_status(priv, priv->ioaddr);
+
+		/* PCS link status */
+		if (priv->hw->pcs) {
+			if (priv->xstats.pcs_link)
+				netif_carrier_on(dev);
+			else
+				netif_carrier_off(dev);
+		}
+	}
+
+	return IRQ_HANDLED;
+}
+
+/**
+ *  stmmac_msi_non_dma - secondary ISR for dma interrupt handling only
+ *  @irq: interrupt number.
+ *  @dev_id: to pass the net device pointer.
+ *  Description: ISR to service dma interrupts only when msi is available
+ *  It can call:
+ *  o DMA service routine (to manage incoming frame reception and transmission
+ *    status)
+ */
+static irqreturn_t stmmac_msi_dma(int irq, void *dev_id)
+{
+	struct net_device *dev = (struct net_device *)dev_id;
+	struct stmmac_priv *priv = netdev_priv(dev);
+	u32 tx_channel_count = priv->plat->tx_queues_to_use;
+	u32 rx_channel_count = priv->plat->rx_queues_to_use;
+
+	u32 chan = -1; /* Invalid channel number */
+	int i;
+	int status;
+
+	if (unlikely(!dev)) {
+		netdev_err(priv->dev, "%s: invalid dev pointer\n", __func__);
+		return IRQ_NONE;
+	}
+
+	/* Check if adapter is up */
+	if (test_bit(STMMAC_DOWN, &priv->state))
+		return IRQ_HANDLED;
+
+	/* Find the queue/channel this IRQ is assigned to */
+	for (i = 0; i < rx_channel_count; i++)
+		if (priv->rx_irq[i] == irq)
+			chan = i;
+
+	if (chan < 0) {
+		for (i = 0; chan < tx_channel_count; i++)
+			if (priv->tx_irq[i] == irq)
+				chan = i;
+	}
+
+	spin_lock(&priv->dma_chan_status_lock);
+	status = stmmac_napi_check(priv, chan);
+	spin_unlock(&priv->dma_chan_status_lock);
+
+	if (unlikely(status & tx_hard_error_bump_tc)) {
+		/* Try to bump up the dma threshold on this failure */
+		if (unlikely(priv->xstats.threshold != SF_DMA_MODE) &&
+		    tc <= 256) {
+			tc += 64;
+			spin_lock(&priv->dma_operation_lock);
+
+			if (priv->plat->force_thresh_dma_mode)
+				stmmac_set_dma_operation_mode(priv,
+							      tc,
+							      tc,
+							      chan);
+			else
+				stmmac_set_dma_operation_mode(priv,
+							      tc,
+							      SF_DMA_MODE,
+							      chan);
+
+			spin_unlock(&priv->dma_operation_lock);
+			priv->xstats.threshold = tc;
+		}
+	} else if (unlikely(status == tx_hard_error)) {
+		stmmac_tx_err(priv, chan);
+	}
+
+	 /* To handle DMA interrupts */
+	stmmac_dma_interrupt(priv);
+
+	return IRQ_HANDLED;
+}
+
 /**
  *  stmmac_interrupt - main ISR
  *  @irq: interrupt number.
@@ -4365,6 +4668,7 @@ int stmmac_dvr_probe(struct device *device,
 	struct stmmac_priv *priv;
 	u32 queue, maxq;
 	int ret = 0;
+	int i;
 
 	ndev = alloc_etherdev_mqs(sizeof(struct stmmac_priv),
 				  MTL_MAX_TX_QUEUES,
@@ -4388,6 +4692,15 @@ int stmmac_dvr_probe(struct device *device,
 	priv->wol_irq = res->wol_irq;
 	priv->lpi_irq = res->lpi_irq;
 	priv->xpcs_irq = res->xpcs_irq;
+	priv->mac_irq = res->mac_irq;
+	priv->sfty_ue_irq = res->sfty_ue_irq;
+	priv->sfty_ce_irq = res->sfty_ce_irq;
+
+	for (i = 0; i < priv->plat->tx_queues_to_use; i++)
+		priv->tx_irq[i] = res->tx_irq[i];
+
+	for (i = 0; i < priv->plat->rx_queues_to_use; i++)
+		priv->rx_irq[i] = res->rx_irq[i];
 
 	if (!IS_ERR_OR_NULL(res->mac))
 		memcpy(priv->dev->dev_addr, res->mac, ETH_ALEN);
@@ -4508,6 +4821,9 @@ int stmmac_dvr_probe(struct device *device,
 	}
 
 	mutex_init(&priv->lock);
+	spin_lock_init(&priv->dma_chan_status_lock);
+	spin_lock_init(&priv->dma_intr_enable_lock);
+	spin_lock_init(&priv->dma_operation_lock);
 
 	/* If a specific clk_csr value is passed from the platform
 	 * this means that the CSR Clock Range selection cannot be
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_pci.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_pci.c
index b9cdc857400c..faded7622324 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_pci.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_pci.c
@@ -436,7 +436,6 @@ static int stmmac_pci_probe(struct pci_dev *pdev,
 	}
 
 	pci_set_master(pdev);
-
 	ret = info->setup(pdev, plat);
 	if (ret)
 		return ret;
@@ -449,19 +448,38 @@ static int stmmac_pci_probe(struct pci_dev *pdev,
 	if (ret > 1) {
 		dev_info(&pdev->dev, "%s: Multi-MSI with %d vectors\n",
 			 __func__, ret);
-		/* MAC MSI vector offset at 29 */
-		res.irq = pci_irq_vector(pdev, 29);
+		plat->multi_msi_en = 1;
+
+		for (i = 0; i < plat->rx_queues_to_use; i++)
+			res.rx_irq[i] = pci_irq_vector(pdev,
+						       MSI_RX_OFFSET_VEC + i * 2);
+
+		for (i = 0; i < plat->tx_queues_to_use; i++)
+			res.tx_irq[i] = pci_irq_vector(pdev,
+						       MSI_TX_OFFSET_VEC + i * 2);
+
+		res.mac_irq = pci_irq_vector(pdev, MSI_MAC_VEC);
+		res.lpi_irq = pci_irq_vector(pdev, MSI_LPI_VEC);
+		res.xpcs_irq = pci_irq_vector(pdev, MSI_PCS_VEC);
+		res.sfty_ue_irq = pci_irq_vector(pdev, MSI_SAFETY_UE_VEC);
+		res.sfty_ce_irq = pci_irq_vector(pdev, MSI_SAFETY_CE_VEC);
+
 	} else if (ret == 1) {
 		dev_info(&pdev->dev, "%s: Single MSI\n",
 			 __func__);
+		plat->multi_msi_en = 0;
 		res.irq = pci_irq_vector(pdev, 0);
+		res.wol_irq = res.irq;
+		res.mac_irq = 0;
 	} else {
 		dev_info(&pdev->dev, "%s: Fall back to legacy IRQ\n",
 			 __func__);
+		plat->multi_msi_en = 0;
 		res.irq = pdev->irq;
+		res.wol_irq = res.irq;
+		res.mac_irq = 0;
 	}
 
-	res.wol_irq = res.irq;
 	res.xpcs_irq = 0;
 
 	return stmmac_dvr_probe(&pdev->dev, plat, &res);
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.c
index 0f0f4b31eb7e..2da7b021d622 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_platform.c
@@ -386,7 +386,6 @@ stmmac_probe_config_dt(struct platform_device *pdev, const char **mac)
 
 	*mac = of_get_mac_address(np);
 	plat->interface = of_get_phy_mode(np);
-
 	/* Get max speed of operation from device tree */
 	if (of_property_read_u32(np, "max-speed", &plat->max_speed))
 		plat->max_speed = -1;
@@ -609,7 +608,6 @@ int stmmac_get_platform_resources(struct platform_device *pdev,
 	struct resource *res;
 
 	memset(stmmac_res, 0, sizeof(*stmmac_res));
-
 	/* Get IRQ information early to have an ability to ask for deferred
 	 * probe if needed before we went too far with resource allocation.
 	 */
diff --git a/include/linux/stmmac.h b/include/linux/stmmac.h
index b9da1a64f0e0..baca96d83293 100644
--- a/include/linux/stmmac.h
+++ b/include/linux/stmmac.h
@@ -23,6 +23,16 @@
 #define STMMAC_RX_COE_TYPE1	1
 #define STMMAC_RX_COE_TYPE2	2
 
+/* Multi interrupt MSI vector */
+#define STMMAC_MAX_MSI_VECS	32
+#define MSI_RX_OFFSET_VEC	0
+#define MSI_TX_OFFSET_VEC	1
+#define MSI_SAFETY_UE_VEC	26
+#define MSI_SAFETY_CE_VEC	27
+#define MSI_LPI_VEC		28
+#define MSI_MAC_VEC		29
+#define MSI_PCS_VEC		30
+
 /* Define the macros for CSR clock range parameters to be passed by
  * platform code.
  * This could also be configured at run time using CPU freq framework. */
@@ -193,5 +203,16 @@ struct plat_stmmacenet_data {
 	unsigned int ctov;
 	unsigned int tils;
 	bool has_safety_feat;
+	int dma_tx_totalirq;
+	int dma_rx_totalirq;
+	int dma_tx_os;
+	int dma_rx_os;
+	int mac_irq_os;
+	int sfty_ue_irq_os;
+	int sfty_ce_irq_os;
+	int lpi_irq_os;
+	int xpcs_irq_os;
+	int wol_irq_os;
+	bool multi_msi_en;
 };
 #endif
-- 
2.17.1

