From a782f2661cd151166d6c00dcc2c9298cf45e834b Mon Sep 17 00:00:00 2001
From: Faycal Benmlih <faycal.benmlih@intel.com>
Date: Thu, 2 Jan 2020 15:06:40 -0600
Subject: [PATCH 29/30] platform/x86: Update SoCWatch driver for 5.5 pull

Update to SoCWatch driver version 2.11 which has a fix
to the CTA driver interface for the 5.5 pull

Signed-off-by: Faycal Benmlih <faycal.benmlih@intel.com>
---
 .../platform/x86/socwatch/inc/sw_collector.h  |  268 +--
 .../platform/x86/socwatch/inc/sw_file_ops.h   |  138 +-
 .../x86/socwatch/inc/sw_kernel_defines.h      |  328 ++--
 drivers/platform/x86/socwatch/inc/sw_mem.h    |  162 +-
 .../x86/socwatch/inc/sw_ops_provider.h        |  122 +-
 .../x86/socwatch/inc/sw_output_buffer.h       |  284 +--
 .../socwatch/inc/sw_overhead_measurements.h   |  368 ++--
 .../socwatch/inc/sw_trace_notifier_provider.h |  162 +-
 .../x86/socwatch/inc/sw_tracepoint_handlers.h |  310 +--
 drivers/platform/x86/socwatch/inc/sw_types.h  |  302 +--
 drivers/platform/x86/socwatch/sw_collector.c  | 1368 ++++++-------
 drivers/platform/x86/socwatch/sw_cta.c        |  649 +++---
 drivers/platform/x86/socwatch/sw_file_ops.c   |  674 +++----
 drivers/platform/x86/socwatch/sw_mem.c        |  644 +++---
 .../platform/x86/socwatch/sw_output_buffer.c  | 1676 ++++++++--------
 drivers/platform/x86/socwatch/sw_reader.c     |  318 +--
 drivers/platform/x86/socwatch/sw_telem.c      | 1746 ++++++++---------
 .../x86/socwatch/sw_tracepoint_handlers.c     |  812 ++++----
 18 files changed, 5166 insertions(+), 5165 deletions(-)

diff --git a/drivers/platform/x86/socwatch/inc/sw_collector.h b/drivers/platform/x86/socwatch/inc/sw_collector.h
index ab042abfe73a..69a7a4833b1d 100644
--- a/drivers/platform/x86/socwatch/inc/sw_collector.h
+++ b/drivers/platform/x86/socwatch/inc/sw_collector.h
@@ -1,134 +1,134 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef __SW_COLLECTOR_H__
-
-#include "sw_internal.h"
-
-/*
- * Forward declaration
- */
-struct sw_hw_ops;
-
-/* TODO: convert from 'list_head' to 'hlist_head' */
-/**
- * struct - sw_collector_data
- * Information about the collector to be invoked at collection time.
- *
- * The collector_lists array holds linked lists of collectors to
- * be exercised at specific points in time during the collection
- * (e.g. begin, poll, end, etc.).  At a trigger time, the driver walks
- * that time's list of nodes, and exercises the collectors on that list.
- *
- * @list:                   List/link implementation
- * @cpumask:                Collect if cpu matches mask
- * @info:                   Ptr to metric info
- * @ops:                    Ptr to collector's operations
- * @last_update_jiffies:    Indicates when this node was last exercised.
- * @per_msg_payload_size:   Data size
- * @msg:                    Ptr to collected data
- */
-struct sw_collector_data {
-	SW_LIST_ENTRY(list, sw_collector_data);
-	struct cpumask                  cpumask;
-	struct sw_driver_interface_info *info;
-	const struct sw_hw_ops          **ops;
-	size_t                          per_msg_payload_size;
-	u64                             last_update_jiffies;
-	struct sw_driver_msg *msg;
-};
-
-#define GET_MSG_SLOT_FOR_CPU(msgs, cpu, size) ((struct sw_driver_msg *) & \
-	(((char *)(msgs))[(cpu) * (sizeof(struct sw_driver_msg) + (size))]))
-
-struct sw_collector_data *sw_alloc_collector_node(void);
-void sw_free_collector_node(struct sw_collector_data *node);
-int sw_handle_collector_node(struct sw_collector_data *data);
-int sw_handle_collector_node_on_cpu(struct sw_collector_data *data, int cpu);
-int sw_write_collector_node(struct sw_collector_data *data);
-
-void sw_init_collector_list(void *list_head);
-void sw_destroy_collector_list(void *list_head);
-int sw_handle_collector_list(void *list_head,
-	int (*func)(struct sw_collector_data *data));
-int sw_handle_collector_list_on_cpu(void *list_head,
-	int (*func)(struct sw_collector_data *data, int cpu),
-	int cpu);
-
-int sw_handle_driver_io_descriptor(char *dst_vals,
-	int cpu,
-	const struct sw_driver_io_descriptor *descriptor,
-	const struct sw_hw_ops *hw_ops);
-int sw_init_driver_io_descriptor(struct sw_driver_io_descriptor *descriptor);
-int sw_reset_driver_io_descriptor(struct sw_driver_io_descriptor *descriptor);
-
-int sw_add_driver_info(void *list_head,
-	const struct sw_driver_interface_info *info);
-
-void sw_handle_per_cpu_msg(void *info);
-void sw_handle_per_cpu_msg_no_sched(void *info);
-void sw_handle_per_cpu_msg_on_cpu(int cpu, void *info);
-
-void sw_set_collector_ops(const struct sw_hw_ops *hw_ops);
-
-/**
- * Process all messages for the given time.
- * @param[in]   when    The time period e.g. 'BEGIN' or 'END'
- *
- * @returns     0   on success, non-zero on error
- */
-extern int sw_process_snapshot(enum sw_when_type when);
-extern int sw_process_snapshot_on_cpu(enum sw_when_type when, int cpu);
-#endif /* __SW_COLLECTOR_H__ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __SW_COLLECTOR_H__
+
+#include "sw_internal.h"
+
+/*
+ * Forward declaration
+ */
+struct sw_hw_ops;
+
+/* TODO: convert from 'list_head' to 'hlist_head' */
+/**
+ * struct - sw_collector_data
+ * Information about the collector to be invoked at collection time.
+ *
+ * The collector_lists array holds linked lists of collectors to
+ * be exercised at specific points in time during the collection
+ * (e.g. begin, poll, end, etc.).  At a trigger time, the driver walks
+ * that time's list of nodes, and exercises the collectors on that list.
+ *
+ * @list:                   List/link implementation
+ * @cpumask:                Collect if cpu matches mask
+ * @info:                   Ptr to metric info
+ * @ops:                    Ptr to collector's operations
+ * @last_update_jiffies:    Indicates when this node was last exercised.
+ * @per_msg_payload_size:   Data size
+ * @msg:                    Ptr to collected data
+ */
+struct sw_collector_data {
+	SW_LIST_ENTRY(list, sw_collector_data);
+	struct cpumask                  cpumask;
+	struct sw_driver_interface_info *info;
+	const struct sw_hw_ops          **ops;
+	size_t                          per_msg_payload_size;
+	u64                             last_update_jiffies;
+	struct sw_driver_msg *msg;
+};
+
+#define GET_MSG_SLOT_FOR_CPU(msgs, cpu, size) ((struct sw_driver_msg *) & \
+	(((char *)(msgs))[(cpu) * (sizeof(struct sw_driver_msg) + (size))]))
+
+struct sw_collector_data *sw_alloc_collector_node(void);
+void sw_free_collector_node(struct sw_collector_data *node);
+int sw_handle_collector_node(struct sw_collector_data *data);
+int sw_handle_collector_node_on_cpu(struct sw_collector_data *data, int cpu);
+int sw_write_collector_node(struct sw_collector_data *data);
+
+void sw_init_collector_list(void *list_head);
+void sw_destroy_collector_list(void *list_head);
+int sw_handle_collector_list(void *list_head,
+	int (*func)(struct sw_collector_data *data));
+int sw_handle_collector_list_on_cpu(void *list_head,
+	int (*func)(struct sw_collector_data *data, int cpu),
+	int cpu);
+
+int sw_handle_driver_io_descriptor(char *dst_vals,
+	int cpu,
+	const struct sw_driver_io_descriptor *descriptor,
+	const struct sw_hw_ops *hw_ops);
+int sw_init_driver_io_descriptor(struct sw_driver_io_descriptor *descriptor);
+int sw_reset_driver_io_descriptor(struct sw_driver_io_descriptor *descriptor);
+
+int sw_add_driver_info(void *list_head,
+	const struct sw_driver_interface_info *info);
+
+void sw_handle_per_cpu_msg(void *info);
+void sw_handle_per_cpu_msg_no_sched(void *info);
+void sw_handle_per_cpu_msg_on_cpu(int cpu, void *info);
+
+void sw_set_collector_ops(const struct sw_hw_ops *hw_ops);
+
+/**
+ * Process all messages for the given time.
+ * @param[in]   when    The time period e.g. 'BEGIN' or 'END'
+ *
+ * @returns     0   on success, non-zero on error
+ */
+extern int sw_process_snapshot(enum sw_when_type when);
+extern int sw_process_snapshot_on_cpu(enum sw_when_type when, int cpu);
+#endif /* __SW_COLLECTOR_H__ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_file_ops.h b/drivers/platform/x86/socwatch/inc/sw_file_ops.h
index a6ed219c1df0..bba7e5ddbb87 100644
--- a/drivers/platform/x86/socwatch/inc/sw_file_ops.h
+++ b/drivers/platform/x86/socwatch/inc/sw_file_ops.h
@@ -1,69 +1,69 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#ifndef __SW_FILE_OPS_H__
-#define __SW_FILE_OPS_H__
-
-enum sw_driver_collection_cmd;
-struct sw_file_ops {
-	long (*ioctl_handler)(unsigned int ioctl_num, void *local_args);
-	int (*stop_handler)(void);
-	enum sw_driver_collection_cmd (*get_current_cmd)(void);
-	bool (*should_flush)(void);
-};
-
-int sw_register_dev(struct sw_file_ops *ops);
-void sw_unregister_dev(void);
-
-#endif /* __SW_FILE_OPS_H__ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __SW_FILE_OPS_H__
+#define __SW_FILE_OPS_H__
+
+enum sw_driver_collection_cmd;
+struct sw_file_ops {
+	long (*ioctl_handler)(unsigned int ioctl_num, void *local_args);
+	int (*stop_handler)(void);
+	enum sw_driver_collection_cmd (*get_current_cmd)(void);
+	bool (*should_flush)(void);
+};
+
+int sw_register_dev(struct sw_file_ops *ops);
+void sw_unregister_dev(void);
+
+#endif /* __SW_FILE_OPS_H__ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_kernel_defines.h b/drivers/platform/x86/socwatch/inc/sw_kernel_defines.h
index dd004a1f45a4..eaa730491a6e 100644
--- a/drivers/platform/x86/socwatch/inc/sw_kernel_defines.h
+++ b/drivers/platform/x86/socwatch/inc/sw_kernel_defines.h
@@ -1,164 +1,164 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _SW_KERNEL_DEFINES_H_
-#define _SW_KERNEL_DEFINES_H_ 1
-
-#include "sw_defines.h"
-
-#if defined(__APPLE__)
-	#define likely(x)   (x)
-	#define unlikely(x) (x)
-#endif /* __APPLE__ */
-
-#if !defined(__APPLE__)
-	#define CPU() (raw_smp_processor_id())
-	#define RAW_CPU() (raw_smp_processor_id())
-#else
-	#define CPU() (cpu_number())
-	#define RAW_CPU() (cpu_number())
-#endif /* __APPLE__ */
-
-#define TID() (current->pid)
-#define PID() (current->tgid)
-#define NAME() (current->comm)
-#define PKG(c) (cpu_data(c).phys_proc_id)
-#define IT_REAL_INCR() (current->signal->it_real_incr.tv64)
-
-#define ATOMIC_CAS(ptr, old_val, new_val)							  \
-	(cmpxchg((ptr), (old_val), (new_val)) == (old_val))
-
-/*
- * Should we measure overheads?
- * '1' ==> YES
- * '0' ==> NO
- */
-#define DO_OVERHEAD_MEASUREMENTS 0
-/*
- * Should we track memory usage?
- * '1' ==> YES
- * '0' ==> NO
- */
-#define DO_TRACK_MEMORY_USAGE 0
-/*
- * Are we compiling with driver profiling support
- * turned ON? If YES then force 'DO_OVERHEAD_MEASUREMENTS'
- * and 'DO_TRACK_MEMORY_USAGE' to be TRUE.
- */
-#if DO_DRIVER_PROFILING
-	#if !DO_OVERHEAD_MEASUREMENTS
-		#undef DO_OVERHEAD_MEASUREMENTS
-		#define DO_OVERHEAD_MEASUREMENTS 1
-	#endif /* DO_OVERHEAD_MEASUREMENTS */
-	#if !DO_TRACK_MEMORY_USAGE
-		#undef DO_TRACK_MEMORY_USAGE
-		#define DO_TRACK_MEMORY_USAGE 1
-	#endif /* DO_TRACK_MEMORY_USAGE */
-#endif /* DO_DRIVER_PROFILING */
-/*
- * Should we allow debug output.
- * Set to: "1" ==> 'OUTPUT' is enabled.
- *		 "0" ==> 'OUTPUT' is disabled.
- */
-#define DO_DEBUG_OUTPUT 0
-/*
- * Control whether to output driver ERROR messages.
- * These are independent of the 'OUTPUT' macro
- * (which controls debug messages).
- * Set to '1' ==> Print driver error messages (to '/var/log/messages')
- *		'0' ==> Do NOT print driver error messages
- */
-#define DO_PRINT_DRIVER_ERROR_MESSAGES 1
-/*
- * Macros to control output printing.
- */
-#if !defined(__APPLE__)
-	#if DO_DEBUG_OUTPUT
-		#define pw_pr_debug(...) pr_info(__VA_ARGS__)
-		#define pw_pr_warn(...) pr_warn(__VA_ARGS__)
-	#else
-		#define pw_pr_debug(...)
-		#define pw_pr_warn(...)
-	#endif
-	#define pw_pr_force(...) pr_info(__VA_ARGS__)
-#else
-	#if DO_DEBUG_OUTPUT
-		#define pw_pr_debug(...) IOLog(__VA_ARGS__)
-		#define pw_pr_warn(...) IOLog(__VA_ARGS__)
-	#else
-		#define pw_pr_debug(...)
-		#define pw_pr_warn(...)
-	#endif
-	#define pw_pr_force(...) IOLog(__VA_ARGS__)
-#endif /* __APPLE__ */
-
-/*
- * Macro for driver error messages.
- */
-#if !defined(__APPLE__)
-	#if (DO_PRINT_DRIVER_ERROR_MESSAGES || DO_DEBUG_OUTPUT)
-		#define pw_pr_error(...) pr_err(__VA_ARGS__)
-	#else
-		#define pw_pr_error(...)
-	#endif
-#else
-	#if (DO_PRINT_DRIVER_ERROR_MESSAGES || DO_DEBUG_OUTPUT)
-		#define pw_pr_error(...) IOLog(__VA_ARGS__)
-	#else
-		#define pw_pr_error(...)
-	#endif
-#endif /* __APPLE__ */
-
-#endif /* _SW_KERNEL_DEFINES_H_ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef _SW_KERNEL_DEFINES_H_
+#define _SW_KERNEL_DEFINES_H_ 1
+
+#include "sw_defines.h"
+
+#if defined(__APPLE__)
+	#define likely(x)   (x)
+	#define unlikely(x) (x)
+#endif /* __APPLE__ */
+
+#if !defined(__APPLE__)
+	#define CPU() (raw_smp_processor_id())
+	#define RAW_CPU() (raw_smp_processor_id())
+#else
+	#define CPU() (cpu_number())
+	#define RAW_CPU() (cpu_number())
+#endif /* __APPLE__ */
+
+#define TID() (current->pid)
+#define PID() (current->tgid)
+#define NAME() (current->comm)
+#define PKG(c) (cpu_data(c).phys_proc_id)
+#define IT_REAL_INCR() (current->signal->it_real_incr.tv64)
+
+#define ATOMIC_CAS(ptr, old_val, new_val)							  \
+	(cmpxchg((ptr), (old_val), (new_val)) == (old_val))
+
+/*
+ * Should we measure overheads?
+ * '1' ==> YES
+ * '0' ==> NO
+ */
+#define DO_OVERHEAD_MEASUREMENTS 0
+/*
+ * Should we track memory usage?
+ * '1' ==> YES
+ * '0' ==> NO
+ */
+#define DO_TRACK_MEMORY_USAGE 0
+/*
+ * Are we compiling with driver profiling support
+ * turned ON? If YES then force 'DO_OVERHEAD_MEASUREMENTS'
+ * and 'DO_TRACK_MEMORY_USAGE' to be TRUE.
+ */
+#if DO_DRIVER_PROFILING
+	#if !DO_OVERHEAD_MEASUREMENTS
+		#undef DO_OVERHEAD_MEASUREMENTS
+		#define DO_OVERHEAD_MEASUREMENTS 1
+	#endif /* DO_OVERHEAD_MEASUREMENTS */
+	#if !DO_TRACK_MEMORY_USAGE
+		#undef DO_TRACK_MEMORY_USAGE
+		#define DO_TRACK_MEMORY_USAGE 1
+	#endif /* DO_TRACK_MEMORY_USAGE */
+#endif /* DO_DRIVER_PROFILING */
+/*
+ * Should we allow debug output.
+ * Set to: "1" ==> 'OUTPUT' is enabled.
+ *		 "0" ==> 'OUTPUT' is disabled.
+ */
+#define DO_DEBUG_OUTPUT 0
+/*
+ * Control whether to output driver ERROR messages.
+ * These are independent of the 'OUTPUT' macro
+ * (which controls debug messages).
+ * Set to '1' ==> Print driver error messages (to '/var/log/messages')
+ *		'0' ==> Do NOT print driver error messages
+ */
+#define DO_PRINT_DRIVER_ERROR_MESSAGES 1
+/*
+ * Macros to control output printing.
+ */
+#if !defined(__APPLE__)
+	#if DO_DEBUG_OUTPUT
+		#define pw_pr_debug(...) pr_info(__VA_ARGS__)
+		#define pw_pr_warn(...) pr_warn(__VA_ARGS__)
+	#else
+		#define pw_pr_debug(...)
+		#define pw_pr_warn(...)
+	#endif
+	#define pw_pr_force(...) pr_info(__VA_ARGS__)
+#else
+	#if DO_DEBUG_OUTPUT
+		#define pw_pr_debug(...) IOLog(__VA_ARGS__)
+		#define pw_pr_warn(...) IOLog(__VA_ARGS__)
+	#else
+		#define pw_pr_debug(...)
+		#define pw_pr_warn(...)
+	#endif
+	#define pw_pr_force(...) IOLog(__VA_ARGS__)
+#endif /* __APPLE__ */
+
+/*
+ * Macro for driver error messages.
+ */
+#if !defined(__APPLE__)
+	#if (DO_PRINT_DRIVER_ERROR_MESSAGES || DO_DEBUG_OUTPUT)
+		#define pw_pr_error(...) pr_err(__VA_ARGS__)
+	#else
+		#define pw_pr_error(...)
+	#endif
+#else
+	#if (DO_PRINT_DRIVER_ERROR_MESSAGES || DO_DEBUG_OUTPUT)
+		#define pw_pr_error(...) IOLog(__VA_ARGS__)
+	#else
+		#define pw_pr_error(...)
+	#endif
+#endif /* __APPLE__ */
+
+#endif /* _SW_KERNEL_DEFINES_H_ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_mem.h b/drivers/platform/x86/socwatch/inc/sw_mem.h
index 0944d80947d1..b8797fd1dab1 100644
--- a/drivers/platform/x86/socwatch/inc/sw_mem.h
+++ b/drivers/platform/x86/socwatch/inc/sw_mem.h
@@ -1,81 +1,81 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Description: file containing memory management routines
- * used by the power driver.
- */
-
-#ifndef _SW_MEM_H_
-#define _SW_MEM_H_ 1
-
-#include "sw_types.h"
-
-void *sw_kmalloc(size_t size, unsigned int flags);
-void sw_kfree(const void *obj);
-/*
- * Allocate free pages.
- */
-unsigned long sw_allocate_pages(unsigned int flags,
-	unsigned int alloc_size_in_bytes);
-/*
- * Free up previously allocated pages.
- */
-void sw_release_pages(unsigned long addr, unsigned int alloc_size_in_bytes);
-
-u64 sw_get_total_bytes_alloced(void);
-u64 sw_get_max_bytes_alloced(void);
-u64 sw_get_curr_bytes_alloced(void);
-#endif /* _SW_MEM_H_ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * Description: file containing memory management routines
+ * used by the power driver.
+ */
+
+#ifndef _SW_MEM_H_
+#define _SW_MEM_H_ 1
+
+#include "sw_types.h"
+
+void *sw_kmalloc(size_t size, unsigned int flags);
+void sw_kfree(const void *obj);
+/*
+ * Allocate free pages.
+ */
+unsigned long sw_allocate_pages(unsigned int flags,
+	unsigned int alloc_size_in_bytes);
+/*
+ * Free up previously allocated pages.
+ */
+void sw_release_pages(unsigned long addr, unsigned int alloc_size_in_bytes);
+
+u64 sw_get_total_bytes_alloced(void);
+u64 sw_get_max_bytes_alloced(void);
+u64 sw_get_curr_bytes_alloced(void);
+#endif /* _SW_MEM_H_ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_ops_provider.h b/drivers/platform/x86/socwatch/inc/sw_ops_provider.h
index 30e6937f943f..69b1b70a3fdc 100644
--- a/drivers/platform/x86/socwatch/inc/sw_ops_provider.h
+++ b/drivers/platform/x86/socwatch/inc/sw_ops_provider.h
@@ -1,61 +1,61 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#ifndef __SW_OPS_PROVIDER_H__
-#define __SW_OPS_PROVIDER_H__
-
-int sw_register_ops_providers(void);
-void sw_free_ops_providers(void);
-
-#endif /* __SW_OPS_PROVIDER_H__ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __SW_OPS_PROVIDER_H__
+#define __SW_OPS_PROVIDER_H__
+
+int sw_register_ops_providers(void);
+void sw_free_ops_providers(void);
+
+#endif /* __SW_OPS_PROVIDER_H__ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_output_buffer.h b/drivers/platform/x86/socwatch/inc/sw_output_buffer.h
index e8efba2ff4ba..d7138a7aa866 100644
--- a/drivers/platform/x86/socwatch/inc/sw_output_buffer.h
+++ b/drivers/platform/x86/socwatch/inc/sw_output_buffer.h
@@ -1,142 +1,142 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _SW_OUTPUT_BUFFER_H_
-#define _SW_OUTPUT_BUFFER_H_ 1
-/*
- * Special mask for the case where all buffers have been flushed.
- */
-/* #define sw_ALL_WRITES_DONE_MASK 0xffffffff */
-#define SW_ALL_WRITES_DONE_MASK ((u32)-1)
-/*
- * Special mask for the case where no data is available to be read.
- */
-#define SW_NO_DATA_AVAIL_MASK ((u32)-2)
-
-/*
- * Forward declarations.
- */
-struct sw_driver_msg;
-
-/*
- * Data structures.
- */
-enum sw_wakeup_action {
-	SW_WAKEUP_ACTION_DIRECT,
-	SW_WAKEUP_ACTION_TIMER,
-	SW_WAKEUP_ACTION_NONE,
-};
-
-/*
- * Variable declarations.
- */
-extern u64 sw_num_samples_produced, sw_num_samples_dropped;
-extern unsigned long sw_buffer_alloc_size;
-extern int sw_max_num_cpus;
-extern wait_queue_head_t sw_reader_queue;
-
-/*
- * Public API.
- */
-int sw_init_per_cpu_buffers(void);
-void sw_destroy_per_cpu_buffers(void);
-void sw_reset_per_cpu_buffers(void);
-
-void sw_count_samples_produced_dropped(void);
-
-int sw_produce_generic_msg(struct sw_driver_msg *, enum sw_wakeup_action);
-
-bool sw_any_seg_full(u32 *val, bool is_flush_mode);
-ssize_t sw_consume_data(u32 mask, void __user *buffer, size_t bytes_to_read);
-
-unsigned int sw_get_output_buffer_size(void);
-
-void sw_wait_once(void);
-void sw_wakeup(void);
-
-void sw_print_output_buffer_overheads(void);
-
-/*
- * Init reader queue.
- */
-int sw_init_reader_queue(void);
-/*
- * Destroy reader queue.
- */
-void sw_destroy_reader_queue(void);
-/*
- * Wakeup client waiting for a full buffer.
- */
-void sw_wakeup_reader(enum sw_wakeup_action);
-/*
- * Wakeup client waiting for a full buffer, and
- * cancel any timers initialized by the reader
- * subsys.
- */
-void sw_cancel_reader(void);
-/*
- * Print some stats about the reader subsys.
- */
-void sw_print_reader_stats(void);
-
-/* *************************************************
- * For circular buffer (continuous profiling)
- * *************************************************
- */
-long initialize_circular_buffer(size_t size);
-void reset_circular_buffer(void);
-void destroy_circular_buffer(void);
-
-#endif /* _SW_OUTPUT_BUFFER_H_ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef _SW_OUTPUT_BUFFER_H_
+#define _SW_OUTPUT_BUFFER_H_ 1
+/*
+ * Special mask for the case where all buffers have been flushed.
+ */
+/* #define sw_ALL_WRITES_DONE_MASK 0xffffffff */
+#define SW_ALL_WRITES_DONE_MASK ((u32)-1)
+/*
+ * Special mask for the case where no data is available to be read.
+ */
+#define SW_NO_DATA_AVAIL_MASK ((u32)-2)
+
+/*
+ * Forward declarations.
+ */
+struct sw_driver_msg;
+
+/*
+ * Data structures.
+ */
+enum sw_wakeup_action {
+	SW_WAKEUP_ACTION_DIRECT,
+	SW_WAKEUP_ACTION_TIMER,
+	SW_WAKEUP_ACTION_NONE,
+};
+
+/*
+ * Variable declarations.
+ */
+extern u64 sw_num_samples_produced, sw_num_samples_dropped;
+extern unsigned long sw_buffer_alloc_size;
+extern int sw_max_num_cpus;
+extern wait_queue_head_t sw_reader_queue;
+
+/*
+ * Public API.
+ */
+int sw_init_per_cpu_buffers(void);
+void sw_destroy_per_cpu_buffers(void);
+void sw_reset_per_cpu_buffers(void);
+
+void sw_count_samples_produced_dropped(void);
+
+int sw_produce_generic_msg(struct sw_driver_msg *, enum sw_wakeup_action);
+
+bool sw_any_seg_full(u32 *val, bool is_flush_mode);
+ssize_t sw_consume_data(u32 mask, void __user *buffer, size_t bytes_to_read);
+
+unsigned int sw_get_output_buffer_size(void);
+
+void sw_wait_once(void);
+void sw_wakeup(void);
+
+void sw_print_output_buffer_overheads(void);
+
+/*
+ * Init reader queue.
+ */
+int sw_init_reader_queue(void);
+/*
+ * Destroy reader queue.
+ */
+void sw_destroy_reader_queue(void);
+/*
+ * Wakeup client waiting for a full buffer.
+ */
+void sw_wakeup_reader(enum sw_wakeup_action);
+/*
+ * Wakeup client waiting for a full buffer, and
+ * cancel any timers initialized by the reader
+ * subsys.
+ */
+void sw_cancel_reader(void);
+/*
+ * Print some stats about the reader subsys.
+ */
+void sw_print_reader_stats(void);
+
+/* *************************************************
+ * For circular buffer (continuous profiling)
+ * *************************************************
+ */
+long initialize_circular_buffer(size_t size);
+void reset_circular_buffer(void);
+void destroy_circular_buffer(void);
+
+#endif /* _SW_OUTPUT_BUFFER_H_ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_overhead_measurements.h b/drivers/platform/x86/socwatch/inc/sw_overhead_measurements.h
index 25148def4dc7..b665f5438a3f 100644
--- a/drivers/platform/x86/socwatch/inc/sw_overhead_measurements.h
+++ b/drivers/platform/x86/socwatch/inc/sw_overhead_measurements.h
@@ -1,184 +1,184 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-/*
- * Description: file containing overhead measurement
- * routines used by the power driver.
- */
-
-#ifndef _PW_OVERHEAD_MEASUREMENTS_H_
-#define _PW_OVERHEAD_MEASUREMENTS_H_
-
-/*
- * Helper macro to declare variables required
- * for conducting overhead measurements.
- */
-/*
- * For each function that you want to profile,
- * do the following (e.g. function 'foo'):
- * **************************************************
- * DECLARE_OVERHEAD_VARS(foo);
- * **************************************************
- * This will declare the two variables required
- * to keep track of overheads incurred in
- * calling/servicing 'foo'. Note that the name
- * that you declare here *MUST* match the function name!
- */
-
-#if DO_OVERHEAD_MEASUREMENTS
-
-#ifndef __get_cpu_var
-	/*
-	 * Kernels >= 3.19 don't include a definition
-	 * of '__get_cpu_var'. Create one now.
-	 */
-	#define __get_cpu_var(var) (*this_cpu_ptr(&var))
-#endif /* __get_cpu_var */
-#ifndef __raw_get_cpu_var
-	/*
-	 * Kernels >= 3.19 don't include a definition
-	 * of '__raw_get_cpu_var'. Create one now.
-	 */
-	#define __raw_get_cpu_var(var) (*raw_cpu_ptr(&var))
-#endif /* __get_cpu_var */
-
-extern u64 sw_timestamp(void);
-
-#define DECLARE_OVERHEAD_VARS(name)					\
-	static DEFINE_PER_CPU(u64, name##_elapsed_time);		\
-	static DEFINE_PER_CPU(local_t, name##_num_iters) =		\
-							 LOCAL_INIT(0);	\
-	static inline u64 get_my_cumulative_elapsed_time_##name(void)	\
-	{								\
-		return *(&__get_cpu_var(name##_elapsed_time));		\
-	}								\
-	static inline int get_my_cumulative_num_iters_##name(void)	\
-	{								\
-		return local_read(&__get_cpu_var(name##_num_iters));	\
-	}								\
-	static inline u64 name##_get_cumulative_elapsed_time_for(	\
-							int cpu)	\
-	{								\
-		return *(&per_cpu(name##_elapsed_time, cpu));		\
-	}								\
-	static inline int name##_get_cumulative_num_iters_for(int cpu)	\
-	{								\
-		return local_read(&per_cpu(name##_num_iters, cpu));	\
-	}								\
-	static inline void name##_get_cumulative_overhead_params(	\
-							u64 *time,	\
-							int *iters)	\
-	{								\
-		int cpu = 0;						\
-		*time = 0; *iters = 0;					\
-		for_each_online_cpu(cpu) {				\
-			*iters += name##_get_cumulative_num_iters_for(	\
-								cpu);	\
-			*time += name##_get_cumulative_elapsed_time_for(\
-								cpu);	\
-		}							\
-		return;							\
-	}								\
-	static inline void name##_print_cumulative_overhead_params(	\
-							const char *str)\
-	{								\
-		int num = 0;						\
-		u64 time = 0;						\
-		name##_get_cumulative_overhead_params(&time, &num);	\
-		pw_pr_error("%s: %d iters took %llu nano seconds!\n",	\
-			str, num, time);				\
-	}
-
-#define DO_PER_CPU_OVERHEAD_FUNC(func, ...) do {			\
-	u64 *__v = &__raw_get_cpu_var(func##_elapsed_time);		\
-	u64 tmp_1 = 0, tmp_2 = 0;					\
-	local_inc(&__raw_get_cpu_var(func##_num_iters));		\
-	tmp_1 = sw_timestamp();						\
-	{								\
-		func(__VA_ARGS__);						\
-	}								\
-	tmp_2 = sw_timestamp();						\
-	*(__v) += (tmp_2 - tmp_1);					\
-} while (0)
-
-#define DO_PER_CPU_OVERHEAD_FUNC_RET(type, func, ...) ({		\
-	type __ret;							\
-	u64 *__v = &__raw_get_cpu_var(func##_elapsed_time);		\
-	u64 tmp_1 = 0, tmp_2 = 0;					\
-	local_inc(&__raw_get_cpu_var(func##_num_iters));		\
-	tmp_1 = sw_timestamp();						\
-	{								\
-		__ret = func(__VA_ARGS__);					\
-	}								\
-	tmp_2 = sw_timestamp();						\
-	*(__v) += (tmp_2 - tmp_1);					\
-	__ret;								\
-})
-
-#else /* !DO_OVERHEAD_MEASUREMENTS */
-#define DECLARE_OVERHEAD_VARS(name)					\
-	static inline void name##_print_cumulative_overhead_params(	\
-							const char *str)\
-		{ /* NOP */ }
-
-#define DO_PER_CPU_OVERHEAD_FUNC(func, ...) func(__VA_ARGS__)
-#define DO_PER_CPU_OVERHEAD_FUNC_RET(type, func, ...) func(__VA_ARGS__)
-
-#endif /* DO_OVERHEAD_MEASUREMENTS */
-
-#define PRINT_CUMULATIVE_OVERHEAD_PARAMS(name, str)			\
-	name##_print_cumulative_overhead_params(str)
-
-#endif /* _PW_OVERHEAD_MEASUREMENTS_H_ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+/*
+ * Description: file containing overhead measurement
+ * routines used by the power driver.
+ */
+
+#ifndef _PW_OVERHEAD_MEASUREMENTS_H_
+#define _PW_OVERHEAD_MEASUREMENTS_H_
+
+/*
+ * Helper macro to declare variables required
+ * for conducting overhead measurements.
+ */
+/*
+ * For each function that you want to profile,
+ * do the following (e.g. function 'foo'):
+ * **************************************************
+ * DECLARE_OVERHEAD_VARS(foo);
+ * **************************************************
+ * This will declare the two variables required
+ * to keep track of overheads incurred in
+ * calling/servicing 'foo'. Note that the name
+ * that you declare here *MUST* match the function name!
+ */
+
+#if DO_OVERHEAD_MEASUREMENTS
+
+#ifndef __get_cpu_var
+	/*
+	 * Kernels >= 3.19 don't include a definition
+	 * of '__get_cpu_var'. Create one now.
+	 */
+	#define __get_cpu_var(var) (*this_cpu_ptr(&var))
+#endif /* __get_cpu_var */
+#ifndef __raw_get_cpu_var
+	/*
+	 * Kernels >= 3.19 don't include a definition
+	 * of '__raw_get_cpu_var'. Create one now.
+	 */
+	#define __raw_get_cpu_var(var) (*raw_cpu_ptr(&var))
+#endif /* __get_cpu_var */
+
+extern u64 sw_timestamp(void);
+
+#define DECLARE_OVERHEAD_VARS(name)					\
+	static DEFINE_PER_CPU(u64, name##_elapsed_time);		\
+	static DEFINE_PER_CPU(local_t, name##_num_iters) =		\
+							 LOCAL_INIT(0);	\
+	static inline u64 get_my_cumulative_elapsed_time_##name(void)	\
+	{								\
+		return *(&__get_cpu_var(name##_elapsed_time));		\
+	}								\
+	static inline int get_my_cumulative_num_iters_##name(void)	\
+	{								\
+		return local_read(&__get_cpu_var(name##_num_iters));	\
+	}								\
+	static inline u64 name##_get_cumulative_elapsed_time_for(	\
+							int cpu)	\
+	{								\
+		return *(&per_cpu(name##_elapsed_time, cpu));		\
+	}								\
+	static inline int name##_get_cumulative_num_iters_for(int cpu)	\
+	{								\
+		return local_read(&per_cpu(name##_num_iters, cpu));	\
+	}								\
+	static inline void name##_get_cumulative_overhead_params(	\
+							u64 *time,	\
+							int *iters)	\
+	{								\
+		int cpu = 0;						\
+		*time = 0; *iters = 0;					\
+		for_each_online_cpu(cpu) {				\
+			*iters += name##_get_cumulative_num_iters_for(	\
+								cpu);	\
+			*time += name##_get_cumulative_elapsed_time_for(\
+								cpu);	\
+		}							\
+		return;							\
+	}								\
+	static inline void name##_print_cumulative_overhead_params(	\
+							const char *str)\
+	{								\
+		int num = 0;						\
+		u64 time = 0;						\
+		name##_get_cumulative_overhead_params(&time, &num);	\
+		pw_pr_error("%s: %d iters took %llu nano seconds!\n",	\
+			str, num, time);				\
+	}
+
+#define DO_PER_CPU_OVERHEAD_FUNC(func, ...) do {			\
+	u64 *__v = &__raw_get_cpu_var(func##_elapsed_time);		\
+	u64 tmp_1 = 0, tmp_2 = 0;					\
+	local_inc(&__raw_get_cpu_var(func##_num_iters));		\
+	tmp_1 = sw_timestamp();						\
+	{								\
+		func(__VA_ARGS__);						\
+	}								\
+	tmp_2 = sw_timestamp();						\
+	*(__v) += (tmp_2 - tmp_1);					\
+} while (0)
+
+#define DO_PER_CPU_OVERHEAD_FUNC_RET(type, func, ...) ({		\
+	type __ret;							\
+	u64 *__v = &__raw_get_cpu_var(func##_elapsed_time);		\
+	u64 tmp_1 = 0, tmp_2 = 0;					\
+	local_inc(&__raw_get_cpu_var(func##_num_iters));		\
+	tmp_1 = sw_timestamp();						\
+	{								\
+		__ret = func(__VA_ARGS__);					\
+	}								\
+	tmp_2 = sw_timestamp();						\
+	*(__v) += (tmp_2 - tmp_1);					\
+	__ret;								\
+})
+
+#else /* !DO_OVERHEAD_MEASUREMENTS */
+#define DECLARE_OVERHEAD_VARS(name)					\
+	static inline void name##_print_cumulative_overhead_params(	\
+							const char *str)\
+		{ /* NOP */ }
+
+#define DO_PER_CPU_OVERHEAD_FUNC(func, ...) func(__VA_ARGS__)
+#define DO_PER_CPU_OVERHEAD_FUNC_RET(type, func, ...) func(__VA_ARGS__)
+
+#endif /* DO_OVERHEAD_MEASUREMENTS */
+
+#define PRINT_CUMULATIVE_OVERHEAD_PARAMS(name, str)			\
+	name##_print_cumulative_overhead_params(str)
+
+#endif /* _PW_OVERHEAD_MEASUREMENTS_H_ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_trace_notifier_provider.h b/drivers/platform/x86/socwatch/inc/sw_trace_notifier_provider.h
index 61e10efca418..470f962858a8 100644
--- a/drivers/platform/x86/socwatch/inc/sw_trace_notifier_provider.h
+++ b/drivers/platform/x86/socwatch/inc/sw_trace_notifier_provider.h
@@ -1,81 +1,81 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#ifndef __SW_TRACE_NOTIFIER_PROVIDER_H__
-#define __SW_TRACE_NOTIFIER_PROVIDER_H__
-
-u64 sw_timestamp(void);
-/*
- * Some architectures and OS versions require a "discovery"
- * phase for tracepoints and/or notifiers. Allow for that here.
- */
-int sw_extract_trace_notifier_providers(void);
-/*
- * Reset trace/notifier providers at the end
- * of a collection.
- */
-void sw_reset_trace_notifier_providers(void);
-/*
- * Print statistics on trace/notifier provider overheads.
- */
-void sw_print_trace_notifier_provider_overheads(void);
-/*
- * Add all trace/notifier providers.
- */
-int sw_add_trace_notifier_providers(void);
-/*
- * Remove previously added providers.
- */
-void sw_remove_trace_notifier_providers(void);
-#endif /* __SW_TRACE_NOTIFIER_PROVIDER_H__ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#ifndef __SW_TRACE_NOTIFIER_PROVIDER_H__
+#define __SW_TRACE_NOTIFIER_PROVIDER_H__
+
+u64 sw_timestamp(void);
+/*
+ * Some architectures and OS versions require a "discovery"
+ * phase for tracepoints and/or notifiers. Allow for that here.
+ */
+int sw_extract_trace_notifier_providers(void);
+/*
+ * Reset trace/notifier providers at the end
+ * of a collection.
+ */
+void sw_reset_trace_notifier_providers(void);
+/*
+ * Print statistics on trace/notifier provider overheads.
+ */
+void sw_print_trace_notifier_provider_overheads(void);
+/*
+ * Add all trace/notifier providers.
+ */
+int sw_add_trace_notifier_providers(void);
+/*
+ * Remove previously added providers.
+ */
+void sw_remove_trace_notifier_providers(void);
+#endif /* __SW_TRACE_NOTIFIER_PROVIDER_H__ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_tracepoint_handlers.h b/drivers/platform/x86/socwatch/inc/sw_tracepoint_handlers.h
index 45caa550804b..70e5b83a72ca 100644
--- a/drivers/platform/x86/socwatch/inc/sw_tracepoint_handlers.h
+++ b/drivers/platform/x86/socwatch/inc/sw_tracepoint_handlers.h
@@ -1,155 +1,155 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef __SW_TRACEPOINT_HANDLERS_H__
-#define __SW_TRACEPOINT_HANDLERS_H__
-
-#include "sw_internal.h"
-
-extern pw_u16_t sw_min_polling_interval_msecs;
-
-enum sw_trace_data_type {
-	SW_TRACE_COLLECTOR_TRACEPOINT,
-	SW_TRACE_COLLECTOR_NOTIFIER
-};
-
-struct sw_trace_notifier_name {
-	const char *kernel_name;   /* The tracepoint name; used by the kernel
-				    * to identify tracepoints
-				    */
-	const char *abstract_name; /* An abstract name used by plugins
-				    * tospecify tracepoints-of-interest;
-				    * shared with Ring-3
-				    */
-};
-
-typedef struct sw_trace_notifier_data sw_trace_notifier_data_t;
-
-typedef int (*sw_trace_notifier_register_func)(
-			struct sw_trace_notifier_data *node);
-typedef int (*sw_trace_notifier_unregister_func)(
-			struct sw_trace_notifier_data *node);
-
-struct sw_trace_notifier_data {
-	/* Tracepoint or Notifier */
-	enum sw_trace_data_type type;
-	/* Tracepoint name(s) */
-	const struct sw_trace_notifier_name *name;
-	/* probe register function */
-	sw_trace_notifier_register_func probe_register;
-	/* probe unregister function */
-	sw_trace_notifier_unregister_func probe_unregister;
-	struct tracepoint *tp;
-	bool always_register;	/* Set to TRUE if this tracepoint/notifier must
-				 * ALWAYS be registered, regardless of whether
-				 * the user has specified anything to collect
-				 */
-	bool was_registered;
-	/* List of 'sw_collector_data' instances for this
-	 * tracepoint or notifier
-	 */
-	SW_DEFINE_LIST_HEAD(list, sw_collector_data);
-};
-
-struct sw_topology_node {
-	struct sw_driver_topology_change change;
-
-	SW_LIST_ENTRY(list, sw_topology_node);
-};
-
-/* List of entries tracking changes in CPU topology */
-SW_DECLARE_LIST_HEAD(sw_topology_list, sw_topology_node);
-extern size_t sw_num_topology_entries; /* Size of the 'sw_topology_list' */
-
-int sw_extract_tracepoints(void);
-int sw_register_trace_notifiers(void);
-int sw_unregister_trace_notifiers(void);
-
-/*
- * Register a single TRACE/NOTIFY provider.
- */
-int sw_register_trace_notify_provider(struct sw_trace_notifier_data *tnode);
-/*
- * Add all TRACE/NOTIFY providers.
- */
-int sw_add_trace_notify(void);
-void sw_remove_trace_notify(void);
-
-void sw_reset_trace_notifier_lists(void);
-
-void sw_print_trace_notifier_overheads(void);
-
-int sw_for_each_tracepoint_node(
-	int (*func)(struct sw_trace_notifier_data *node, void *priv),
-	void *priv,
-	bool return_on_error);
-int sw_for_each_notifier_node(
-	int (*func)(struct sw_trace_notifier_data *node, void *priv),
-	void *priv,
-	bool return_on_error);
-
-int sw_get_trace_notifier_id(struct sw_trace_notifier_data *node);
-
-const char *sw_get_trace_notifier_kernel_name(
-	struct sw_trace_notifier_data *node);
-const char *sw_get_trace_notifier_abstract_name(
-	struct sw_trace_notifier_data *node);
-
-/*
- * Clear out the topology list.
- */
-void sw_clear_topology_list(void);
-
-#endif /* __SW_TRACEPOINT_HANDLERS_H__ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef __SW_TRACEPOINT_HANDLERS_H__
+#define __SW_TRACEPOINT_HANDLERS_H__
+
+#include "sw_internal.h"
+
+extern pw_u16_t sw_min_polling_interval_msecs;
+
+enum sw_trace_data_type {
+	SW_TRACE_COLLECTOR_TRACEPOINT,
+	SW_TRACE_COLLECTOR_NOTIFIER
+};
+
+struct sw_trace_notifier_name {
+	const char *kernel_name;   /* The tracepoint name; used by the kernel
+				    * to identify tracepoints
+				    */
+	const char *abstract_name; /* An abstract name used by plugins
+				    * tospecify tracepoints-of-interest;
+				    * shared with Ring-3
+				    */
+};
+
+typedef struct sw_trace_notifier_data sw_trace_notifier_data_t;
+
+typedef int (*sw_trace_notifier_register_func)(
+			struct sw_trace_notifier_data *node);
+typedef int (*sw_trace_notifier_unregister_func)(
+			struct sw_trace_notifier_data *node);
+
+struct sw_trace_notifier_data {
+	/* Tracepoint or Notifier */
+	enum sw_trace_data_type type;
+	/* Tracepoint name(s) */
+	const struct sw_trace_notifier_name *name;
+	/* probe register function */
+	sw_trace_notifier_register_func probe_register;
+	/* probe unregister function */
+	sw_trace_notifier_unregister_func probe_unregister;
+	struct tracepoint *tp;
+	bool always_register;	/* Set to TRUE if this tracepoint/notifier must
+				 * ALWAYS be registered, regardless of whether
+				 * the user has specified anything to collect
+				 */
+	bool was_registered;
+	/* List of 'sw_collector_data' instances for this
+	 * tracepoint or notifier
+	 */
+	SW_DEFINE_LIST_HEAD(list, sw_collector_data);
+};
+
+struct sw_topology_node {
+	struct sw_driver_topology_change change;
+
+	SW_LIST_ENTRY(list, sw_topology_node);
+};
+
+/* List of entries tracking changes in CPU topology */
+SW_DECLARE_LIST_HEAD(sw_topology_list, sw_topology_node);
+extern size_t sw_num_topology_entries; /* Size of the 'sw_topology_list' */
+
+int sw_extract_tracepoints(void);
+int sw_register_trace_notifiers(void);
+int sw_unregister_trace_notifiers(void);
+
+/*
+ * Register a single TRACE/NOTIFY provider.
+ */
+int sw_register_trace_notify_provider(struct sw_trace_notifier_data *tnode);
+/*
+ * Add all TRACE/NOTIFY providers.
+ */
+int sw_add_trace_notify(void);
+void sw_remove_trace_notify(void);
+
+void sw_reset_trace_notifier_lists(void);
+
+void sw_print_trace_notifier_overheads(void);
+
+int sw_for_each_tracepoint_node(
+	int (*func)(struct sw_trace_notifier_data *node, void *priv),
+	void *priv,
+	bool return_on_error);
+int sw_for_each_notifier_node(
+	int (*func)(struct sw_trace_notifier_data *node, void *priv),
+	void *priv,
+	bool return_on_error);
+
+int sw_get_trace_notifier_id(struct sw_trace_notifier_data *node);
+
+const char *sw_get_trace_notifier_kernel_name(
+	struct sw_trace_notifier_data *node);
+const char *sw_get_trace_notifier_abstract_name(
+	struct sw_trace_notifier_data *node);
+
+/*
+ * Clear out the topology list.
+ */
+void sw_clear_topology_list(void);
+
+#endif /* __SW_TRACEPOINT_HANDLERS_H__ */
diff --git a/drivers/platform/x86/socwatch/inc/sw_types.h b/drivers/platform/x86/socwatch/inc/sw_types.h
index b6be5483bd7c..e9af829c31c8 100644
--- a/drivers/platform/x86/socwatch/inc/sw_types.h
+++ b/drivers/platform/x86/socwatch/inc/sw_types.h
@@ -1,151 +1,151 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#ifndef _PW_TYPES_H_
-#define _PW_TYPES_H_
-
-#if defined(__linux__) || defined(__APPLE__) || defined(__QNX__)
-
-#ifndef __KERNEL__
-/*
- * Called from Ring-3.
- */
-#include <stdint.h> /* Grab 'uint64_t' etc. */
-#include <unistd.h> /* Grab 'pid_t' */
-/*
- * UNSIGNED types...
- */
-typedef uint8_t  u8;
-typedef uint16_t u16;
-typedef uint32_t u32;
-typedef uint64_t u64;
-/*
- * SIGNED types...
- */
-typedef int8_t s8;
-typedef int16_t s16;
-typedef int32_t s32;
-typedef int64_t s64;
-
-#else /* __KERNEL__ */
-#if !defined(__APPLE__)
-#include <linux/types.h>
-#else /* __APPLE__ */
-#include <sys/types.h>
-#include <stdint.h> /* Grab 'uint64_t' etc. */
-
-typedef uint8_t  u8;
-typedef uint16_t u16;
-typedef uint32_t u32;
-typedef uint64_t u64;
-/*
-* SIGNED types...
-*/
-typedef int8_t s8;
-typedef int16_t s16;
-typedef int32_t s32;
-typedef int64_t s64;
-#endif /* __APPLE__ */
-#endif /* __KERNEL__ */
-
-#elif defined(_WIN32)
-typedef __int32 int32_t;
-typedef unsigned __int32 uint32_t;
-typedef __int64 int64_t;
-typedef unsigned __int64 uint64_t;
-
-/*
- * UNSIGNED types...
- */
-typedef unsigned char u8;
-typedef unsigned short u16;
-typedef unsigned int u32;
-typedef unsigned long long u64;
-
-/*
- * SIGNED types...
- */
-typedef signed char s8;
-typedef signed short s16;
-typedef signed int s32;
-typedef signed long long s64;
-typedef s32 pid_t;
-typedef s32 ssize_t;
-
-#endif /* _WIN32 */
-
-/* ************************************
- * Common to both operating systems.
- * ************************************
- */
-/*
- * UNSIGNED types...
- */
-typedef u8 pw_u8_t;
-typedef u16 pw_u16_t;
-typedef u32 pw_u32_t;
-typedef u64 pw_u64_t;
-
-/*
- * SIGNED types...
- */
-typedef s8 pw_s8_t;
-typedef s16 pw_s16_t;
-typedef s32 pw_s32_t;
-typedef s64 pw_s64_t;
-
-typedef pid_t pw_pid_t;
-
-#endif /* _PW_TYPES_H_ */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#ifndef _PW_TYPES_H_
+#define _PW_TYPES_H_
+
+#if defined(__linux__) || defined(__APPLE__) || defined(__QNX__)
+
+#ifndef __KERNEL__
+/*
+ * Called from Ring-3.
+ */
+#include <stdint.h> /* Grab 'uint64_t' etc. */
+#include <unistd.h> /* Grab 'pid_t' */
+/*
+ * UNSIGNED types...
+ */
+typedef uint8_t  u8;
+typedef uint16_t u16;
+typedef uint32_t u32;
+typedef uint64_t u64;
+/*
+ * SIGNED types...
+ */
+typedef int8_t s8;
+typedef int16_t s16;
+typedef int32_t s32;
+typedef int64_t s64;
+
+#else /* __KERNEL__ */
+#if !defined(__APPLE__)
+#include <linux/types.h>
+#else /* __APPLE__ */
+#include <sys/types.h>
+#include <stdint.h> /* Grab 'uint64_t' etc. */
+
+typedef uint8_t  u8;
+typedef uint16_t u16;
+typedef uint32_t u32;
+typedef uint64_t u64;
+/*
+* SIGNED types...
+*/
+typedef int8_t s8;
+typedef int16_t s16;
+typedef int32_t s32;
+typedef int64_t s64;
+#endif /* __APPLE__ */
+#endif /* __KERNEL__ */
+
+#elif defined(_WIN32)
+typedef __int32 int32_t;
+typedef unsigned __int32 uint32_t;
+typedef __int64 int64_t;
+typedef unsigned __int64 uint64_t;
+
+/*
+ * UNSIGNED types...
+ */
+typedef unsigned char u8;
+typedef unsigned short u16;
+typedef unsigned int u32;
+typedef unsigned long long u64;
+
+/*
+ * SIGNED types...
+ */
+typedef signed char s8;
+typedef signed short s16;
+typedef signed int s32;
+typedef signed long long s64;
+typedef s32 pid_t;
+typedef s32 ssize_t;
+
+#endif /* _WIN32 */
+
+/* ************************************
+ * Common to both operating systems.
+ * ************************************
+ */
+/*
+ * UNSIGNED types...
+ */
+typedef u8 pw_u8_t;
+typedef u16 pw_u16_t;
+typedef u32 pw_u32_t;
+typedef u64 pw_u64_t;
+
+/*
+ * SIGNED types...
+ */
+typedef s8 pw_s8_t;
+typedef s16 pw_s16_t;
+typedef s32 pw_s32_t;
+typedef s64 pw_s64_t;
+
+typedef pid_t pw_pid_t;
+
+#endif /* _PW_TYPES_H_ */
diff --git a/drivers/platform/x86/socwatch/sw_collector.c b/drivers/platform/x86/socwatch/sw_collector.c
index c1be7b9d8b1e..652d5af6113b 100644
--- a/drivers/platform/x86/socwatch/sw_collector.c
+++ b/drivers/platform/x86/socwatch/sw_collector.c
@@ -1,684 +1,684 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "sw_collector.h"
-#include "sw_hardware_io.h"
-#include "sw_internal.h"
-#include "sw_kernel_defines.h"
-#include "sw_mem.h"
-#include "sw_output_buffer.h"
-#include "sw_structs.h"
-#include "sw_types.h"
-
-/* -------------------------------------------------
- * Variables.
- * -------------------------------------------------
- */
-const static struct sw_hw_ops *s_hw_ops;
-/* -------------------------------------------------
- * Function definitions.
- * -------------------------------------------------
- */
-/*
- * Driver interface info functions.
- */
-
-/**
- * sw_copy_driver_interface_info_i - Allocate and copy the passed-in "info".
- *
- * @info: Information about the metric and collection properties
- *
- * Returns: a pointer to the newly allocated sw_driver_interface_info,
- *          which is a copy of the version passed in via the info pointer.
- */
-struct sw_driver_interface_info *
-sw_copy_driver_interface_info_i(const struct sw_driver_interface_info *info)
-{
-	size_t size;
-	struct sw_driver_interface_info *node = NULL;
-
-	if (!info) {
-		pw_pr_error("ERROR: NULL sw_driver_interface_info in alloc!\n");
-		return node;
-	}
-
-	size = SW_DRIVER_INTERFACE_INFO_HEADER_SIZE() +
-	       (info->num_io_descriptors *
-		sizeof(struct sw_driver_io_descriptor));
-	node = (struct sw_driver_interface_info *)sw_kmalloc(size, GFP_KERNEL);
-	if (!node) {
-		pw_pr_error("ERROR allocating driver interface info!\n");
-		return node;
-	}
-	memcpy((char *)node, (const char *)info, size);
-
-	/*
-	 * Do debug dump.
-	 */
-	pw_pr_debug(
-		"DRIVER info has plugin_ID = %d, metric_ID = %d, msg_ID = %d\n",
-		node->plugin_id, node->metric_id, node->msg_id);
-
-	return node;
-}
-
-int sw_init_driver_interface_info_i(struct sw_driver_interface_info *info)
-{
-	/*
-	 * Do any initialization here.
-	 * For now, only IPC/MMIO descriptors need to be initialized.
-	 */
-	int i = 0;
-	struct sw_driver_io_descriptor *descriptor = NULL;
-
-	if (!info) {
-		pw_pr_error("ERROR: no info!\n");
-		return -PW_ERROR;
-	}
-	for (i = 0,
-	    descriptor = (struct sw_driver_io_descriptor *)info->descriptors;
-	     i < info->num_io_descriptors; ++i, ++descriptor) {
-		if (sw_init_driver_io_descriptor(descriptor))
-			return -PW_ERROR;
-	}
-	return PW_SUCCESS;
-}
-
-int sw_init_ops_i(const struct sw_hw_ops **ops,
-		const struct sw_driver_interface_info *info)
-{
-	int i = 0;
-	struct sw_driver_io_descriptor *descriptor = NULL;
-
-	if (!ops || !info)
-		return -PW_ERROR;
-
-	for (i = 0,
-	descriptor = (struct sw_driver_io_descriptor *)info->descriptors;
-	i < info->num_io_descriptors; ++i, ++descriptor) {
-		ops[i] = sw_get_hw_ops_for(descriptor->collection_type);
-		if (ops[i] == NULL)
-			return -PW_ERROR;
-	}
-	return PW_SUCCESS;
-}
-
-size_t sw_get_payload_size_i(const struct sw_driver_interface_info *info)
-{
-	size_t size = 0;
-	int i = 0;
-
-	if (info) {
-		for (i = 0;
-			i < info->num_io_descriptors;
-			size += ((struct sw_driver_io_descriptor *)
-				info->descriptors)[i].counter_size_in_bytes,
-			++i
-		)
-			;
-	}
-	return size;
-}
-
-sw_driver_msg_t *
-sw_alloc_collector_msg_i(const struct sw_driver_interface_info *info,
-			 size_t per_msg_payload_size)
-{
-	size_t per_msg_size = 0, total_size = 0;
-	sw_driver_msg_t *msg = NULL;
-
-	if (!info)
-		return NULL;
-
-	per_msg_size = sizeof(struct sw_driver_msg) + per_msg_payload_size;
-	total_size = per_msg_size * num_possible_cpus();
-	msg = (sw_driver_msg_t *)sw_kmalloc(total_size, GFP_KERNEL);
-	if (msg) {
-		int cpu = -1;
-
-		memset(msg, 0, total_size);
-		for_each_possible_cpu(cpu) {
-			sw_driver_msg_t *__msg = GET_MSG_SLOT_FOR_CPU(
-				msg, cpu, per_msg_payload_size);
-			char *__payload =
-				(char *)__msg + sizeof(struct sw_driver_msg);
-
-			__msg->cpuidx = (pw_u16_t)cpu;
-			__msg->plugin_id = (pw_u8_t)info->plugin_id;
-			__msg->metric_id = (pw_u8_t)info->metric_id;
-			__msg->msg_id = (pw_u8_t)info->msg_id;
-			__msg->payload_len = per_msg_payload_size;
-			__msg->p_payload = __payload;
-			pw_pr_debug(
-				"[%d]: per_msg_payload_size = %zx, msg = %p, payload = %p\n",
-				cpu, per_msg_payload_size, __msg, __payload);
-		}
-	}
-	return msg;
-}
-
-const struct sw_hw_ops **sw_alloc_ops_i(pw_u16_t num_io_descriptors)
-{
-	size_t size = num_io_descriptors * sizeof(struct sw_hw_ops *);
-	const struct sw_hw_ops **ops = sw_kmalloc(size, GFP_KERNEL);
-
-	if (ops)
-		memset(ops, 0, size);
-
-	return ops;
-}
-
-/**
- * sw_add_driver_info() - Add a collector node to the list called at this
- *                      "when type".
- * @head:   The collector node list to add the new node to.
- * @info:   Driver information to add to the list.
- *
- *  This function allocates and links in a "collector node" for each
- *  collector based on the collector info in the info parameter.
- *  The function allocates the new node, and links it to a local copy
- *  of the passed-in driver interface info.  If the collector has an
- *  init function among its operations, it iterates through the
- *  descriptors in info, passing each one to the init function.
- *
- *  Finally, it allocates and initializes the "collector message" which
- *  buffers a data sample that this collector gathers during the run.
- *
- * Returns:  -PW_ERROR on failure, PW_SUCCESS on success.
- */
-int sw_add_driver_info(void *list_head,
-		       const struct sw_driver_interface_info *info)
-{
-	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
-	struct sw_collector_data *node = sw_alloc_collector_node();
-
-	if (!node) {
-		pw_pr_error("ERROR allocating collector node!\n");
-		return -PW_ERROR;
-	}
-
-	node->info = sw_copy_driver_interface_info_i(info);
-	if (!node->info) {
-		pw_pr_error(
-			"ERROR allocating or copying driver_interface_info!\n");
-		sw_free_collector_node(node);
-		return -PW_ERROR;
-	}
-	/*
-	 * Initialize the collectors in the node's descriptors.
-	 */
-	if (sw_init_driver_interface_info_i(node->info)) {
-		pw_pr_error(
-			"ERROR initializing a driver_interface_info node!\n");
-		sw_free_collector_node(node);
-		return -PW_ERROR;
-	}
-	/*
-	 * Allocate the ops array. We do this one time as an optimization
-	 * (we could always just repeatedly call 'sw_get_hw_ops_for()'
-	 * during the collection but we want to avoid that overhead)
-	 */
-	node->ops = sw_alloc_ops_i(info->num_io_descriptors);
-	if (!node->ops || sw_init_ops_i(node->ops, info)) {
-		pw_pr_error("ERROR initializing the ops array!\n");
-		sw_free_collector_node(node);
-		return -PW_ERROR;
-	}
-	/*
-	 * Allocate and initialize the "collector message".
-	 */
-	node->per_msg_payload_size = sw_get_payload_size_i(info);
-	pw_pr_debug("Debug: Per msg payload size = %u\n",
-		    (unsigned int)node->per_msg_payload_size);
-	node->msg = sw_alloc_collector_msg_i(info, node->per_msg_payload_size);
-	if (!node->msg) {
-		pw_pr_error("ERROR allocating space for a collector msg!\n");
-		sw_free_collector_node(node);
-		return -PW_ERROR;
-	}
-	pw_pr_debug("NODE = %p, NODE->MSG = %p\n", node, node->msg);
-	cpumask_clear(&node->cpumask);
-	{
-		/*
-		 * For now, use following protocol:
-		 * cpu_mask == -2 ==> Collect on ALL CPUs
-		 * cpu_mask == -1 ==> Collect on ANY CPU
-		 * cpu_mask >= 0 ==> Collect on a specific CPU
-		 */
-		if (node->info->cpu_mask >= 0) {
-			/*
-			 * Collect data on 'node->info->cpu_mask'
-			 */
-			cpumask_set_cpu(node->info->cpu_mask, &node->cpumask);
-			pw_pr_debug("OK: set CPU = %d\n", node->info->cpu_mask);
-		} else if (node->info->cpu_mask == -1) {
-			/*
-			 * Collect data on ANY CPU.  Leave empty as a flag to
-			 * signify user wishes to collect data on 'ANY' cpu.
-			 */
-			pw_pr_debug("OK: set ANY CPU\n");
-		} else {
-			/*
-			 * Collect data on ALL cpus.
-			 */
-			cpumask_copy(&node->cpumask, cpu_present_mask);
-			pw_pr_debug("OK: set ALL CPUs\n");
-		}
-	}
-	SW_LIST_ADD(head, node, list);
-	return PW_SUCCESS;
-}
-
-void sw_free_driver_interface_info_i(struct sw_driver_interface_info *info)
-{
-	if (info)
-		sw_kfree(info);
-}
-
-void sw_free_ops_i(const struct sw_hw_ops **ops)
-{
-	if (ops)
-		sw_kfree(ops);
-}
-
-int sw_reset_driver_interface_info_i(struct sw_driver_interface_info *info)
-{
-	/*
-	 * Do any finalization here.
-	 * For now, only IPC/MMIO descriptors need to be finalized.
-	 */
-	int i = 0;
-	struct sw_driver_io_descriptor *descriptor = NULL;
-
-	if (!info) {
-		pw_pr_error("ERROR: no info!\n");
-		return -PW_ERROR;
-	}
-	for (i = 0,
-	    descriptor = (struct sw_driver_io_descriptor *)info->descriptors;
-	     i < info->num_io_descriptors; ++i, ++descriptor) {
-		if (sw_reset_driver_io_descriptor(descriptor))
-			return -PW_ERROR;
-	}
-	return PW_SUCCESS;
-}
-
-/* If this descriptor's collector has an init function, call it passing in */
-/* this descriptor.  That allows the collector to perform any initialization */
-/* or registration specific to this metric. */
-int sw_init_driver_io_descriptor(struct sw_driver_io_descriptor *descriptor)
-{
-	sw_io_desc_init_func_t init_func = NULL;
-	const struct sw_hw_ops *ops =
-		sw_get_hw_ops_for(descriptor->collection_type);
-
-	if (ops == NULL) {
-		pw_pr_error("NULL ops found in init_driver_io_desc: type %d\n",
-			    descriptor->collection_type);
-		return -PW_ERROR;
-	}
-	init_func = ops->init;
-
-	if (init_func) {
-		int retval = (*init_func)(descriptor);
-
-		if (retval)
-			pw_pr_error("(*init) return value for type %d: %d\n",
-				    descriptor->collection_type, retval);
-
-		return retval;
-	}
-	return PW_SUCCESS;
-}
-
-/*
- * If this descriptor's collector has a finalize function, call it passing in
- * this
- * descriptor. This allows the collector to perform any finalization specific to
- * this metric.
- */
-int sw_reset_driver_io_descriptor(struct sw_driver_io_descriptor *descriptor)
-{
-	sw_io_desc_reset_func_t reset_func = NULL;
-	const struct sw_hw_ops *ops =
-		sw_get_hw_ops_for(descriptor->collection_type);
-
-	if (ops == NULL) {
-		pw_pr_error("NULL ops found in reset_driver_io_desc: type %d\n",
-			    descriptor->collection_type);
-		return -PW_ERROR;
-	}
-	pw_pr_debug("calling reset on descriptor of type %d\n",
-		    descriptor->collection_type);
-	reset_func = ops->reset;
-
-	if (reset_func) {
-		int retval = (*reset_func)(descriptor);
-
-		if (retval)
-			pw_pr_error("(*reset) return value for type %d: %d\n",
-				    descriptor->collection_type, retval);
-
-		return retval;
-	}
-	return PW_SUCCESS;
-}
-
-int sw_handle_driver_io_descriptor(
-	char *dst_vals, int cpu,
-	const struct sw_driver_io_descriptor *descriptor,
-	const struct sw_hw_ops *hw_ops)
-{
-	typedef void (*sw_hardware_io_func_t)(
-		char *, int, const struct sw_driver_io_descriptor *, u16);
-	sw_hardware_io_func_t hardware_io_func = NULL;
-
-	if (descriptor->collection_command < SW_IO_CMD_READ ||
-	    descriptor->collection_command > SW_IO_CMD_WRITE) {
-		return -PW_ERROR;
-	}
-	switch (descriptor->collection_command) {
-	case SW_IO_CMD_READ:
-		hardware_io_func = hw_ops->read;
-		break;
-	case SW_IO_CMD_WRITE:
-		hardware_io_func = hw_ops->write;
-		break;
-	default:
-		break;
-	}
-	if (hardware_io_func) {
-		(*hardware_io_func)(dst_vals, cpu, descriptor,
-				    descriptor->counter_size_in_bytes);
-	} else {
-		pw_pr_debug(
-			"NO ops to satisfy %u operation for collection type %u!\n",
-			descriptor->collection_command,
-			descriptor->collection_type);
-	}
-	return PW_SUCCESS;
-}
-
-void sw_free_collector_msg_i(sw_driver_msg_t *msg)
-{
-	if (msg)
-		sw_kfree(msg);
-}
-
-void sw_handle_per_cpu_msg_i(void *info, enum sw_wakeup_action action)
-{
-	/*
-	 * Basic algo:
-	 * For each descriptor in 'node->info->descriptors'; do:
-	 * 1. Perform H/W read; use 'descriptor->collection_type' to
-	 * determine type of read; use 'descriptor->counter_size_in_bytes'
-	 * for read size. Use msg->p_payload[dst_idx] as dst address
-	 * 2. Increment dst idx by 'descriptor->counter_size_in_bytes'
-	 */
-	struct sw_collector_data *node = (struct sw_collector_data *)info;
-	int cpu = RAW_CPU();
-	u16 num_descriptors = node->info->num_io_descriptors, i = 0;
-	struct sw_driver_io_descriptor *descriptors =
-		(struct sw_driver_io_descriptor *)node->info->descriptors;
-	sw_driver_msg_t *msg = GET_MSG_SLOT_FOR_CPU(node->msg, cpu,
-						    node->per_msg_payload_size);
-	char *dst_vals = msg->p_payload;
-	const struct sw_hw_ops **ops = node->ops;
-	bool wasAnyWrite = false;
-
-	/* msg TSC assigned when msg is written to buffer */
-	msg->cpuidx = cpu;
-
-	for (i = 0; i < num_descriptors; ++i,
-	    dst_vals += descriptors->counter_size_in_bytes, ++descriptors) {
-		if (unlikely(ops[i] == NULL)) {
-			pw_pr_debug("NULL OPS!\n");
-			continue;
-		}
-		if (descriptors->collection_command == SW_IO_CMD_WRITE)
-			wasAnyWrite = true;
-
-		if (sw_handle_driver_io_descriptor(dst_vals, cpu, descriptors,
-						   ops[i]))
-			pw_pr_error("ERROR reading descriptor with type %d\n",
-				    descriptors->collection_type);
-	}
-
-	/*
-	 * We produce messages only on READs. Note that SWA prohibits
-	 * messages that contain both READ and WRITE descriptors, so it
-	 * is enough to check if there was ANY WRITE descriptor in this
-	 * message.
-	 */
-	if (likely(wasAnyWrite == false)) {
-		if (sw_produce_generic_msg(msg, action))
-			pw_pr_warn("WARNING: could NOT produce message!\n");
-	}
-}
-
-/*
- * Collector list and node functions.
- */
-struct sw_collector_data *sw_alloc_collector_node(void)
-{
-	struct sw_collector_data *node = (struct sw_collector_data *)sw_kmalloc(
-		sizeof(struct sw_collector_data), GFP_KERNEL);
-
-	if (node) {
-		node->per_msg_payload_size = 0x0;
-		node->last_update_jiffies = 0x0;
-		node->info = NULL;
-		node->ops = NULL;
-		node->msg = NULL;
-		SW_LIST_ENTRY_INIT(node, list);
-	}
-	return node;
-}
-
-void sw_free_collector_node(struct sw_collector_data *node)
-{
-	if (node) {
-		if (node->info) {
-			sw_reset_driver_interface_info_i(node->info);
-			sw_free_driver_interface_info_i(node->info);
-			node->info = NULL;
-		}
-		if (node->ops) {
-			sw_free_ops_i(node->ops);
-			node->ops = NULL;
-		}
-		if (node->msg) {
-			sw_free_collector_msg_i(node->msg);
-			node->msg = NULL;
-		}
-		sw_kfree(node);
-	}
-}
-
-int sw_handle_collector_node(struct sw_collector_data *node)
-{
-	if (!node || !node->info || !node->ops || !node->msg)
-		return -PW_ERROR;
-
-	pw_pr_debug("Calling SMP_CALL_FUNCTION_MANY!\n");
-	sw_schedule_work(&node->cpumask, &sw_handle_per_cpu_msg, node);
-	return PW_SUCCESS;
-}
-
-int sw_handle_collector_node_on_cpu(struct sw_collector_data *node, int cpu)
-{
-	if (!node || !node->info || !node->ops || !node->msg)
-		return -PW_ERROR;
-
-	/*
-	 * Check if this node indicates it should be scheduled
-	 * on the given cpu. If so, clear all other CPUs from the
-	 * mask and schedule the node.
-	 */
-	if (cpumask_test_cpu(cpu, &node->cpumask)) {
-		struct cpumask tmp_mask;
-
-		cpumask_clear(&tmp_mask);
-		cpumask_set_cpu(cpu, &tmp_mask);
-		pw_pr_debug("Calling SMP_CALL_FUNCTION_MANY!\n");
-		sw_schedule_work(&tmp_mask, &sw_handle_per_cpu_msg, node);
-	}
-	return PW_SUCCESS;
-}
-
-void sw_init_collector_list(void *list_head)
-{
-	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
-	SW_LIST_HEAD_INIT(head);
-}
-
-void sw_destroy_collector_list(void *list_head)
-{
-	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
-	while (!SW_LIST_EMPTY(head)) {
-		struct sw_collector_data *curr =
-			SW_LIST_GET_HEAD_ENTRY(head,
-				sw_collector_data,
-				list);
-
-		BUG_ON(!curr->info);
-		SW_LIST_UNLINK(curr, list);
-		sw_free_collector_node(curr);
-	}
-}
-
-/**
- * sw_handle_collector_list - Iterate through the collector list, calling
- *                            func() upon each element.
- * @list_head:  The collector list head.
- * @func:  The function to call for each collector.
- *
- * This function is called when one of the "when types" fires, since the
- * passed-in collector node list is the list of collections to do at that time.
- *
- * Returns: PW_SUCCESS on success, -PW_ERROR on error.
- */
-int sw_handle_collector_list(void *list_head,
-			     int (*func)(struct sw_collector_data *data))
-{
-	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
-	int retVal = PW_SUCCESS;
-	struct sw_collector_data *curr = NULL;
-
-	if (!head || !func)
-		return -PW_ERROR;
-
-	SW_LIST_FOR_EACH_ENTRY(curr, head, list)
-	{
-		pw_pr_debug("HANDLING\n");
-		if ((*func)(curr))
-			retVal = -PW_ERROR;
-
-	}
-	return retVal;
-}
-
-int sw_handle_collector_list_on_cpu(void *list_head,
-				    int (*func)(struct sw_collector_data *data,
-						int cpu),
-				    int cpu)
-{
-	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
-	int retVal = PW_SUCCESS;
-	struct sw_collector_data *curr = NULL;
-
-	if (!head || !func)
-		return -PW_ERROR;
-
-	SW_LIST_FOR_EACH_ENTRY(curr, head, list)
-	{
-		pw_pr_debug("HANDLING\n");
-		if ((*func)(curr, cpu))
-			retVal = -PW_ERROR;
-
-	}
-	return retVal;
-}
-
-void sw_handle_per_cpu_msg(void *info)
-{
-	sw_handle_per_cpu_msg_i(info, SW_WAKEUP_ACTION_DIRECT);
-}
-
-void sw_handle_per_cpu_msg_no_sched(void *info)
-{
-	sw_handle_per_cpu_msg_i(info, SW_WAKEUP_ACTION_TIMER);
-}
-
-void sw_handle_per_cpu_msg_on_cpu(int cpu, void *info)
-{
-	if (unlikely(cpu == RAW_CPU()))
-		sw_handle_per_cpu_msg_no_sched(info);
-	else {
-		pw_pr_debug("[%d] is handling for %d\n", RAW_CPU(), cpu);
-		/*
-		 * No need to disable preemption -- 'smp_call_function_single'
-		 * does that for us.
-		 */
-		smp_call_function_single(
-			cpu, &sw_handle_per_cpu_msg_no_sched, info,
-			false
-			/* false ==> do NOT wait for function completion */);
-	}
-}
-
-void sw_set_collector_ops(const struct sw_hw_ops *hw_ops)
-{
-	s_hw_ops = hw_ops;
-}
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "sw_collector.h"
+#include "sw_hardware_io.h"
+#include "sw_internal.h"
+#include "sw_kernel_defines.h"
+#include "sw_mem.h"
+#include "sw_output_buffer.h"
+#include "sw_structs.h"
+#include "sw_types.h"
+
+/* -------------------------------------------------
+ * Variables.
+ * -------------------------------------------------
+ */
+const static struct sw_hw_ops *s_hw_ops;
+/* -------------------------------------------------
+ * Function definitions.
+ * -------------------------------------------------
+ */
+/*
+ * Driver interface info functions.
+ */
+
+/**
+ * sw_copy_driver_interface_info_i - Allocate and copy the passed-in "info".
+ *
+ * @info: Information about the metric and collection properties
+ *
+ * Returns: a pointer to the newly allocated sw_driver_interface_info,
+ *          which is a copy of the version passed in via the info pointer.
+ */
+struct sw_driver_interface_info *
+sw_copy_driver_interface_info_i(const struct sw_driver_interface_info *info)
+{
+	size_t size;
+	struct sw_driver_interface_info *node = NULL;
+
+	if (!info) {
+		pw_pr_error("ERROR: NULL sw_driver_interface_info in alloc!\n");
+		return node;
+	}
+
+	size = SW_DRIVER_INTERFACE_INFO_HEADER_SIZE() +
+	       (info->num_io_descriptors *
+		sizeof(struct sw_driver_io_descriptor));
+	node = (struct sw_driver_interface_info *)sw_kmalloc(size, GFP_KERNEL);
+	if (!node) {
+		pw_pr_error("ERROR allocating driver interface info!\n");
+		return node;
+	}
+	memcpy((char *)node, (const char *)info, size);
+
+	/*
+	 * Do debug dump.
+	 */
+	pw_pr_debug(
+		"DRIVER info has plugin_ID = %d, metric_ID = %d, msg_ID = %d\n",
+		node->plugin_id, node->metric_id, node->msg_id);
+
+	return node;
+}
+
+int sw_init_driver_interface_info_i(struct sw_driver_interface_info *info)
+{
+	/*
+	 * Do any initialization here.
+	 * For now, only IPC/MMIO descriptors need to be initialized.
+	 */
+	int i = 0;
+	struct sw_driver_io_descriptor *descriptor = NULL;
+
+	if (!info) {
+		pw_pr_error("ERROR: no info!\n");
+		return -PW_ERROR;
+	}
+	for (i = 0,
+	    descriptor = (struct sw_driver_io_descriptor *)info->descriptors;
+	     i < info->num_io_descriptors; ++i, ++descriptor) {
+		if (sw_init_driver_io_descriptor(descriptor))
+			return -PW_ERROR;
+	}
+	return PW_SUCCESS;
+}
+
+int sw_init_ops_i(const struct sw_hw_ops **ops,
+		const struct sw_driver_interface_info *info)
+{
+	int i = 0;
+	struct sw_driver_io_descriptor *descriptor = NULL;
+
+	if (!ops || !info)
+		return -PW_ERROR;
+
+	for (i = 0,
+	descriptor = (struct sw_driver_io_descriptor *)info->descriptors;
+	i < info->num_io_descriptors; ++i, ++descriptor) {
+		ops[i] = sw_get_hw_ops_for(descriptor->collection_type);
+		if (ops[i] == NULL)
+			return -PW_ERROR;
+	}
+	return PW_SUCCESS;
+}
+
+size_t sw_get_payload_size_i(const struct sw_driver_interface_info *info)
+{
+	size_t size = 0;
+	int i = 0;
+
+	if (info) {
+		for (i = 0;
+			i < info->num_io_descriptors;
+			size += ((struct sw_driver_io_descriptor *)
+				info->descriptors)[i].counter_size_in_bytes,
+			++i
+		)
+			;
+	}
+	return size;
+}
+
+sw_driver_msg_t *
+sw_alloc_collector_msg_i(const struct sw_driver_interface_info *info,
+			 size_t per_msg_payload_size)
+{
+	size_t per_msg_size = 0, total_size = 0;
+	sw_driver_msg_t *msg = NULL;
+
+	if (!info)
+		return NULL;
+
+	per_msg_size = sizeof(struct sw_driver_msg) + per_msg_payload_size;
+	total_size = per_msg_size * num_possible_cpus();
+	msg = (sw_driver_msg_t *)sw_kmalloc(total_size, GFP_KERNEL);
+	if (msg) {
+		int cpu = -1;
+
+		memset(msg, 0, total_size);
+		for_each_possible_cpu(cpu) {
+			sw_driver_msg_t *__msg = GET_MSG_SLOT_FOR_CPU(
+				msg, cpu, per_msg_payload_size);
+			char *__payload =
+				(char *)__msg + sizeof(struct sw_driver_msg);
+
+			__msg->cpuidx = (pw_u16_t)cpu;
+			__msg->plugin_id = (pw_u8_t)info->plugin_id;
+			__msg->metric_id = (pw_u8_t)info->metric_id;
+			__msg->msg_id = (pw_u8_t)info->msg_id;
+			__msg->payload_len = per_msg_payload_size;
+			__msg->p_payload = __payload;
+			pw_pr_debug(
+				"[%d]: per_msg_payload_size = %zx, msg = %p, payload = %p\n",
+				cpu, per_msg_payload_size, __msg, __payload);
+		}
+	}
+	return msg;
+}
+
+const struct sw_hw_ops **sw_alloc_ops_i(pw_u16_t num_io_descriptors)
+{
+	size_t size = num_io_descriptors * sizeof(struct sw_hw_ops *);
+	const struct sw_hw_ops **ops = sw_kmalloc(size, GFP_KERNEL);
+
+	if (ops)
+		memset(ops, 0, size);
+
+	return ops;
+}
+
+/**
+ * sw_add_driver_info() - Add a collector node to the list called at this
+ *                      "when type".
+ * @head:   The collector node list to add the new node to.
+ * @info:   Driver information to add to the list.
+ *
+ *  This function allocates and links in a "collector node" for each
+ *  collector based on the collector info in the info parameter.
+ *  The function allocates the new node, and links it to a local copy
+ *  of the passed-in driver interface info.  If the collector has an
+ *  init function among its operations, it iterates through the
+ *  descriptors in info, passing each one to the init function.
+ *
+ *  Finally, it allocates and initializes the "collector message" which
+ *  buffers a data sample that this collector gathers during the run.
+ *
+ * Returns:  -PW_ERROR on failure, PW_SUCCESS on success.
+ */
+int sw_add_driver_info(void *list_head,
+		       const struct sw_driver_interface_info *info)
+{
+	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
+	struct sw_collector_data *node = sw_alloc_collector_node();
+
+	if (!node) {
+		pw_pr_error("ERROR allocating collector node!\n");
+		return -PW_ERROR;
+	}
+
+	node->info = sw_copy_driver_interface_info_i(info);
+	if (!node->info) {
+		pw_pr_error(
+			"ERROR allocating or copying driver_interface_info!\n");
+		sw_free_collector_node(node);
+		return -PW_ERROR;
+	}
+	/*
+	 * Initialize the collectors in the node's descriptors.
+	 */
+	if (sw_init_driver_interface_info_i(node->info)) {
+		pw_pr_error(
+			"ERROR initializing a driver_interface_info node!\n");
+		sw_free_collector_node(node);
+		return -PW_ERROR;
+	}
+	/*
+	 * Allocate the ops array. We do this one time as an optimization
+	 * (we could always just repeatedly call 'sw_get_hw_ops_for()'
+	 * during the collection but we want to avoid that overhead)
+	 */
+	node->ops = sw_alloc_ops_i(info->num_io_descriptors);
+	if (!node->ops || sw_init_ops_i(node->ops, info)) {
+		pw_pr_error("ERROR initializing the ops array!\n");
+		sw_free_collector_node(node);
+		return -PW_ERROR;
+	}
+	/*
+	 * Allocate and initialize the "collector message".
+	 */
+	node->per_msg_payload_size = sw_get_payload_size_i(info);
+	pw_pr_debug("Debug: Per msg payload size = %u\n",
+		    (unsigned int)node->per_msg_payload_size);
+	node->msg = sw_alloc_collector_msg_i(info, node->per_msg_payload_size);
+	if (!node->msg) {
+		pw_pr_error("ERROR allocating space for a collector msg!\n");
+		sw_free_collector_node(node);
+		return -PW_ERROR;
+	}
+	pw_pr_debug("NODE = %p, NODE->MSG = %p\n", node, node->msg);
+	cpumask_clear(&node->cpumask);
+	{
+		/*
+		 * For now, use following protocol:
+		 * cpu_mask == -2 ==> Collect on ALL CPUs
+		 * cpu_mask == -1 ==> Collect on ANY CPU
+		 * cpu_mask >= 0 ==> Collect on a specific CPU
+		 */
+		if (node->info->cpu_mask >= 0) {
+			/*
+			 * Collect data on 'node->info->cpu_mask'
+			 */
+			cpumask_set_cpu(node->info->cpu_mask, &node->cpumask);
+			pw_pr_debug("OK: set CPU = %d\n", node->info->cpu_mask);
+		} else if (node->info->cpu_mask == -1) {
+			/*
+			 * Collect data on ANY CPU.  Leave empty as a flag to
+			 * signify user wishes to collect data on 'ANY' cpu.
+			 */
+			pw_pr_debug("OK: set ANY CPU\n");
+		} else {
+			/*
+			 * Collect data on ALL cpus.
+			 */
+			cpumask_copy(&node->cpumask, cpu_present_mask);
+			pw_pr_debug("OK: set ALL CPUs\n");
+		}
+	}
+	SW_LIST_ADD(head, node, list);
+	return PW_SUCCESS;
+}
+
+void sw_free_driver_interface_info_i(struct sw_driver_interface_info *info)
+{
+	if (info)
+		sw_kfree(info);
+}
+
+void sw_free_ops_i(const struct sw_hw_ops **ops)
+{
+	if (ops)
+		sw_kfree(ops);
+}
+
+int sw_reset_driver_interface_info_i(struct sw_driver_interface_info *info)
+{
+	/*
+	 * Do any finalization here.
+	 * For now, only IPC/MMIO descriptors need to be finalized.
+	 */
+	int i = 0;
+	struct sw_driver_io_descriptor *descriptor = NULL;
+
+	if (!info) {
+		pw_pr_error("ERROR: no info!\n");
+		return -PW_ERROR;
+	}
+	for (i = 0,
+	    descriptor = (struct sw_driver_io_descriptor *)info->descriptors;
+	     i < info->num_io_descriptors; ++i, ++descriptor) {
+		if (sw_reset_driver_io_descriptor(descriptor))
+			return -PW_ERROR;
+	}
+	return PW_SUCCESS;
+}
+
+/* If this descriptor's collector has an init function, call it passing in */
+/* this descriptor.  That allows the collector to perform any initialization */
+/* or registration specific to this metric. */
+int sw_init_driver_io_descriptor(struct sw_driver_io_descriptor *descriptor)
+{
+	sw_io_desc_init_func_t init_func = NULL;
+	const struct sw_hw_ops *ops =
+		sw_get_hw_ops_for(descriptor->collection_type);
+
+	if (ops == NULL) {
+		pw_pr_error("NULL ops found in init_driver_io_desc: type %d\n",
+			    descriptor->collection_type);
+		return -PW_ERROR;
+	}
+	init_func = ops->init;
+
+	if (init_func) {
+		int retval = (*init_func)(descriptor);
+
+		if (retval)
+			pw_pr_error("(*init) return value for type %d: %d\n",
+				    descriptor->collection_type, retval);
+
+		return retval;
+	}
+	return PW_SUCCESS;
+}
+
+/*
+ * If this descriptor's collector has a finalize function, call it passing in
+ * this
+ * descriptor. This allows the collector to perform any finalization specific to
+ * this metric.
+ */
+int sw_reset_driver_io_descriptor(struct sw_driver_io_descriptor *descriptor)
+{
+	sw_io_desc_reset_func_t reset_func = NULL;
+	const struct sw_hw_ops *ops =
+		sw_get_hw_ops_for(descriptor->collection_type);
+
+	if (ops == NULL) {
+		pw_pr_error("NULL ops found in reset_driver_io_desc: type %d\n",
+			    descriptor->collection_type);
+		return -PW_ERROR;
+	}
+	pw_pr_debug("calling reset on descriptor of type %d\n",
+		    descriptor->collection_type);
+	reset_func = ops->reset;
+
+	if (reset_func) {
+		int retval = (*reset_func)(descriptor);
+
+		if (retval)
+			pw_pr_error("(*reset) return value for type %d: %d\n",
+				    descriptor->collection_type, retval);
+
+		return retval;
+	}
+	return PW_SUCCESS;
+}
+
+int sw_handle_driver_io_descriptor(
+	char *dst_vals, int cpu,
+	const struct sw_driver_io_descriptor *descriptor,
+	const struct sw_hw_ops *hw_ops)
+{
+	typedef void (*sw_hardware_io_func_t)(
+		char *, int, const struct sw_driver_io_descriptor *, u16);
+	sw_hardware_io_func_t hardware_io_func = NULL;
+
+	if (descriptor->collection_command < SW_IO_CMD_READ ||
+	    descriptor->collection_command > SW_IO_CMD_WRITE) {
+		return -PW_ERROR;
+	}
+	switch (descriptor->collection_command) {
+	case SW_IO_CMD_READ:
+		hardware_io_func = hw_ops->read;
+		break;
+	case SW_IO_CMD_WRITE:
+		hardware_io_func = hw_ops->write;
+		break;
+	default:
+		break;
+	}
+	if (hardware_io_func) {
+		(*hardware_io_func)(dst_vals, cpu, descriptor,
+				    descriptor->counter_size_in_bytes);
+	} else {
+		pw_pr_debug(
+			"NO ops to satisfy %u operation for collection type %u!\n",
+			descriptor->collection_command,
+			descriptor->collection_type);
+	}
+	return PW_SUCCESS;
+}
+
+void sw_free_collector_msg_i(sw_driver_msg_t *msg)
+{
+	if (msg)
+		sw_kfree(msg);
+}
+
+void sw_handle_per_cpu_msg_i(void *info, enum sw_wakeup_action action)
+{
+	/*
+	 * Basic algo:
+	 * For each descriptor in 'node->info->descriptors'; do:
+	 * 1. Perform H/W read; use 'descriptor->collection_type' to
+	 * determine type of read; use 'descriptor->counter_size_in_bytes'
+	 * for read size. Use msg->p_payload[dst_idx] as dst address
+	 * 2. Increment dst idx by 'descriptor->counter_size_in_bytes'
+	 */
+	struct sw_collector_data *node = (struct sw_collector_data *)info;
+	int cpu = RAW_CPU();
+	u16 num_descriptors = node->info->num_io_descriptors, i = 0;
+	struct sw_driver_io_descriptor *descriptors =
+		(struct sw_driver_io_descriptor *)node->info->descriptors;
+	sw_driver_msg_t *msg = GET_MSG_SLOT_FOR_CPU(node->msg, cpu,
+						    node->per_msg_payload_size);
+	char *dst_vals = msg->p_payload;
+	const struct sw_hw_ops **ops = node->ops;
+	bool wasAnyWrite = false;
+
+	/* msg TSC assigned when msg is written to buffer */
+	msg->cpuidx = cpu;
+
+	for (i = 0; i < num_descriptors; ++i,
+	    dst_vals += descriptors->counter_size_in_bytes, ++descriptors) {
+		if (unlikely(ops[i] == NULL)) {
+			pw_pr_debug("NULL OPS!\n");
+			continue;
+		}
+		if (descriptors->collection_command == SW_IO_CMD_WRITE)
+			wasAnyWrite = true;
+
+		if (sw_handle_driver_io_descriptor(dst_vals, cpu, descriptors,
+						   ops[i]))
+			pw_pr_error("ERROR reading descriptor with type %d\n",
+				    descriptors->collection_type);
+	}
+
+	/*
+	 * We produce messages only on READs. Note that SWA prohibits
+	 * messages that contain both READ and WRITE descriptors, so it
+	 * is enough to check if there was ANY WRITE descriptor in this
+	 * message.
+	 */
+	if (likely(wasAnyWrite == false)) {
+		if (sw_produce_generic_msg(msg, action))
+			pw_pr_warn("WARNING: could NOT produce message!\n");
+	}
+}
+
+/*
+ * Collector list and node functions.
+ */
+struct sw_collector_data *sw_alloc_collector_node(void)
+{
+	struct sw_collector_data *node = (struct sw_collector_data *)sw_kmalloc(
+		sizeof(struct sw_collector_data), GFP_KERNEL);
+
+	if (node) {
+		node->per_msg_payload_size = 0x0;
+		node->last_update_jiffies = 0x0;
+		node->info = NULL;
+		node->ops = NULL;
+		node->msg = NULL;
+		SW_LIST_ENTRY_INIT(node, list);
+	}
+	return node;
+}
+
+void sw_free_collector_node(struct sw_collector_data *node)
+{
+	if (node) {
+		if (node->info) {
+			sw_reset_driver_interface_info_i(node->info);
+			sw_free_driver_interface_info_i(node->info);
+			node->info = NULL;
+		}
+		if (node->ops) {
+			sw_free_ops_i(node->ops);
+			node->ops = NULL;
+		}
+		if (node->msg) {
+			sw_free_collector_msg_i(node->msg);
+			node->msg = NULL;
+		}
+		sw_kfree(node);
+	}
+}
+
+int sw_handle_collector_node(struct sw_collector_data *node)
+{
+	if (!node || !node->info || !node->ops || !node->msg)
+		return -PW_ERROR;
+
+	pw_pr_debug("Calling SMP_CALL_FUNCTION_MANY!\n");
+	sw_schedule_work(&node->cpumask, &sw_handle_per_cpu_msg, node);
+	return PW_SUCCESS;
+}
+
+int sw_handle_collector_node_on_cpu(struct sw_collector_data *node, int cpu)
+{
+	if (!node || !node->info || !node->ops || !node->msg)
+		return -PW_ERROR;
+
+	/*
+	 * Check if this node indicates it should be scheduled
+	 * on the given cpu. If so, clear all other CPUs from the
+	 * mask and schedule the node.
+	 */
+	if (cpumask_test_cpu(cpu, &node->cpumask)) {
+		struct cpumask tmp_mask;
+
+		cpumask_clear(&tmp_mask);
+		cpumask_set_cpu(cpu, &tmp_mask);
+		pw_pr_debug("Calling SMP_CALL_FUNCTION_MANY!\n");
+		sw_schedule_work(&tmp_mask, &sw_handle_per_cpu_msg, node);
+	}
+	return PW_SUCCESS;
+}
+
+void sw_init_collector_list(void *list_head)
+{
+	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
+	SW_LIST_HEAD_INIT(head);
+}
+
+void sw_destroy_collector_list(void *list_head)
+{
+	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
+	while (!SW_LIST_EMPTY(head)) {
+		struct sw_collector_data *curr =
+			SW_LIST_GET_HEAD_ENTRY(head,
+				sw_collector_data,
+				list);
+
+		BUG_ON(!curr->info);
+		SW_LIST_UNLINK(curr, list);
+		sw_free_collector_node(curr);
+	}
+}
+
+/**
+ * sw_handle_collector_list - Iterate through the collector list, calling
+ *                            func() upon each element.
+ * @list_head:  The collector list head.
+ * @func:  The function to call for each collector.
+ *
+ * This function is called when one of the "when types" fires, since the
+ * passed-in collector node list is the list of collections to do at that time.
+ *
+ * Returns: PW_SUCCESS on success, -PW_ERROR on error.
+ */
+int sw_handle_collector_list(void *list_head,
+			     int (*func)(struct sw_collector_data *data))
+{
+	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
+	int retVal = PW_SUCCESS;
+	struct sw_collector_data *curr = NULL;
+
+	if (!head || !func)
+		return -PW_ERROR;
+
+	SW_LIST_FOR_EACH_ENTRY(curr, head, list)
+	{
+		pw_pr_debug("HANDLING\n");
+		if ((*func)(curr))
+			retVal = -PW_ERROR;
+
+	}
+	return retVal;
+}
+
+int sw_handle_collector_list_on_cpu(void *list_head,
+				    int (*func)(struct sw_collector_data *data,
+						int cpu),
+				    int cpu)
+{
+	SW_LIST_HEAD_VAR(sw_collector_data) * head = list_head;
+	int retVal = PW_SUCCESS;
+	struct sw_collector_data *curr = NULL;
+
+	if (!head || !func)
+		return -PW_ERROR;
+
+	SW_LIST_FOR_EACH_ENTRY(curr, head, list)
+	{
+		pw_pr_debug("HANDLING\n");
+		if ((*func)(curr, cpu))
+			retVal = -PW_ERROR;
+
+	}
+	return retVal;
+}
+
+void sw_handle_per_cpu_msg(void *info)
+{
+	sw_handle_per_cpu_msg_i(info, SW_WAKEUP_ACTION_DIRECT);
+}
+
+void sw_handle_per_cpu_msg_no_sched(void *info)
+{
+	sw_handle_per_cpu_msg_i(info, SW_WAKEUP_ACTION_TIMER);
+}
+
+void sw_handle_per_cpu_msg_on_cpu(int cpu, void *info)
+{
+	if (unlikely(cpu == RAW_CPU()))
+		sw_handle_per_cpu_msg_no_sched(info);
+	else {
+		pw_pr_debug("[%d] is handling for %d\n", RAW_CPU(), cpu);
+		/*
+		 * No need to disable preemption -- 'smp_call_function_single'
+		 * does that for us.
+		 */
+		smp_call_function_single(
+			cpu, &sw_handle_per_cpu_msg_no_sched, info,
+			false
+			/* false ==> do NOT wait for function completion */);
+	}
+}
+
+void sw_set_collector_ops(const struct sw_hw_ops *hw_ops)
+{
+	s_hw_ops = hw_ops;
+}
diff --git a/drivers/platform/x86/socwatch/sw_cta.c b/drivers/platform/x86/socwatch/sw_cta.c
index ddf15e03fd4d..0890b409ae16 100644
--- a/drivers/platform/x86/socwatch/sw_cta.c
+++ b/drivers/platform/x86/socwatch/sw_cta.c
@@ -1,324 +1,325 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <linux/compiler.h>     /* Definition of __weak */
-#include <linux/kref.h> /* struct kref */
-#include <linux/notifier.h> /* struct notifier_block */
-
-#include "sw_structs.h"      /* sw_driver_io_descriptor */
-#include "sw_cta.h"
-
-/* *********************************
- * Begin CTA driver import
- * *********************************
- */
-
-/*
- * Struct definitions taken from CTA driver.
- */
-
-enum intel_cta_ep_type {
-        INTEL_CTA_EP_TYPE_ANY = 0,
-        INTEL_CTA_EP_TYPE_PUNIT,
-        INTEL_CTA_EP_TYPE_GPU,
-        NUM_INTEL_CTA_EP_TYPES
-};
-
-struct telem_header {
-        u8      access_type;
-        u8      telem_type;
-        u16     size;
-        u32     guid;
-        u32     base_offset;
-        u32     tele_id;
-};
-
-struct discovery_entry {
-        struct telem_header     header;
-        void __iomem            *disc_offset;
-        void __iomem            *counter_base;
-};
-
-/**
- * struct telem_endpoint - telemetry endpoint description
- * @pci_bus_no:      pci device bus number
- * @pci_devfn:       encoded pci device and function number
- * @num_entries:     Number of entries
- * @telem_ep_type:   Device specific telemetry type
- * @header_size:     Size in bytes of the discovery header
- * @discovery_entry: Pointer to list of telemetry entries. Used by
- *                   driver API to get direct access to the endpoint.
- *                   Do not dereference directly. Use driver API which
- *                   checks for device availability.
- * @kref:            Driver reference count - do not modify directly. Use
- *                   the register_endpoint and unregister_endpoint API's.
- */
-struct telem_endpoint {
-        u16                             pci_bus_no;
-        u8                              pci_devfn;
-        int                             num_entries;
-        u32                             telem_ep_type;  //TODO: Implement
-        u32                             header_size;
-        struct discovery_entry          *entry;
-        struct kref                     kref;
-};
-
-struct telem_header_info {
-        u8      access_type;
-        u16     size;
-        u32     guid;
-};
-
-/*
- * Weak linkage of functions from the CTA driver
- */
-/**
- * cta_telem_get_next_endpoint() - Get next id for a telemetry endpoint
- * @start:  starting index to look from
- * @type:   filter for type of endpoint
- *
- * Return:
- * * index       - index of next present endpoint after start
- * * 0           - when no more endpoints are present after start
- */
-extern unsigned long __weak
-cta_telem_get_next_endpoint(unsigned long start,
-                            enum intel_cta_ep_type type);
-
-/**
- * cta_telem_register_endpoint() - Register use of telemetry endpoint
- * @handle: ID associated with the telemetry endpoint
- *
- * Return:
- * * ep          - Succes
- * * -ENXIO      - telemetry endpoint not found
- */
-
-extern struct telem_endpoint * __weak
-cta_telem_register_endpoint(unsigned long handle);
-
-/**
- * cta_telem_unregister_endpoint() - Unregister use of telemetry endpoint
- * @ep:   ep structure to populate.
- */
-extern void __weak
-cta_telem_unregister_endpoint(struct telem_endpoint *ep);
-
-
-/**
- * cta_telem_get_header_info() - Get header info from a telem entry
- * @handle: ID associated with the telemetry endpoint
- * @idx:    Index of the entry
- * @info: Allocated header info structure to fill
- *
- * Return:
- * * 0           - Success
- * * -ENXIO      - telemetry endpoint not found
- * * -EINVAL     - bad argument (@idx out of range or null @info)
- */
-extern int __weak
-cta_telem_get_header_info(unsigned long handle, u8 idx,
-                          struct telem_header_info *info);
-/**
- * cta_telem_counter_read32() - Read dwords from telemetry sram into buffer
- * @ep:     Pointer to telemetry endpoint to access
- * @index:  Index of the entry
- * @offset: Register offset in bytes
- * @data:   Preallocated dword buffer to fill
- * @count:  Number of dwords requested
- *
- * Callers must ensure reads are aligned, and that both the entry index and
- * offset are within bounds. When the call returns -ENODEV, the device has
- * been removed and callers should unregister the telemetry endpoint.
- *
- * Context: RCU used to guard reads from device removal and unmap. Do not
- *          sleep.
- *
- * Return:
- * * 0           - Success
- * * -ENODEV     - The device had been removed.
- */
-extern int __weak
-cta_telem_counter_read32(struct telem_endpoint *ep, u32 index, u32 offset,
-                         u32 *data, u32 count);
-/**
- * cta_telem_counter_read64() - Read qwords from telemetry sram into buffer
- * @ep:     Pointer to telemetry endpoint to access
- * @index:  Index of the entry
- * @offset: Register offset in bytes
- * @data:   Preallocated buffer of qwords
- * @count:  Number of qwords requested
- *
- * Callers must ensure reads are aligned, and that both the entry index and
- * offset are within bounds. When the call returns -ENODEV, the device has
- * been removed and callers should unregister the telemetry endpoint.
- *
- * Context: RCU used to guard reads from device removal and unmap. Do not
- *          sleep.
- *
- * Return:
- * * 0           - Success
- * * -ENODEV     - The device had been removed.
- */
-extern int __weak
-cta_telem_counter_read64(struct telem_endpoint *ep, u32 index, u32 offset,
-                         u64 *data, u32 count);
-
-extern int __weak cta_telem_register_notifier(struct notifier_block *nb);
-extern int __weak cta_telem_unregister_notifier(struct notifier_block *nb);
-
-/* *********************************
- * End CTA driver import
- * *********************************
- */
-
-#define MAX_TELEM_ENDPOINTS MAX_TELEM_AGGR_DEVICES /* For now */
-static struct telem_endpoint *s_telem_endpoints[MAX_TELEM_ENDPOINTS]; /* TODO: make this a linked list instead */
-size_t s_endpoint_index = 0;
-
-static struct _sw_aggregator_msg s_telem_aggregators;
-
-void sw_read_cta_info(char *dst, int cpu,
-		const struct sw_driver_io_descriptor *descriptor,
-		u16 counter_size_in_bytes)
-{
-	u64 *data64 = (u64 *)dst;
-	u32 *data32 = (u32 *)dst;
-	int retval = 0;
-	const struct sw_driver_aggr_telem_io_descriptor *td =
-		&(descriptor->aggr_telem_descriptor);
-	u32 offset = (u32)td->offset;
-	struct telem_endpoint *ep = s_telem_endpoints[0];
-
-	/* We can only support one endpoint as of now */
-	if (!ep) {
-		return;
-	}
-	switch (descriptor->counter_size_in_bytes) {
-		case 4:
-			retval = cta_telem_counter_read32(ep, 0/*index*/, offset, data32, td->num_entries);
-			break;
-		case 8:
-			retval = cta_telem_counter_read64(ep, 0/*index*/, offset, data64, td->num_entries);
-			break;
-		default:
-			printk(KERN_ERR "Invalid CTA counter size %u\n", descriptor->counter_size_in_bytes);
-			return;
-	}
-	if (retval) {
-		printk(KERN_ERR "Error reading %u byte CTA value from offset 0x%x, val = %d\n", descriptor->counter_size_in_bytes, offset, retval);
-	}
-}
-
-bool sw_cta_available(void)
-{
-	/* 1: check if the CTA driver is loaded */
-	if (!cta_telem_get_next_endpoint) {
-		return false;
-	}
-	/* 2: TODO: other checks here */
-	/*
-	 * Note: registering telemetry endpoints done in 'register' since
-	 * those endpoints also need to be unregistered (Done in 'fini')
-	 */
-	return true;
-}
-
-bool sw_cta_register(void)
-{
-	unsigned long index = 0;
-	if (!sw_cta_available()) {
-		return false;
-	}
-        s_telem_aggregators.num_entries = 0;
-        s_endpoint_index = 0;
-	/*
-	 * Retrieve list of telemetry endpoints.
-	 * TODO: we can only support one endpoint as of now, so should we be
-	 * checking the GUID to retrieve onl tthe endpoints of interest?
-	 */
-	s_endpoint_index = 0;
-	while ((index = cta_telem_get_next_endpoint(index, INTEL_CTA_EP_TYPE_ANY)) && s_endpoint_index < (MAX_TELEM_ENDPOINTS-1)) {
-		struct telem_header_info telem_info;
-		u8 idx = 0;
-		if (cta_telem_get_header_info(index, idx, &telem_info)) {
-			printk(KERN_ERR "Could not retrieve telemetry header for CTA endpoint %lu\n", index);
-			continue;
-		}
-		s_telem_endpoints[s_endpoint_index] = cta_telem_register_endpoint(index);
-		s_telem_aggregators.info[s_telem_aggregators.num_entries++].globalUniqueID = telem_info.guid;
-		++s_endpoint_index;
-	}
-	return s_endpoint_index > 0;
-}
-
-bool sw_cta_unregister(void)
-{
-	size_t i=0;
-	if (!sw_cta_available()) {
-		return false;
-	}
-	for (i=0; i<s_endpoint_index; ++i) {
-		cta_telem_unregister_endpoint(s_telem_endpoints[i]);
-	}
-	s_endpoint_index = 0;
-	s_telem_aggregators.num_entries = 0;
-	return true;
-}
-
-struct _sw_aggregator_msg *sw_cta_aggregators(void)
-{
-	return &s_telem_aggregators;
-}
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/compiler.h>     /* Definition of __weak */
+#include <linux/kref.h> /* struct kref */
+#include <linux/notifier.h> /* struct notifier_block */
+#include <linux/pci.h> /* struct pci_dev */
+#include <linux/ioport.h> /* struct resource */
+#include <linux/kref.h> /* struct kref */
+
+#include "sw_structs.h"      /* sw_driver_io_descriptor */
+#include "sw_cta.h"
+
+/* *********************************
+ * Begin CTA driver import
+ * *********************************
+ */
+
+/*
+ * Struct definitions taken from CTA driver.
+ */
+
+struct telem_header {
+        u8      access_type;
+        u8      telem_type;
+        u16     size;
+        u32     guid;
+        u32     base_offset;
+};
+
+struct telem_endpoint {
+        struct pci_dev        *parent;
+        struct telem_header   header;
+        void __iomem          *base;
+        struct resource       res;
+        bool                  present;
+        struct kref           kref;
+};
+
+struct telem_endpoint_info {
+        struct pci_dev          *pdev;
+        struct telem_header     header;
+};
+
+/*
+ * Weak linkage of functions from the CTA driver
+ */
+
+/**
+ * cta_telem_get_next_endpoint() - Get next device id for a telemetry endpoint
+ * @start:  starting devid to look from
+ *
+ * This functions can be used in a while loop predicate to retrieve the devid
+ * of all available telemetry endpoints. Functions cta_telem_get_next_endpoint()
+ * and cta_telem_register_endpoint() can be used inside of the loop to examine
+ * endpoint info and register to receive a pointer to the endpoint. The pointer
+ * is then usable in the telemetry read calls to access the telemetry data.
+ *
+ * Return:
+ * * devid       - devid of the next present endpoint from start
+ * * 0           - when no more endpoints are present after start
+ */
+extern int __weak
+cta_telem_get_next_endpoint(int start);
+
+/**
+ * cta_telem_register_endpoint() - Register a telemetry endpoint
+ * @devid: device id/handle of the telemetry endpoint
+ *
+ * Increments the kref usage counter for the endpoint.
+ *
+ * Return:
+ * * endpoint    - On success returns pointer to the telemetry endpoint
+ * * -ENXIO      - telemetry endpoint not found
+ */
+extern struct telem_endpoint * __weak
+cta_telem_register_endpoint(int devid);
+
+/**
+ * cta_telem_unregister_endpoint() - Unregister a telemetry endpoint
+ * @ep:   ep structure to populate.
+ *
+ * Decrements the kref usage counter for the endpoint.
+ */
+extern void __weak
+cta_telem_unregister_endpoint(struct telem_endpoint *ep);
+
+/**
+ * cta_telem_get_endpoint_info() - Get info for an endpoint from its devid
+ * @devid:  device id/handle of the telemetry endpoint
+ * @info:   Endpoint info structure to be populated
+ *
+ * Return:
+ * * 0           - Success
+ * * -ENXIO      - telemetry endpoint not found for the devid
+ * * -EINVAL     - @info is NULL
+ */
+extern int __weak
+cta_telem_get_endpoint_info(int devid,
+				struct telem_endpoint_info *info);
+
+/**
+ * cta_telem_read32() - Read dwords from telemetry sram
+ * @ep:     Telemetry endpoint to be read
+ * @offset: Register offset in bytes
+ * @data:   Allocated dword buffer
+ * @count:  Number of dwords requested
+ *
+ * Callers must ensure reads are aligned. When the call returns -ENODEV,
+ * the device has been removed and callers should unregister the telemetry
+ * endpoint.
+ *
+ * Return:
+ * * 0           - Success
+ * * -ENODEV	 - The device is not present.
+ * * -EINVAL	 - The offset is out out bounds
+ * * -EPIPE	 - The device was removed during the read. Data written
+ *		   but should be considered invalid.
+ */
+extern int __weak
+cta_telem_read32(struct telem_endpoint *ep, u32 offset, u32 *data,
+		     u32 count);
+
+/**
+ * cta_telem_read64() - Read qwords from counter sram
+ * @ep:     Telemetry endpoint to be read
+ * @offset: Register offset in bytes
+ * @data:   Allocated qword buffer
+ * @count:  Number of qwords requested
+ *
+ * Callers must ensure reads are aligned. When the call returns -ENODEV,
+ * the device has been removed and callers should unregister the telemetry
+ * endpoint.
+ *
+ * Return:
+ * * 0           - Success
+ * * -ENODEV	 - The device is not present.
+ * * -EINVAL	 - The offset is out out bounds
+ * * -EPIPE	 - The device was removed during the read. Data written
+ *		   but should be considered not valid.
+ */
+extern int __weak
+cta_telem_read64(struct telem_endpoint *ep, u32 offset, u64 *data,
+		     u32 count);
+
+/* Notifiers */
+
+#define CTA_TELEM_NOTIFY_ADD	0
+#define CTA_TELEM_NOTIFY_REMOVE	1
+
+/**
+ * cta_telem_register_notifier() - Receive notification endpoint events
+ * @nb:   Notifier block
+ *
+ * Events:
+ *   CTA_TELEM_NOTIFY_ADD   - An endpoint has been added. Notifier data
+ *                            is the devid
+ *   CTA_TELEM_NOTIF_REMOVE - An endpoint has been removed. Notifier data
+ *                            is the devid
+ */
+extern int __weak
+cta_telem_register_notifier(struct notifier_block *nb);
+
+/**
+ * cta_telem_unregister_notifier() - Unregister notification of endpoint events
+ * @nb:   Notifier block
+ *
+ */
+extern int __weak
+cta_telem_unregister_notifier(struct notifier_block *nb);
+
+/* *********************************
+ * End CTA driver import
+ * *********************************
+ */
+
+#define MAX_TELEM_ENDPOINTS MAX_TELEM_AGGR_DEVICES /* For now */
+static struct telem_endpoint *s_telem_endpoints[MAX_TELEM_ENDPOINTS]; /* TODO: make this a linked list instead */
+size_t s_endpoint_index = 0;
+
+static struct _sw_aggregator_msg s_telem_aggregators;
+
+void sw_read_cta_info(char *dst, int cpu,
+		const struct sw_driver_io_descriptor *descriptor,
+		u16 counter_size_in_bytes)
+{
+	u64 *data64 = (u64 *)dst;
+	u32 *data32 = (u32 *)dst;
+	int retval = 0;
+	const struct sw_driver_aggr_telem_io_descriptor *td =
+		&(descriptor->aggr_telem_descriptor);
+	u32 offset = (u32)td->offset;
+	struct telem_endpoint *ep = s_telem_endpoints[0];
+
+	/* We can only support one endpoint as of now */
+	if (!ep) {
+		return;
+	}
+	switch (descriptor->counter_size_in_bytes) {
+		case 4:
+			retval = cta_telem_read32(ep, offset, data32, td->num_entries);
+			break;
+		case 8:
+			retval = cta_telem_read64(ep, offset, data64, td->num_entries);
+			break;
+		default:
+			printk(KERN_ERR "Invalid CTA counter size %u\n", descriptor->counter_size_in_bytes);
+			return;
+	}
+	if (retval) {
+		printk(KERN_ERR "Error reading %u byte CTA value from offset 0x%x, val = %d\n", descriptor->counter_size_in_bytes, offset, retval);
+	}
+}
+
+bool sw_cta_available(void)
+{
+	/* 1: check if the CTA driver is loaded */
+	if (!cta_telem_get_endpoint_info) {
+		return false;
+	}
+	/* 2: TODO: other checks here */
+	/*
+	 * Note: registering telemetry endpoints done in 'register' since
+	 * those endpoints also need to be unregistered (Done in 'fini')
+	 */
+	return true;
+}
+
+bool sw_cta_register(void)
+{
+	unsigned long index = 0;
+	if (!sw_cta_available()) {
+		return false;
+	}
+        s_telem_aggregators.num_entries = 0;
+        s_endpoint_index = 0;
+	/*
+	 * Retrieve list of telemetry endpoints.
+	 * TODO: we can only support one endpoint as of now, so should we be
+	 * checking the GUID to retrieve only the endpoints of interest?
+	 */
+	s_endpoint_index = 0;
+	while ((index = cta_telem_get_next_endpoint(index)) && s_endpoint_index < (MAX_TELEM_ENDPOINTS-1)) {
+		struct telem_endpoint_info ep_info;
+		if (cta_telem_get_endpoint_info(index, &ep_info)) {
+			printk(KERN_ERR "Could not retrieve telemetry header for CTA endpoint %lu\n", index);
+			continue;
+		}
+		s_telem_endpoints[s_endpoint_index] = cta_telem_register_endpoint(index);
+		s_telem_aggregators.info[s_telem_aggregators.num_entries++].globalUniqueID = ep_info.header.guid;
+		++s_endpoint_index;
+	}
+	return s_endpoint_index > 0;
+}
+
+bool sw_cta_unregister(void)
+{
+	size_t i=0;
+	if (!sw_cta_available()) {
+		return false;
+	}
+	for (i=0; i<s_endpoint_index; ++i) {
+		cta_telem_unregister_endpoint(s_telem_endpoints[i]);
+	}
+	s_endpoint_index = 0;
+	s_telem_aggregators.num_entries = 0;
+	return true;
+}
+
+struct _sw_aggregator_msg *sw_cta_aggregators(void)
+{
+	return &s_telem_aggregators;
+}
diff --git a/drivers/platform/x86/socwatch/sw_file_ops.c b/drivers/platform/x86/socwatch/sw_file_ops.c
index 504d851db539..199ae560801e 100644
--- a/drivers/platform/x86/socwatch/sw_file_ops.c
+++ b/drivers/platform/x86/socwatch/sw_file_ops.c
@@ -1,337 +1,337 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <linux/module.h>  /* try_module_get */
-#include <linux/fs.h>      /* inode */
-#include <linux/device.h>  /* class_create */
-#include <linux/cdev.h>    /* cdev_alloc */
-#include <linux/version.h> /* LINUX_VERSION_CODE */
-#if KERNEL_VERSION(4, 12, 0) > LINUX_VERSION_CODE
-    #include <asm/uaccess.h>   /* copy_to_user */
-#else
-    #include <linux/uaccess.h>   /* copy_to_user */
-#endif /* LINUX_VERSION_CODE */
-#include <linux/wait.h>    /* wait_event_interruptible */
-#include <linux/sched.h>   /* TASK_INTERRUPTIBLE */
-
-#include "sw_kernel_defines.h"
-#include "sw_types.h"
-#include "sw_structs.h"
-#include "sw_file_ops.h"
-#include "sw_ioctl.h"
-#include "sw_output_buffer.h"
-
-/* -------------------------------------------------
- * Compile time constants.
- * -------------------------------------------------
- */
-/*
- * Get current command.
- */
-#define GET_CMD() ((*s_file_ops->get_current_cmd)())
-/*
- * Check if we're currently collecting data.
- */
-#define IS_COLLECTING() ({					\
-	sw_driver_collection_cmd_t __cmd = GET_CMD();		\
-	bool __val = (__cmd == SW_DRIVER_START_COLLECTION ||	\
-			__cmd == SW_DRIVER_RESUME_COLLECTION);	\
-	__val; })
-
-/*
- * Check if we're currently paused.
- */
-#define IS_SLEEPING() ({					\
-	sw_driver_collection_cmd_t __cmd = GET_CMD();		\
-	bool __val = __cmd == SW_DRIVER_PAUSE_COLLECTION;	\
-	__val; })
-
-/*
- * Character device file MAJOR
- * number -- we're now obtaining
- * this dynamically.
- */
-static int apwr_dev_major_num = -1;
-/*
- * Variables to create the character device file
- */
-static dev_t apwr_dev;
-static struct cdev *apwr_cdev;
-static struct class *apwr_class;
-/*
- * Operations exported by the main driver.
- */
-static struct sw_file_ops *s_file_ops;
-/*
- * Is the device open right now? Used to prevent
- * concurent access into the same device.
- */
-#define DEV_IS_OPEN 0 /* see if device is in use */
-static volatile unsigned long dev_status;
-
-/*
- * File operations.
- */
-/*
- * Service an "open(...)" call from user-space.
- */
-static int sw_device_open_i(struct inode *inode, struct file *file)
-{
-	/*
-	 * We don't want to talk to two processes at the same time
-	 */
-	if (test_and_set_bit(DEV_IS_OPEN, &dev_status))
-		return -EBUSY; /* Device is busy */
-
-
-	if (!try_module_get(THIS_MODULE)) {
-		pw_pr_error("ERROR: Device not found!\n");
-		return -ENODEV;/* No such device */
-	}
-	pw_pr_debug("OK, allowed client open!\n");
-	return PW_SUCCESS;
-}
-
-/*
- * Service a "close(...)" call from user-space.
- */
-static int sw_device_release_i(struct inode *inode, struct file *file)
-{
-	/*
-	 * Did the client just try to zombie us?
-	 */
-	int retVal = PW_SUCCESS;
-
-	if (IS_COLLECTING()) {
-		pw_pr_error(
-			"ERROR: Detected ongoing collection on a device release!\n");
-		retVal = (*s_file_ops->stop_handler)();
-	}
-	module_put(THIS_MODULE);
-	/*
-	 * We're now ready for our next caller
-	 */
-	clear_bit(DEV_IS_OPEN, &dev_status);
-	return retVal;
-}
-
-static ssize_t sw_device_read_i(struct file *file, char __user *user_buffer,
-	size_t length, loff_t *offset)
-{
-	ssize_t bytes_read = 0;
-	u32 val = 0;
-
-	if (!user_buffer) {
-		pw_pr_error(
-			"ERROR: \"read\" called with an empty user_buffer?!\n");
-		return -PW_ERROR;
-	}
-	do {
-		val = SW_ALL_WRITES_DONE_MASK;
-		if (wait_event_interruptible(sw_reader_queue,
-			(sw_any_seg_full(&val, (*s_file_ops->should_flush)()) ||
-				 (!IS_COLLECTING() && !IS_SLEEPING())))) {
-			pw_pr_error("wait_event_interruptible error\n");
-			return -ERESTARTSYS;
-		}
-		pw_pr_debug("After wait: val = %u\n", val);
-	} while (val == SW_NO_DATA_AVAIL_MASK);
-	/*
-	 * Are we done producing/consuming?
-	 */
-	if (val == SW_ALL_WRITES_DONE_MASK)
-		return 0; /* "0" ==> EOF */
-
-	/*
-	 * Copy the buffer contents into userspace.
-	 */
-	/* 'read' returns # of bytes actually read */
-	bytes_read = sw_consume_data(val, user_buffer, length);
-	if (unlikely(bytes_read <= 0)) {
-		/* Cannot be EOF since that has already been checked above */
-		return -EIO;
-	}
-	return bytes_read;
-}
-
-/*
- * (1) Handle 32b IOCTLs in 32b kernel-space.
- * (2) Handle 64b IOCTLs in 64b kernel-space.
- */
-static long sw_device_unlocked_ioctl_i(
-	struct file *filp, unsigned int ioctl_num, unsigned long ioctl_param)
-{
-	struct sw_driver_ioctl_arg __user *remote_args =
-			(struct sw_driver_ioctl_arg __user *)ioctl_param;
-	struct sw_driver_ioctl_arg local_args;
-
-	if (copy_from_user(&local_args, remote_args, sizeof(local_args))) {
-		pw_pr_error("ERROR copying ioctl args from userspace\n");
-		return -PW_ERROR;
-	}
-	return (*s_file_ops->ioctl_handler)(ioctl_num, &local_args);
-};
-
-#if defined(CONFIG_COMPAT) && defined(CONFIG_X86_64)
-#include <linux/compat.h>
-/*
- * Helper struct for use in translating
- * IOCTLs from 32b user programs in 64b
- * kernels.
- */
-#pragma pack(push, 1)
-struct sw_driver_ioctl_arg32 {
-	pw_s32_t in_len;
-	pw_s32_t out_len;
-	compat_caddr_t in_arg;
-	compat_caddr_t out_arg;
-};
-#pragma pack(pop)
-
-/*
- * Handle 32b IOCTLs in 64b kernel-space.
- */
-static long sw_device_compat_ioctl_i(
-	struct file *file, unsigned int ioctl_num, unsigned long ioctl_param)
-{
-	struct sw_driver_ioctl_arg32 __user *remote_args32 =
-						compat_ptr(ioctl_param);
-	struct sw_driver_ioctl_arg local_args;
-	u32 data;
-
-	if (get_user(local_args.in_len, &remote_args32->in_len))
-		return -PW_ERROR;
-
-	if (get_user(local_args.out_len, &remote_args32->out_len))
-		return -PW_ERROR;
-
-	if (get_user(data, &remote_args32->in_arg))
-		return -PW_ERROR;
-
-	local_args.in_arg = (char *)(unsigned long)data;
-	if (get_user(data, &remote_args32->out_arg))
-		return -PW_ERROR;
-
-	local_args.out_arg = (char *)(unsigned long)data;
-	return (*s_file_ops->ioctl_handler)(ioctl_num, &local_args);
-}
-#endif
-
-/*
- * File operations exported by the driver.
- */
-static const struct file_operations s_fops = {
-	.open = &sw_device_open_i,
-	.read = &sw_device_read_i,
-	.unlocked_ioctl = &sw_device_unlocked_ioctl_i,
-#if defined(CONFIG_COMPAT) && defined(CONFIG_X86_64)
-	.compat_ioctl = &sw_device_compat_ioctl_i,
-#endif /* COMPAT && x64 */
-	.release = &sw_device_release_i,
-};
-
-
-/*
- * Device creation, deletion operations.
- */
-int sw_register_dev(struct sw_file_ops *ops)
-{
-	int ret;
-	/*
-	 * Ensure we have valid handlers!
-	 */
-	if (!ops) {
-		pw_pr_error("NULL file ops?!\n");
-		return -PW_ERROR;
-	}
-
-	/*
-	 * Create the character device
-	 */
-	ret = alloc_chrdev_region(&apwr_dev, 0, 1, PW_DEVICE_NAME);
-	apwr_dev_major_num = MAJOR(apwr_dev);
-	apwr_class = class_create(THIS_MODULE, "apwr");
-	if (IS_ERR(apwr_class))
-		pw_pr_error("Error registering apwr class\n");
-
-
-	device_create(apwr_class, NULL, apwr_dev, NULL, PW_DEVICE_NAME);
-	apwr_cdev = cdev_alloc();
-	if (apwr_cdev == NULL) {
-		pw_pr_error("Error allocating character device\n");
-		return ret;
-	}
-	apwr_cdev->owner = THIS_MODULE;
-	apwr_cdev->ops = &s_fops;
-	if (cdev_add(apwr_cdev, apwr_dev, 1) < 0)  {
-		pw_pr_error("Error registering device driver\n");
-		return ret;
-	}
-	s_file_ops = ops;
-
-	return ret;
-}
-
-void sw_unregister_dev(void)
-{
-	/*
-	 * Remove the device
-	 */
-	unregister_chrdev(apwr_dev_major_num, PW_DEVICE_NAME);
-	device_destroy(apwr_class, apwr_dev);
-	class_destroy(apwr_class);
-	unregister_chrdev_region(apwr_dev, 1);
-	cdev_del(apwr_cdev);
-}
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/module.h>  /* try_module_get */
+#include <linux/fs.h>      /* inode */
+#include <linux/device.h>  /* class_create */
+#include <linux/cdev.h>    /* cdev_alloc */
+#include <linux/version.h> /* LINUX_VERSION_CODE */
+#if KERNEL_VERSION(4, 12, 0) > LINUX_VERSION_CODE
+    #include <asm/uaccess.h>   /* copy_to_user */
+#else
+    #include <linux/uaccess.h>   /* copy_to_user */
+#endif /* LINUX_VERSION_CODE */
+#include <linux/wait.h>    /* wait_event_interruptible */
+#include <linux/sched.h>   /* TASK_INTERRUPTIBLE */
+
+#include "sw_kernel_defines.h"
+#include "sw_types.h"
+#include "sw_structs.h"
+#include "sw_file_ops.h"
+#include "sw_ioctl.h"
+#include "sw_output_buffer.h"
+
+/* -------------------------------------------------
+ * Compile time constants.
+ * -------------------------------------------------
+ */
+/*
+ * Get current command.
+ */
+#define GET_CMD() ((*s_file_ops->get_current_cmd)())
+/*
+ * Check if we're currently collecting data.
+ */
+#define IS_COLLECTING() ({					\
+	sw_driver_collection_cmd_t __cmd = GET_CMD();		\
+	bool __val = (__cmd == SW_DRIVER_START_COLLECTION ||	\
+			__cmd == SW_DRIVER_RESUME_COLLECTION);	\
+	__val; })
+
+/*
+ * Check if we're currently paused.
+ */
+#define IS_SLEEPING() ({					\
+	sw_driver_collection_cmd_t __cmd = GET_CMD();		\
+	bool __val = __cmd == SW_DRIVER_PAUSE_COLLECTION;	\
+	__val; })
+
+/*
+ * Character device file MAJOR
+ * number -- we're now obtaining
+ * this dynamically.
+ */
+static int apwr_dev_major_num = -1;
+/*
+ * Variables to create the character device file
+ */
+static dev_t apwr_dev;
+static struct cdev *apwr_cdev;
+static struct class *apwr_class;
+/*
+ * Operations exported by the main driver.
+ */
+static struct sw_file_ops *s_file_ops;
+/*
+ * Is the device open right now? Used to prevent
+ * concurent access into the same device.
+ */
+#define DEV_IS_OPEN 0 /* see if device is in use */
+static volatile unsigned long dev_status;
+
+/*
+ * File operations.
+ */
+/*
+ * Service an "open(...)" call from user-space.
+ */
+static int sw_device_open_i(struct inode *inode, struct file *file)
+{
+	/*
+	 * We don't want to talk to two processes at the same time
+	 */
+	if (test_and_set_bit(DEV_IS_OPEN, &dev_status))
+		return -EBUSY; /* Device is busy */
+
+
+	if (!try_module_get(THIS_MODULE)) {
+		pw_pr_error("ERROR: Device not found!\n");
+		return -ENODEV;/* No such device */
+	}
+	pw_pr_debug("OK, allowed client open!\n");
+	return PW_SUCCESS;
+}
+
+/*
+ * Service a "close(...)" call from user-space.
+ */
+static int sw_device_release_i(struct inode *inode, struct file *file)
+{
+	/*
+	 * Did the client just try to zombie us?
+	 */
+	int retVal = PW_SUCCESS;
+
+	if (IS_COLLECTING()) {
+		pw_pr_error(
+			"ERROR: Detected ongoing collection on a device release!\n");
+		retVal = (*s_file_ops->stop_handler)();
+	}
+	module_put(THIS_MODULE);
+	/*
+	 * We're now ready for our next caller
+	 */
+	clear_bit(DEV_IS_OPEN, &dev_status);
+	return retVal;
+}
+
+static ssize_t sw_device_read_i(struct file *file, char __user *user_buffer,
+	size_t length, loff_t *offset)
+{
+	ssize_t bytes_read = 0;
+	u32 val = 0;
+
+	if (!user_buffer) {
+		pw_pr_error(
+			"ERROR: \"read\" called with an empty user_buffer?!\n");
+		return -PW_ERROR;
+	}
+	do {
+		val = SW_ALL_WRITES_DONE_MASK;
+		if (wait_event_interruptible(sw_reader_queue,
+			(sw_any_seg_full(&val, (*s_file_ops->should_flush)()) ||
+				 (!IS_COLLECTING() && !IS_SLEEPING())))) {
+			pw_pr_error("wait_event_interruptible error\n");
+			return -ERESTARTSYS;
+		}
+		pw_pr_debug("After wait: val = %u\n", val);
+	} while (val == SW_NO_DATA_AVAIL_MASK);
+	/*
+	 * Are we done producing/consuming?
+	 */
+	if (val == SW_ALL_WRITES_DONE_MASK)
+		return 0; /* "0" ==> EOF */
+
+	/*
+	 * Copy the buffer contents into userspace.
+	 */
+	/* 'read' returns # of bytes actually read */
+	bytes_read = sw_consume_data(val, user_buffer, length);
+	if (unlikely(bytes_read <= 0)) {
+		/* Cannot be EOF since that has already been checked above */
+		return -EIO;
+	}
+	return bytes_read;
+}
+
+/*
+ * (1) Handle 32b IOCTLs in 32b kernel-space.
+ * (2) Handle 64b IOCTLs in 64b kernel-space.
+ */
+static long sw_device_unlocked_ioctl_i(
+	struct file *filp, unsigned int ioctl_num, unsigned long ioctl_param)
+{
+	struct sw_driver_ioctl_arg __user *remote_args =
+			(struct sw_driver_ioctl_arg __user *)ioctl_param;
+	struct sw_driver_ioctl_arg local_args;
+
+	if (copy_from_user(&local_args, remote_args, sizeof(local_args))) {
+		pw_pr_error("ERROR copying ioctl args from userspace\n");
+		return -PW_ERROR;
+	}
+	return (*s_file_ops->ioctl_handler)(ioctl_num, &local_args);
+};
+
+#if defined(CONFIG_COMPAT) && defined(CONFIG_X86_64)
+#include <linux/compat.h>
+/*
+ * Helper struct for use in translating
+ * IOCTLs from 32b user programs in 64b
+ * kernels.
+ */
+#pragma pack(push, 1)
+struct sw_driver_ioctl_arg32 {
+	pw_s32_t in_len;
+	pw_s32_t out_len;
+	compat_caddr_t in_arg;
+	compat_caddr_t out_arg;
+};
+#pragma pack(pop)
+
+/*
+ * Handle 32b IOCTLs in 64b kernel-space.
+ */
+static long sw_device_compat_ioctl_i(
+	struct file *file, unsigned int ioctl_num, unsigned long ioctl_param)
+{
+	struct sw_driver_ioctl_arg32 __user *remote_args32 =
+						compat_ptr(ioctl_param);
+	struct sw_driver_ioctl_arg local_args;
+	u32 data;
+
+	if (get_user(local_args.in_len, &remote_args32->in_len))
+		return -PW_ERROR;
+
+	if (get_user(local_args.out_len, &remote_args32->out_len))
+		return -PW_ERROR;
+
+	if (get_user(data, &remote_args32->in_arg))
+		return -PW_ERROR;
+
+	local_args.in_arg = (char *)(unsigned long)data;
+	if (get_user(data, &remote_args32->out_arg))
+		return -PW_ERROR;
+
+	local_args.out_arg = (char *)(unsigned long)data;
+	return (*s_file_ops->ioctl_handler)(ioctl_num, &local_args);
+}
+#endif
+
+/*
+ * File operations exported by the driver.
+ */
+static const struct file_operations s_fops = {
+	.open = &sw_device_open_i,
+	.read = &sw_device_read_i,
+	.unlocked_ioctl = &sw_device_unlocked_ioctl_i,
+#if defined(CONFIG_COMPAT) && defined(CONFIG_X86_64)
+	.compat_ioctl = &sw_device_compat_ioctl_i,
+#endif /* COMPAT && x64 */
+	.release = &sw_device_release_i,
+};
+
+
+/*
+ * Device creation, deletion operations.
+ */
+int sw_register_dev(struct sw_file_ops *ops)
+{
+	int ret;
+	/*
+	 * Ensure we have valid handlers!
+	 */
+	if (!ops) {
+		pw_pr_error("NULL file ops?!\n");
+		return -PW_ERROR;
+	}
+
+	/*
+	 * Create the character device
+	 */
+	ret = alloc_chrdev_region(&apwr_dev, 0, 1, PW_DEVICE_NAME);
+	apwr_dev_major_num = MAJOR(apwr_dev);
+	apwr_class = class_create(THIS_MODULE, "apwr");
+	if (IS_ERR(apwr_class))
+		pw_pr_error("Error registering apwr class\n");
+
+
+	device_create(apwr_class, NULL, apwr_dev, NULL, PW_DEVICE_NAME);
+	apwr_cdev = cdev_alloc();
+	if (apwr_cdev == NULL) {
+		pw_pr_error("Error allocating character device\n");
+		return ret;
+	}
+	apwr_cdev->owner = THIS_MODULE;
+	apwr_cdev->ops = &s_fops;
+	if (cdev_add(apwr_cdev, apwr_dev, 1) < 0)  {
+		pw_pr_error("Error registering device driver\n");
+		return ret;
+	}
+	s_file_ops = ops;
+
+	return ret;
+}
+
+void sw_unregister_dev(void)
+{
+	/*
+	 * Remove the device
+	 */
+	unregister_chrdev(apwr_dev_major_num, PW_DEVICE_NAME);
+	device_destroy(apwr_class, apwr_dev);
+	class_destroy(apwr_class);
+	unregister_chrdev_region(apwr_dev, 1);
+	cdev_del(apwr_cdev);
+}
diff --git a/drivers/platform/x86/socwatch/sw_mem.c b/drivers/platform/x86/socwatch/sw_mem.c
index a0a0c3485c6c..c1e22611ba67 100644
--- a/drivers/platform/x86/socwatch/sw_mem.c
+++ b/drivers/platform/x86/socwatch/sw_mem.c
@@ -1,322 +1,322 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#include <linux/slab.h>
-
-#include "sw_kernel_defines.h"
-#include "sw_lock_defs.h"
-#include "sw_mem.h"
-
-/*
- * How do we behave if we ever
- * get an allocation error?
- * (a) Setting to '1' REFUSES ANY FURTHER
- * allocation requests.
- * (b) Setting to '0' treats each
- * allocation request as separate, and
- * handles them on an on-demand basis
- */
-#define DO_MEM_PANIC_ON_ALLOC_ERROR 0
-
-#if DO_MEM_PANIC_ON_ALLOC_ERROR
-/*
- * If we ever run into memory allocation errors then
- * stop (and drop) everything.
- */
-static atomic_t pw_mem_should_panic = ATOMIC_INIT(0);
-/*
- * Macro to check if PANIC is on.
- */
-#define MEM_PANIC() do {						\
-		atomic_set(&pw_mem_should_panic, 1);			\
-		smp_mb(); /* memory access ordering */			\
-	} while (0)
-
-#define SHOULD_TRACE() ({						\
-	bool __tmp = false;						\
-	smp_mb(); /* memory access ordering */				\
-	__tmp = (atomic_read(&pw_mem_should_panic) == 0);		\
-	__tmp; })
-
-#else /* if !DO_MEM_PANIC_ON_ALLOC_ERROR */
-
-#define MEM_PANIC()
-#define SHOULD_TRACE() (true)
-
-#endif
-
-/*
- * Variables to track memory usage.
- */
-/*
- * TOTAL num bytes allocated.
- */
-static u64 total_num_bytes_alloced;
-/*
- * Num of allocated bytes that have
- * not yet been freed.
- */
-static u64 curr_num_bytes_alloced;
-/*
- * Max # of allocated bytes that
- * have not been freed at any point
- * in time.
- */
-static u64 max_num_bytes_alloced;
-
-u64 sw_get_total_bytes_alloced(void)
-{
-	return total_num_bytes_alloced;
-};
-
-u64 sw_get_max_bytes_alloced(void)
-{
-	return max_num_bytes_alloced;
-};
-
-u64 sw_get_curr_bytes_alloced(void)
-{
-	return curr_num_bytes_alloced;
-};
-
-/*
- * Allocate free pages.
- * TODO: add memory tracker?
- */
-unsigned long sw_allocate_pages(
-	unsigned int flags, unsigned int alloc_size_in_bytes)
-{
-	return __get_free_pages(
-		(gfp_t)flags, get_order(alloc_size_in_bytes));
-}
-/*
- * Free up previously allocated pages.
- * TODO: add memory tracker?
- */
-void sw_release_pages(
-	unsigned long addr, unsigned int alloc_size_in_bytes)
-{
-	free_pages(addr, get_order(alloc_size_in_bytes));
-}
-
-#if DO_TRACK_MEMORY_USAGE
-
-/*
- * Lock to guard access to memory
- * debugging stats.
- */
-static SW_DEFINE_SPINLOCK(sw_kmalloc_lock);
-
-/*
- * Helper macros to print out
- * mem debugging stats.
- */
-#define TOTAL_NUM_BYTES_ALLOCED() total_num_bytes_alloced
-#define CURR_NUM_BYTES_ALLOCED() curr_num_bytes_alloced
-#define MAX_NUM_BYTES_ALLOCED() max_num_bytes_alloced
-
-/*
- * MAGIC number based memory tracker. Relies on
- * storing (a) a MAGIC marker and (b) the requested
- * size WITHIN the allocated block of memory. Standard
- * malloc-tracking stuff, really.
- *
- * Overview:
- * (1) ALLOCATION:
- * When asked to allocate a block of 'X' bytes, allocate
- * 'X' + 8 bytes. Then, in the FIRST 4 bytes, write the
- * requested size. In the NEXT 4 bytes, write a special
- * (i.e. MAGIC) number to let our deallocator know that
- * this block of memory was allocated using this technique.
- * Also, keep track of the number of bytes allocated.
- *
- * (2) DEALLOCATION:
- * When given an object to deallocate, we first check
- * the MAGIC number by decrementing the pointer by
- * 4 bytes and reading the (integer) stored there.
- * After ensuring the pointer was, in fact, allocated
- * by us, we then read the size of the allocated
- * block (again, by decrementing the pointer by 4
- * bytes and reading the integer size). We
- * use this size argument to decrement # of bytes
- * allocated.
- */
-#define PW_MEM_MAGIC 0xdeadbeef
-
-#define PW_ADD_MAGIC(x) ({					\
-	char *__tmp1 = (char *)(x);				\
-	*((int *)__tmp1) = PW_MEM_MAGIC;			\
-	__tmp1 += sizeof(int); __tmp1; })
-
-#define PW_ADD_SIZE(x, s) ({					\
-	char *__tmp1 = (char *)(x);				\
-	*((int *)__tmp1) = (s);					\
-	__tmp1 += sizeof(int); __tmp1; })
-
-#define PW_ADD_STAMP(x, s) PW_ADD_MAGIC(PW_ADD_SIZE((x), (s)))
-
-#define PW_IS_MAGIC(x) ({					\
-	int *__tmp1 = (int *)((char *)(x) - sizeof(int));	\
-	*__tmp1 == PW_MEM_MAGIC; })
-#define PW_REMOVE_STAMP(x) ({					\
-	char *__tmp1 = (char *)(x);				\
-	__tmp1 -= sizeof(int) * 2; __tmp1; })
-
-#define PW_GET_SIZE(x) (*((int *)(x)))
-
-void *sw_kmalloc(size_t size, unsigned int flags)
-{
-	size_t act_size = 0;
-	void *retVal = NULL;
-	/*
-	 * No point in allocating if
-	 * we were unable to allocate
-	 * previously!
-	 */
-	{
-		if (!SHOULD_TRACE())
-			return NULL;
-	}
-	/*
-	 * (1) Allocate requested block.
-	 */
-	act_size = size + sizeof(int) * 2;
-	retVal = kmalloc(act_size, (gfp_t)flags);
-	if (!retVal) {
-		/*
-		 * Panic if we couldn't allocate
-		 * requested memory.
-		 */
-		pw_pr_debug("ERROR: could NOT allocate memory!\n");
-		MEM_PANIC();
-		return NULL;
-	}
-	/*
-	 * (2) Update memory usage stats.
-	 */
-	LOCK(sw_kmalloc_lock);
-	{
-		total_num_bytes_alloced += size;
-		curr_num_bytes_alloced += size;
-		if (curr_num_bytes_alloced > max_num_bytes_alloced)
-			max_num_bytes_alloced = curr_num_bytes_alloced;
-	}
-	UNLOCK(sw_kmalloc_lock);
-	/*
-	 * (3) And finally, add the 'size'
-	 * and 'magic' stamps.
-	 */
-	return PW_ADD_STAMP(retVal, size);
-};
-
-void sw_kfree(const void *obj)
-{
-	void *tmp = NULL;
-	size_t size = 0;
-
-	/*
-	 * (1) Check if this block was allocated
-	 * by us.
-	 */
-	if (!PW_IS_MAGIC(obj)) {
-		pw_pr_debug("ERROR: %p is NOT a PW_MAGIC ptr!\n", obj);
-		return;
-	}
-	/*
-	 * (2) Strip the magic num...
-	 */
-	tmp = PW_REMOVE_STAMP(obj);
-	/*
-	 * ...and retrieve size of block.
-	 */
-	size = PW_GET_SIZE(tmp);
-	/*
-	 * (3) Update memory usage stats.
-	 */
-	LOCK(sw_kmalloc_lock);
-	{
-		curr_num_bytes_alloced -= size;
-	}
-	UNLOCK(sw_kmalloc_lock);
-	/*
-	 * And finally, free the block.
-	 */
-	kfree(tmp);
-};
-
-#else /* !DO_TRACK_MEMORY_USAGE */
-
-void *sw_kmalloc(size_t size, unsigned int flags)
-{
-	void *ret = NULL;
-
-	if (SHOULD_TRACE()) {
-		ret = kmalloc(size, (gfp_t)flags);
-		if (!ret) {
-			/*
-			 * Panic if we couldn't allocate
-			 * requested memory.
-			 */
-			MEM_PANIC();
-		}
-	}
-	return ret;
-};
-
-void sw_kfree(const void *mem)
-{
-	kfree(mem);
-};
-
-#endif /* DO_TRACK_MEMORY_USAGE */
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include <linux/slab.h>
+
+#include "sw_kernel_defines.h"
+#include "sw_lock_defs.h"
+#include "sw_mem.h"
+
+/*
+ * How do we behave if we ever
+ * get an allocation error?
+ * (a) Setting to '1' REFUSES ANY FURTHER
+ * allocation requests.
+ * (b) Setting to '0' treats each
+ * allocation request as separate, and
+ * handles them on an on-demand basis
+ */
+#define DO_MEM_PANIC_ON_ALLOC_ERROR 0
+
+#if DO_MEM_PANIC_ON_ALLOC_ERROR
+/*
+ * If we ever run into memory allocation errors then
+ * stop (and drop) everything.
+ */
+static atomic_t pw_mem_should_panic = ATOMIC_INIT(0);
+/*
+ * Macro to check if PANIC is on.
+ */
+#define MEM_PANIC() do {						\
+		atomic_set(&pw_mem_should_panic, 1);			\
+		smp_mb(); /* memory access ordering */			\
+	} while (0)
+
+#define SHOULD_TRACE() ({						\
+	bool __tmp = false;						\
+	smp_mb(); /* memory access ordering */				\
+	__tmp = (atomic_read(&pw_mem_should_panic) == 0);		\
+	__tmp; })
+
+#else /* if !DO_MEM_PANIC_ON_ALLOC_ERROR */
+
+#define MEM_PANIC()
+#define SHOULD_TRACE() (true)
+
+#endif
+
+/*
+ * Variables to track memory usage.
+ */
+/*
+ * TOTAL num bytes allocated.
+ */
+static u64 total_num_bytes_alloced;
+/*
+ * Num of allocated bytes that have
+ * not yet been freed.
+ */
+static u64 curr_num_bytes_alloced;
+/*
+ * Max # of allocated bytes that
+ * have not been freed at any point
+ * in time.
+ */
+static u64 max_num_bytes_alloced;
+
+u64 sw_get_total_bytes_alloced(void)
+{
+	return total_num_bytes_alloced;
+};
+
+u64 sw_get_max_bytes_alloced(void)
+{
+	return max_num_bytes_alloced;
+};
+
+u64 sw_get_curr_bytes_alloced(void)
+{
+	return curr_num_bytes_alloced;
+};
+
+/*
+ * Allocate free pages.
+ * TODO: add memory tracker?
+ */
+unsigned long sw_allocate_pages(
+	unsigned int flags, unsigned int alloc_size_in_bytes)
+{
+	return __get_free_pages(
+		(gfp_t)flags, get_order(alloc_size_in_bytes));
+}
+/*
+ * Free up previously allocated pages.
+ * TODO: add memory tracker?
+ */
+void sw_release_pages(
+	unsigned long addr, unsigned int alloc_size_in_bytes)
+{
+	free_pages(addr, get_order(alloc_size_in_bytes));
+}
+
+#if DO_TRACK_MEMORY_USAGE
+
+/*
+ * Lock to guard access to memory
+ * debugging stats.
+ */
+static SW_DEFINE_SPINLOCK(sw_kmalloc_lock);
+
+/*
+ * Helper macros to print out
+ * mem debugging stats.
+ */
+#define TOTAL_NUM_BYTES_ALLOCED() total_num_bytes_alloced
+#define CURR_NUM_BYTES_ALLOCED() curr_num_bytes_alloced
+#define MAX_NUM_BYTES_ALLOCED() max_num_bytes_alloced
+
+/*
+ * MAGIC number based memory tracker. Relies on
+ * storing (a) a MAGIC marker and (b) the requested
+ * size WITHIN the allocated block of memory. Standard
+ * malloc-tracking stuff, really.
+ *
+ * Overview:
+ * (1) ALLOCATION:
+ * When asked to allocate a block of 'X' bytes, allocate
+ * 'X' + 8 bytes. Then, in the FIRST 4 bytes, write the
+ * requested size. In the NEXT 4 bytes, write a special
+ * (i.e. MAGIC) number to let our deallocator know that
+ * this block of memory was allocated using this technique.
+ * Also, keep track of the number of bytes allocated.
+ *
+ * (2) DEALLOCATION:
+ * When given an object to deallocate, we first check
+ * the MAGIC number by decrementing the pointer by
+ * 4 bytes and reading the (integer) stored there.
+ * After ensuring the pointer was, in fact, allocated
+ * by us, we then read the size of the allocated
+ * block (again, by decrementing the pointer by 4
+ * bytes and reading the integer size). We
+ * use this size argument to decrement # of bytes
+ * allocated.
+ */
+#define PW_MEM_MAGIC 0xdeadbeef
+
+#define PW_ADD_MAGIC(x) ({					\
+	char *__tmp1 = (char *)(x);				\
+	*((int *)__tmp1) = PW_MEM_MAGIC;			\
+	__tmp1 += sizeof(int); __tmp1; })
+
+#define PW_ADD_SIZE(x, s) ({					\
+	char *__tmp1 = (char *)(x);				\
+	*((int *)__tmp1) = (s);					\
+	__tmp1 += sizeof(int); __tmp1; })
+
+#define PW_ADD_STAMP(x, s) PW_ADD_MAGIC(PW_ADD_SIZE((x), (s)))
+
+#define PW_IS_MAGIC(x) ({					\
+	int *__tmp1 = (int *)((char *)(x) - sizeof(int));	\
+	*__tmp1 == PW_MEM_MAGIC; })
+#define PW_REMOVE_STAMP(x) ({					\
+	char *__tmp1 = (char *)(x);				\
+	__tmp1 -= sizeof(int) * 2; __tmp1; })
+
+#define PW_GET_SIZE(x) (*((int *)(x)))
+
+void *sw_kmalloc(size_t size, unsigned int flags)
+{
+	size_t act_size = 0;
+	void *retVal = NULL;
+	/*
+	 * No point in allocating if
+	 * we were unable to allocate
+	 * previously!
+	 */
+	{
+		if (!SHOULD_TRACE())
+			return NULL;
+	}
+	/*
+	 * (1) Allocate requested block.
+	 */
+	act_size = size + sizeof(int) * 2;
+	retVal = kmalloc(act_size, (gfp_t)flags);
+	if (!retVal) {
+		/*
+		 * Panic if we couldn't allocate
+		 * requested memory.
+		 */
+		pw_pr_debug("ERROR: could NOT allocate memory!\n");
+		MEM_PANIC();
+		return NULL;
+	}
+	/*
+	 * (2) Update memory usage stats.
+	 */
+	LOCK(sw_kmalloc_lock);
+	{
+		total_num_bytes_alloced += size;
+		curr_num_bytes_alloced += size;
+		if (curr_num_bytes_alloced > max_num_bytes_alloced)
+			max_num_bytes_alloced = curr_num_bytes_alloced;
+	}
+	UNLOCK(sw_kmalloc_lock);
+	/*
+	 * (3) And finally, add the 'size'
+	 * and 'magic' stamps.
+	 */
+	return PW_ADD_STAMP(retVal, size);
+};
+
+void sw_kfree(const void *obj)
+{
+	void *tmp = NULL;
+	size_t size = 0;
+
+	/*
+	 * (1) Check if this block was allocated
+	 * by us.
+	 */
+	if (!PW_IS_MAGIC(obj)) {
+		pw_pr_debug("ERROR: %p is NOT a PW_MAGIC ptr!\n", obj);
+		return;
+	}
+	/*
+	 * (2) Strip the magic num...
+	 */
+	tmp = PW_REMOVE_STAMP(obj);
+	/*
+	 * ...and retrieve size of block.
+	 */
+	size = PW_GET_SIZE(tmp);
+	/*
+	 * (3) Update memory usage stats.
+	 */
+	LOCK(sw_kmalloc_lock);
+	{
+		curr_num_bytes_alloced -= size;
+	}
+	UNLOCK(sw_kmalloc_lock);
+	/*
+	 * And finally, free the block.
+	 */
+	kfree(tmp);
+};
+
+#else /* !DO_TRACK_MEMORY_USAGE */
+
+void *sw_kmalloc(size_t size, unsigned int flags)
+{
+	void *ret = NULL;
+
+	if (SHOULD_TRACE()) {
+		ret = kmalloc(size, (gfp_t)flags);
+		if (!ret) {
+			/*
+			 * Panic if we couldn't allocate
+			 * requested memory.
+			 */
+			MEM_PANIC();
+		}
+	}
+	return ret;
+};
+
+void sw_kfree(const void *mem)
+{
+	kfree(mem);
+};
+
+#endif /* DO_TRACK_MEMORY_USAGE */
diff --git a/drivers/platform/x86/socwatch/sw_output_buffer.c b/drivers/platform/x86/socwatch/sw_output_buffer.c
index 11ef7fcb2b69..eaccc29f18ea 100644
--- a/drivers/platform/x86/socwatch/sw_output_buffer.c
+++ b/drivers/platform/x86/socwatch/sw_output_buffer.c
@@ -1,838 +1,838 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include "sw_internal.h"
-#include "sw_output_buffer.h"
-#include "sw_kernel_defines.h"
-#include "sw_mem.h"
-#include "sw_lock_defs.h"
-#include "sw_overhead_measurements.h"
-
-/* -------------------------------------------------
- * Compile time constants and macros.
- * -------------------------------------------------
- */
-#define NUM_SEGS_PER_BUFFER 2 /* MUST be pow 2! */
-#define NUM_SEGS_PER_BUFFER_MASK (NUM_SEGS_PER_BUFFER - 1)
-/*
- * The size of the 'buffer' data array in each segment.
- */
-#define SW_SEG_DATA_SIZE (sw_buffer_alloc_size)
-/*
- * Min size of per-cpu output buffers.
- */
-#define SW_MIN_SEG_SIZE_BYTES (1 << 10) /* 1kB */
-#define SW_MIN_OUTPUT_BUFFER_SIZE (SW_MIN_SEG_SIZE_BYTES * NUM_SEGS_PER_BUFFER)
-/*
- * A symbolic constant for an empty buffer index.
- */
-#define EMPTY_SEG (-1)
-/*
- * How much space is available in a given segment?
- */
-#define EMPTY_TSC ((u64)-1)
-#define SEG_IS_FULL(seg) ({bool __full = false; \
-	smp_mb(); /* memory access ordering */\
-	__full = ((seg)->is_full != EMPTY_TSC); \
-	__full; })
-#define SEG_SET_FULL(seg, tsc) do { \
-	(seg)->is_full = (tsc); \
-	smp_mb(); /* memory access ordering */\
-} while (0)
-#define SEG_SET_EMPTY(seg) do { \
-	barrier(); \
-	(seg)->bytes_written = 0; \
-	SEG_SET_FULL(seg, EMPTY_TSC); \
-} while (0)
-#define SPACE_AVAIL(seg) (SW_SEG_DATA_SIZE - (seg)->bytes_written)
-#define SEG_IS_EMPTY(seg) (SPACE_AVAIL(seg) == SW_SEG_DATA_SIZE)
-
-#define GET_OUTPUT_BUFFER(cpu) (&per_cpu_output_buffers[(cpu)])
-/*
- * Convenience macro: iterate over each segment in a per-cpu output buffer.
- */
-#define for_each_segment(i) for (i = 0; i < NUM_SEGS_PER_BUFFER; ++i)
-#define for_each_seg(buffer, seg)					 \
-	for (int i = 0;							 \
-		i < NUM_SEGS_PER_BUFFER && (seg = (buffer)->segments[i]);\
-		++i)
-/*
- * How many buffers are we using?
- */
-#define GET_NUM_OUTPUT_BUFFERS() (sw_max_num_cpus + 1)
-/*
- * Convenience macro: iterate over each per-cpu output buffer.
- */
-#define for_each_output_buffer(i) for (i = 0; i < GET_NUM_OUTPUT_BUFFERS(); ++i)
-
-/* -------------------------------------------------
- * Local data structures.
- * -------------------------------------------------
- */
-struct sw_data_buffer {
-	u64 is_full;
-	u32 bytes_written;
-	char *buffer;
-} __packed;
-#define SW_SEG_HEADER_SIZE() (sizeof(struct sw_data_buffer) - sizeof(char *))
-
-struct sw_output_buffer {
-	struct sw_data_buffer buffers[NUM_SEGS_PER_BUFFER];
-	int buff_index;
-	u32 produced_samples;
-	u32 dropped_samples;
-	int last_seg_read;
-	unsigned int mem_alloc_size;
-	unsigned long free_pages;
-} ____cacheline_aligned_in_smp;
-
-/* *************************************************
- * For circular buffer (continuous profiling)
- * *************************************************
- */
-static char *output_buffer;
-
-struct buffer {
-	union {
-		char *data;
-		unsigned long free_pages;
-	};
-	size_t read_index, write_index;
-	unsigned long size;
-};
-SW_DECLARE_RWLOCK(sw_continuous_lock);
-
-static struct buffer buffer; /* TODO: rename */
-
-/* -------------------------------------------------
- * Function declarations.
- * -------------------------------------------------
- */
-extern u64 sw_timestamp(void);
-
-/* -------------------------------------------------
- * Variable definitions.
- * -------------------------------------------------
- */
-u64 sw_num_samples_produced = 0, sw_num_samples_dropped = 0;
-int sw_max_num_cpus = -1;
-
-DECLARE_OVERHEAD_VARS(sw_produce_generic_msg_i);
-/*
- * Per-cpu output buffers.
- */
-static struct sw_output_buffer *per_cpu_output_buffers;
-/*
- * Variables for book keeping.
- */
-static volatile int sw_last_cpu_read = -1;
-static volatile s32 sw_last_mask = -1;
-/*
- * Lock for the polled buffer.
- */
-SW_DECLARE_SPINLOCK(sw_polled_lock);
-/*
- * Buffer allocation size.
- */
-unsigned long sw_buffer_alloc_size = (1 << 16); /* 64 KB */
-
-/* -------------------------------------------------
- * Function definitions.
- * -------------------------------------------------
- */
-
-/* *************************************************
- * For circular buffer (continuous profiling)
- * *************************************************
- */
-#define MIN(x, y) ((x) <= (y) ? (x) : (y))
-
-#define IS_BUFFER_EMPTY(buffer)					\
-	((buffer).write_index == (buffer).read_index)
-#define IS_BUFFER_FULL(buffer)					\
-	((buffer).write_index ==				\
-		((buffer).read_index + 1) & (buffer.size - 1))
-
-static inline size_t get_space_available(struct buffer *buffer)
-{
-	size_t read = 0, write = 0;
-
-	smp_mb(); /* memory access ordering */
-	read = buffer->read_index;
-	write = buffer->write_index;
-	if (write < read)
-		return read - write;
-
-	return (buffer->size - write) + read;
-}
-
-static inline size_t get_data_available(struct buffer *buffer)
-{
-	size_t read = 0, write = 0;
-
-	smp_mb(); /* memory access ordering */
-	read = buffer->read_index;
-	write = buffer->write_index;
-	if (read <= write)
-		return write - read;
-
-	return (buffer->size - read) + write;
-}
-
-static void copy_wraparound(const char *src, size_t src_size, size_t *index)
-{
-	size_t buff_size_left = buffer.size - *index;
-	size_t to_write = MIN(buff_size_left, src_size);
-	size_t _index = *index;
-
-	if (src_size < buff_size_left) {
-		memcpy(&buffer.data[_index], src, src_size);
-		_index += src_size;
-	} else {
-		memcpy(&buffer.data[_index], src, to_write);
-		_index = 0;
-		src += to_write;
-		to_write = src_size - to_write;
-		memcpy(&buffer.data[_index], src, to_write);
-		_index += to_write;
-		pw_pr_debug("DEBUG: wrap memcpy\n");
-	}
-	*index = (*index + src_size) & (buffer.size - 1);
-}
-
-static int enqueue_data(struct sw_driver_msg *msg, enum sw_wakeup_action action)
-{
-	size_t size = SW_DRIVER_MSG_HEADER_SIZE() + msg->payload_len;
-	bool wrapped = false;
-
-	msg->tsc = 0;
-
-	READ_LOCK(sw_continuous_lock);
-	while (true) {
-		size_t old_write_index = buffer.write_index;
-		size_t new_write_index = (old_write_index + size) &
-						(buffer.size - 1);
-
-		if (get_space_available(&buffer) < size)
-			break;
-
-		if (CAS32(&buffer.write_index, old_write_index,
-				new_write_index)) {
-			msg->tsc = sw_timestamp();
-			wrapped = new_write_index <= old_write_index;
-			/* First copy header */
-			copy_wraparound((const char *)msg,
-				SW_DRIVER_MSG_HEADER_SIZE(), &old_write_index);
-			/* Then copy payload */
-			copy_wraparound((const char *)msg->p_payload,
-				msg->payload_len, &old_write_index);
-			break;
-		}
-	}
-	READ_UNLOCK(sw_continuous_lock);
-	if (!msg->tsc)
-		pw_pr_error("ERROR: couldn't enqueue data\n");
-	if (wrapped)
-		pw_pr_debug("DEBUG: wrapped!\n");
-
-	return msg->tsc ? 0 : -1;
-}
-
-/*
- * Returns # of bytes successfully consumed on success
- * 0 on EOF (no error condition)
- */
-static size_t consume_buffer(void *dest, size_t bytes_to_read)
-{
-	size_t read_index = 0, write_index = 0, dst_index = 0;
-	size_t to_read = 0;
-	bool wrapped = false;
-	size_t read_size = bytes_to_read;
-	unsigned long bytes_not_copied = 0;
-	struct sw_driver_continuous_collect data = {0};
-
-	WRITE_LOCK(sw_continuous_lock);
-	smp_mb(); /* memory access ordering */
-	read_index = buffer.read_index;
-	write_index = buffer.write_index;
-	/* EXE sends size as header + payload; we only want payload */
-	read_size -= SW_DRIVER_CONTINUOUS_COLLECT_HEADER_SIZE();
-	data.collection_size = to_read =
-		MIN(read_size, get_data_available(&buffer));
-	pw_pr_debug(
-		"DEBUG: read = %zu, write = %zu, avail = %zu, to_read = %zu\n",
-		read_index, write_index, get_data_available(&buffer), to_read);
-	while (to_read) {
-		size_t curr_read = to_read;
-
-		if (read_index + to_read > buffer.size) {
-			curr_read = buffer.size - read_index;
-			wrapped = true;
-			pw_pr_debug(
-				"DEBUG: read = %zu, to_read = %zu, curr_read = %zu, buffer.size = %lu, WRAPPED!\n",
-				read_index, to_read, curr_read, buffer.size);
-		}
-		memcpy(&output_buffer[dst_index],
-			&buffer.data[read_index], curr_read);
-		read_index = (read_index + curr_read) & (buffer.size - 1);
-		to_read -= curr_read;
-		dst_index += curr_read;
-	}
-	buffer.read_index = read_index;
-	smp_mb(); /* memory access ordering */
-	pw_pr_debug("DEBUG: read at end of while = %zu\n", buffer.read_index);
-	WRITE_UNLOCK(sw_continuous_lock);
-
-	/*
-	 * Call 'copy_to_user' instead of 'sw_copy_to_user' since
-	 * sw_copy_to_user expects to see a 'struct uio' while this
-	 * is called from an IOCTL which does NOT have a 'struct uio'
-	 */
-	bytes_not_copied =
-	copy_to_user(dest, (char *)&data,
-		SW_DRIVER_CONTINUOUS_COLLECT_HEADER_SIZE());
-	if (bytes_not_copied)
-		return 0;
-
-	pw_pr_debug("DEBUG: collection size = %u\n", data.collection_size);
-	if (data.collection_size) {
-		bytes_not_copied =
-			copy_to_user(dest +
-				SW_DRIVER_CONTINUOUS_COLLECT_HEADER_SIZE(),
-				output_buffer, data.collection_size);
-		if (bytes_not_copied)
-			return 0;
-
-	}
-	return data.collection_size;
-}
-
-long initialize_circular_buffer(size_t size)
-{
-	size_t alloc_size = size, read_size = size;
-	/*
-	 * We require a power of two size
-	 */
-	pw_pr_debug("DEBUG: old alloc size = %zu\n", alloc_size);
-	if ((alloc_size & (alloc_size - 1)) != 0)
-		alloc_size = 1 << fls(alloc_size);
-
-	pw_pr_debug("DEBUG: new alloc size = %zu\n", alloc_size);
-	/* Create double-sized buffer */
-	alloc_size <<= 1;
-	pw_pr_debug("DEBUG: double alloc size = %zu\n", alloc_size);
-	memset(&buffer, 0, sizeof(buffer));
-	buffer.free_pages =
-		sw_allocate_pages(GFP_KERNEL | __GFP_ZERO, alloc_size);
-	if (!buffer.free_pages) {
-		pw_pr_error("Couldn't allocate space for buffer!\n");
-		return -ENOMEM;
-	}
-	buffer.read_index = buffer.write_index = 0;
-	buffer.size = alloc_size;
-	SW_INIT_RWLOCK(sw_continuous_lock);
-	/*
-	 * Create temp output buffer
-	 */
-	output_buffer = vmalloc(read_size);
-	if (!output_buffer) {
-		pw_pr_error(
-			"Couldn't create temporary buffer for data output!\n");
-		return -ENOMEM;
-	}
-	return 0;
-}
-
-void reset_output_buffers(void)
-{
-	buffer.read_index = buffer.write_index = 0;
-}
-
-
-void destroy_circular_buffer(void)
-{
-	if (buffer.free_pages) {
-		sw_release_pages(buffer.free_pages, buffer.size);
-		buffer.free_pages = 0;
-	}
-	if (output_buffer) {
-		vfree(output_buffer);
-		output_buffer = NULL;
-	}
-	SW_DESTROY_RWLOCK(sw_continuous_lock);
-	pw_pr_debug("DEBUG: read = %zu, write = %zu\n", buffer.read_index,
-	buffer.write_index);
-}
-
-/* *************************************************
- * For per-cpu buffers (non circular)
- * *************************************************
- */
-
-static char *reserve_seg_space_i(size_t size, int cpu, bool *should_wakeup,
-	u64 *reservation_tsc)
-{
-	struct sw_output_buffer *buffer = GET_OUTPUT_BUFFER(cpu);
-	int i = 0;
-	int buff_index = buffer->buff_index;
-	char *dst = NULL;
-
-	if (buff_index < 0 || buff_index >= NUM_SEGS_PER_BUFFER)
-		goto prod_seg_done;
-
-	for_each_segment(i) {
-		struct sw_data_buffer *seg = &buffer->buffers[buff_index];
-
-		if (SEG_IS_FULL(seg) == false) {
-			if (SPACE_AVAIL(seg) >= size) {
-				*reservation_tsc = sw_timestamp();
-				dst = &seg->buffer[seg->bytes_written];
-				seg->bytes_written += size;
-				smp_mb(); /* memory access ordering */
-				buffer->buff_index = buff_index;
-				buffer->produced_samples++;
-				goto prod_seg_done;
-			}
-			SEG_SET_FULL(seg, sw_timestamp());
-		}
-		buff_index = CIRCULAR_INC(buff_index, NUM_SEGS_PER_BUFFER_MASK);
-		*should_wakeup = true;
-	}
-prod_seg_done:
-	if (!dst)
-		buffer->dropped_samples++;
-
-	return dst;
-};
-
-#ifdef CONFIG_PREEMPT_COUNT
-static int produce_polled_msg(struct sw_driver_msg *msg,
-	enum sw_wakeup_action action)
-{
-	int cpu = GET_POLLED_CPU();
-	bool should_wakeup = false;
-	int retVal = PW_SUCCESS;
-
-	if (!msg)
-		return -PW_ERROR;
-
-	pw_pr_debug("POLLED! cpu = %d\n", cpu);
-	LOCK(sw_polled_lock);
-	{
-		size_t size = SW_DRIVER_MSG_HEADER_SIZE() + msg->payload_len;
-		char *dst = reserve_seg_space_i(size, cpu,
-						&should_wakeup, &msg->tsc);
-
-		if (dst) {
-			/*
-			 * Assign a special CPU number to this CPU.
-			 * This is OK, because messages enqueued in this buffer
-			 * are always CPU agnostic (otherwise they would
-			 * be invoked from within a preempt_disable()d context
-			 * in 'sw_handle_collector_node_i()', which ensures
-			 * they will be enqueued within the
-			 * 'sw_produce_generic_msg_on_cpu()' function).
-			 */
-			msg->cpuidx = cpu;
-			memcpy(dst, msg, SW_DRIVER_MSG_HEADER_SIZE());
-			dst += SW_DRIVER_MSG_HEADER_SIZE();
-			memcpy(dst, msg->p_payload, msg->payload_len);
-		} else {
-			pw_pr_debug("NO space in polled msg!\n");
-			retVal = -PW_ERROR;
-		}
-	}
-	UNLOCK(sw_polled_lock);
-	if (unlikely(should_wakeup))
-		sw_wakeup_reader(action);
-
-	return retVal;
-};
-#endif /* CONFIG_PREEMPT_COUNT */
-
-static int sw_produce_generic_msg_i(struct sw_driver_msg *msg,
-	enum sw_wakeup_action action)
-{
-	int retval = PW_SUCCESS;
-	bool should_wakeup = false;
-	int cpu = -1;
-	unsigned long flags = 0;
-
-	if (!msg) {
-		pw_pr_error("ERROR: CANNOT produce a NULL msg!\n");
-		return -PW_ERROR;
-	}
-
-	/* Check if we need to use circular buffer */
-	if (output_buffer)
-		return enqueue_data(msg, action);
-
-#ifdef CONFIG_PREEMPT_COUNT
-	if (!in_atomic())
-		return produce_polled_msg(msg, action);
-#endif
-
-	cpu = sw_get_cpu(&flags);
-	{
-		size_t size = msg->payload_len +
-				SW_DRIVER_MSG_HEADER_SIZE();
-		char *dst = reserve_seg_space_i(size, cpu, &should_wakeup,
-						&msg->tsc);
-
-		if (likely(dst)) {
-			memcpy(dst, msg, SW_DRIVER_MSG_HEADER_SIZE());
-			dst += SW_DRIVER_MSG_HEADER_SIZE();
-			memcpy(dst, msg->p_payload, msg->payload_len);
-		} else
-			retval = -PW_ERROR;
-	}
-	sw_put_cpu(flags);
-
-	if (unlikely(should_wakeup))
-		sw_wakeup_reader(action);
-
-	return retval;
-};
-
-int sw_produce_generic_msg(struct sw_driver_msg *msg,
-	enum sw_wakeup_action action)
-{
-	return DO_PER_CPU_OVERHEAD_FUNC_RET(int, sw_produce_generic_msg_i,
-		msg, action);
-};
-
-static int sw_init_per_cpu_buffers_i(unsigned long per_cpu_mem_size)
-{
-	int cpu = -1;
-
-	per_cpu_output_buffers =
-	(struct sw_output_buffer *)sw_kmalloc(sizeof(struct sw_output_buffer) *
-	GET_NUM_OUTPUT_BUFFERS(), GFP_KERNEL | __GFP_ZERO);
-	if (per_cpu_output_buffers == NULL) {
-		pw_pr_error(
-			"ERROR allocating space for per-cpu output buffers!\n");
-		sw_destroy_per_cpu_buffers();
-		return -PW_ERROR;
-	}
-	for_each_output_buffer(cpu) {
-		struct sw_output_buffer *buffer = &per_cpu_output_buffers[cpu];
-		char *buff = NULL;
-		int i = 0;
-
-		buffer->mem_alloc_size = per_cpu_mem_size;
-		buffer->free_pages = sw_allocate_pages(GFP_KERNEL | __GFP_ZERO,
-			(unsigned int)per_cpu_mem_size);
-		if (buffer->free_pages == 0) {
-			pw_pr_error("ERROR allocating pages for buffer [%d]!\n",
-				cpu);
-			sw_destroy_per_cpu_buffers();
-			return -PW_ERROR;
-		}
-		buff = (char *)buffer->free_pages;
-		for_each_segment(i) {
-			buffer->buffers[i].buffer = (char *)buff;
-			buff += SW_SEG_DATA_SIZE;
-		}
-	}
-	pw_pr_debug("PER_CPU_MEM_SIZE = %lu, order = %u\n",
-	(unsigned long)per_cpu_mem_size, get_order(per_cpu_mem_size));
-	return PW_SUCCESS;
-};
-
-int sw_init_per_cpu_buffers(void)
-{
-	unsigned int per_cpu_mem_size = sw_get_output_buffer_size();
-
-	pw_pr_debug("Buffer alloc size = %ld\n", sw_buffer_alloc_size);
-
-	if (GET_NUM_OUTPUT_BUFFERS() <= 0) {
-		pw_pr_error("ERROR: max # output buffers= %d\n",
-			GET_NUM_OUTPUT_BUFFERS());
-		return -PW_ERROR;
-	}
-
-	pw_pr_debug("DEBUG: sw_max_num_cpus = %d, num output buffers = %d\n",
-	sw_max_num_cpus, GET_NUM_OUTPUT_BUFFERS());
-
-	/*
-	 * Try to allocate per-cpu buffers. If allocation fails, decrease
-	 * buffer size and retry. Stop trying if size drops below 2KB
-	 * (which means 1KB for each buffer).
-	 */
-	while (per_cpu_mem_size >= SW_MIN_OUTPUT_BUFFER_SIZE &&
-		sw_init_per_cpu_buffers_i(per_cpu_mem_size)) {
-		pw_pr_debug("WARNING: couldn't allocate per-cpu buffers with size %u -- trying smaller size!\n",
-			per_cpu_mem_size);
-		sw_buffer_alloc_size >>= 1;
-		per_cpu_mem_size = sw_get_output_buffer_size();
-	}
-
-	if (unlikely(per_cpu_output_buffers == NULL)) {
-		pw_pr_error("ERROR: couldn't allocate space for per-cpu output buffers!\n");
-		return -PW_ERROR;
-	}
-	/*
-	 * Initialize our locks.
-	 */
-	SW_INIT_SPINLOCK(sw_polled_lock);
-
-	pw_pr_debug("OK, allocated per-cpu buffers with size = %lu\n",
-		(unsigned long)per_cpu_mem_size);
-
-	if (sw_init_reader_queue()) {
-		pw_pr_error("ERROR initializing reader subsys\n");
-		return -PW_ERROR;
-	}
-
-	return PW_SUCCESS;
-};
-
-void sw_destroy_per_cpu_buffers(void)
-{
-	int cpu = -1;
-
-	/*
-	 * Perform lock finalization.
-	 */
-	SW_DESTROY_SPINLOCK(sw_polled_lock);
-
-	if (per_cpu_output_buffers != NULL) {
-		for_each_output_buffer(cpu) {
-			struct sw_output_buffer *buffer =
-					&per_cpu_output_buffers[cpu];
-
-			if (buffer->free_pages != 0) {
-				sw_release_pages(buffer->free_pages,
-					buffer->mem_alloc_size);
-				buffer->free_pages = 0;
-			}
-		}
-		sw_kfree(per_cpu_output_buffers);
-		per_cpu_output_buffers = NULL;
-	}
-};
-
-void sw_reset_per_cpu_buffers(void)
-{
-	int cpu = 0, i = 0;
-
-	for_each_output_buffer(cpu) {
-		struct sw_output_buffer *buffer = GET_OUTPUT_BUFFER(cpu);
-
-		buffer->buff_index = buffer->dropped_samples =
-			buffer->produced_samples = 0;
-		buffer->last_seg_read = -1;
-
-		for_each_segment(i) {
-			struct sw_data_buffer *seg = &buffer->buffers[i];
-
-			memset(seg->buffer, 0, SW_SEG_DATA_SIZE);
-			SEG_SET_EMPTY(seg);
-		}
-	}
-	sw_last_cpu_read = -1;
-	sw_last_mask = -1;
-	pw_pr_debug("OK, reset per-cpu output buffers!\n");
-	/*
-	 * Reset circular buffer if it has been allocated
-	 */
-	if (output_buffer)
-		buffer.read_index = buffer.write_index = 0;
-
-};
-
-bool sw_any_seg_full(u32 *val, bool is_flush_mode)
-{
-	int num_visited = 0, i = 0;
-
-	if (!val) {
-		pw_pr_error("ERROR: NULL ptrs in %s!\n", __func__);
-		return false;
-	}
-
-	*val = SW_NO_DATA_AVAIL_MASK;
-	pw_pr_debug("Checking for full seg: val = %u, flush = %s\n",
-		 *val, GET_BOOL_STRING(is_flush_mode));
-	for_each_output_buffer(num_visited) {
-		int min_seg = EMPTY_SEG, non_empty_seg = EMPTY_SEG;
-		u64 min_tsc = EMPTY_TSC;
-		struct sw_output_buffer *buffer = NULL;
-
-		if (++sw_last_cpu_read >= GET_NUM_OUTPUT_BUFFERS())
-			sw_last_cpu_read = 0;
-
-		buffer = GET_OUTPUT_BUFFER(sw_last_cpu_read);
-		for_each_segment(i) {
-			struct sw_data_buffer *seg = &buffer->buffers[i];
-			u64 seg_tsc = seg->is_full;
-
-			if (SEG_IS_EMPTY(seg))
-				continue;
-
-			non_empty_seg = i;
-			if (seg_tsc < min_tsc) {
-				/*
-				 * Can only happen if seg was full, provided
-				 * 'EMPTY_TSC' is set to "(u64)-1"
-				 */
-				min_tsc = seg_tsc;
-				min_seg = i;
-			}
-		}
-		if (min_seg != EMPTY_SEG) {
-			*val = (sw_last_cpu_read & 0xffff) << 16 |
-				(min_seg & 0xffff);
-			return true;
-		} else if (is_flush_mode && non_empty_seg != EMPTY_SEG) {
-			*val = (sw_last_cpu_read & 0xffff) << 16 |
-				(non_empty_seg & 0xffff);
-			return true;
-		}
-	}
-	/*
-	 * Reaches here only if there's no data to be read.
-	 */
-	if (is_flush_mode) {
-		/*
-		 * We've drained all buffers and need to tell the userspace
-		 * application there isn't any data. Unfortunately, we can't
-		 * just return a 'zero' value for the mask (because that could
-		 * also indicate that segment # 0 of cpu #0 has data).
-		 */
-		*val = SW_ALL_WRITES_DONE_MASK;
-		return true;
-	}
-	return false;
-};
-
-/*
- * Returns: number of bytes consumed on SUCCESS, 0 on EOF, negative
- * error code on FAILURE
- */
-ssize_t sw_consume_data(u32 mask, void __user *buffer, size_t bytes_to_read)
-{
-	int which_cpu = -1, which_seg = -1;
-	unsigned long bytes_not_copied = 0;
-	struct sw_output_buffer *buff = NULL;
-	struct sw_data_buffer *seg = NULL;
-	size_t bytes_read = 0;
-
-	/* Check if we need to use circular buffer */
-	if (output_buffer)
-		return (ssize_t)consume_buffer(buffer, bytes_to_read);
-
-	if (!sw_check_output_buffer_params(buffer, bytes_to_read,
-			SW_SEG_DATA_SIZE)) {
-		pw_pr_error("ERROR: invalid params to \"%s\"!\n", __func__);
-		return -EIO;
-	}
-
-	which_cpu = mask >> 16; which_seg = mask & 0xffff;
-	pw_pr_debug("CONSUME: cpu = %d, seg = %d\n", which_cpu, which_seg);
-	if (which_seg >= NUM_SEGS_PER_BUFFER) {
-		pw_pr_error(
-			"Error: which_seg (%d) >= NUM_SEGS_PER_BUFFER (%d)\n",
-			which_seg, NUM_SEGS_PER_BUFFER);
-		return -EIO;
-	}
-	/*
-	 * OK to access unlocked; either the segment is FULL, or no collection
-	 * is ongoing. In either case, we're GUARANTEED no producer is touching
-	 * this segment.
-	 */
-	buff = GET_OUTPUT_BUFFER(which_cpu);
-	seg = &buff->buffers[which_seg];
-
-	bytes_not_copied = sw_copy_to_user(buffer,
-		seg->buffer, seg->bytes_written); /* dst, src */
-
-	if (likely(bytes_not_copied == 0))
-		bytes_read = seg->bytes_written;
-	else {
-		pw_pr_error("Warning: couldn't copy %lu bytes\n",
-			bytes_not_copied);
-		bytes_read = 0;
-	}
-	SEG_SET_EMPTY(seg);
-	return bytes_read;
-}
-
-unsigned int sw_get_output_buffer_size(void)
-{
-	return (sw_buffer_alloc_size * NUM_SEGS_PER_BUFFER);
-};
-
-void sw_count_samples_produced_dropped(void)
-{
-	int cpu = 0;
-
-	sw_num_samples_produced = sw_num_samples_dropped = 0;
-	if (per_cpu_output_buffers == NULL)
-		return;
-
-	for_each_output_buffer(cpu) {
-		struct sw_output_buffer *buff = GET_OUTPUT_BUFFER(cpu);
-
-		sw_num_samples_dropped += buff->dropped_samples;
-		sw_num_samples_produced += buff->produced_samples;
-	}
-};
-
-void sw_print_output_buffer_overheads(void)
-{
-	PRINT_CUMULATIVE_OVERHEAD_PARAMS(sw_produce_generic_msg_i,
-		"PRODUCE_GENERIC_MSG");
-	sw_print_reader_stats();
-};
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include "sw_internal.h"
+#include "sw_output_buffer.h"
+#include "sw_kernel_defines.h"
+#include "sw_mem.h"
+#include "sw_lock_defs.h"
+#include "sw_overhead_measurements.h"
+
+/* -------------------------------------------------
+ * Compile time constants and macros.
+ * -------------------------------------------------
+ */
+#define NUM_SEGS_PER_BUFFER 2 /* MUST be pow 2! */
+#define NUM_SEGS_PER_BUFFER_MASK (NUM_SEGS_PER_BUFFER - 1)
+/*
+ * The size of the 'buffer' data array in each segment.
+ */
+#define SW_SEG_DATA_SIZE (sw_buffer_alloc_size)
+/*
+ * Min size of per-cpu output buffers.
+ */
+#define SW_MIN_SEG_SIZE_BYTES (1 << 10) /* 1kB */
+#define SW_MIN_OUTPUT_BUFFER_SIZE (SW_MIN_SEG_SIZE_BYTES * NUM_SEGS_PER_BUFFER)
+/*
+ * A symbolic constant for an empty buffer index.
+ */
+#define EMPTY_SEG (-1)
+/*
+ * How much space is available in a given segment?
+ */
+#define EMPTY_TSC ((u64)-1)
+#define SEG_IS_FULL(seg) ({bool __full = false; \
+	smp_mb(); /* memory access ordering */\
+	__full = ((seg)->is_full != EMPTY_TSC); \
+	__full; })
+#define SEG_SET_FULL(seg, tsc) do { \
+	(seg)->is_full = (tsc); \
+	smp_mb(); /* memory access ordering */\
+} while (0)
+#define SEG_SET_EMPTY(seg) do { \
+	barrier(); \
+	(seg)->bytes_written = 0; \
+	SEG_SET_FULL(seg, EMPTY_TSC); \
+} while (0)
+#define SPACE_AVAIL(seg) (SW_SEG_DATA_SIZE - (seg)->bytes_written)
+#define SEG_IS_EMPTY(seg) (SPACE_AVAIL(seg) == SW_SEG_DATA_SIZE)
+
+#define GET_OUTPUT_BUFFER(cpu) (&per_cpu_output_buffers[(cpu)])
+/*
+ * Convenience macro: iterate over each segment in a per-cpu output buffer.
+ */
+#define for_each_segment(i) for (i = 0; i < NUM_SEGS_PER_BUFFER; ++i)
+#define for_each_seg(buffer, seg)					 \
+	for (int i = 0;							 \
+		i < NUM_SEGS_PER_BUFFER && (seg = (buffer)->segments[i]);\
+		++i)
+/*
+ * How many buffers are we using?
+ */
+#define GET_NUM_OUTPUT_BUFFERS() (sw_max_num_cpus + 1)
+/*
+ * Convenience macro: iterate over each per-cpu output buffer.
+ */
+#define for_each_output_buffer(i) for (i = 0; i < GET_NUM_OUTPUT_BUFFERS(); ++i)
+
+/* -------------------------------------------------
+ * Local data structures.
+ * -------------------------------------------------
+ */
+struct sw_data_buffer {
+	u64 is_full;
+	u32 bytes_written;
+	char *buffer;
+} __packed;
+#define SW_SEG_HEADER_SIZE() (sizeof(struct sw_data_buffer) - sizeof(char *))
+
+struct sw_output_buffer {
+	struct sw_data_buffer buffers[NUM_SEGS_PER_BUFFER];
+	int buff_index;
+	u32 produced_samples;
+	u32 dropped_samples;
+	int last_seg_read;
+	unsigned int mem_alloc_size;
+	unsigned long free_pages;
+} ____cacheline_aligned_in_smp;
+
+/* *************************************************
+ * For circular buffer (continuous profiling)
+ * *************************************************
+ */
+static char *output_buffer;
+
+struct buffer {
+	union {
+		char *data;
+		unsigned long free_pages;
+	};
+	size_t read_index, write_index;
+	unsigned long size;
+};
+SW_DECLARE_RWLOCK(sw_continuous_lock);
+
+static struct buffer buffer; /* TODO: rename */
+
+/* -------------------------------------------------
+ * Function declarations.
+ * -------------------------------------------------
+ */
+extern u64 sw_timestamp(void);
+
+/* -------------------------------------------------
+ * Variable definitions.
+ * -------------------------------------------------
+ */
+u64 sw_num_samples_produced = 0, sw_num_samples_dropped = 0;
+int sw_max_num_cpus = -1;
+
+DECLARE_OVERHEAD_VARS(sw_produce_generic_msg_i);
+/*
+ * Per-cpu output buffers.
+ */
+static struct sw_output_buffer *per_cpu_output_buffers;
+/*
+ * Variables for book keeping.
+ */
+static volatile int sw_last_cpu_read = -1;
+static volatile s32 sw_last_mask = -1;
+/*
+ * Lock for the polled buffer.
+ */
+SW_DECLARE_SPINLOCK(sw_polled_lock);
+/*
+ * Buffer allocation size.
+ */
+unsigned long sw_buffer_alloc_size = (1 << 16); /* 64 KB */
+
+/* -------------------------------------------------
+ * Function definitions.
+ * -------------------------------------------------
+ */
+
+/* *************************************************
+ * For circular buffer (continuous profiling)
+ * *************************************************
+ */
+#define MIN(x, y) ((x) <= (y) ? (x) : (y))
+
+#define IS_BUFFER_EMPTY(buffer)					\
+	((buffer).write_index == (buffer).read_index)
+#define IS_BUFFER_FULL(buffer)					\
+	((buffer).write_index ==				\
+		((buffer).read_index + 1) & (buffer.size - 1))
+
+static inline size_t get_space_available(struct buffer *buffer)
+{
+	size_t read = 0, write = 0;
+
+	smp_mb(); /* memory access ordering */
+	read = buffer->read_index;
+	write = buffer->write_index;
+	if (write < read)
+		return read - write;
+
+	return (buffer->size - write) + read;
+}
+
+static inline size_t get_data_available(struct buffer *buffer)
+{
+	size_t read = 0, write = 0;
+
+	smp_mb(); /* memory access ordering */
+	read = buffer->read_index;
+	write = buffer->write_index;
+	if (read <= write)
+		return write - read;
+
+	return (buffer->size - read) + write;
+}
+
+static void copy_wraparound(const char *src, size_t src_size, size_t *index)
+{
+	size_t buff_size_left = buffer.size - *index;
+	size_t to_write = MIN(buff_size_left, src_size);
+	size_t _index = *index;
+
+	if (src_size < buff_size_left) {
+		memcpy(&buffer.data[_index], src, src_size);
+		_index += src_size;
+	} else {
+		memcpy(&buffer.data[_index], src, to_write);
+		_index = 0;
+		src += to_write;
+		to_write = src_size - to_write;
+		memcpy(&buffer.data[_index], src, to_write);
+		_index += to_write;
+		pw_pr_debug("DEBUG: wrap memcpy\n");
+	}
+	*index = (*index + src_size) & (buffer.size - 1);
+}
+
+static int enqueue_data(struct sw_driver_msg *msg, enum sw_wakeup_action action)
+{
+	size_t size = SW_DRIVER_MSG_HEADER_SIZE() + msg->payload_len;
+	bool wrapped = false;
+
+	msg->tsc = 0;
+
+	READ_LOCK(sw_continuous_lock);
+	while (true) {
+		size_t old_write_index = buffer.write_index;
+		size_t new_write_index = (old_write_index + size) &
+						(buffer.size - 1);
+
+		if (get_space_available(&buffer) < size)
+			break;
+
+		if (CAS32(&buffer.write_index, old_write_index,
+				new_write_index)) {
+			msg->tsc = sw_timestamp();
+			wrapped = new_write_index <= old_write_index;
+			/* First copy header */
+			copy_wraparound((const char *)msg,
+				SW_DRIVER_MSG_HEADER_SIZE(), &old_write_index);
+			/* Then copy payload */
+			copy_wraparound((const char *)msg->p_payload,
+				msg->payload_len, &old_write_index);
+			break;
+		}
+	}
+	READ_UNLOCK(sw_continuous_lock);
+	if (!msg->tsc)
+		pw_pr_error("ERROR: couldn't enqueue data\n");
+	if (wrapped)
+		pw_pr_debug("DEBUG: wrapped!\n");
+
+	return msg->tsc ? 0 : -1;
+}
+
+/*
+ * Returns # of bytes successfully consumed on success
+ * 0 on EOF (no error condition)
+ */
+static size_t consume_buffer(void *dest, size_t bytes_to_read)
+{
+	size_t read_index = 0, write_index = 0, dst_index = 0;
+	size_t to_read = 0;
+	bool wrapped = false;
+	size_t read_size = bytes_to_read;
+	unsigned long bytes_not_copied = 0;
+	struct sw_driver_continuous_collect data = {0};
+
+	WRITE_LOCK(sw_continuous_lock);
+	smp_mb(); /* memory access ordering */
+	read_index = buffer.read_index;
+	write_index = buffer.write_index;
+	/* EXE sends size as header + payload; we only want payload */
+	read_size -= SW_DRIVER_CONTINUOUS_COLLECT_HEADER_SIZE();
+	data.collection_size = to_read =
+		MIN(read_size, get_data_available(&buffer));
+	pw_pr_debug(
+		"DEBUG: read = %zu, write = %zu, avail = %zu, to_read = %zu\n",
+		read_index, write_index, get_data_available(&buffer), to_read);
+	while (to_read) {
+		size_t curr_read = to_read;
+
+		if (read_index + to_read > buffer.size) {
+			curr_read = buffer.size - read_index;
+			wrapped = true;
+			pw_pr_debug(
+				"DEBUG: read = %zu, to_read = %zu, curr_read = %zu, buffer.size = %lu, WRAPPED!\n",
+				read_index, to_read, curr_read, buffer.size);
+		}
+		memcpy(&output_buffer[dst_index],
+			&buffer.data[read_index], curr_read);
+		read_index = (read_index + curr_read) & (buffer.size - 1);
+		to_read -= curr_read;
+		dst_index += curr_read;
+	}
+	buffer.read_index = read_index;
+	smp_mb(); /* memory access ordering */
+	pw_pr_debug("DEBUG: read at end of while = %zu\n", buffer.read_index);
+	WRITE_UNLOCK(sw_continuous_lock);
+
+	/*
+	 * Call 'copy_to_user' instead of 'sw_copy_to_user' since
+	 * sw_copy_to_user expects to see a 'struct uio' while this
+	 * is called from an IOCTL which does NOT have a 'struct uio'
+	 */
+	bytes_not_copied =
+	copy_to_user(dest, (char *)&data,
+		SW_DRIVER_CONTINUOUS_COLLECT_HEADER_SIZE());
+	if (bytes_not_copied)
+		return 0;
+
+	pw_pr_debug("DEBUG: collection size = %u\n", data.collection_size);
+	if (data.collection_size) {
+		bytes_not_copied =
+			copy_to_user(dest +
+				SW_DRIVER_CONTINUOUS_COLLECT_HEADER_SIZE(),
+				output_buffer, data.collection_size);
+		if (bytes_not_copied)
+			return 0;
+
+	}
+	return data.collection_size;
+}
+
+long initialize_circular_buffer(size_t size)
+{
+	size_t alloc_size = size, read_size = size;
+	/*
+	 * We require a power of two size
+	 */
+	pw_pr_debug("DEBUG: old alloc size = %zu\n", alloc_size);
+	if ((alloc_size & (alloc_size - 1)) != 0)
+		alloc_size = 1 << fls(alloc_size);
+
+	pw_pr_debug("DEBUG: new alloc size = %zu\n", alloc_size);
+	/* Create double-sized buffer */
+	alloc_size <<= 1;
+	pw_pr_debug("DEBUG: double alloc size = %zu\n", alloc_size);
+	memset(&buffer, 0, sizeof(buffer));
+	buffer.free_pages =
+		sw_allocate_pages(GFP_KERNEL | __GFP_ZERO, alloc_size);
+	if (!buffer.free_pages) {
+		pw_pr_error("Couldn't allocate space for buffer!\n");
+		return -ENOMEM;
+	}
+	buffer.read_index = buffer.write_index = 0;
+	buffer.size = alloc_size;
+	SW_INIT_RWLOCK(sw_continuous_lock);
+	/*
+	 * Create temp output buffer
+	 */
+	output_buffer = vmalloc(read_size);
+	if (!output_buffer) {
+		pw_pr_error(
+			"Couldn't create temporary buffer for data output!\n");
+		return -ENOMEM;
+	}
+	return 0;
+}
+
+void reset_output_buffers(void)
+{
+	buffer.read_index = buffer.write_index = 0;
+}
+
+
+void destroy_circular_buffer(void)
+{
+	if (buffer.free_pages) {
+		sw_release_pages(buffer.free_pages, buffer.size);
+		buffer.free_pages = 0;
+	}
+	if (output_buffer) {
+		vfree(output_buffer);
+		output_buffer = NULL;
+	}
+	SW_DESTROY_RWLOCK(sw_continuous_lock);
+	pw_pr_debug("DEBUG: read = %zu, write = %zu\n", buffer.read_index,
+	buffer.write_index);
+}
+
+/* *************************************************
+ * For per-cpu buffers (non circular)
+ * *************************************************
+ */
+
+static char *reserve_seg_space_i(size_t size, int cpu, bool *should_wakeup,
+	u64 *reservation_tsc)
+{
+	struct sw_output_buffer *buffer = GET_OUTPUT_BUFFER(cpu);
+	int i = 0;
+	int buff_index = buffer->buff_index;
+	char *dst = NULL;
+
+	if (buff_index < 0 || buff_index >= NUM_SEGS_PER_BUFFER)
+		goto prod_seg_done;
+
+	for_each_segment(i) {
+		struct sw_data_buffer *seg = &buffer->buffers[buff_index];
+
+		if (SEG_IS_FULL(seg) == false) {
+			if (SPACE_AVAIL(seg) >= size) {
+				*reservation_tsc = sw_timestamp();
+				dst = &seg->buffer[seg->bytes_written];
+				seg->bytes_written += size;
+				smp_mb(); /* memory access ordering */
+				buffer->buff_index = buff_index;
+				buffer->produced_samples++;
+				goto prod_seg_done;
+			}
+			SEG_SET_FULL(seg, sw_timestamp());
+		}
+		buff_index = CIRCULAR_INC(buff_index, NUM_SEGS_PER_BUFFER_MASK);
+		*should_wakeup = true;
+	}
+prod_seg_done:
+	if (!dst)
+		buffer->dropped_samples++;
+
+	return dst;
+};
+
+#ifdef CONFIG_PREEMPT_COUNT
+static int produce_polled_msg(struct sw_driver_msg *msg,
+	enum sw_wakeup_action action)
+{
+	int cpu = GET_POLLED_CPU();
+	bool should_wakeup = false;
+	int retVal = PW_SUCCESS;
+
+	if (!msg)
+		return -PW_ERROR;
+
+	pw_pr_debug("POLLED! cpu = %d\n", cpu);
+	LOCK(sw_polled_lock);
+	{
+		size_t size = SW_DRIVER_MSG_HEADER_SIZE() + msg->payload_len;
+		char *dst = reserve_seg_space_i(size, cpu,
+						&should_wakeup, &msg->tsc);
+
+		if (dst) {
+			/*
+			 * Assign a special CPU number to this CPU.
+			 * This is OK, because messages enqueued in this buffer
+			 * are always CPU agnostic (otherwise they would
+			 * be invoked from within a preempt_disable()d context
+			 * in 'sw_handle_collector_node_i()', which ensures
+			 * they will be enqueued within the
+			 * 'sw_produce_generic_msg_on_cpu()' function).
+			 */
+			msg->cpuidx = cpu;
+			memcpy(dst, msg, SW_DRIVER_MSG_HEADER_SIZE());
+			dst += SW_DRIVER_MSG_HEADER_SIZE();
+			memcpy(dst, msg->p_payload, msg->payload_len);
+		} else {
+			pw_pr_debug("NO space in polled msg!\n");
+			retVal = -PW_ERROR;
+		}
+	}
+	UNLOCK(sw_polled_lock);
+	if (unlikely(should_wakeup))
+		sw_wakeup_reader(action);
+
+	return retVal;
+};
+#endif /* CONFIG_PREEMPT_COUNT */
+
+static int sw_produce_generic_msg_i(struct sw_driver_msg *msg,
+	enum sw_wakeup_action action)
+{
+	int retval = PW_SUCCESS;
+	bool should_wakeup = false;
+	int cpu = -1;
+	unsigned long flags = 0;
+
+	if (!msg) {
+		pw_pr_error("ERROR: CANNOT produce a NULL msg!\n");
+		return -PW_ERROR;
+	}
+
+	/* Check if we need to use circular buffer */
+	if (output_buffer)
+		return enqueue_data(msg, action);
+
+#ifdef CONFIG_PREEMPT_COUNT
+	if (!in_atomic())
+		return produce_polled_msg(msg, action);
+#endif
+
+	cpu = sw_get_cpu(&flags);
+	{
+		size_t size = msg->payload_len +
+				SW_DRIVER_MSG_HEADER_SIZE();
+		char *dst = reserve_seg_space_i(size, cpu, &should_wakeup,
+						&msg->tsc);
+
+		if (likely(dst)) {
+			memcpy(dst, msg, SW_DRIVER_MSG_HEADER_SIZE());
+			dst += SW_DRIVER_MSG_HEADER_SIZE();
+			memcpy(dst, msg->p_payload, msg->payload_len);
+		} else
+			retval = -PW_ERROR;
+	}
+	sw_put_cpu(flags);
+
+	if (unlikely(should_wakeup))
+		sw_wakeup_reader(action);
+
+	return retval;
+};
+
+int sw_produce_generic_msg(struct sw_driver_msg *msg,
+	enum sw_wakeup_action action)
+{
+	return DO_PER_CPU_OVERHEAD_FUNC_RET(int, sw_produce_generic_msg_i,
+		msg, action);
+};
+
+static int sw_init_per_cpu_buffers_i(unsigned long per_cpu_mem_size)
+{
+	int cpu = -1;
+
+	per_cpu_output_buffers =
+	(struct sw_output_buffer *)sw_kmalloc(sizeof(struct sw_output_buffer) *
+	GET_NUM_OUTPUT_BUFFERS(), GFP_KERNEL | __GFP_ZERO);
+	if (per_cpu_output_buffers == NULL) {
+		pw_pr_error(
+			"ERROR allocating space for per-cpu output buffers!\n");
+		sw_destroy_per_cpu_buffers();
+		return -PW_ERROR;
+	}
+	for_each_output_buffer(cpu) {
+		struct sw_output_buffer *buffer = &per_cpu_output_buffers[cpu];
+		char *buff = NULL;
+		int i = 0;
+
+		buffer->mem_alloc_size = per_cpu_mem_size;
+		buffer->free_pages = sw_allocate_pages(GFP_KERNEL | __GFP_ZERO,
+			(unsigned int)per_cpu_mem_size);
+		if (buffer->free_pages == 0) {
+			pw_pr_error("ERROR allocating pages for buffer [%d]!\n",
+				cpu);
+			sw_destroy_per_cpu_buffers();
+			return -PW_ERROR;
+		}
+		buff = (char *)buffer->free_pages;
+		for_each_segment(i) {
+			buffer->buffers[i].buffer = (char *)buff;
+			buff += SW_SEG_DATA_SIZE;
+		}
+	}
+	pw_pr_debug("PER_CPU_MEM_SIZE = %lu, order = %u\n",
+	(unsigned long)per_cpu_mem_size, get_order(per_cpu_mem_size));
+	return PW_SUCCESS;
+};
+
+int sw_init_per_cpu_buffers(void)
+{
+	unsigned int per_cpu_mem_size = sw_get_output_buffer_size();
+
+	pw_pr_debug("Buffer alloc size = %ld\n", sw_buffer_alloc_size);
+
+	if (GET_NUM_OUTPUT_BUFFERS() <= 0) {
+		pw_pr_error("ERROR: max # output buffers= %d\n",
+			GET_NUM_OUTPUT_BUFFERS());
+		return -PW_ERROR;
+	}
+
+	pw_pr_debug("DEBUG: sw_max_num_cpus = %d, num output buffers = %d\n",
+	sw_max_num_cpus, GET_NUM_OUTPUT_BUFFERS());
+
+	/*
+	 * Try to allocate per-cpu buffers. If allocation fails, decrease
+	 * buffer size and retry. Stop trying if size drops below 2KB
+	 * (which means 1KB for each buffer).
+	 */
+	while (per_cpu_mem_size >= SW_MIN_OUTPUT_BUFFER_SIZE &&
+		sw_init_per_cpu_buffers_i(per_cpu_mem_size)) {
+		pw_pr_debug("WARNING: couldn't allocate per-cpu buffers with size %u -- trying smaller size!\n",
+			per_cpu_mem_size);
+		sw_buffer_alloc_size >>= 1;
+		per_cpu_mem_size = sw_get_output_buffer_size();
+	}
+
+	if (unlikely(per_cpu_output_buffers == NULL)) {
+		pw_pr_error("ERROR: couldn't allocate space for per-cpu output buffers!\n");
+		return -PW_ERROR;
+	}
+	/*
+	 * Initialize our locks.
+	 */
+	SW_INIT_SPINLOCK(sw_polled_lock);
+
+	pw_pr_debug("OK, allocated per-cpu buffers with size = %lu\n",
+		(unsigned long)per_cpu_mem_size);
+
+	if (sw_init_reader_queue()) {
+		pw_pr_error("ERROR initializing reader subsys\n");
+		return -PW_ERROR;
+	}
+
+	return PW_SUCCESS;
+};
+
+void sw_destroy_per_cpu_buffers(void)
+{
+	int cpu = -1;
+
+	/*
+	 * Perform lock finalization.
+	 */
+	SW_DESTROY_SPINLOCK(sw_polled_lock);
+
+	if (per_cpu_output_buffers != NULL) {
+		for_each_output_buffer(cpu) {
+			struct sw_output_buffer *buffer =
+					&per_cpu_output_buffers[cpu];
+
+			if (buffer->free_pages != 0) {
+				sw_release_pages(buffer->free_pages,
+					buffer->mem_alloc_size);
+				buffer->free_pages = 0;
+			}
+		}
+		sw_kfree(per_cpu_output_buffers);
+		per_cpu_output_buffers = NULL;
+	}
+};
+
+void sw_reset_per_cpu_buffers(void)
+{
+	int cpu = 0, i = 0;
+
+	for_each_output_buffer(cpu) {
+		struct sw_output_buffer *buffer = GET_OUTPUT_BUFFER(cpu);
+
+		buffer->buff_index = buffer->dropped_samples =
+			buffer->produced_samples = 0;
+		buffer->last_seg_read = -1;
+
+		for_each_segment(i) {
+			struct sw_data_buffer *seg = &buffer->buffers[i];
+
+			memset(seg->buffer, 0, SW_SEG_DATA_SIZE);
+			SEG_SET_EMPTY(seg);
+		}
+	}
+	sw_last_cpu_read = -1;
+	sw_last_mask = -1;
+	pw_pr_debug("OK, reset per-cpu output buffers!\n");
+	/*
+	 * Reset circular buffer if it has been allocated
+	 */
+	if (output_buffer)
+		buffer.read_index = buffer.write_index = 0;
+
+};
+
+bool sw_any_seg_full(u32 *val, bool is_flush_mode)
+{
+	int num_visited = 0, i = 0;
+
+	if (!val) {
+		pw_pr_error("ERROR: NULL ptrs in %s!\n", __func__);
+		return false;
+	}
+
+	*val = SW_NO_DATA_AVAIL_MASK;
+	pw_pr_debug("Checking for full seg: val = %u, flush = %s\n",
+		 *val, GET_BOOL_STRING(is_flush_mode));
+	for_each_output_buffer(num_visited) {
+		int min_seg = EMPTY_SEG, non_empty_seg = EMPTY_SEG;
+		u64 min_tsc = EMPTY_TSC;
+		struct sw_output_buffer *buffer = NULL;
+
+		if (++sw_last_cpu_read >= GET_NUM_OUTPUT_BUFFERS())
+			sw_last_cpu_read = 0;
+
+		buffer = GET_OUTPUT_BUFFER(sw_last_cpu_read);
+		for_each_segment(i) {
+			struct sw_data_buffer *seg = &buffer->buffers[i];
+			u64 seg_tsc = seg->is_full;
+
+			if (SEG_IS_EMPTY(seg))
+				continue;
+
+			non_empty_seg = i;
+			if (seg_tsc < min_tsc) {
+				/*
+				 * Can only happen if seg was full, provided
+				 * 'EMPTY_TSC' is set to "(u64)-1"
+				 */
+				min_tsc = seg_tsc;
+				min_seg = i;
+			}
+		}
+		if (min_seg != EMPTY_SEG) {
+			*val = (sw_last_cpu_read & 0xffff) << 16 |
+				(min_seg & 0xffff);
+			return true;
+		} else if (is_flush_mode && non_empty_seg != EMPTY_SEG) {
+			*val = (sw_last_cpu_read & 0xffff) << 16 |
+				(non_empty_seg & 0xffff);
+			return true;
+		}
+	}
+	/*
+	 * Reaches here only if there's no data to be read.
+	 */
+	if (is_flush_mode) {
+		/*
+		 * We've drained all buffers and need to tell the userspace
+		 * application there isn't any data. Unfortunately, we can't
+		 * just return a 'zero' value for the mask (because that could
+		 * also indicate that segment # 0 of cpu #0 has data).
+		 */
+		*val = SW_ALL_WRITES_DONE_MASK;
+		return true;
+	}
+	return false;
+};
+
+/*
+ * Returns: number of bytes consumed on SUCCESS, 0 on EOF, negative
+ * error code on FAILURE
+ */
+ssize_t sw_consume_data(u32 mask, void __user *buffer, size_t bytes_to_read)
+{
+	int which_cpu = -1, which_seg = -1;
+	unsigned long bytes_not_copied = 0;
+	struct sw_output_buffer *buff = NULL;
+	struct sw_data_buffer *seg = NULL;
+	size_t bytes_read = 0;
+
+	/* Check if we need to use circular buffer */
+	if (output_buffer)
+		return (ssize_t)consume_buffer(buffer, bytes_to_read);
+
+	if (!sw_check_output_buffer_params(buffer, bytes_to_read,
+			SW_SEG_DATA_SIZE)) {
+		pw_pr_error("ERROR: invalid params to \"%s\"!\n", __func__);
+		return -EIO;
+	}
+
+	which_cpu = mask >> 16; which_seg = mask & 0xffff;
+	pw_pr_debug("CONSUME: cpu = %d, seg = %d\n", which_cpu, which_seg);
+	if (which_seg >= NUM_SEGS_PER_BUFFER) {
+		pw_pr_error(
+			"Error: which_seg (%d) >= NUM_SEGS_PER_BUFFER (%d)\n",
+			which_seg, NUM_SEGS_PER_BUFFER);
+		return -EIO;
+	}
+	/*
+	 * OK to access unlocked; either the segment is FULL, or no collection
+	 * is ongoing. In either case, we're GUARANTEED no producer is touching
+	 * this segment.
+	 */
+	buff = GET_OUTPUT_BUFFER(which_cpu);
+	seg = &buff->buffers[which_seg];
+
+	bytes_not_copied = sw_copy_to_user(buffer,
+		seg->buffer, seg->bytes_written); /* dst, src */
+
+	if (likely(bytes_not_copied == 0))
+		bytes_read = seg->bytes_written;
+	else {
+		pw_pr_error("Warning: couldn't copy %lu bytes\n",
+			bytes_not_copied);
+		bytes_read = 0;
+	}
+	SEG_SET_EMPTY(seg);
+	return bytes_read;
+}
+
+unsigned int sw_get_output_buffer_size(void)
+{
+	return (sw_buffer_alloc_size * NUM_SEGS_PER_BUFFER);
+};
+
+void sw_count_samples_produced_dropped(void)
+{
+	int cpu = 0;
+
+	sw_num_samples_produced = sw_num_samples_dropped = 0;
+	if (per_cpu_output_buffers == NULL)
+		return;
+
+	for_each_output_buffer(cpu) {
+		struct sw_output_buffer *buff = GET_OUTPUT_BUFFER(cpu);
+
+		sw_num_samples_dropped += buff->dropped_samples;
+		sw_num_samples_produced += buff->produced_samples;
+	}
+};
+
+void sw_print_output_buffer_overheads(void)
+{
+	PRINT_CUMULATIVE_OVERHEAD_PARAMS(sw_produce_generic_msg_i,
+		"PRODUCE_GENERIC_MSG");
+	sw_print_reader_stats();
+};
diff --git a/drivers/platform/x86/socwatch/sw_reader.c b/drivers/platform/x86/socwatch/sw_reader.c
index 99e0b54747c0..ea039c6fe72a 100644
--- a/drivers/platform/x86/socwatch/sw_reader.c
+++ b/drivers/platform/x86/socwatch/sw_reader.c
@@ -1,159 +1,159 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#include "sw_internal.h"
-#include "sw_output_buffer.h"
-#include "sw_kernel_defines.h"
-
-/* delay buffer cleanup by 10^6 nsec i.e. 1 msec */
-#define SW_BUFFER_CLEANUP_TIMER_DELAY_NSEC 1000000
-
-/*
- * The alarm queue.
- */
-wait_queue_head_t sw_reader_queue;
-/*
- * Reader wakeup timer.
- */
-static struct hrtimer s_reader_wakeup_timer;
-/*
- * Variable to track # timer fires.
- */
-static int s_num_timer_fires;
-
-/*
- * The alarm callback.
- */
-static enum hrtimer_restart sw_wakeup_callback_i(struct hrtimer *timer)
-{
-	++s_num_timer_fires;
-	wake_up_interruptible(&sw_reader_queue);
-	return HRTIMER_NORESTART;
-}
-
-/*
- * Init reader queue.
- */
-int sw_init_reader_queue(void)
-{
-	init_waitqueue_head(&sw_reader_queue);
-	/*
-	 * Also init wakeup timer (used in low-overhead mode).
-	 */
-	hrtimer_init(&s_reader_wakeup_timer,
-		CLOCK_MONOTONIC, HRTIMER_MODE_REL);
-	s_reader_wakeup_timer.function = &sw_wakeup_callback_i;
-
-	return PW_SUCCESS;
-}
-/*
- * Destroy reader queue.
- */
-void sw_destroy_reader_queue(void)
-{
-	/* NOP */
-}
-/*
- * Wakeup client waiting for a full buffer.
- */
-void sw_wakeup_reader(enum sw_wakeup_action action)
-{
-	if (waitqueue_active(&sw_reader_queue)) { /* direct mode */
-		switch (action) {
-		case SW_WAKEUP_ACTION_DIRECT:
-			wake_up_interruptible(&sw_reader_queue);
-			break;
-		case SW_WAKEUP_ACTION_TIMER:
-			if (!hrtimer_active(&s_reader_wakeup_timer)) {
-				ktime_t ktime = ns_to_ktime(
-					SW_BUFFER_CLEANUP_TIMER_DELAY_NSEC);
-				/* TODO: possible race here --
-				 * introduce locks?
-				 */
-				hrtimer_start(&s_reader_wakeup_timer,
-					ktime, HRTIMER_MODE_REL);
-			}
-			break;
-		default:
-			break;
-		}
-	}
-}
-/*
- * Wakeup client waiting for a full buffer, and
- * cancel any timers initialized by the reader
- * subsys.
- */
-void sw_cancel_reader(void)
-{
-	/*
-	 * Cancel pending wakeup timer (used in low-overhead mode).
-	 */
-	if (hrtimer_active(&s_reader_wakeup_timer))
-		hrtimer_cancel(&s_reader_wakeup_timer);
-
-	/*
-	 * There might be a reader thread blocked on a read: wake
-	 * it up to give it a chance to respond to changed
-	 * conditions.
-	 */
-	sw_wakeup_reader(SW_WAKEUP_ACTION_DIRECT);
-}
-
-void sw_print_reader_stats(void)
-{
-#if DO_OVERHEAD_MEASUREMENTS
-	pw_pr_debug("# reader queue timer fires = %d\n", s_num_timer_fires);
-#endif /* OVERHEAD */
-}
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "sw_internal.h"
+#include "sw_output_buffer.h"
+#include "sw_kernel_defines.h"
+
+/* delay buffer cleanup by 10^6 nsec i.e. 1 msec */
+#define SW_BUFFER_CLEANUP_TIMER_DELAY_NSEC 1000000
+
+/*
+ * The alarm queue.
+ */
+wait_queue_head_t sw_reader_queue;
+/*
+ * Reader wakeup timer.
+ */
+static struct hrtimer s_reader_wakeup_timer;
+/*
+ * Variable to track # timer fires.
+ */
+static int s_num_timer_fires;
+
+/*
+ * The alarm callback.
+ */
+static enum hrtimer_restart sw_wakeup_callback_i(struct hrtimer *timer)
+{
+	++s_num_timer_fires;
+	wake_up_interruptible(&sw_reader_queue);
+	return HRTIMER_NORESTART;
+}
+
+/*
+ * Init reader queue.
+ */
+int sw_init_reader_queue(void)
+{
+	init_waitqueue_head(&sw_reader_queue);
+	/*
+	 * Also init wakeup timer (used in low-overhead mode).
+	 */
+	hrtimer_init(&s_reader_wakeup_timer,
+		CLOCK_MONOTONIC, HRTIMER_MODE_REL);
+	s_reader_wakeup_timer.function = &sw_wakeup_callback_i;
+
+	return PW_SUCCESS;
+}
+/*
+ * Destroy reader queue.
+ */
+void sw_destroy_reader_queue(void)
+{
+	/* NOP */
+}
+/*
+ * Wakeup client waiting for a full buffer.
+ */
+void sw_wakeup_reader(enum sw_wakeup_action action)
+{
+	if (waitqueue_active(&sw_reader_queue)) { /* direct mode */
+		switch (action) {
+		case SW_WAKEUP_ACTION_DIRECT:
+			wake_up_interruptible(&sw_reader_queue);
+			break;
+		case SW_WAKEUP_ACTION_TIMER:
+			if (!hrtimer_active(&s_reader_wakeup_timer)) {
+				ktime_t ktime = ns_to_ktime(
+					SW_BUFFER_CLEANUP_TIMER_DELAY_NSEC);
+				/* TODO: possible race here --
+				 * introduce locks?
+				 */
+				hrtimer_start(&s_reader_wakeup_timer,
+					ktime, HRTIMER_MODE_REL);
+			}
+			break;
+		default:
+			break;
+		}
+	}
+}
+/*
+ * Wakeup client waiting for a full buffer, and
+ * cancel any timers initialized by the reader
+ * subsys.
+ */
+void sw_cancel_reader(void)
+{
+	/*
+	 * Cancel pending wakeup timer (used in low-overhead mode).
+	 */
+	if (hrtimer_active(&s_reader_wakeup_timer))
+		hrtimer_cancel(&s_reader_wakeup_timer);
+
+	/*
+	 * There might be a reader thread blocked on a read: wake
+	 * it up to give it a chance to respond to changed
+	 * conditions.
+	 */
+	sw_wakeup_reader(SW_WAKEUP_ACTION_DIRECT);
+}
+
+void sw_print_reader_stats(void)
+{
+#if DO_OVERHEAD_MEASUREMENTS
+	pw_pr_debug("# reader queue timer fires = %d\n", s_num_timer_fires);
+#endif /* OVERHEAD */
+}
diff --git a/drivers/platform/x86/socwatch/sw_telem.c b/drivers/platform/x86/socwatch/sw_telem.c
index 1bc0f63dfa20..eb162b1b28e3 100644
--- a/drivers/platform/x86/socwatch/sw_telem.c
+++ b/drivers/platform/x86/socwatch/sw_telem.c
@@ -1,873 +1,873 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-
-#include <linux/module.h>
-#include <linux/init.h>
-#include <linux/compiler.h>     /* Definition of __weak */
-#include <linux/version.h>      /* LINUX_VERSION_CODE */
-#include <linux/delay.h>        /* 'udelay' */
-#include <linux/io.h>           /* Definition of ioremap_nocache and iounmap */
-#include "sw_kernel_defines.h"  /* pw_pr_debug */
-#include "sw_mem.h"             /* sw_kmalloc/free */
-#include "sw_lock_defs.h"       /* Various lock-related definitions */
-#include "sw_telem.h"           /* Signatures of fn's exported from here. */
-
-/*
- * These functions and data structures are exported by the Telemetry
- * driver.  However, that file may not be available in the kernel for
- * which this driver is being built, so we re-define many of the same
- * things here.
- */
-/**
- * struct telemetry_evtlog - The "event log" returned by the kernel's
- *                           full-read telemetry driver.
- * @telem_evtid:   The 16-bit event ID.
- * @telem_evtlog:  The actual telemetry data.
- */
-struct telemetry_evtlog {
-	u32 telem_evtid;	/* Event ID of a data item. */
-	u64 telem_evtlog;   /* Counter data */
-};
-
-struct telemetry_evtconfig {
-	u32 *evtmap;	/* Array of Event-IDs to Enable */
-	u8 num_evts;	/* Number of Events (<29) in evtmap */
-	u8 period;	  /* Sampling period */
-};
-
-#define MAX_TELEM_EVENTS 28  /* Max telem events per unit */
-
-/* The enable bit is set when programming events, but is returned
- * cleared for queried events requests.
- */
-#define TELEM_EVENT_ENABLE 0x8000 /* Enabled when Event ID HIGH bit */
-
-/*
- * Sampling Period values.
- * The sampling period is encoded in an 7-bit value, where
- *	Period = (Value * 16^Exponent) usec where:
- *		bits[6:3] -> Value;
- *		bits [0:2]-> Exponent;
- * Here are some of the calculated possible values:
- * | Value  Val+Exp  | Value | Exponent | Period (usec) | Period (msec) |
- * |-----------------+-------+----------+---------------+---------------|
- * | 0xA = 000 1+010 |   1   |     2    |           256 |         0.256 |
- * | 0x12= 001 0+010 |   2   |     2    |           512 |         0.512 |
- * | 0x22= 010 0+010 |   4   |     2    |          1024 |         1.024 |
- * | 0xB = 000 1+011 |   1   |     3    |          4096 |         4.096 |
- * | 0x13= 001 0+011 |   2   |     3    |          8192 |         8.192 |
- * | 0x1B= 001 1+011 |   3   |     3    |         12288 |        12.288 |
- * | 0x0C= 000 1+100 |   1   |     4    |         65536 |        65.536 |
- * | 0x0D= 000 1+101 |   1   |     5    |       1048576 |      1048.576 |
- */
-#define TELEM_SAMPLING_1MS 0x22  /* Approximately 1 ms */
-#define TELEM_SAMPLING_1S  0x0D  /* Approximately 1 s */
-
-/* These functions make up the main APIs of the telemetry driver.  We
- * define all of them with weak linkage so that we can still compile
- * and load into kernels which don't have a telemetry driver.
- */
-extern int __weak telemetry_get_eventconfig(
-	struct telemetry_evtconfig *punit_config,
-	struct telemetry_evtconfig *pmc_config,
-	int  punit_len,
-	int  pmc_len);
-
-extern int __weak telemetry_reset_events(void);
-
-extern int __weak telemetry_set_sampling_period(
-	u8 punit_period,
-	u8 pmc_period);
-/*
- * Older kernels didn't have the p-unit/pmc ipc command interface
- */
-extern int __weak intel_punit_ipc_command(
-	u32 cmd, u32 para1, u32 para2, u32 *in, u32 *out);
-
-extern int __weak intel_pmc_ipc_command(
-	u32 cmd, u32 sub, u8 *in, u32 inlen, u32 *out, u32 outlen);
-/*
- * Spinlock to guard updates to the 'iters' values.
- */
-static SW_DEFINE_SPINLOCK(sw_telem_lock);
-
-
-/* ************************************************
- * Constants for P-unit/PMC telemetry interface
- *  ***********************************************
- */
-
-#define PUNIT_MAILBOX_INTERFACE_OFFSET		0x7084
-#define PUNIT_MAILBOX_DATA_OFFSET		0x7080
-
-#define PSS_TELEM_SSRAM_OFFSET			0x1A00
-#define IOSS_TELEM_SSRAM_OFFSET			0x1B00
-#define TELEM_SSRAM_SIZE			240
-
-#define PMC_IPC_CMD				0x0
-
-#define PMC_IPC_STATUS				0x04
-
-#define PMC_IPC_WRITE_BUFFER			0x80
-#define PMC_IPC_READ_BUFFER			0x90
-
-#define PMC_IPC_PMC_TELEMETRY_COMMAND		0xEB
-
-
-#define TELEM_READ_TIMEOUT_TRIAL		10
-#define TELEM_MAILBOX_STATUS_TIMEOUT		1000
-
-#define IPC_BIOS_PUNIT_CMD_BASE			0x00
-
-#define IPC_BIOS_PUNIT_CMD_READ_TELE_INFO				\
-					(IPC_BIOS_PUNIT_CMD_BASE + 0x09)
-#define IPC_BIOS_PUNIT_CMD_READ_TELE_EVENT_CTRL				\
-					(IPC_BIOS_PUNIT_CMD_BASE + 0x0c)
-#define IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT_CTRL			\
-					(IPC_BIOS_PUNIT_CMD_BASE + 0x0d)
-#define IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT				\
-					(IPC_BIOS_PUNIT_CMD_BASE + 0x11)
-
-#define IOSS_TELEM_EVENT_WRITE			0x1
-#define IOSS_TELEM_INFO_READ			0x2
-#define IOSS_TELEM_EVENT_CTL_READ		0x7
-#define IOSS_TELEM_EVENT_CTL_WRITE		0x8
-
-#define IOSS_TELEM_EVT_CTRL_WRITE_SIZE		0x4
-#define IOSS_TELEM_READ_WORD			0x1
-#define IOSS_TELEM_EVT_WRITE_SIZE		0x3
-
-#ifndef BIT
-	#define BIT(x)				(1<<x)
-#endif /* BIT */
-
-#define TELEM_DISABLE(x)			((x) &= ~(BIT(31)))
-#define TELEM_ENABLE_SSRAM_EVT_TRACE(x)		((x) &= ~(BIT(30) | BIT(24)))
-#define TELEM_ENABLE_PERIODIC(x)	((x) |= (BIT(23) | BIT(31) | BIT(7)))
-#define TELEM_IOSS_EVTID_SHIFT			8
-
-#define TELEM_INFO_SSRAMEVTS_MASK		0xFF00
-#define TELEM_INFO_SSRAMEVTS_SHIFT		0x8
-
-#define TELEM_MIN_PERIOD(x)			((x) & 0x7F0000)
-#define TELEM_MAX_PERIOD(x)			((x) & 0x7F000000)
-#define TELEM_CLEAR_SAMPLE_PERIOD(x)		((x) &= ~0x7F)
-#define TELEM_DEFAULT_SAMPLING_PERIOD		TELEM_SAMPLING_1MS
-
-#define IS_TELEM_CONFIGURED()			\
-	(s_telemEventInfo[TELEM_PUNIT].idx > 0	\
-	|| s_telemEventInfo[TELEM_PMC].idx > 0)
-
-static u64 s_mchBarAddrs[3] = {0, 0, 0};
-
-static struct {
-	volatile u64 *ssram_virt_addr;
-	int idx, iters;
-	u32 events[MAX_TELEM_EVENTS];
-	u64 data_buffer[MAX_TELEM_EVENTS];
-} s_telemEventInfo[TELEM_UNIT_NONE] = {
-	[TELEM_PUNIT] = {NULL, 0, 0},
-	[TELEM_PMC] = {NULL, 0, 0},
-};
-
-static volatile u64 *s_punitInterfaceAddr;
-static volatile u64 *s_punitDataAddr;
-static volatile u64 *s_pmcIPCCmdAddr;
-static volatile u64 *s_pmcIPCStsAddr;
-static volatile u64 *s_pmcIPCWBufAddr;
-static volatile u64 *s_pmcIPCRBufAddr;
-
-/**
- * setup_punit_mbox -- Setup P-Unit virtual mappings
- *
- * Returns: true if setup successfully
- */
-static bool setup_punit_mbox(void)
-{
-	s_punitInterfaceAddr = (u64 *)ioremap_nocache(
-				(unsigned long)s_mchBarAddrs[TELEM_MCHBAR_CFG] +
-				PUNIT_MAILBOX_INTERFACE_OFFSET, 0x4);
-	s_punitDataAddr = (u64 *)ioremap_nocache(
-				(unsigned long)s_mchBarAddrs[TELEM_MCHBAR_CFG] +
-				PUNIT_MAILBOX_DATA_OFFSET, 0x4);
-	s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr = (u64 *)ioremap_nocache(
-				(unsigned long)
-					s_mchBarAddrs[TELEM_SSRAMBAR_CFG] +
-				PSS_TELEM_SSRAM_OFFSET, TELEM_SSRAM_SIZE);
-
-	return (s_punitInterfaceAddr && s_punitDataAddr &&
-		s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr);
-}
-
-/**
- * destroy_punit_mbox -- Unmap p-unit virtual addresses
- */
-static void destroy_punit_mbox(void)
-{
-	if (s_punitInterfaceAddr) {
-		iounmap(s_punitInterfaceAddr);
-		s_punitInterfaceAddr = NULL;
-	}
-	if (s_punitDataAddr) {
-		iounmap(s_punitDataAddr);
-		s_punitDataAddr = NULL;
-	}
-	if (s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr) {
-		iounmap(s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr);
-		s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr = NULL;
-	}
-}
-
-/**
- * setup_pmc_mbox -- Setup PMC virtual mappings
- *
- * Returns: true if setup successfully
- */
-static bool setup_pmc_mbox(void)
-{
-	s_pmcIPCCmdAddr = (u64 *)ioremap_nocache(
-			(unsigned long)s_mchBarAddrs[TELEM_IPC1BAR_CFG] +
-			PMC_IPC_CMD, 0x4);
-	s_pmcIPCStsAddr = (u64 *)ioremap_nocache(
-			(unsigned long)s_mchBarAddrs[TELEM_IPC1BAR_CFG] +
-			PMC_IPC_STATUS, 0x4);
-	s_pmcIPCWBufAddr = (u64 *)ioremap_nocache(
-			(unsigned long)s_mchBarAddrs[TELEM_IPC1BAR_CFG] +
-			PMC_IPC_WRITE_BUFFER, 0x4);
-	s_pmcIPCRBufAddr = (u64 *)ioremap_nocache(
-			(unsigned long)s_mchBarAddrs[TELEM_IPC1BAR_CFG] +
-			PMC_IPC_READ_BUFFER, 0x4);
-	s_telemEventInfo[TELEM_PMC].ssram_virt_addr = (u64 *)ioremap_nocache(
-			(unsigned long)s_mchBarAddrs[TELEM_SSRAMBAR_CFG] +
-			IOSS_TELEM_SSRAM_OFFSET, TELEM_SSRAM_SIZE);
-
-	return (s_pmcIPCCmdAddr && s_pmcIPCStsAddr &&
-		s_pmcIPCWBufAddr && s_pmcIPCRBufAddr &&
-		s_telemEventInfo[TELEM_PMC].ssram_virt_addr);
-}
-
-/**
- * destroy_pmc_mbox -- Unmap PMC virtual addresses
- */
-static void destroy_pmc_mbox(void)
-{
-	if (s_pmcIPCCmdAddr) {
-		iounmap(s_pmcIPCCmdAddr);
-		s_pmcIPCCmdAddr = NULL;
-	}
-	if (s_pmcIPCStsAddr) {
-		iounmap(s_pmcIPCStsAddr);
-		s_pmcIPCStsAddr = NULL;
-	}
-	if (s_pmcIPCWBufAddr) {
-		iounmap(s_pmcIPCWBufAddr);
-		s_pmcIPCWBufAddr = NULL;
-	}
-	if (s_pmcIPCRBufAddr) {
-		iounmap(s_pmcIPCRBufAddr);
-		s_pmcIPCRBufAddr = NULL;
-	}
-	if (s_telemEventInfo[TELEM_PMC].ssram_virt_addr) {
-		iounmap(s_telemEventInfo[TELEM_PMC].ssram_virt_addr);
-		s_telemEventInfo[TELEM_PMC].ssram_virt_addr = NULL;
-	}
-}
-
-/**
- * setup_telem - Setup telemetry interface
- *
- * Returns: 0 if setup successfully, 1 otherwise
- */
-int setup_telem(u64 addrs[3])
-{
-	/*
-	 * Don't setup if already done so
-	 */
-	if (s_mchBarAddrs[TELEM_MCHBAR_CFG])
-		return 0;
-
-	memcpy(s_mchBarAddrs, addrs, sizeof(s_mchBarAddrs));
-	/*
-	 * Setup Punit
-	 */
-	if (!setup_punit_mbox()) {
-		pw_pr_error("Couldn't setup PUNIT mbox\n");
-		return -1;
-	}
-	/*
-	 * Setup PMC
-	 */
-	if (!setup_pmc_mbox()) {
-		pw_pr_error("Couldn't setup PMC mbox\n");
-		return -1;
-	}
-	return 0;
-}
-
-/**
- * destroy_telem - Destroy telemetry interface
- */
-void destroy_telem(void)
-{
-	destroy_punit_mbox();
-	destroy_pmc_mbox();
-
-	memset(s_mchBarAddrs, 0, sizeof(s_mchBarAddrs));
-}
-
-/**
- * get_or_set_id - Add ID to list of events if not previously added
- *
- * Returns: 0 if setup successfully, 1 otherwise
- */
-static int get_or_set_id(u32 *events, u32 *unit_idx, u32 id)
-{
-	u32 i = 0;
-
-	if (*unit_idx >= MAX_TELEM_EVENTS)
-		return -1;
-
-	for (i = 0; i <  *unit_idx; ++i) {
-		if (events[i] == id)
-			return i;
-	}
-	events[*unit_idx] = id;
-	return (*unit_idx)++;
-}
-
-static int add_telem_id(enum telemetry_unit unit, u32 id)
-{
-	return get_or_set_id(
-		s_telemEventInfo[unit].events,
-		&s_telemEventInfo[unit].idx, id);
-}
-
-static void remove_telem_ids(void)
-{
-	memset(s_telemEventInfo, 0, sizeof(s_telemEventInfo));
-}
-
-
-static u64 read_telem_data(u64 *dst, volatile void *src, size_t num_events)
-{
-	u32 i, timeout = 0;
-	u64 prev_timestamp = 0, next_timestamp = 0, start_time = 0, event_data;
-
-	if (!dst)
-		return 0;
-
-	do {
-		u64 *_src = (u64 *)src;
-
-		prev_timestamp = *_src;
-		if (!prev_timestamp)
-			return 0;
-
-		start_time = *(_src + 1);
-
-		for (i = 0; i < num_events; ++i) {
-			event_data = *(_src + 2 + i);
-			dst[i] = event_data;
-		}
-		next_timestamp = *_src;
-
-		if (!next_timestamp)
-			return 0;
-
-		if (++timeout == TELEM_READ_TIMEOUT_TRIAL)
-			break;
-
-	} while (prev_timestamp != next_timestamp);
-	return prev_timestamp == next_timestamp ? start_time : 0;
-}
-
-/**
- * @returns timestamp (1st entry of SSRAM)
- */
-static u64 flush_telem_to_buffer(enum telemetry_unit unit)
-{
-	return read_telem_data(s_telemEventInfo[unit].data_buffer,
-			   s_telemEventInfo[unit].ssram_virt_addr,
-			   s_telemEventInfo[unit].idx);
-}
-
-static void read_telem_from_buffer(u64 *dst, enum telemetry_unit unit)
-{
-	memcpy(dst, s_telemEventInfo[unit].data_buffer,
-		s_telemEventInfo[unit].idx * sizeof(*dst));
-}
-
-static u64 read_event_from_buffer(enum telemetry_unit unit, int idx)
-{
-	if (idx < 0 || idx >= MAX_TELEM_EVENTS)
-		return SW_TELEM_READ_FAIL_VALUE;
-
-	return s_telemEventInfo[unit].data_buffer[idx];
-}
-
-static bool punit_start_telem(void)
-{
-	u32 telem_info = 0, telem_ctrl = 0, i;
-
-	/* Reset data buffer */
-	memset(s_telemEventInfo[TELEM_PUNIT].data_buffer, 0,
-		sizeof(s_telemEventInfo[TELEM_PUNIT].data_buffer));
-
-	/* Read basic config */
-	if (intel_punit_ipc_command(IPC_BIOS_PUNIT_CMD_READ_TELE_INFO, 0, 0,
-			NULL, &telem_info))
-		pw_pr_warn("Could not execute P-unit IPC command to read telem info\n");
-
-	/* Debug info */
-	pw_pr_debug("DEBUG: Read P-Unit telem_info = 0x%x\n", telem_info);
-	pw_pr_debug("## SOCWATCHDRV ## PUNIT Telemetry info has events = %u\n",
-		(telem_info & TELEM_INFO_SSRAMEVTS_MASK) >>
-			TELEM_INFO_SSRAMEVTS_SHIFT);
-	pw_pr_debug(
-		"## SOCWATCHDRV ## PUNIT Telemetry info has event_regs = %u\n",
-		telem_info & TELEM_INFO_SSRAMEVTS_MASK);
-	pw_pr_debug(
-		"## SOCWATCHDRV ## PUNIT Telemetry info has min_period = %u\n",
-		TELEM_MIN_PERIOD(telem_info));
-	pw_pr_debug(
-		"## SOCWATCHDRV ## PUNIT Telemetry info has max_period = %u\n",
-		TELEM_MAX_PERIOD(telem_info));
-
-	/*TODO: check if #events or #event_regs is less than 28; exit if so */
-
-	/* Read control structure */
-	if (intel_punit_ipc_command(IPC_BIOS_PUNIT_CMD_READ_TELE_EVENT_CTRL,
-			0, 0, NULL, &telem_ctrl))
-		pw_pr_warn("Could not execute P-unit IPC command to read telem ctrl structure\n");
-
-	/* Disable telem */
-	TELEM_DISABLE(telem_ctrl);
-	if (intel_punit_ipc_command(IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT_CTRL,
-			0, 0, &telem_ctrl, NULL))
-		pw_pr_warn("Could not execute P-unit IPC command to write telem ctrl structure\n");
-
-	/* Each event added requires a separate command */
-	for (i = 0; i < s_telemEventInfo[TELEM_PUNIT].idx; ++i) {
-		u32 event = s_telemEventInfo[TELEM_PUNIT].events[i] |
-			TELEM_EVENT_ENABLE;
-
-		pw_pr_debug("DEBUG: enabling PUNIT event 0x%x\n",
-		s_telemEventInfo[TELEM_PUNIT].events[i]);
-		if (intel_punit_ipc_command(
-				IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT, i, 0,
-				&event, NULL))
-			pw_pr_warn("Could not execute P-unit IPC command to write telem event\n");
-
-	}
-
-	TELEM_CLEAR_SAMPLE_PERIOD(telem_ctrl);
-	TELEM_ENABLE_SSRAM_EVT_TRACE(telem_ctrl);
-	TELEM_ENABLE_PERIODIC(telem_ctrl);
-	telem_ctrl |= TELEM_DEFAULT_SAMPLING_PERIOD;
-
-	/* Enable telemetry via control structure */
-	if (intel_punit_ipc_command(IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT_CTRL,
-			0, 0, &telem_ctrl, NULL))
-		pw_pr_warn("Could not execute P-unit IPC command to write telem ctrl structure\n");
-
-	return true;
-}
-
-static void punit_stop_telem(void)
-{
-	u32 telem_ctrl = 0;
-
-	if (intel_punit_ipc_command(
-			IPC_BIOS_PUNIT_CMD_READ_TELE_EVENT_CTRL, 0, 0,
-			NULL, &telem_ctrl))
-		pw_pr_warn("Could not execute P-unit IPC command to read telem ctrl structure\n");
-
-	/* Disable telem */
-	TELEM_DISABLE(telem_ctrl);
-	if (intel_punit_ipc_command(
-			IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT_CTRL, 0, 0,
-			&telem_ctrl, NULL))
-		pw_pr_warn("Could not execute P-unit IPC command to write telem ctrl structure\n");
-}
-
-static bool pmc_start_telem(void)
-{
-	u32 telem_info = 0, telem_ctrl = 0, i;
-
-	/* Reset data buffer */
-	memset(s_telemEventInfo[TELEM_PMC].data_buffer,
-		0, sizeof(s_telemEventInfo[TELEM_PMC].data_buffer));
-
-	/* Read basic config */
-	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
-			IOSS_TELEM_INFO_READ, NULL, 0, &telem_info,
-			IOSS_TELEM_READ_WORD))
-		pw_pr_warn("Could not execute PMC IPC command to read telemetry info\n");
-
-	pw_pr_debug("DEBUG: Read PMC telem_info = 0x%x\n", telem_info);
-	pw_pr_debug("## SOCWATCHDRV ## PMC Telemetry info has events = %u\n",
-		(telem_info & TELEM_INFO_SSRAMEVTS_MASK) >>
-			TELEM_INFO_SSRAMEVTS_SHIFT);
-	pw_pr_debug("## SOCWATCHDRV ## PMC Telemetry info has event_regs = %u\n",
-		telem_info & TELEM_INFO_SSRAMEVTS_MASK);
-	pw_pr_debug("## SOCWATCHDRV ## PMC Telemetry info has min_period = %u\n",
-		TELEM_MIN_PERIOD(telem_info));
-	pw_pr_debug("## SOCWATCHDRV ## PMC Telemetry info has max_period = %u\n",
-		TELEM_MAX_PERIOD(telem_info));
-
-	/*TODO: check if #events or #event_regs is less than 28; exit if so */
-
-	/* Read control structure */
-	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
-			IOSS_TELEM_EVENT_CTL_READ, NULL, 0, &telem_ctrl,
-			IOSS_TELEM_READ_WORD))
-		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
-
-	/* Disable telemetry */
-	TELEM_DISABLE(telem_ctrl);
-	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
-			IOSS_TELEM_EVENT_CTL_WRITE, (u8 *)&telem_ctrl,
-			IOSS_TELEM_EVT_CTRL_WRITE_SIZE, NULL, 0))
-		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
-
-
-	/* Each event added requires a separate command */
-	for (i = 0; i < s_telemEventInfo[TELEM_PMC].idx; ++i) {
-		u32 event =
-			s_telemEventInfo[TELEM_PMC].events[i] |
-			TELEM_EVENT_ENABLE;
-
-		event <<= TELEM_IOSS_EVTID_SHIFT;
-		event |= i; /* Set the index register */
-		pw_pr_debug("DEBUG: enabling PMC event 0x%x\n",
-			s_telemEventInfo[TELEM_PMC].events[i]);
-		if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
-				IOSS_TELEM_EVENT_WRITE, (u8 *)&event,
-				IOSS_TELEM_EVT_WRITE_SIZE, NULL, 0))
-			pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
-	}
-
-	TELEM_CLEAR_SAMPLE_PERIOD(telem_ctrl);
-	TELEM_ENABLE_SSRAM_EVT_TRACE(telem_ctrl);
-	TELEM_ENABLE_PERIODIC(telem_ctrl);
-	telem_ctrl |= TELEM_DEFAULT_SAMPLING_PERIOD;
-
-	/* Enable telemetry via control structure */
-	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
-			IOSS_TELEM_EVENT_CTL_WRITE, (u8 *)&telem_ctrl,
-			IOSS_TELEM_EVT_CTRL_WRITE_SIZE, NULL, 0))
-		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
-
-	return true;
-}
-
-static void pmc_stop_telem(void)
-{
-	u32 telem_ctrl = 0;
-
-	/* Read control structure */
-	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
-			IOSS_TELEM_EVENT_CTL_READ, NULL, 0, &telem_ctrl,
-			IOSS_TELEM_READ_WORD))
-		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
-
-	/* Disable telemetry */
-	TELEM_DISABLE(telem_ctrl);
-	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
-			IOSS_TELEM_EVENT_CTL_WRITE, (u8 *)&telem_ctrl,
-			IOSS_TELEM_EVT_CTRL_WRITE_SIZE, NULL, 0))
-		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
-}
-
-/**
- * Configurs events + starts counters
- * @returns  0 on success
- */
-static int start_telem(void)
-{
-	if (s_telemEventInfo[TELEM_PUNIT].idx) {
-		if (punit_start_telem() == false)
-			return -1;
-
-		/* Return value is don't care */
-		flush_telem_to_buffer(TELEM_PUNIT);
-	}
-
-	if (s_telemEventInfo[TELEM_PMC].idx) {
-		if (pmc_start_telem() == false)
-			return -1;
-
-		flush_telem_to_buffer(TELEM_PMC);
-	}
-	pw_pr_debug("OK, bypass telem started\n");
-	return 0;
-}
-
-static void stop_telem(void)
-{
-	if (s_telemEventInfo[TELEM_PUNIT].idx) {
-		punit_stop_telem();
-		s_telemEventInfo[TELEM_PUNIT].idx = 0;
-	}
-	if (s_telemEventInfo[TELEM_PMC].idx) {
-		pmc_stop_telem();
-		s_telemEventInfo[TELEM_PMC].idx = 0;
-	}
-	pw_pr_debug("OK, bypass telem stopped\n");
-}
-
-int read_telem(u64 *dst, enum telemetry_unit unit, bool should_retry)
-{
-	size_t num_iters = should_retry ? 10 : 0;
-	u64 timestamp = 0;
-
-	do {
-		timestamp = flush_telem_to_buffer(unit);
-	} while (!timestamp && should_retry && num_iters--);
-
-	if (timestamp) {
-		read_telem_from_buffer(dst, unit);
-		return 0;
-	}
-	return -1;
-}
-
-/**
- * builtin_telemetry_available - Determine if telemetry driver is present
- *
- * Returns: 1 if telemetry driver is present, 0 if not.
- */
-static int builtin_telemetry_available(void)
-{
-	int retval = 0;
-	struct telemetry_evtconfig punit_evtconfig;
-	struct telemetry_evtconfig pmc_evtconfig;
-	u32 punit_event_map[MAX_TELEM_EVENTS];
-	u32 pmc_event_map[MAX_TELEM_EVENTS];
-
-
-	/* The symbol below is weak.  We return 1 if we have a definition
-	 * for this telemetry-driver-supplied symbol, or 0 if only the
-	 * weak definition exists. This test will suffice to detect if
-	 * the telemetry driver is loaded.
-	 */
-	if (telemetry_get_eventconfig) {
-		/* OK, the telemetry driver is loaded. But it's possible it
-		 * hasn't been configured properly. To check that, retrieve
-		 * the number of events currently configured. This should never
-		 * be zero since the telemetry driver reserves some SSRAM slots
-		 * for its own use
-		 */
-		memset(&punit_evtconfig, 0, sizeof(punit_evtconfig));
-		memset(&pmc_evtconfig, 0, sizeof(pmc_evtconfig));
-
-		punit_evtconfig.evtmap = (u32 *) &punit_event_map;
-		pmc_evtconfig.evtmap = (u32 *) &pmc_event_map;
-
-		retval = telemetry_get_eventconfig(&punit_evtconfig, &pmc_evtconfig,
-						MAX_TELEM_EVENTS, MAX_TELEM_EVENTS);
-		return (retval == 0 && punit_evtconfig.num_evts > 0 &&
-			pmc_evtconfig.num_evts > 0);
-	}
-	return 0;
-}
-
-/**
- * was_telemetry_setup - Check if the P-unit and PMC addresses have been mapped
- *
- * Returns: true if successfully mapped
- */
-static bool was_telemetry_setup(void)
-{
-	return s_punitInterfaceAddr && s_punitDataAddr &&
-		s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr /* P-unit */ &&
-		s_pmcIPCCmdAddr && s_pmcIPCStsAddr && s_pmcIPCWBufAddr &&
-		s_pmcIPCRBufAddr && s_telemEventInfo[TELEM_PMC].ssram_virt_addr;
-}
-
-
-/**
- * sw_telem_init_func - Set up the telemetry unit to retrieve a data item
- *						(e.g. counter).
- * @descriptor:  The IO descriptor containing the unit and ID
- *						of the telemetry info to gather.
- *
- * Because we don't (currently) control all of the counters, we
- * economize by seeing if it's already being collected before allocate
- * a slot for it.
- *
- * Returns: PW_SUCCESS  if the telem collector can collect the requested data.
- *		 -PW_ERROR   if the the addition of that item fails.
- */
-int sw_telem_init_func(struct sw_driver_io_descriptor *descriptor)
-{
-	struct sw_driver_telem_io_descriptor *td =
-		&(descriptor->telem_descriptor);
-	u8  unit = td->unit;  /* Telemetry unit to use. */
-	u32 id; /* Event ID we want telemetry to track. */
-
-	if (!was_telemetry_setup())
-		return -ENXIO;
-
-	id = (u32)(td->id);
-
-	td->idx = add_telem_id(unit, id);
-	if (td->idx < 0) {
-		pw_pr_error("ERROR adding id 0x%x to unit %d\n", id, unit);
-		return -1;
-	}
-	pw_pr_debug("OK, added id 0x%x to unit %d at pos %d\n",
-			id, unit, td->idx);
-
-	return 0;
-}
-
-
-/**
- * sw_read_telem_info - Read a metric's data from the telemetry driver.
- * @dest:		Destination (storage for the read data)
- * @cpu:		Which CPU to read from (not used)
- * @descriptor:		The descriptor containing the data ID to read
- * @data_size_in_bytes: The # of bytes in the result (always 8)
- *
- * Returns: Nothing, but stores SW_TELEM_READ_FAIL_VALUE to dest if
- * the read fails.
- */
-void sw_read_telem_info(char *dest, int cpu,
-			  const sw_driver_io_descriptor_t *descriptor,
-			  u16 data_size_in_bytes)
-{
-	u64 *data_dest = (u64 *)dest;
-	const struct sw_driver_telem_io_descriptor *td =
-		&(descriptor->telem_descriptor);
-	u8 unit = td->unit;
-	bool needs_refresh = false;
-
-	/*
-	 * Check if we need to refresh the list of values
-	 */
-	LOCK(sw_telem_lock);
-	{
-		if (s_telemEventInfo[unit].iters == 0)
-			needs_refresh = true;
-
-		if (++s_telemEventInfo[unit].iters ==
-				s_telemEventInfo[unit].idx)
-			s_telemEventInfo[unit].iters = 0;
-	}
-
-	UNLOCK(sw_telem_lock);
-
-	if (needs_refresh) {
-		u64 timestamp = flush_telem_to_buffer(unit);
-
-		pw_pr_debug("DEBUG: unit %d refreshed, timestamp = %llu\n",
-			unit, timestamp);
-		if (!timestamp) { /* failure */
-			*data_dest = SW_TELEM_READ_FAIL_VALUE;
-			return;
-		}
-	} else
-		pw_pr_debug("DEBUG: unit %d NOT refreshed\n", unit);
-
-	*data_dest = read_event_from_buffer(unit, td->idx);
-}
-
-/**
- * sw_reset_telem - Stop collecting telemetry info.
- * @descriptor: Unused in this function
- *
- * Stop collecting anything extra, and give the driver back to
- * debugfs.  Because this driver increases the sampling rate, the
- * kernel's telemetry driver can't succesfully reset the driver unless
- * we first drop the rate back down to a much slower rate.  This is a
- * temporary measure, since the reset operation will then reset the
- * sampling interval to whatever the GMIN driver wants.
- *
- * Returns: 0
- */
-int sw_reset_telem(const struct sw_driver_io_descriptor *descriptor)
-{
-	if (IS_TELEM_CONFIGURED()) {
-		stop_telem();
-		remove_telem_ids();
-		/* Return control to 'builtin' telemetry driver */
-		telemetry_set_sampling_period(TELEM_SAMPLING_1S,
-					  TELEM_SAMPLING_1S);
-		telemetry_reset_events();
-	}
-	return 0;
-}
-
-/**
- * sw_available_telem -- Decide if the telemetry subsystem is available for use
- */
-bool sw_telem_available(void)
-{
-	/*
-	 * Telemetry driver MUST be loaded; we perform this check because
-	 * on some systems an error with the p-unit/pmc IPC interface causes
-	 * kernel panics.
-	 */
-	return builtin_telemetry_available();
-};
-
-bool sw_telem_post_config(void)
-{
-	if (start_telem())
-		return false;
-
-	return true;
-}
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/compiler.h>     /* Definition of __weak */
+#include <linux/version.h>      /* LINUX_VERSION_CODE */
+#include <linux/delay.h>        /* 'udelay' */
+#include <linux/io.h>           /* Definition of ioremap_nocache and iounmap */
+#include "sw_kernel_defines.h"  /* pw_pr_debug */
+#include "sw_mem.h"             /* sw_kmalloc/free */
+#include "sw_lock_defs.h"       /* Various lock-related definitions */
+#include "sw_telem.h"           /* Signatures of fn's exported from here. */
+
+/*
+ * These functions and data structures are exported by the Telemetry
+ * driver.  However, that file may not be available in the kernel for
+ * which this driver is being built, so we re-define many of the same
+ * things here.
+ */
+/**
+ * struct telemetry_evtlog - The "event log" returned by the kernel's
+ *                           full-read telemetry driver.
+ * @telem_evtid:   The 16-bit event ID.
+ * @telem_evtlog:  The actual telemetry data.
+ */
+struct telemetry_evtlog {
+	u32 telem_evtid;	/* Event ID of a data item. */
+	u64 telem_evtlog;   /* Counter data */
+};
+
+struct telemetry_evtconfig {
+	u32 *evtmap;	/* Array of Event-IDs to Enable */
+	u8 num_evts;	/* Number of Events (<29) in evtmap */
+	u8 period;	  /* Sampling period */
+};
+
+#define MAX_TELEM_EVENTS 28  /* Max telem events per unit */
+
+/* The enable bit is set when programming events, but is returned
+ * cleared for queried events requests.
+ */
+#define TELEM_EVENT_ENABLE 0x8000 /* Enabled when Event ID HIGH bit */
+
+/*
+ * Sampling Period values.
+ * The sampling period is encoded in an 7-bit value, where
+ *	Period = (Value * 16^Exponent) usec where:
+ *		bits[6:3] -> Value;
+ *		bits [0:2]-> Exponent;
+ * Here are some of the calculated possible values:
+ * | Value  Val+Exp  | Value | Exponent | Period (usec) | Period (msec) |
+ * |-----------------+-------+----------+---------------+---------------|
+ * | 0xA = 000 1+010 |   1   |     2    |           256 |         0.256 |
+ * | 0x12= 001 0+010 |   2   |     2    |           512 |         0.512 |
+ * | 0x22= 010 0+010 |   4   |     2    |          1024 |         1.024 |
+ * | 0xB = 000 1+011 |   1   |     3    |          4096 |         4.096 |
+ * | 0x13= 001 0+011 |   2   |     3    |          8192 |         8.192 |
+ * | 0x1B= 001 1+011 |   3   |     3    |         12288 |        12.288 |
+ * | 0x0C= 000 1+100 |   1   |     4    |         65536 |        65.536 |
+ * | 0x0D= 000 1+101 |   1   |     5    |       1048576 |      1048.576 |
+ */
+#define TELEM_SAMPLING_1MS 0x22  /* Approximately 1 ms */
+#define TELEM_SAMPLING_1S  0x0D  /* Approximately 1 s */
+
+/* These functions make up the main APIs of the telemetry driver.  We
+ * define all of them with weak linkage so that we can still compile
+ * and load into kernels which don't have a telemetry driver.
+ */
+extern int __weak telemetry_get_eventconfig(
+	struct telemetry_evtconfig *punit_config,
+	struct telemetry_evtconfig *pmc_config,
+	int  punit_len,
+	int  pmc_len);
+
+extern int __weak telemetry_reset_events(void);
+
+extern int __weak telemetry_set_sampling_period(
+	u8 punit_period,
+	u8 pmc_period);
+/*
+ * Older kernels didn't have the p-unit/pmc ipc command interface
+ */
+extern int __weak intel_punit_ipc_command(
+	u32 cmd, u32 para1, u32 para2, u32 *in, u32 *out);
+
+extern int __weak intel_pmc_ipc_command(
+	u32 cmd, u32 sub, u8 *in, u32 inlen, u32 *out, u32 outlen);
+/*
+ * Spinlock to guard updates to the 'iters' values.
+ */
+static SW_DEFINE_SPINLOCK(sw_telem_lock);
+
+
+/* ************************************************
+ * Constants for P-unit/PMC telemetry interface
+ *  ***********************************************
+ */
+
+#define PUNIT_MAILBOX_INTERFACE_OFFSET		0x7084
+#define PUNIT_MAILBOX_DATA_OFFSET		0x7080
+
+#define PSS_TELEM_SSRAM_OFFSET			0x1A00
+#define IOSS_TELEM_SSRAM_OFFSET			0x1B00
+#define TELEM_SSRAM_SIZE			240
+
+#define PMC_IPC_CMD				0x0
+
+#define PMC_IPC_STATUS				0x04
+
+#define PMC_IPC_WRITE_BUFFER			0x80
+#define PMC_IPC_READ_BUFFER			0x90
+
+#define PMC_IPC_PMC_TELEMETRY_COMMAND		0xEB
+
+
+#define TELEM_READ_TIMEOUT_TRIAL		10
+#define TELEM_MAILBOX_STATUS_TIMEOUT		1000
+
+#define IPC_BIOS_PUNIT_CMD_BASE			0x00
+
+#define IPC_BIOS_PUNIT_CMD_READ_TELE_INFO				\
+					(IPC_BIOS_PUNIT_CMD_BASE + 0x09)
+#define IPC_BIOS_PUNIT_CMD_READ_TELE_EVENT_CTRL				\
+					(IPC_BIOS_PUNIT_CMD_BASE + 0x0c)
+#define IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT_CTRL			\
+					(IPC_BIOS_PUNIT_CMD_BASE + 0x0d)
+#define IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT				\
+					(IPC_BIOS_PUNIT_CMD_BASE + 0x11)
+
+#define IOSS_TELEM_EVENT_WRITE			0x1
+#define IOSS_TELEM_INFO_READ			0x2
+#define IOSS_TELEM_EVENT_CTL_READ		0x7
+#define IOSS_TELEM_EVENT_CTL_WRITE		0x8
+
+#define IOSS_TELEM_EVT_CTRL_WRITE_SIZE		0x4
+#define IOSS_TELEM_READ_WORD			0x1
+#define IOSS_TELEM_EVT_WRITE_SIZE		0x3
+
+#ifndef BIT
+	#define BIT(x)				(1<<x)
+#endif /* BIT */
+
+#define TELEM_DISABLE(x)			((x) &= ~(BIT(31)))
+#define TELEM_ENABLE_SSRAM_EVT_TRACE(x)		((x) &= ~(BIT(30) | BIT(24)))
+#define TELEM_ENABLE_PERIODIC(x)	((x) |= (BIT(23) | BIT(31) | BIT(7)))
+#define TELEM_IOSS_EVTID_SHIFT			8
+
+#define TELEM_INFO_SSRAMEVTS_MASK		0xFF00
+#define TELEM_INFO_SSRAMEVTS_SHIFT		0x8
+
+#define TELEM_MIN_PERIOD(x)			((x) & 0x7F0000)
+#define TELEM_MAX_PERIOD(x)			((x) & 0x7F000000)
+#define TELEM_CLEAR_SAMPLE_PERIOD(x)		((x) &= ~0x7F)
+#define TELEM_DEFAULT_SAMPLING_PERIOD		TELEM_SAMPLING_1MS
+
+#define IS_TELEM_CONFIGURED()			\
+	(s_telemEventInfo[TELEM_PUNIT].idx > 0	\
+	|| s_telemEventInfo[TELEM_PMC].idx > 0)
+
+static u64 s_mchBarAddrs[3] = {0, 0, 0};
+
+static struct {
+	volatile u64 *ssram_virt_addr;
+	int idx, iters;
+	u32 events[MAX_TELEM_EVENTS];
+	u64 data_buffer[MAX_TELEM_EVENTS];
+} s_telemEventInfo[TELEM_UNIT_NONE] = {
+	[TELEM_PUNIT] = {NULL, 0, 0},
+	[TELEM_PMC] = {NULL, 0, 0},
+};
+
+static volatile u64 *s_punitInterfaceAddr;
+static volatile u64 *s_punitDataAddr;
+static volatile u64 *s_pmcIPCCmdAddr;
+static volatile u64 *s_pmcIPCStsAddr;
+static volatile u64 *s_pmcIPCWBufAddr;
+static volatile u64 *s_pmcIPCRBufAddr;
+
+/**
+ * setup_punit_mbox -- Setup P-Unit virtual mappings
+ *
+ * Returns: true if setup successfully
+ */
+static bool setup_punit_mbox(void)
+{
+	s_punitInterfaceAddr = (u64 *)ioremap_nocache(
+				(unsigned long)s_mchBarAddrs[TELEM_MCHBAR_CFG] +
+				PUNIT_MAILBOX_INTERFACE_OFFSET, 0x4);
+	s_punitDataAddr = (u64 *)ioremap_nocache(
+				(unsigned long)s_mchBarAddrs[TELEM_MCHBAR_CFG] +
+				PUNIT_MAILBOX_DATA_OFFSET, 0x4);
+	s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr = (u64 *)ioremap_nocache(
+				(unsigned long)
+					s_mchBarAddrs[TELEM_SSRAMBAR_CFG] +
+				PSS_TELEM_SSRAM_OFFSET, TELEM_SSRAM_SIZE);
+
+	return (s_punitInterfaceAddr && s_punitDataAddr &&
+		s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr);
+}
+
+/**
+ * destroy_punit_mbox -- Unmap p-unit virtual addresses
+ */
+static void destroy_punit_mbox(void)
+{
+	if (s_punitInterfaceAddr) {
+		iounmap(s_punitInterfaceAddr);
+		s_punitInterfaceAddr = NULL;
+	}
+	if (s_punitDataAddr) {
+		iounmap(s_punitDataAddr);
+		s_punitDataAddr = NULL;
+	}
+	if (s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr) {
+		iounmap(s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr);
+		s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr = NULL;
+	}
+}
+
+/**
+ * setup_pmc_mbox -- Setup PMC virtual mappings
+ *
+ * Returns: true if setup successfully
+ */
+static bool setup_pmc_mbox(void)
+{
+	s_pmcIPCCmdAddr = (u64 *)ioremap_nocache(
+			(unsigned long)s_mchBarAddrs[TELEM_IPC1BAR_CFG] +
+			PMC_IPC_CMD, 0x4);
+	s_pmcIPCStsAddr = (u64 *)ioremap_nocache(
+			(unsigned long)s_mchBarAddrs[TELEM_IPC1BAR_CFG] +
+			PMC_IPC_STATUS, 0x4);
+	s_pmcIPCWBufAddr = (u64 *)ioremap_nocache(
+			(unsigned long)s_mchBarAddrs[TELEM_IPC1BAR_CFG] +
+			PMC_IPC_WRITE_BUFFER, 0x4);
+	s_pmcIPCRBufAddr = (u64 *)ioremap_nocache(
+			(unsigned long)s_mchBarAddrs[TELEM_IPC1BAR_CFG] +
+			PMC_IPC_READ_BUFFER, 0x4);
+	s_telemEventInfo[TELEM_PMC].ssram_virt_addr = (u64 *)ioremap_nocache(
+			(unsigned long)s_mchBarAddrs[TELEM_SSRAMBAR_CFG] +
+			IOSS_TELEM_SSRAM_OFFSET, TELEM_SSRAM_SIZE);
+
+	return (s_pmcIPCCmdAddr && s_pmcIPCStsAddr &&
+		s_pmcIPCWBufAddr && s_pmcIPCRBufAddr &&
+		s_telemEventInfo[TELEM_PMC].ssram_virt_addr);
+}
+
+/**
+ * destroy_pmc_mbox -- Unmap PMC virtual addresses
+ */
+static void destroy_pmc_mbox(void)
+{
+	if (s_pmcIPCCmdAddr) {
+		iounmap(s_pmcIPCCmdAddr);
+		s_pmcIPCCmdAddr = NULL;
+	}
+	if (s_pmcIPCStsAddr) {
+		iounmap(s_pmcIPCStsAddr);
+		s_pmcIPCStsAddr = NULL;
+	}
+	if (s_pmcIPCWBufAddr) {
+		iounmap(s_pmcIPCWBufAddr);
+		s_pmcIPCWBufAddr = NULL;
+	}
+	if (s_pmcIPCRBufAddr) {
+		iounmap(s_pmcIPCRBufAddr);
+		s_pmcIPCRBufAddr = NULL;
+	}
+	if (s_telemEventInfo[TELEM_PMC].ssram_virt_addr) {
+		iounmap(s_telemEventInfo[TELEM_PMC].ssram_virt_addr);
+		s_telemEventInfo[TELEM_PMC].ssram_virt_addr = NULL;
+	}
+}
+
+/**
+ * setup_telem - Setup telemetry interface
+ *
+ * Returns: 0 if setup successfully, 1 otherwise
+ */
+int setup_telem(u64 addrs[3])
+{
+	/*
+	 * Don't setup if already done so
+	 */
+	if (s_mchBarAddrs[TELEM_MCHBAR_CFG])
+		return 0;
+
+	memcpy(s_mchBarAddrs, addrs, sizeof(s_mchBarAddrs));
+	/*
+	 * Setup Punit
+	 */
+	if (!setup_punit_mbox()) {
+		pw_pr_error("Couldn't setup PUNIT mbox\n");
+		return -1;
+	}
+	/*
+	 * Setup PMC
+	 */
+	if (!setup_pmc_mbox()) {
+		pw_pr_error("Couldn't setup PMC mbox\n");
+		return -1;
+	}
+	return 0;
+}
+
+/**
+ * destroy_telem - Destroy telemetry interface
+ */
+void destroy_telem(void)
+{
+	destroy_punit_mbox();
+	destroy_pmc_mbox();
+
+	memset(s_mchBarAddrs, 0, sizeof(s_mchBarAddrs));
+}
+
+/**
+ * get_or_set_id - Add ID to list of events if not previously added
+ *
+ * Returns: 0 if setup successfully, 1 otherwise
+ */
+static int get_or_set_id(u32 *events, u32 *unit_idx, u32 id)
+{
+	u32 i = 0;
+
+	if (*unit_idx >= MAX_TELEM_EVENTS)
+		return -1;
+
+	for (i = 0; i <  *unit_idx; ++i) {
+		if (events[i] == id)
+			return i;
+	}
+	events[*unit_idx] = id;
+	return (*unit_idx)++;
+}
+
+static int add_telem_id(enum telemetry_unit unit, u32 id)
+{
+	return get_or_set_id(
+		s_telemEventInfo[unit].events,
+		&s_telemEventInfo[unit].idx, id);
+}
+
+static void remove_telem_ids(void)
+{
+	memset(s_telemEventInfo, 0, sizeof(s_telemEventInfo));
+}
+
+
+static u64 read_telem_data(u64 *dst, volatile void *src, size_t num_events)
+{
+	u32 i, timeout = 0;
+	u64 prev_timestamp = 0, next_timestamp = 0, start_time = 0, event_data;
+
+	if (!dst)
+		return 0;
+
+	do {
+		u64 *_src = (u64 *)src;
+
+		prev_timestamp = *_src;
+		if (!prev_timestamp)
+			return 0;
+
+		start_time = *(_src + 1);
+
+		for (i = 0; i < num_events; ++i) {
+			event_data = *(_src + 2 + i);
+			dst[i] = event_data;
+		}
+		next_timestamp = *_src;
+
+		if (!next_timestamp)
+			return 0;
+
+		if (++timeout == TELEM_READ_TIMEOUT_TRIAL)
+			break;
+
+	} while (prev_timestamp != next_timestamp);
+	return prev_timestamp == next_timestamp ? start_time : 0;
+}
+
+/**
+ * @returns timestamp (1st entry of SSRAM)
+ */
+static u64 flush_telem_to_buffer(enum telemetry_unit unit)
+{
+	return read_telem_data(s_telemEventInfo[unit].data_buffer,
+			   s_telemEventInfo[unit].ssram_virt_addr,
+			   s_telemEventInfo[unit].idx);
+}
+
+static void read_telem_from_buffer(u64 *dst, enum telemetry_unit unit)
+{
+	memcpy(dst, s_telemEventInfo[unit].data_buffer,
+		s_telemEventInfo[unit].idx * sizeof(*dst));
+}
+
+static u64 read_event_from_buffer(enum telemetry_unit unit, int idx)
+{
+	if (idx < 0 || idx >= MAX_TELEM_EVENTS)
+		return SW_TELEM_READ_FAIL_VALUE;
+
+	return s_telemEventInfo[unit].data_buffer[idx];
+}
+
+static bool punit_start_telem(void)
+{
+	u32 telem_info = 0, telem_ctrl = 0, i;
+
+	/* Reset data buffer */
+	memset(s_telemEventInfo[TELEM_PUNIT].data_buffer, 0,
+		sizeof(s_telemEventInfo[TELEM_PUNIT].data_buffer));
+
+	/* Read basic config */
+	if (intel_punit_ipc_command(IPC_BIOS_PUNIT_CMD_READ_TELE_INFO, 0, 0,
+			NULL, &telem_info))
+		pw_pr_warn("Could not execute P-unit IPC command to read telem info\n");
+
+	/* Debug info */
+	pw_pr_debug("DEBUG: Read P-Unit telem_info = 0x%x\n", telem_info);
+	pw_pr_debug("## SOCWATCHDRV ## PUNIT Telemetry info has events = %u\n",
+		(telem_info & TELEM_INFO_SSRAMEVTS_MASK) >>
+			TELEM_INFO_SSRAMEVTS_SHIFT);
+	pw_pr_debug(
+		"## SOCWATCHDRV ## PUNIT Telemetry info has event_regs = %u\n",
+		telem_info & TELEM_INFO_SSRAMEVTS_MASK);
+	pw_pr_debug(
+		"## SOCWATCHDRV ## PUNIT Telemetry info has min_period = %u\n",
+		TELEM_MIN_PERIOD(telem_info));
+	pw_pr_debug(
+		"## SOCWATCHDRV ## PUNIT Telemetry info has max_period = %u\n",
+		TELEM_MAX_PERIOD(telem_info));
+
+	/*TODO: check if #events or #event_regs is less than 28; exit if so */
+
+	/* Read control structure */
+	if (intel_punit_ipc_command(IPC_BIOS_PUNIT_CMD_READ_TELE_EVENT_CTRL,
+			0, 0, NULL, &telem_ctrl))
+		pw_pr_warn("Could not execute P-unit IPC command to read telem ctrl structure\n");
+
+	/* Disable telem */
+	TELEM_DISABLE(telem_ctrl);
+	if (intel_punit_ipc_command(IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT_CTRL,
+			0, 0, &telem_ctrl, NULL))
+		pw_pr_warn("Could not execute P-unit IPC command to write telem ctrl structure\n");
+
+	/* Each event added requires a separate command */
+	for (i = 0; i < s_telemEventInfo[TELEM_PUNIT].idx; ++i) {
+		u32 event = s_telemEventInfo[TELEM_PUNIT].events[i] |
+			TELEM_EVENT_ENABLE;
+
+		pw_pr_debug("DEBUG: enabling PUNIT event 0x%x\n",
+		s_telemEventInfo[TELEM_PUNIT].events[i]);
+		if (intel_punit_ipc_command(
+				IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT, i, 0,
+				&event, NULL))
+			pw_pr_warn("Could not execute P-unit IPC command to write telem event\n");
+
+	}
+
+	TELEM_CLEAR_SAMPLE_PERIOD(telem_ctrl);
+	TELEM_ENABLE_SSRAM_EVT_TRACE(telem_ctrl);
+	TELEM_ENABLE_PERIODIC(telem_ctrl);
+	telem_ctrl |= TELEM_DEFAULT_SAMPLING_PERIOD;
+
+	/* Enable telemetry via control structure */
+	if (intel_punit_ipc_command(IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT_CTRL,
+			0, 0, &telem_ctrl, NULL))
+		pw_pr_warn("Could not execute P-unit IPC command to write telem ctrl structure\n");
+
+	return true;
+}
+
+static void punit_stop_telem(void)
+{
+	u32 telem_ctrl = 0;
+
+	if (intel_punit_ipc_command(
+			IPC_BIOS_PUNIT_CMD_READ_TELE_EVENT_CTRL, 0, 0,
+			NULL, &telem_ctrl))
+		pw_pr_warn("Could not execute P-unit IPC command to read telem ctrl structure\n");
+
+	/* Disable telem */
+	TELEM_DISABLE(telem_ctrl);
+	if (intel_punit_ipc_command(
+			IPC_BIOS_PUNIT_CMD_WRITE_TELE_EVENT_CTRL, 0, 0,
+			&telem_ctrl, NULL))
+		pw_pr_warn("Could not execute P-unit IPC command to write telem ctrl structure\n");
+}
+
+static bool pmc_start_telem(void)
+{
+	u32 telem_info = 0, telem_ctrl = 0, i;
+
+	/* Reset data buffer */
+	memset(s_telemEventInfo[TELEM_PMC].data_buffer,
+		0, sizeof(s_telemEventInfo[TELEM_PMC].data_buffer));
+
+	/* Read basic config */
+	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
+			IOSS_TELEM_INFO_READ, NULL, 0, &telem_info,
+			IOSS_TELEM_READ_WORD))
+		pw_pr_warn("Could not execute PMC IPC command to read telemetry info\n");
+
+	pw_pr_debug("DEBUG: Read PMC telem_info = 0x%x\n", telem_info);
+	pw_pr_debug("## SOCWATCHDRV ## PMC Telemetry info has events = %u\n",
+		(telem_info & TELEM_INFO_SSRAMEVTS_MASK) >>
+			TELEM_INFO_SSRAMEVTS_SHIFT);
+	pw_pr_debug("## SOCWATCHDRV ## PMC Telemetry info has event_regs = %u\n",
+		telem_info & TELEM_INFO_SSRAMEVTS_MASK);
+	pw_pr_debug("## SOCWATCHDRV ## PMC Telemetry info has min_period = %u\n",
+		TELEM_MIN_PERIOD(telem_info));
+	pw_pr_debug("## SOCWATCHDRV ## PMC Telemetry info has max_period = %u\n",
+		TELEM_MAX_PERIOD(telem_info));
+
+	/*TODO: check if #events or #event_regs is less than 28; exit if so */
+
+	/* Read control structure */
+	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
+			IOSS_TELEM_EVENT_CTL_READ, NULL, 0, &telem_ctrl,
+			IOSS_TELEM_READ_WORD))
+		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
+
+	/* Disable telemetry */
+	TELEM_DISABLE(telem_ctrl);
+	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
+			IOSS_TELEM_EVENT_CTL_WRITE, (u8 *)&telem_ctrl,
+			IOSS_TELEM_EVT_CTRL_WRITE_SIZE, NULL, 0))
+		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
+
+
+	/* Each event added requires a separate command */
+	for (i = 0; i < s_telemEventInfo[TELEM_PMC].idx; ++i) {
+		u32 event =
+			s_telemEventInfo[TELEM_PMC].events[i] |
+			TELEM_EVENT_ENABLE;
+
+		event <<= TELEM_IOSS_EVTID_SHIFT;
+		event |= i; /* Set the index register */
+		pw_pr_debug("DEBUG: enabling PMC event 0x%x\n",
+			s_telemEventInfo[TELEM_PMC].events[i]);
+		if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
+				IOSS_TELEM_EVENT_WRITE, (u8 *)&event,
+				IOSS_TELEM_EVT_WRITE_SIZE, NULL, 0))
+			pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
+	}
+
+	TELEM_CLEAR_SAMPLE_PERIOD(telem_ctrl);
+	TELEM_ENABLE_SSRAM_EVT_TRACE(telem_ctrl);
+	TELEM_ENABLE_PERIODIC(telem_ctrl);
+	telem_ctrl |= TELEM_DEFAULT_SAMPLING_PERIOD;
+
+	/* Enable telemetry via control structure */
+	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
+			IOSS_TELEM_EVENT_CTL_WRITE, (u8 *)&telem_ctrl,
+			IOSS_TELEM_EVT_CTRL_WRITE_SIZE, NULL, 0))
+		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
+
+	return true;
+}
+
+static void pmc_stop_telem(void)
+{
+	u32 telem_ctrl = 0;
+
+	/* Read control structure */
+	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
+			IOSS_TELEM_EVENT_CTL_READ, NULL, 0, &telem_ctrl,
+			IOSS_TELEM_READ_WORD))
+		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
+
+	/* Disable telemetry */
+	TELEM_DISABLE(telem_ctrl);
+	if (intel_pmc_ipc_command(PMC_IPC_PMC_TELEMETRY_COMMAND,
+			IOSS_TELEM_EVENT_CTL_WRITE, (u8 *)&telem_ctrl,
+			IOSS_TELEM_EVT_CTRL_WRITE_SIZE, NULL, 0))
+		pw_pr_warn("Could not execute PMC IPC command to read telem control info\n");
+}
+
+/**
+ * Configurs events + starts counters
+ * @returns  0 on success
+ */
+static int start_telem(void)
+{
+	if (s_telemEventInfo[TELEM_PUNIT].idx) {
+		if (punit_start_telem() == false)
+			return -1;
+
+		/* Return value is don't care */
+		flush_telem_to_buffer(TELEM_PUNIT);
+	}
+
+	if (s_telemEventInfo[TELEM_PMC].idx) {
+		if (pmc_start_telem() == false)
+			return -1;
+
+		flush_telem_to_buffer(TELEM_PMC);
+	}
+	pw_pr_debug("OK, bypass telem started\n");
+	return 0;
+}
+
+static void stop_telem(void)
+{
+	if (s_telemEventInfo[TELEM_PUNIT].idx) {
+		punit_stop_telem();
+		s_telemEventInfo[TELEM_PUNIT].idx = 0;
+	}
+	if (s_telemEventInfo[TELEM_PMC].idx) {
+		pmc_stop_telem();
+		s_telemEventInfo[TELEM_PMC].idx = 0;
+	}
+	pw_pr_debug("OK, bypass telem stopped\n");
+}
+
+int read_telem(u64 *dst, enum telemetry_unit unit, bool should_retry)
+{
+	size_t num_iters = should_retry ? 10 : 0;
+	u64 timestamp = 0;
+
+	do {
+		timestamp = flush_telem_to_buffer(unit);
+	} while (!timestamp && should_retry && num_iters--);
+
+	if (timestamp) {
+		read_telem_from_buffer(dst, unit);
+		return 0;
+	}
+	return -1;
+}
+
+/**
+ * builtin_telemetry_available - Determine if telemetry driver is present
+ *
+ * Returns: 1 if telemetry driver is present, 0 if not.
+ */
+static int builtin_telemetry_available(void)
+{
+	int retval = 0;
+	struct telemetry_evtconfig punit_evtconfig;
+	struct telemetry_evtconfig pmc_evtconfig;
+	u32 punit_event_map[MAX_TELEM_EVENTS];
+	u32 pmc_event_map[MAX_TELEM_EVENTS];
+
+
+	/* The symbol below is weak.  We return 1 if we have a definition
+	 * for this telemetry-driver-supplied symbol, or 0 if only the
+	 * weak definition exists. This test will suffice to detect if
+	 * the telemetry driver is loaded.
+	 */
+	if (telemetry_get_eventconfig) {
+		/* OK, the telemetry driver is loaded. But it's possible it
+		 * hasn't been configured properly. To check that, retrieve
+		 * the number of events currently configured. This should never
+		 * be zero since the telemetry driver reserves some SSRAM slots
+		 * for its own use
+		 */
+		memset(&punit_evtconfig, 0, sizeof(punit_evtconfig));
+		memset(&pmc_evtconfig, 0, sizeof(pmc_evtconfig));
+
+		punit_evtconfig.evtmap = (u32 *) &punit_event_map;
+		pmc_evtconfig.evtmap = (u32 *) &pmc_event_map;
+
+		retval = telemetry_get_eventconfig(&punit_evtconfig, &pmc_evtconfig,
+						MAX_TELEM_EVENTS, MAX_TELEM_EVENTS);
+		return (retval == 0 && punit_evtconfig.num_evts > 0 &&
+			pmc_evtconfig.num_evts > 0);
+	}
+	return 0;
+}
+
+/**
+ * was_telemetry_setup - Check if the P-unit and PMC addresses have been mapped
+ *
+ * Returns: true if successfully mapped
+ */
+static bool was_telemetry_setup(void)
+{
+	return s_punitInterfaceAddr && s_punitDataAddr &&
+		s_telemEventInfo[TELEM_PUNIT].ssram_virt_addr /* P-unit */ &&
+		s_pmcIPCCmdAddr && s_pmcIPCStsAddr && s_pmcIPCWBufAddr &&
+		s_pmcIPCRBufAddr && s_telemEventInfo[TELEM_PMC].ssram_virt_addr;
+}
+
+
+/**
+ * sw_telem_init_func - Set up the telemetry unit to retrieve a data item
+ *						(e.g. counter).
+ * @descriptor:  The IO descriptor containing the unit and ID
+ *						of the telemetry info to gather.
+ *
+ * Because we don't (currently) control all of the counters, we
+ * economize by seeing if it's already being collected before allocate
+ * a slot for it.
+ *
+ * Returns: PW_SUCCESS  if the telem collector can collect the requested data.
+ *		 -PW_ERROR   if the the addition of that item fails.
+ */
+int sw_telem_init_func(struct sw_driver_io_descriptor *descriptor)
+{
+	struct sw_driver_telem_io_descriptor *td =
+		&(descriptor->telem_descriptor);
+	u8  unit = td->unit;  /* Telemetry unit to use. */
+	u32 id; /* Event ID we want telemetry to track. */
+
+	if (!was_telemetry_setup())
+		return -ENXIO;
+
+	id = (u32)(td->id);
+
+	td->idx = add_telem_id(unit, id);
+	if (td->idx < 0) {
+		pw_pr_error("ERROR adding id 0x%x to unit %d\n", id, unit);
+		return -1;
+	}
+	pw_pr_debug("OK, added id 0x%x to unit %d at pos %d\n",
+			id, unit, td->idx);
+
+	return 0;
+}
+
+
+/**
+ * sw_read_telem_info - Read a metric's data from the telemetry driver.
+ * @dest:		Destination (storage for the read data)
+ * @cpu:		Which CPU to read from (not used)
+ * @descriptor:		The descriptor containing the data ID to read
+ * @data_size_in_bytes: The # of bytes in the result (always 8)
+ *
+ * Returns: Nothing, but stores SW_TELEM_READ_FAIL_VALUE to dest if
+ * the read fails.
+ */
+void sw_read_telem_info(char *dest, int cpu,
+			  const sw_driver_io_descriptor_t *descriptor,
+			  u16 data_size_in_bytes)
+{
+	u64 *data_dest = (u64 *)dest;
+	const struct sw_driver_telem_io_descriptor *td =
+		&(descriptor->telem_descriptor);
+	u8 unit = td->unit;
+	bool needs_refresh = false;
+
+	/*
+	 * Check if we need to refresh the list of values
+	 */
+	LOCK(sw_telem_lock);
+	{
+		if (s_telemEventInfo[unit].iters == 0)
+			needs_refresh = true;
+
+		if (++s_telemEventInfo[unit].iters ==
+				s_telemEventInfo[unit].idx)
+			s_telemEventInfo[unit].iters = 0;
+	}
+
+	UNLOCK(sw_telem_lock);
+
+	if (needs_refresh) {
+		u64 timestamp = flush_telem_to_buffer(unit);
+
+		pw_pr_debug("DEBUG: unit %d refreshed, timestamp = %llu\n",
+			unit, timestamp);
+		if (!timestamp) { /* failure */
+			*data_dest = SW_TELEM_READ_FAIL_VALUE;
+			return;
+		}
+	} else
+		pw_pr_debug("DEBUG: unit %d NOT refreshed\n", unit);
+
+	*data_dest = read_event_from_buffer(unit, td->idx);
+}
+
+/**
+ * sw_reset_telem - Stop collecting telemetry info.
+ * @descriptor: Unused in this function
+ *
+ * Stop collecting anything extra, and give the driver back to
+ * debugfs.  Because this driver increases the sampling rate, the
+ * kernel's telemetry driver can't succesfully reset the driver unless
+ * we first drop the rate back down to a much slower rate.  This is a
+ * temporary measure, since the reset operation will then reset the
+ * sampling interval to whatever the GMIN driver wants.
+ *
+ * Returns: 0
+ */
+int sw_reset_telem(const struct sw_driver_io_descriptor *descriptor)
+{
+	if (IS_TELEM_CONFIGURED()) {
+		stop_telem();
+		remove_telem_ids();
+		/* Return control to 'builtin' telemetry driver */
+		telemetry_set_sampling_period(TELEM_SAMPLING_1S,
+					  TELEM_SAMPLING_1S);
+		telemetry_reset_events();
+	}
+	return 0;
+}
+
+/**
+ * sw_available_telem -- Decide if the telemetry subsystem is available for use
+ */
+bool sw_telem_available(void)
+{
+	/*
+	 * Telemetry driver MUST be loaded; we perform this check because
+	 * on some systems an error with the p-unit/pmc IPC interface causes
+	 * kernel panics.
+	 */
+	return builtin_telemetry_available();
+};
+
+bool sw_telem_post_config(void)
+{
+	if (start_telem())
+		return false;
+
+	return true;
+}
diff --git a/drivers/platform/x86/socwatch/sw_tracepoint_handlers.c b/drivers/platform/x86/socwatch/sw_tracepoint_handlers.c
index 6ecf02e7acd9..b03155c89c14 100644
--- a/drivers/platform/x86/socwatch/sw_tracepoint_handlers.c
+++ b/drivers/platform/x86/socwatch/sw_tracepoint_handlers.c
@@ -1,406 +1,406 @@
-/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
- *
- * This file is provided under a dual BSD/GPLv2 license.  When using or
- * redistributing this file, you may do so under either license.
- *
- * GPL LICENSE SUMMARY
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * This program is free software; you can redistribute it and/or modify
- * it under the terms of version 2 of the GNU General Public License as
- * published by the Free Software Foundation.
- *
- * This program is distributed in the hope that it will be useful, but
- * WITHOUT ANY WARRANTY; without even the implied warranty of
- * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
- * General Public License for more details.
- *
- * Contact Information:
- * SoC Watch Developer Team <socwatchdevelopers@intel.com>
- * Intel Corporation,
- * 1300 S Mopac Expwy,
- * Austin, TX 78746
- *
- * BSD LICENSE
- *
- * Copyright(c) 2014 - 2019 Intel Corporation.
- *
- * Redistribution and use in source and binary forms, with or without
- * modification, are permitted provided that the following conditions
- * are met:
- *
- *   * Redistributions of source code must retain the above copyright
- *     notice, this list of conditions and the following disclaimer.
- *   * Redistributions in binary form must reproduce the above copyright
- *     notice, this list of conditions and the following disclaimer in
- *     the documentation and/or other materials provided with the
- *     distribution.
- *   * Neither the name of Intel Corporation nor the names of its
- *     contributors may be used to endorse or promote products derived
- *     from this software without specific prior written permission.
- *
- * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
- * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
- * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
- * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
- * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
- * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
- * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
- * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
- * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
- * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
- * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
- */
-#include "sw_structs.h"
-#include "sw_kernel_defines.h"
-#include "sw_types.h"
-#include "sw_tracepoint_handlers.h"
-#include "sw_trace_notifier_provider.h"
-#include "sw_mem.h"
-
-/* -------------------------------------------------
- * Data structures and variable definitions.
- * -------------------------------------------------
- */
-struct sw_trace_list_node {
-	struct sw_trace_notifier_data *data;
-	int id;
-
-	SW_LIST_ENTRY(list, sw_trace_list_node);
-};
-static SW_DEFINE_LIST_HEAD(s_trace_list, sw_trace_list_node) =
-				SW_LIST_HEAD_INITIALIZER(s_trace_list);
-static SW_DEFINE_LIST_HEAD(s_notifier_list, sw_trace_list_node) =
-				SW_LIST_HEAD_INITIALIZER(s_notifier_list);
-static int s_trace_idx = -1, s_notifier_idx = -1;
-
-SW_DEFINE_LIST_HEAD(sw_topology_list, sw_topology_node) =
-				SW_LIST_HEAD_INITIALIZER(sw_topology_list);
-size_t sw_num_topology_entries;
-
-
-/* -------------------------------------------------
- * Function definitions.
- * -------------------------------------------------
- */
-int sw_extract_tracepoints(void)
-{
-	return sw_extract_trace_notifier_providers();
-}
-
-void sw_reset_trace_notifier_lists(void)
-{
-	sw_reset_trace_notifier_providers();
-}
-
-void sw_print_trace_notifier_overheads(void)
-{
-	sw_print_trace_notifier_provider_overheads();
-}
-
-static int sw_for_each_node_i(
-	void *list_head,
-	int (*func)(struct sw_trace_notifier_data *node, void *priv),
-	void *priv, bool return_on_error)
-{
-	SW_LIST_HEAD_VAR(sw_trace_list_node) * head = list_head;
-	int retval = PW_SUCCESS;
-	struct sw_trace_list_node *lnode = NULL;
-
-	SW_LIST_FOR_EACH_ENTRY(lnode, head, list) {
-		if ((*func)(lnode->data, priv)) {
-			retval = -EIO;
-			if (return_on_error)
-				break;
-		}
-	}
-	return retval;
-}
-
-int sw_for_each_tracepoint_node(
-	int (*func)(struct sw_trace_notifier_data *node, void *priv),
-	void *priv, bool return_on_error)
-{
-	if (func)
-		return sw_for_each_node_i(&s_trace_list,
-			func, priv, return_on_error);
-
-	return PW_SUCCESS;
-}
-
-int sw_for_each_notifier_node(
-	int (*func)(struct sw_trace_notifier_data *node, void *priv),
-	void *priv, bool return_on_error)
-{
-
-	if (func)
-		return sw_for_each_node_i(&s_notifier_list,
-						func, priv, return_on_error);
-
-	return PW_SUCCESS;
-}
-
-/*
- * Retrieve the ID for the corresponding tracepoint/notifier.
- */
-int sw_get_trace_notifier_id(struct sw_trace_notifier_data *tnode)
-{
-	struct sw_trace_list_node *lnode = NULL;
-
-	SW_LIST_HEAD_VAR(sw_trace_list_node) * head = (void *)&s_trace_list;
-	if (!tnode) {
-		pw_pr_error(
-			"ERROR: cannot get ID for NULL trace/notifier data!\n");
-		return -EIO;
-	}
-	if (!(tnode->type == SW_TRACE_COLLECTOR_TRACEPOINT ||
-			tnode->type == SW_TRACE_COLLECTOR_NOTIFIER)) {
-		pw_pr_error(
-			"ERROR: cannot get ID for invalid trace/notifier data!\n");
-		return -EIO;
-	}
-	if (!tnode->name || !tnode->name->abstract_name) {
-		pw_pr_error(
-			"ERROR: cannot get ID for trace/notifier data without valid name!\n");
-		return -EIO;
-	}
-
-#if defined(LINUX_VERSION_CODE)
-#if KERNEL_VERSION(3, 15, 0) <= LINUX_VERSION_CODE &&	\
-	defined(CONFIG_TRACEPOINTS)
-
-	if (tnode->type == SW_TRACE_COLLECTOR_TRACEPOINT &&
-		tnode->name->kernel_name && !tnode->tp) {
-		/* No tracepoint structure found so no ID possible */
-		return -EIO;
-	}
-#endif
-#endif
-	if (tnode->type == SW_TRACE_COLLECTOR_NOTIFIER)
-		head = (void *)&s_notifier_list;
-
-	SW_LIST_FOR_EACH_ENTRY(lnode, head, list) {
-		struct sw_trace_notifier_data *data = lnode->data;
-
-		if (!strcmp(
-			data->name->abstract_name, tnode->name->abstract_name))
-			return lnode->id;
-	}
-	return -1;
-}
-/*
- * Retrieve the "kernel" name for this tracepoint/notifier.
- */
-const char *sw_get_trace_notifier_kernel_name(
-		struct sw_trace_notifier_data *node)
-{
-	return node->name->kernel_name;
-};
-/*
- * Retrieve the "abstract" name for this tracepoint/notifier.
- */
-const char *sw_get_trace_notifier_abstract_name(
-			struct sw_trace_notifier_data *node)
-{
-	return node->name->abstract_name;
-};
-
-/*
- * Add a single TRACE/NOTIFY provider.
- */
-int sw_register_trace_notify_provider(struct sw_trace_notifier_data *data)
-{
-	struct sw_trace_list_node *lnode = NULL;
-
-	if (!data) {
-		pw_pr_error(
-			"ERROR: cannot add NULL trace/notifier provider!\n");
-		return -EIO;
-	}
-	if (!(data->type == SW_TRACE_COLLECTOR_TRACEPOINT ||
-			data->type == SW_TRACE_COLLECTOR_NOTIFIER)) {
-		pw_pr_error(
-			"ERROR: cannot add invalid trace/notifier data!\n");
-		return -EIO;
-	}
-	/*
-	 * Kernel name is allowed to be NULL, but abstract name
-	 * MUST be present!
-	 */
-	if (!data->name || !data->name->abstract_name) {
-		pw_pr_error(
-			"ERROR: cannot add trace/notifier provider without an abstract name!\n");
-		pw_pr_error("ERROR: data->name = %p\n", data->name);
-		return -EIO;
-	}
-	lnode = sw_kmalloc(sizeof(*lnode), GFP_KERNEL);
-	if (!lnode) {
-		pw_pr_error(
-			"ERROR: couldn't allocate a list node when adding a trace/notifier provider!\n");
-		return -ENOMEM;
-	}
-	lnode->data = data;
-	SW_LIST_ENTRY_INIT(lnode, list);
-	if (data->type == SW_TRACE_COLLECTOR_TRACEPOINT) {
-		lnode->id = ++s_trace_idx;
-		SW_LIST_ADD(&s_trace_list, lnode, list);
-	} else {
-		lnode->id = ++s_notifier_idx;
-		SW_LIST_ADD(&s_notifier_list, lnode, list);
-	}
-	return PW_SUCCESS;
-}
-/*
- * Add all TRACE/NOTIFY providers.
- */
-int sw_add_trace_notify(void)
-{
-	return sw_add_trace_notifier_providers();
-}
-
-static void sw_free_trace_notifier_list_i(void *list_head)
-{
-	SW_LIST_HEAD_VAR(sw_trace_list_node) * head = list_head;
-	while (!SW_LIST_EMPTY(head)) {
-		struct sw_trace_list_node *lnode =
-			SW_LIST_GET_HEAD_ENTRY(head, sw_trace_list_node, list);
-
-		SW_LIST_UNLINK(lnode, list);
-		sw_kfree(lnode);
-	}
-}
-/*
- * Remove TRACE/NOTIFY providers.
- */
-void sw_remove_trace_notify(void)
-{
-	/*
-	 * Free all nodes.
-	 */
-	sw_free_trace_notifier_list_i(&s_trace_list);
-	sw_free_trace_notifier_list_i(&s_notifier_list);
-	/*
-	 * Call our providers to deallocate resources.
-	 */
-	sw_remove_trace_notifier_providers();
-	/*
-	 * Clear out the topology list
-	 */
-	sw_clear_topology_list();
-}
-
-#define REG_FLAG (void *)1
-#define UNREG_FLAG (void *)2
-static int sw_reg_unreg_node_i(struct sw_trace_notifier_data *node,
-				void *is_reg)
-{
-	if (is_reg == REG_FLAG) {
-		/*
-		 * Do we have anything to collect?
-		 * Update: or were we asked to always register?
-		 */
-		if (SW_LIST_EMPTY(&node->list) && !node->always_register)
-			return PW_SUCCESS;
-
-		/*
-		 * Sanity: ensure we have a register AND an unregister function
-		 * before proceeding!
-		 */
-		if (node->probe_register == NULL ||
-				node->probe_unregister == NULL) {
-			pw_pr_debug(
-				"WARNING: invalid trace/notifier register/unregister function for %s\n",
-				 sw_get_trace_notifier_kernel_name(node));
-			/*
-			 * Don't flag this as an error -- some socwatch
-			 * trace providers don't have a register/unregister
-			 * function
-			 */
-			return PW_SUCCESS;
-		}
-		if ((*node->probe_register)(node))
-			return -EIO;
-
-		node->was_registered = true;
-		return PW_SUCCESS;
-	} else if (is_reg == UNREG_FLAG) {
-		if (node->was_registered) {
-			/*
-			 * No need to check for validity of probe unregister
-			 * function -- 'sw_register_notifiers_i()'
-			 * would already have done so!
-			 */
-			WARN_ON((*node->probe_unregister)(node));
-			node->was_registered = false;
-			pw_pr_debug("OK, unregistered trace/notifier for %s\n",
-				sw_get_trace_notifier_kernel_name(node));
-		}
-		return PW_SUCCESS;
-	}
-	pw_pr_error("ERROR: invalid reg/unreg flag value 0x%lx\n",
-		(unsigned long)is_reg);
-	return -EIO;
-}
-/*
- * Register all required tracepoints and notifiers.
- */
-int sw_register_trace_notifiers(void)
-{
-	/*
-	 * First, the tracepoints.
-	 */
-	if (sw_for_each_tracepoint_node(&sw_reg_unreg_node_i,
-			REG_FLAG, true /* return on error */)) {
-		pw_pr_error("ERROR registering some tracepoints\n");
-		return -EIO;
-	}
-	/*
-	 * And then the notifiers.
-	 */
-	if (sw_for_each_notifier_node(&sw_reg_unreg_node_i,
-			REG_FLAG, true /* return on error */)) {
-		pw_pr_error("ERROR registering some tracepoints\n");
-		return -EIO;
-	}
-	return PW_SUCCESS;
-};
-/*
- * Unregister all previously registered tracepoints and notifiers.
- */
-int sw_unregister_trace_notifiers(void)
-{
-	/*
-	 * First, the notifiers.
-	 */
-	if (sw_for_each_notifier_node(&sw_reg_unreg_node_i, UNREG_FLAG,
-			true /* return on error */)) {
-		pw_pr_error("ERROR registering some tracepoints\n");
-		return -EIO;
-	}
-	/*
-	 * And then the tracepoints.
-	 */
-	if (sw_for_each_tracepoint_node(
-			&sw_reg_unreg_node_i,
-			UNREG_FLAG, true /* return on error */)) {
-		pw_pr_error("ERROR registering some tracepoints\n");
-		return -EIO;
-	}
-	return PW_SUCCESS;
-};
-
-void sw_clear_topology_list(void)
-{
-	SW_LIST_HEAD_VAR(sw_topology_node) * head = &sw_topology_list;
-	while (!SW_LIST_EMPTY(head)) {
-		struct sw_topology_node *lnode =
-			SW_LIST_GET_HEAD_ENTRY(head, sw_topology_node, list);
-
-		pw_pr_debug("Clearing topology node for cpu %d\n",
-			lnode->change.cpu);
-		SW_LIST_UNLINK(lnode, list);
-		sw_kfree(lnode);
-	}
-	sw_num_topology_entries  = 0;
-}
+/* SPDX-License-Identifier: GPL-2.0 AND BSD-3-Clause
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * Contact Information:
+ * SoC Watch Developer Team <socwatchdevelopers@intel.com>
+ * Intel Corporation,
+ * 1300 S Mopac Expwy,
+ * Austin, TX 78746
+ *
+ * BSD LICENSE
+ *
+ * Copyright(c) 2014 - 2019 Intel Corporation.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ */
+#include "sw_structs.h"
+#include "sw_kernel_defines.h"
+#include "sw_types.h"
+#include "sw_tracepoint_handlers.h"
+#include "sw_trace_notifier_provider.h"
+#include "sw_mem.h"
+
+/* -------------------------------------------------
+ * Data structures and variable definitions.
+ * -------------------------------------------------
+ */
+struct sw_trace_list_node {
+	struct sw_trace_notifier_data *data;
+	int id;
+
+	SW_LIST_ENTRY(list, sw_trace_list_node);
+};
+static SW_DEFINE_LIST_HEAD(s_trace_list, sw_trace_list_node) =
+				SW_LIST_HEAD_INITIALIZER(s_trace_list);
+static SW_DEFINE_LIST_HEAD(s_notifier_list, sw_trace_list_node) =
+				SW_LIST_HEAD_INITIALIZER(s_notifier_list);
+static int s_trace_idx = -1, s_notifier_idx = -1;
+
+SW_DEFINE_LIST_HEAD(sw_topology_list, sw_topology_node) =
+				SW_LIST_HEAD_INITIALIZER(sw_topology_list);
+size_t sw_num_topology_entries;
+
+
+/* -------------------------------------------------
+ * Function definitions.
+ * -------------------------------------------------
+ */
+int sw_extract_tracepoints(void)
+{
+	return sw_extract_trace_notifier_providers();
+}
+
+void sw_reset_trace_notifier_lists(void)
+{
+	sw_reset_trace_notifier_providers();
+}
+
+void sw_print_trace_notifier_overheads(void)
+{
+	sw_print_trace_notifier_provider_overheads();
+}
+
+static int sw_for_each_node_i(
+	void *list_head,
+	int (*func)(struct sw_trace_notifier_data *node, void *priv),
+	void *priv, bool return_on_error)
+{
+	SW_LIST_HEAD_VAR(sw_trace_list_node) * head = list_head;
+	int retval = PW_SUCCESS;
+	struct sw_trace_list_node *lnode = NULL;
+
+	SW_LIST_FOR_EACH_ENTRY(lnode, head, list) {
+		if ((*func)(lnode->data, priv)) {
+			retval = -EIO;
+			if (return_on_error)
+				break;
+		}
+	}
+	return retval;
+}
+
+int sw_for_each_tracepoint_node(
+	int (*func)(struct sw_trace_notifier_data *node, void *priv),
+	void *priv, bool return_on_error)
+{
+	if (func)
+		return sw_for_each_node_i(&s_trace_list,
+			func, priv, return_on_error);
+
+	return PW_SUCCESS;
+}
+
+int sw_for_each_notifier_node(
+	int (*func)(struct sw_trace_notifier_data *node, void *priv),
+	void *priv, bool return_on_error)
+{
+
+	if (func)
+		return sw_for_each_node_i(&s_notifier_list,
+						func, priv, return_on_error);
+
+	return PW_SUCCESS;
+}
+
+/*
+ * Retrieve the ID for the corresponding tracepoint/notifier.
+ */
+int sw_get_trace_notifier_id(struct sw_trace_notifier_data *tnode)
+{
+	struct sw_trace_list_node *lnode = NULL;
+
+	SW_LIST_HEAD_VAR(sw_trace_list_node) * head = (void *)&s_trace_list;
+	if (!tnode) {
+		pw_pr_error(
+			"ERROR: cannot get ID for NULL trace/notifier data!\n");
+		return -EIO;
+	}
+	if (!(tnode->type == SW_TRACE_COLLECTOR_TRACEPOINT ||
+			tnode->type == SW_TRACE_COLLECTOR_NOTIFIER)) {
+		pw_pr_error(
+			"ERROR: cannot get ID for invalid trace/notifier data!\n");
+		return -EIO;
+	}
+	if (!tnode->name || !tnode->name->abstract_name) {
+		pw_pr_error(
+			"ERROR: cannot get ID for trace/notifier data without valid name!\n");
+		return -EIO;
+	}
+
+#if defined(LINUX_VERSION_CODE)
+#if KERNEL_VERSION(3, 15, 0) <= LINUX_VERSION_CODE &&	\
+	defined(CONFIG_TRACEPOINTS)
+
+	if (tnode->type == SW_TRACE_COLLECTOR_TRACEPOINT &&
+		tnode->name->kernel_name && !tnode->tp) {
+		/* No tracepoint structure found so no ID possible */
+		return -EIO;
+	}
+#endif
+#endif
+	if (tnode->type == SW_TRACE_COLLECTOR_NOTIFIER)
+		head = (void *)&s_notifier_list;
+
+	SW_LIST_FOR_EACH_ENTRY(lnode, head, list) {
+		struct sw_trace_notifier_data *data = lnode->data;
+
+		if (!strcmp(
+			data->name->abstract_name, tnode->name->abstract_name))
+			return lnode->id;
+	}
+	return -1;
+}
+/*
+ * Retrieve the "kernel" name for this tracepoint/notifier.
+ */
+const char *sw_get_trace_notifier_kernel_name(
+		struct sw_trace_notifier_data *node)
+{
+	return node->name->kernel_name;
+};
+/*
+ * Retrieve the "abstract" name for this tracepoint/notifier.
+ */
+const char *sw_get_trace_notifier_abstract_name(
+			struct sw_trace_notifier_data *node)
+{
+	return node->name->abstract_name;
+};
+
+/*
+ * Add a single TRACE/NOTIFY provider.
+ */
+int sw_register_trace_notify_provider(struct sw_trace_notifier_data *data)
+{
+	struct sw_trace_list_node *lnode = NULL;
+
+	if (!data) {
+		pw_pr_error(
+			"ERROR: cannot add NULL trace/notifier provider!\n");
+		return -EIO;
+	}
+	if (!(data->type == SW_TRACE_COLLECTOR_TRACEPOINT ||
+			data->type == SW_TRACE_COLLECTOR_NOTIFIER)) {
+		pw_pr_error(
+			"ERROR: cannot add invalid trace/notifier data!\n");
+		return -EIO;
+	}
+	/*
+	 * Kernel name is allowed to be NULL, but abstract name
+	 * MUST be present!
+	 */
+	if (!data->name || !data->name->abstract_name) {
+		pw_pr_error(
+			"ERROR: cannot add trace/notifier provider without an abstract name!\n");
+		pw_pr_error("ERROR: data->name = %p\n", data->name);
+		return -EIO;
+	}
+	lnode = sw_kmalloc(sizeof(*lnode), GFP_KERNEL);
+	if (!lnode) {
+		pw_pr_error(
+			"ERROR: couldn't allocate a list node when adding a trace/notifier provider!\n");
+		return -ENOMEM;
+	}
+	lnode->data = data;
+	SW_LIST_ENTRY_INIT(lnode, list);
+	if (data->type == SW_TRACE_COLLECTOR_TRACEPOINT) {
+		lnode->id = ++s_trace_idx;
+		SW_LIST_ADD(&s_trace_list, lnode, list);
+	} else {
+		lnode->id = ++s_notifier_idx;
+		SW_LIST_ADD(&s_notifier_list, lnode, list);
+	}
+	return PW_SUCCESS;
+}
+/*
+ * Add all TRACE/NOTIFY providers.
+ */
+int sw_add_trace_notify(void)
+{
+	return sw_add_trace_notifier_providers();
+}
+
+static void sw_free_trace_notifier_list_i(void *list_head)
+{
+	SW_LIST_HEAD_VAR(sw_trace_list_node) * head = list_head;
+	while (!SW_LIST_EMPTY(head)) {
+		struct sw_trace_list_node *lnode =
+			SW_LIST_GET_HEAD_ENTRY(head, sw_trace_list_node, list);
+
+		SW_LIST_UNLINK(lnode, list);
+		sw_kfree(lnode);
+	}
+}
+/*
+ * Remove TRACE/NOTIFY providers.
+ */
+void sw_remove_trace_notify(void)
+{
+	/*
+	 * Free all nodes.
+	 */
+	sw_free_trace_notifier_list_i(&s_trace_list);
+	sw_free_trace_notifier_list_i(&s_notifier_list);
+	/*
+	 * Call our providers to deallocate resources.
+	 */
+	sw_remove_trace_notifier_providers();
+	/*
+	 * Clear out the topology list
+	 */
+	sw_clear_topology_list();
+}
+
+#define REG_FLAG (void *)1
+#define UNREG_FLAG (void *)2
+static int sw_reg_unreg_node_i(struct sw_trace_notifier_data *node,
+				void *is_reg)
+{
+	if (is_reg == REG_FLAG) {
+		/*
+		 * Do we have anything to collect?
+		 * Update: or were we asked to always register?
+		 */
+		if (SW_LIST_EMPTY(&node->list) && !node->always_register)
+			return PW_SUCCESS;
+
+		/*
+		 * Sanity: ensure we have a register AND an unregister function
+		 * before proceeding!
+		 */
+		if (node->probe_register == NULL ||
+				node->probe_unregister == NULL) {
+			pw_pr_debug(
+				"WARNING: invalid trace/notifier register/unregister function for %s\n",
+				 sw_get_trace_notifier_kernel_name(node));
+			/*
+			 * Don't flag this as an error -- some socwatch
+			 * trace providers don't have a register/unregister
+			 * function
+			 */
+			return PW_SUCCESS;
+		}
+		if ((*node->probe_register)(node))
+			return -EIO;
+
+		node->was_registered = true;
+		return PW_SUCCESS;
+	} else if (is_reg == UNREG_FLAG) {
+		if (node->was_registered) {
+			/*
+			 * No need to check for validity of probe unregister
+			 * function -- 'sw_register_notifiers_i()'
+			 * would already have done so!
+			 */
+			WARN_ON((*node->probe_unregister)(node));
+			node->was_registered = false;
+			pw_pr_debug("OK, unregistered trace/notifier for %s\n",
+				sw_get_trace_notifier_kernel_name(node));
+		}
+		return PW_SUCCESS;
+	}
+	pw_pr_error("ERROR: invalid reg/unreg flag value 0x%lx\n",
+		(unsigned long)is_reg);
+	return -EIO;
+}
+/*
+ * Register all required tracepoints and notifiers.
+ */
+int sw_register_trace_notifiers(void)
+{
+	/*
+	 * First, the tracepoints.
+	 */
+	if (sw_for_each_tracepoint_node(&sw_reg_unreg_node_i,
+			REG_FLAG, true /* return on error */)) {
+		pw_pr_error("ERROR registering some tracepoints\n");
+		return -EIO;
+	}
+	/*
+	 * And then the notifiers.
+	 */
+	if (sw_for_each_notifier_node(&sw_reg_unreg_node_i,
+			REG_FLAG, true /* return on error */)) {
+		pw_pr_error("ERROR registering some tracepoints\n");
+		return -EIO;
+	}
+	return PW_SUCCESS;
+};
+/*
+ * Unregister all previously registered tracepoints and notifiers.
+ */
+int sw_unregister_trace_notifiers(void)
+{
+	/*
+	 * First, the notifiers.
+	 */
+	if (sw_for_each_notifier_node(&sw_reg_unreg_node_i, UNREG_FLAG,
+			true /* return on error */)) {
+		pw_pr_error("ERROR registering some tracepoints\n");
+		return -EIO;
+	}
+	/*
+	 * And then the tracepoints.
+	 */
+	if (sw_for_each_tracepoint_node(
+			&sw_reg_unreg_node_i,
+			UNREG_FLAG, true /* return on error */)) {
+		pw_pr_error("ERROR registering some tracepoints\n");
+		return -EIO;
+	}
+	return PW_SUCCESS;
+};
+
+void sw_clear_topology_list(void)
+{
+	SW_LIST_HEAD_VAR(sw_topology_node) * head = &sw_topology_list;
+	while (!SW_LIST_EMPTY(head)) {
+		struct sw_topology_node *lnode =
+			SW_LIST_GET_HEAD_ENTRY(head, sw_topology_node, list);
+
+		pw_pr_debug("Clearing topology node for cpu %d\n",
+			lnode->change.cpu);
+		SW_LIST_UNLINK(lnode, list);
+		sw_kfree(lnode);
+	}
+	sw_num_topology_entries  = 0;
+}
-- 
2.17.1

