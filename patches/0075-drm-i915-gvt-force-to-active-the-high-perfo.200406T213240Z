From 2491b2923de83e5111fa2c77013b2d4e4d95a520 Mon Sep 17 00:00:00 2001
From: Weinan Li <weinan.z.li@intel.com>
Date: Tue, 17 Apr 2018 14:37:26 +0800
Subject: [PATCH 075/100] drm/i915/gvt: force to active the high-performance
 mode during vGPU busy

With the RPS interrupt, KMD can adjust the GPU frequency dynamically for
power saving. It works well in the non-virtualized environment, but there
is more latency imported by VMM and virtual interrupt handler which may
break the RPS policy work model, and GPU works in inefficient mode. Here
we force to active the high-performance mode when detect vgpu is busy until
the GPU runs into idle.

Tracked-On: projectacrn/acrn-hypervisor/issues/2227
Signed-off-by: Weinan Li <weinan.z.li@intel.com>
Signed-off-by: Min He <min.he@intel.com>
Reviewed-by: Zhao Yakui <yakui.zhao@intel.com>
Tracked-On: PKT-1642
---
 drivers/gpu/drm/i915/gvt/gvt.h       |  1 +
 drivers/gpu/drm/i915/gvt/scheduler.c | 22 ++++++++++++++++++++++
 2 files changed, 23 insertions(+)

diff --git a/drivers/gpu/drm/i915/gvt/gvt.h b/drivers/gpu/drm/i915/gvt/gvt.h
index 27dc1bf191fa..9332fc5bde76 100644
--- a/drivers/gpu/drm/i915/gvt/gvt.h
+++ b/drivers/gpu/drm/i915/gvt/gvt.h
@@ -361,6 +361,7 @@ struct intel_gvt {
 	} engine_mmio_list;
 
 	struct dentry *debugfs_root;
+	struct work_struct active_hp_work;
 };
 
 static inline struct intel_gvt *to_gvt(struct drm_i915_private *i915)
diff --git a/drivers/gpu/drm/i915/gvt/scheduler.c b/drivers/gpu/drm/i915/gvt/scheduler.c
index 9700bce16c01..abbcc6ac0e2f 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.c
+++ b/drivers/gpu/drm/i915/gvt/scheduler.c
@@ -40,8 +40,11 @@
 #include "gt/intel_context.h"
 #include "gt/intel_ring.h"
 
+#include "gt/intel_rps.h"
+
 #include "i915_drv.h"
 #include "gvt.h"
+#include "intel_pm.h"
 
 #define RING_CTX_OFF(x) \
 	offsetof(struct execlist_ring_context, x)
@@ -224,6 +227,22 @@ static void save_ring_hw_state(struct intel_vgpu *vgpu, int ring_id)
 	vgpu_vreg(vgpu, i915_mmio_reg_offset(reg)) = I915_READ_FW(reg);
 }
 
+static void active_hp_work(struct work_struct *work)
+{
+	struct intel_gvt *gvt =
+		container_of(work, struct intel_gvt, active_hp_work);
+	struct drm_i915_private *dev_priv = gvt->dev_priv;
+	struct intel_rps *rps = &dev_priv->gt.rps;
+	u8 freq = rps->rp0_freq;
+
+	if (IS_BROXTON(dev_priv))
+		freq = intel_freq_opcode(rps, 600);
+
+	if (READ_ONCE(rps->cur_freq) < freq) {
+		intel_rps_set(rps, freq);
+	}
+}
+
 static int shadow_context_status_change(struct notifier_block *nb,
 		unsigned long action, void *data)
 {
@@ -255,6 +274,7 @@ static int shadow_context_status_change(struct notifier_block *nb,
 
 	switch (action) {
 	case INTEL_CONTEXT_SCHEDULE_IN:
+		schedule_work(&gvt->active_hp_work);
 		spin_lock_irqsave(&scheduler->mmio_context_lock, flags);
 		if (workload->vgpu != scheduler->engine_owner[ring_id]) {
 			/* Switch ring from host to vGPU or vGPU to vGPU. */
@@ -1173,6 +1193,8 @@ int intel_gvt_init_workload_scheduler(struct intel_gvt *gvt)
 		atomic_notifier_chain_register(&engine->context_status_notifier,
 					&gvt->shadow_ctx_notifier_block[i]);
 	}
+	INIT_WORK(&gvt->active_hp_work, active_hp_work);
+
 	return 0;
 err:
 	intel_gvt_clean_workload_scheduler(gvt);
-- 
2.17.1

