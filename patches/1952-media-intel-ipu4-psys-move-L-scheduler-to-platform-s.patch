From ae2d6aed0af581a406a377d66460d9c1315d2bed Mon Sep 17 00:00:00 2001
From: Wang Zaikuo <zaikuo.wang@intel.com>
Date: Fri, 18 May 2018 16:13:51 +0800
Subject: [PATCH 1952/2367] media: intel-ipu4: psys: move L-scheduler to
 platform specific

Message for Open Source:
L-scheduler and watchdog mechanism and implement are different
between platforms; it makes sense to move to platform specific
file

Message for Internal:
[Issue/Feature]
This patch is mainly to do preparing for IPU6, which L-scheduler
will be huge different to IPU4 due to use PPG

[Root Cause/Changes]
There will be one ipu6 patch depended on this one to
put same function in IPU6 psys driver to make build pass,
and will implement them by L-Scheduler later
Also, it deleted legacy pg flow in ipu6 psys driver

Change-Id: I110e5d9d4f3d8a1135cfcdd5ce5df9ed72ec3559
Tracked-On: #JKRLSCN-256
Signed-off-by: Wang Zaikuo <zaikuo.wang@intel.com>
Signed-off-by: Meng Wei <wei.meng@intel.com>
---
 drivers/media/pci/intel/ipu-psys.c       | 202 -------------------------------
 drivers/media/pci/intel/ipu-psys.h       |   3 +-
 drivers/media/pci/intel/ipu4/ipu4-psys.c | 202 +++++++++++++++++++++++++++++++
 3 files changed, 204 insertions(+), 203 deletions(-)

diff --git a/drivers/media/pci/intel/ipu-psys.c b/drivers/media/pci/intel/ipu-psys.c
index 66acd73..1a9a0bf 100644
--- a/drivers/media/pci/intel/ipu-psys.c
+++ b/drivers/media/pci/intel/ipu-psys.c
@@ -41,13 +41,8 @@
 #include "ipu-fw-isys.h"
 #include "ipu-fw-com.h"
 
-static bool enable_concurrency = true;
 static bool async_fw_init;
-module_param(enable_concurrency, bool, 0664);
 module_param(async_fw_init, bool, 0664);
-
-MODULE_PARM_DESC(enable_concurrency,
-		 "Enable concurrent execution of program groups");
 MODULE_PARM_DESC(async_fw_init, "Enable asynchronous firmware initialization");
 
 #define IPU_PSYS_NUM_DEVICES		4
@@ -671,203 +666,6 @@ static int ipu_psys_putbuf(struct ipu_psys_buffer *buf, struct ipu_psys_fh *fh)
 	return 0;
 }
 
-/*
- * Schedule next kcmd by finding a runnable kcmd from the highest
- * priority queue in a round-robin fashion versus the client
- * queues and running it.
- * Any kcmds which fail to start are completed with an error.
- */
-static void ipu_psys_run_next(struct ipu_psys *psys)
-{
-	int p;
-
-	/*
-	 * Code below will crash if fhs is empty. Normally this
-	 * shouldn't happen.
-	 */
-	if (list_empty(&psys->fhs)) {
-		WARN_ON(1);
-		return;
-	}
-
-	for (p = 0; p < IPU_PSYS_CMD_PRIORITY_NUM; p++) {
-		int removed;
-
-		do {
-			struct ipu_psys_fh *fh = list_first_entry(&psys->fhs,
-								  struct
-								  ipu_psys_fh,
-								  list);
-			struct ipu_psys_fh *fh_last =
-			    list_last_entry(&psys->fhs,
-					    struct ipu_psys_fh,
-					    list);
-			/*
-			 * When a kcmd is scheduled from a fh, it might expose
-			 * more runnable kcmds behind it in the same queue.
-			 * Therefore loop running kcmds as long as some were
-			 * scheduled.
-			 */
-			removed = 0;
-			do {
-				struct ipu_psys_fh *fh_next =
-				    list_next_entry(fh, list);
-				struct ipu_psys_kcmd *kcmd;
-				int ret;
-
-				mutex_lock(&fh->mutex);
-
-				kcmd = fh->new_kcmd_tail[p];
-				/*
-				 * If concurrency is disabled and there are
-				 * already commands running on the PSYS, do not
-				 * run new commands.
-				 */
-				if (!enable_concurrency &&
-				    psys->active_kcmds > 0) {
-					mutex_unlock(&fh->mutex);
-					return;
-				}
-
-				/* Are there new kcmds available for running? */
-				if (!kcmd)
-					goto next;
-
-				ret = ipu_psys_kcmd_queue(psys, kcmd);
-				if (ret == -ENOSPC)
-					goto next;
-
-				/* Update pointer to the first new kcmd */
-				fh->new_kcmd_tail[p] = NULL;
-				while (kcmd != list_last_entry(&fh->kcmds[p],
-							       struct
-							       ipu_psys_kcmd,
-							       list)) {
-					kcmd = list_next_entry(kcmd, list);
-					if (kcmd->state == KCMD_STATE_NEW) {
-						fh->new_kcmd_tail[p] = kcmd;
-						break;
-					}
-				}
-
-				list_move_tail(&fh->list, &psys->fhs);
-				removed++;
-next:
-				mutex_unlock(&fh->mutex);
-				if (fh == fh_last)
-					break;
-				fh = fh_next;
-			} while (1);
-		} while (removed > 0);
-	}
-}
-
-/*
- * Move all kcmds in all queues forcily into completed state.
- */
-static void ipu_psys_flush_kcmds(struct ipu_psys *psys, int error)
-{
-	struct ipu_psys_fh *fh;
-	struct ipu_psys_kcmd *kcmd;
-	int p;
-
-	dev_err(&psys->dev, "flushing all commands with error: %d\n", error);
-
-	list_for_each_entry(fh, &psys->fhs, list) {
-		mutex_lock(&fh->mutex);
-		for (p = 0; p < IPU_PSYS_CMD_PRIORITY_NUM; p++) {
-			fh->new_kcmd_tail[p] = NULL;
-			list_for_each_entry(kcmd, &fh->kcmds[p], list) {
-				if (kcmd->state == KCMD_STATE_COMPLETE)
-					continue;
-				ipu_psys_kcmd_complete(psys, kcmd, error);
-			}
-		}
-		mutex_unlock(&fh->mutex);
-	}
-}
-
-/*
- * Abort all currently running process groups and reset PSYS
- * by power cycling it. PSYS power must not be acquired
- * except by running kcmds when calling this.
- */
-void ipu_psys_reset(struct ipu_psys *psys)
-{
-#ifdef CONFIG_PM
-	struct device *d = &psys->adev->isp->psys_iommu->dev;
-	int r;
-
-	pm_runtime_dont_use_autosuspend(&psys->adev->dev);
-	r = pm_runtime_get_sync(d);
-	if (r < 0) {
-		pm_runtime_put_noidle(d);
-		dev_err(&psys->adev->dev, "power management failed\n");
-		return;
-	}
-
-	ipu_psys_flush_kcmds(psys, -EIO);
-	flush_workqueue(pm_wq);
-	r = pm_runtime_put_sync(d);	/* Turn big red power knob off here */
-	/* Power was successfully turned off if and only if zero was returned */
-	if (r)
-		dev_warn(&psys->adev->dev,
-			 "power management failed, PSYS reset may be incomplete\n");
-	pm_runtime_use_autosuspend(&psys->adev->dev);
-	ipu_psys_run_next(psys);
-#else
-	dev_err(&psys->adev->dev,
-		"power management disabled, can not reset PSYS\n");
-#endif
-}
-
-static void ipu_psys_watchdog_work(struct work_struct *work)
-{
-	struct ipu_psys *psys = container_of(work,
-					     struct ipu_psys, watchdog_work);
-	struct ipu_psys_fh *fh;
-
-	mutex_lock(&psys->mutex);
-
-	/* Loop over all running kcmds */
-	list_for_each_entry(fh, &psys->fhs, list) {
-		int p, r;
-
-		mutex_lock(&fh->mutex);
-		for (p = 0; p < IPU_PSYS_CMD_PRIORITY_NUM; p++) {
-			struct ipu_psys_kcmd *kcmd;
-
-			list_for_each_entry(kcmd, &fh->kcmds[p], list) {
-				if (fh->new_kcmd_tail[p] == kcmd)
-					break;
-				if (kcmd->state != KCMD_STATE_RUNNING)
-					continue;
-				if (timer_pending(&kcmd->watchdog))
-					continue;
-				/* Found an expired but running command */
-				dev_err(&psys->adev->dev,
-					"kcmd:0x%llx[0x%llx] taking too long\n",
-					kcmd->user_token, kcmd->issue_id);
-				r = ipu_psys_kcmd_abort(psys, kcmd, -ETIME);
-				if (r)
-					goto stop_failed;
-			}
-		}
-		mutex_unlock(&fh->mutex);
-	}
-
-	/* Kick command scheduler thread */
-	atomic_set(&psys->wakeup_sched_thread_count, 1);
-	wake_up_interruptible(&psys->sched_cmd_wq);
-	mutex_unlock(&psys->mutex);
-	return;
-
-stop_failed:
-	mutex_unlock(&fh->mutex);
-	ipu_psys_reset(psys);
-	mutex_unlock(&psys->mutex);
-}
-
 static struct ipu_psys_kcmd *__ipu_get_completed_kcmd(struct ipu_psys *psys,
 						      struct ipu_psys_fh *fh)
 {
diff --git a/drivers/media/pci/intel/ipu-psys.h b/drivers/media/pci/intel/ipu-psys.h
index 55a6744..6378cf4 100644
--- a/drivers/media/pci/intel/ipu-psys.h
+++ b/drivers/media/pci/intel/ipu-psys.h
@@ -218,12 +218,13 @@ long ipu_psys_compat_ioctl32(struct file *file, unsigned int cmd,
 #endif
 
 void ipu_psys_setup_hw(struct ipu_psys *psys);
-void ipu_psys_reset(struct ipu_psys *psys);
 void ipu_psys_handle_events(struct ipu_psys *psys);
 int ipu_psys_kcmd_new(struct ipu_psys_command *cmd, struct ipu_psys_fh *fh);
 int ipu_psys_kcmd_queue(struct ipu_psys *psys, struct ipu_psys_kcmd *kcmd);
 void ipu_psys_kcmd_complete(struct ipu_psys *psys,
 			    struct ipu_psys_kcmd *kcmd, int error);
+void ipu_psys_run_next(struct ipu_psys *psys);
+void ipu_psys_watchdog_work(struct work_struct *work);
 int ipu_psys_kcmd_abort(struct ipu_psys *psys,
 			struct ipu_psys_kcmd *kcmd, int error);
 void ipu_psys_kcmd_free(struct ipu_psys_kcmd *kcmd);
diff --git a/drivers/media/pci/intel/ipu4/ipu4-psys.c b/drivers/media/pci/intel/ipu4/ipu4-psys.c
index 1f6227c..a527561 100644
--- a/drivers/media/pci/intel/ipu4/ipu4-psys.c
+++ b/drivers/media/pci/intel/ipu4/ipu4-psys.c
@@ -27,9 +27,13 @@
 #include "ipu-trace-event.h"
 
 static bool early_pg_transfer;
+static bool enable_concurrency = true;
 module_param(early_pg_transfer, bool, 0664);
+module_param(enable_concurrency, bool, 0664);
 MODULE_PARM_DESC(early_pg_transfer,
 		 "Copy PGs back to user after resource allocation");
+MODULE_PARM_DESC(enable_concurrency,
+		 "Enable concurrent execution of program groups");
 
 struct ipu_trace_block psys_trace_blocks[] = {
 	{
@@ -435,6 +439,97 @@ void ipu_psys_kcmd_complete(struct ipu_psys *psys,
 }
 
 /*
+ * Schedule next kcmd by finding a runnable kcmd from the highest
+ * priority queue in a round-robin fashion versus the client
+ * queues and running it.
+ * Any kcmds which fail to start are completed with an error.
+ */
+void ipu_psys_run_next(struct ipu_psys *psys)
+{
+	int p;
+
+	/*
+	 * Code below will crash if fhs is empty. Normally this
+	 * shouldn't happen.
+	 */
+	if (list_empty(&psys->fhs)) {
+		WARN_ON(1);
+		return;
+	}
+
+	for (p = 0; p < IPU_PSYS_CMD_PRIORITY_NUM; p++) {
+		int removed;
+
+		do {
+			struct ipu_psys_fh *fh = list_first_entry(&psys->fhs,
+								  struct
+								  ipu_psys_fh,
+								  list);
+			struct ipu_psys_fh *fh_last =
+			    list_last_entry(&psys->fhs,
+					    struct ipu_psys_fh,
+					    list);
+			/*
+			 * When a kcmd is scheduled from a fh, it might expose
+			 * more runnable kcmds behind it in the same queue.
+			 * Therefore loop running kcmds as long as some were
+			 * scheduled.
+			 */
+			removed = 0;
+			do {
+				struct ipu_psys_fh *fh_next =
+				    list_next_entry(fh, list);
+				struct ipu_psys_kcmd *kcmd;
+				int ret;
+
+				mutex_lock(&fh->mutex);
+
+				kcmd = fh->new_kcmd_tail[p];
+				/*
+				 * If concurrency is disabled and there are
+				 * already commands running on the PSYS, do not
+				 * run new commands.
+				 */
+				if (!enable_concurrency &&
+				    psys->active_kcmds > 0) {
+					mutex_unlock(&fh->mutex);
+					return;
+				}
+
+				/* Are there new kcmds available for running? */
+				if (!kcmd)
+					goto next;
+
+				ret = ipu_psys_kcmd_queue(psys, kcmd);
+				if (ret == -ENOSPC)
+					goto next;
+
+				/* Update pointer to the first new kcmd */
+				fh->new_kcmd_tail[p] = NULL;
+				while (kcmd != list_last_entry(&fh->kcmds[p],
+							       struct
+							       ipu_psys_kcmd,
+							       list)) {
+					kcmd = list_next_entry(kcmd, list);
+					if (kcmd->state == KCMD_STATE_NEW) {
+						fh->new_kcmd_tail[p] = kcmd;
+						break;
+					}
+				}
+
+				list_move_tail(&fh->list, &psys->fhs);
+				removed++;
+next:
+				mutex_unlock(&fh->mutex);
+				if (fh == fh_last)
+					break;
+				fh = fh_next;
+			} while (1);
+		} while (removed > 0);
+	}
+}
+
+/*
  * Move kcmd into completed state. If kcmd is currently running,
  * abort it.
  */
@@ -544,6 +639,113 @@ static int ipu_psys_kcmd_start(struct ipu_psys *psys,
 	return ret;
 }
 
+/*
+ * Move all kcmds in all queues forcily into completed state.
+ */
+static void ipu_psys_flush_kcmds(struct ipu_psys *psys, int error)
+{
+	struct ipu_psys_fh *fh;
+	struct ipu_psys_kcmd *kcmd;
+	int p;
+
+	dev_err(&psys->dev, "flushing all commands with error: %d\n", error);
+
+	list_for_each_entry(fh, &psys->fhs, list) {
+		mutex_lock(&fh->mutex);
+		for (p = 0; p < IPU_PSYS_CMD_PRIORITY_NUM; p++) {
+			fh->new_kcmd_tail[p] = NULL;
+			list_for_each_entry(kcmd, &fh->kcmds[p], list) {
+				if (kcmd->state == KCMD_STATE_COMPLETE)
+					continue;
+				ipu_psys_kcmd_complete(psys, kcmd, error);
+			}
+		}
+		mutex_unlock(&fh->mutex);
+	}
+}
+
+/*
+ * Abort all currently running process groups and reset PSYS
+ * by power cycling it. PSYS power must not be acquired
+ * except by running kcmds when calling this.
+ */
+static void ipu_psys_reset(struct ipu_psys *psys)
+{
+#ifdef CONFIG_PM
+	struct device *d = &psys->adev->isp->psys_iommu->dev;
+	int r;
+
+	pm_runtime_dont_use_autosuspend(&psys->adev->dev);
+	r = pm_runtime_get_sync(d);
+	if (r < 0) {
+		pm_runtime_put_noidle(d);
+		dev_err(&psys->adev->dev, "power management failed\n");
+		return;
+	}
+
+	ipu_psys_flush_kcmds(psys, -EIO);
+	flush_workqueue(pm_wq);
+	r = pm_runtime_put_sync(d);	/* Turn big red power knob off here */
+	/* Power was successfully turned off if and only if zero was returned */
+	if (r)
+		dev_warn(&psys->adev->dev,
+			 "power management failed, PSYS reset may be incomplete\n");
+	pm_runtime_use_autosuspend(&psys->adev->dev);
+	ipu_psys_run_next(psys);
+#else
+	dev_err(&psys->adev->dev,
+		"power management disabled, can not reset PSYS\n");
+#endif
+}
+
+void ipu_psys_watchdog_work(struct work_struct *work)
+{
+	struct ipu_psys *psys = container_of(work,
+					     struct ipu_psys, watchdog_work);
+	struct ipu_psys_fh *fh;
+
+	mutex_lock(&psys->mutex);
+
+	/* Loop over all running kcmds */
+	list_for_each_entry(fh, &psys->fhs, list) {
+		int p, r;
+
+		mutex_lock(&fh->mutex);
+		for (p = 0; p < IPU_PSYS_CMD_PRIORITY_NUM; p++) {
+			struct ipu_psys_kcmd *kcmd;
+
+			list_for_each_entry(kcmd, &fh->kcmds[p], list) {
+				if (fh->new_kcmd_tail[p] == kcmd)
+					break;
+				if (kcmd->state != KCMD_STATE_RUNNING)
+					continue;
+
+				if (timer_pending(&kcmd->watchdog))
+					continue;
+				/* Found an expired but running command */
+				dev_err(&psys->adev->dev,
+					"kcmd:0x%llx[0x%llx] taking too long\n",
+					kcmd->user_token, kcmd->issue_id);
+				r = ipu_psys_kcmd_abort(psys, kcmd, -ETIME);
+				if (r)
+					goto stop_failed;
+			}
+		}
+		mutex_unlock(&fh->mutex);
+	}
+
+	/* Kick command scheduler thread */
+	atomic_set(&psys->wakeup_sched_thread_count, 1);
+	wake_up_interruptible(&psys->sched_cmd_wq);
+	mutex_unlock(&psys->mutex);
+	return;
+
+stop_failed:
+	mutex_unlock(&fh->mutex);
+	ipu_psys_reset(psys);
+	mutex_unlock(&psys->mutex);
+}
+
 #if LINUX_VERSION_CODE <= KERNEL_VERSION(4, 14, 2)
 static void ipu_psys_watchdog(unsigned long data)
 {
-- 
2.7.4

