From 3ab4a3911959dc2272a6a0728a6b13f81adb10c8 Mon Sep 17 00:00:00 2001
From: Pei Zhang <pei.zhang@intel.com>
Date: Mon, 12 Jun 2017 21:32:23 +0800
Subject: [PATCH 0923/2302] drm/i915/gvt: split a small lock from the gvt big
 lock

The small lock sched_lock in this patch splited from gvt big lock is
used to protect the scheduler data(both gvt and vGPU instance). By doing
this, the performance of mmio emulation which is using the gvt big lock
would get a high improvement.

Change-Id: I172650807b95495d4a82788306eaf74c848717d3
Signed-off-by: Pei Zhang <pei.zhang@intel.com>
Acknowledged-by: Singh, Satyeshwar <satyeshwar.singh@intel.com>
Reviewed-by: He, Min <min.he@intel.com>
Reviewed-by: Jiang, Fei <fei.jiang@intel.com>
Reviewed-by: Dong, Eddie <eddie.dong@intel.com>
Tested-by: Dong, Eddie <eddie.dong@intel.com>
---
 drivers/gpu/drm/i915/gvt/execlist.c     | 11 ++++++++---
 drivers/gpu/drm/i915/gvt/gvt.c          |  1 +
 drivers/gpu/drm/i915/gvt/gvt.h          |  1 +
 drivers/gpu/drm/i915/gvt/handlers.c     | 11 ++++++++++-
 drivers/gpu/drm/i915/gvt/sched_policy.c |  4 ++--
 drivers/gpu/drm/i915/gvt/scheduler.c    | 18 +++++++++++++-----
 drivers/gpu/drm/i915/gvt/vgpu.c         |  8 ++++++++
 7 files changed, 43 insertions(+), 11 deletions(-)

diff --git a/drivers/gpu/drm/i915/gvt/execlist.c b/drivers/gpu/drm/i915/gvt/execlist.c
index e5320b4..f7a21c5 100644
--- a/drivers/gpu/drm/i915/gvt/execlist.c
+++ b/drivers/gpu/drm/i915/gvt/execlist.c
@@ -738,7 +738,7 @@ int intel_vgpu_submit_execlist(struct intel_vgpu *vgpu, int ring_id)
 {
 	struct intel_vgpu_execlist *execlist = &vgpu->execlist[ring_id];
 	struct execlist_ctx_descriptor_format desc[2];
-	int i, ret;
+	int i, ret = 0;
 
 	desc[0] = *get_desc_from_elsp_dwords(&execlist->elsp_dwords, 1);
 	desc[1] = *get_desc_from_elsp_dwords(&execlist->elsp_dwords, 0);
@@ -757,6 +757,9 @@ int intel_vgpu_submit_execlist(struct intel_vgpu *vgpu, int ring_id)
 		}
 	}
 
+	mutex_unlock(&vgpu->gvt->lock);
+	mutex_lock(&vgpu->gvt->sched_lock);
+	mutex_lock(&vgpu->gvt->lock);
 	/* submit workload */
 	for (i = 0; i < ARRAY_SIZE(desc); i++) {
 		if (!desc[i].valid)
@@ -764,11 +767,13 @@ int intel_vgpu_submit_execlist(struct intel_vgpu *vgpu, int ring_id)
 		ret = submit_context(vgpu, ring_id, &desc[i], i == 0);
 		if (ret) {
 			gvt_vgpu_err("failed to submit desc %d\n", i);
-			return ret;
+			goto out;
 		}
 	}
 
-	return 0;
+out:
+	mutex_unlock(&vgpu->gvt->sched_lock);
+	return ret;
 
 inv_desc:
 	gvt_vgpu_err("descriptors content: desc0 %08x %08x desc1 %08x %08x\n",
diff --git a/drivers/gpu/drm/i915/gvt/gvt.c b/drivers/gpu/drm/i915/gvt/gvt.c
index 3923b42..b128fe0 100644
--- a/drivers/gpu/drm/i915/gvt/gvt.c
+++ b/drivers/gpu/drm/i915/gvt/gvt.c
@@ -289,6 +289,7 @@ int intel_gvt_init_device(struct drm_i915_private *dev_priv)
 	idr_init(&gvt->vgpu_idr);
 	spin_lock_init(&gvt->scheduler.mmio_context_lock);
 	mutex_init(&gvt->lock);
+	mutex_init(&gvt->sched_lock);
 	gvt->dev_priv = dev_priv;
 
 	init_device_info(gvt);
diff --git a/drivers/gpu/drm/i915/gvt/gvt.h b/drivers/gpu/drm/i915/gvt/gvt.h
index 836ba0f..8691d71 100644
--- a/drivers/gpu/drm/i915/gvt/gvt.h
+++ b/drivers/gpu/drm/i915/gvt/gvt.h
@@ -281,6 +281,7 @@ struct intel_gvt_pipe_info {
 
 struct intel_gvt {
 	struct mutex lock;
+	struct mutex sched_lock;
 	struct drm_i915_private *dev_priv;
 	struct idr vgpu_idr;	/* vGPU IDR pool */
 
diff --git a/drivers/gpu/drm/i915/gvt/handlers.c b/drivers/gpu/drm/i915/gvt/handlers.c
index cb280ea..41df257 100644
--- a/drivers/gpu/drm/i915/gvt/handlers.c
+++ b/drivers/gpu/drm/i915/gvt/handlers.c
@@ -307,7 +307,11 @@ static int gdrst_mmio_write(struct intel_vgpu *vgpu, unsigned int offset,
 		}
 	}
 
+	mutex_unlock(&vgpu->gvt->lock);
+	mutex_lock(&vgpu->gvt->sched_lock);
+	mutex_lock(&vgpu->gvt->lock);
 	intel_gvt_reset_vgpu_locked(vgpu, false, engine_mask);
+	mutex_unlock(&vgpu->gvt->sched_lock);
 
 	/* sw will wait for the device to ack the reset request */
 	 vgpu_vreg(vgpu, offset) = 0;
@@ -1648,8 +1652,13 @@ static int ring_mode_mmio_write(struct intel_vgpu *vgpu, unsigned int offset,
 				(enable_execlist ? "enabling" : "disabling"),
 				ring_id);
 
-		if (enable_execlist)
+		if (enable_execlist) {
+			mutex_unlock(&vgpu->gvt->lock);
+			mutex_lock(&vgpu->gvt->sched_lock);
+			mutex_lock(&vgpu->gvt->lock);
 			intel_vgpu_start_schedule(vgpu);
+			mutex_unlock(&vgpu->gvt->sched_lock);
+		}
 	}
 	return 0;
 }
diff --git a/drivers/gpu/drm/i915/gvt/sched_policy.c b/drivers/gpu/drm/i915/gvt/sched_policy.c
index 64356ad..6496857 100644
--- a/drivers/gpu/drm/i915/gvt/sched_policy.c
+++ b/drivers/gpu/drm/i915/gvt/sched_policy.c
@@ -228,7 +228,7 @@ void intel_gvt_schedule(struct intel_gvt *gvt)
 	struct gvt_sched_data *sched_data = gvt->scheduler.sched_data;
 	static uint64_t timer_check;
 
-	mutex_lock(&gvt->lock);
+	mutex_lock(&gvt->sched_lock);
 
 	if (test_and_clear_bit(INTEL_GVT_REQUEST_SCHED,
 				(void *)&gvt->service_request)) {
@@ -239,7 +239,7 @@ void intel_gvt_schedule(struct intel_gvt *gvt)
 
 	tbs_sched_func(sched_data);
 
-	mutex_unlock(&gvt->lock);
+	mutex_unlock(&gvt->sched_lock);
 }
 
 static enum hrtimer_restart tbs_timer_fn(struct hrtimer *timer_data)
diff --git a/drivers/gpu/drm/i915/gvt/scheduler.c b/drivers/gpu/drm/i915/gvt/scheduler.c
index 88108bdb..e21de78 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.c
+++ b/drivers/gpu/drm/i915/gvt/scheduler.c
@@ -268,7 +268,11 @@ static int dispatch_workload(struct intel_vgpu_workload *workload)
 		goto out;
 
 	if (workload->prepare) {
+		mutex_unlock(&dev_priv->drm.struct_mutex);
+		mutex_lock(&vgpu->gvt->lock);
+		mutex_lock(&dev_priv->drm.struct_mutex);
 		ret = workload->prepare(workload);
+		mutex_unlock(&vgpu->gvt->lock);
 		if (ret)
 			goto out;
 	}
@@ -308,7 +312,7 @@ static struct intel_vgpu_workload *pick_next_workload(
 	struct intel_gvt_workload_scheduler *scheduler = &gvt->scheduler;
 	struct intel_vgpu_workload *workload = NULL;
 
-	mutex_lock(&gvt->lock);
+	mutex_lock(&gvt->sched_lock);
 
 	/*
 	 * no current vgpu / will be scheduled out / no workload
@@ -354,7 +358,7 @@ static struct intel_vgpu_workload *pick_next_workload(
 
 	atomic_inc(&workload->vgpu->running_workload_num);
 out:
-	mutex_unlock(&gvt->lock);
+	mutex_unlock(&gvt->sched_lock);
 	return workload;
 }
 
@@ -434,7 +438,7 @@ static void complete_current_workload(struct intel_gvt *gvt, int ring_id)
 	struct intel_vgpu *vgpu;
 	int event;
 
-	mutex_lock(&gvt->lock);
+	mutex_lock(&gvt->sched_lock);
 
 	workload = scheduler->current_workload[ring_id];
 	vgpu = workload->vgpu;
@@ -469,9 +473,11 @@ static void complete_current_workload(struct intel_gvt *gvt, int ring_id)
 					   ENGINE_MASK(ring_id))) {
 			update_guest_context(workload);
 
+			mutex_lock(&gvt->lock);
 			for_each_set_bit(event, workload->pending_events,
 					 INTEL_GVT_EVENT_MAX)
 				intel_vgpu_trigger_virtual_event(vgpu, event);
+			mutex_unlock(&gvt->lock);
 		}
 		mutex_lock(&dev_priv->drm.struct_mutex);
 		/* unpin shadow ctx as the shadow_ctx update is done */
@@ -484,6 +490,7 @@ static void complete_current_workload(struct intel_gvt *gvt, int ring_id)
 
 	scheduler->current_workload[ring_id] = NULL;
 
+	mutex_lock(&gvt->lock);
 	list_del_init(&workload->list);
 	workload->complete(workload);
 
@@ -494,6 +501,7 @@ static void complete_current_workload(struct intel_gvt *gvt, int ring_id)
 		intel_gvt_request_service(gvt, INTEL_GVT_REQUEST_EVENT_SCHED);
 
 	mutex_unlock(&gvt->lock);
+	mutex_unlock(&gvt->sched_lock);
 }
 
 struct workload_thread_param {
@@ -548,9 +556,9 @@ static int workload_thread(void *priv)
 			intel_uncore_forcewake_get(gvt->dev_priv,
 					FORCEWAKE_ALL);
 
-		mutex_lock(&gvt->lock);
+		mutex_lock(&gvt->sched_lock);
 		ret = dispatch_workload(workload);
-		mutex_unlock(&gvt->lock);
+		mutex_unlock(&gvt->sched_lock);
 
 		if (ret) {
 			vgpu = workload->vgpu;
diff --git a/drivers/gpu/drm/i915/gvt/vgpu.c b/drivers/gpu/drm/i915/gvt/vgpu.c
index 4d669e3..69f3f892 100644
--- a/drivers/gpu/drm/i915/gvt/vgpu.c
+++ b/drivers/gpu/drm/i915/gvt/vgpu.c
@@ -222,6 +222,7 @@ void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)
 {
 	struct intel_gvt *gvt = vgpu->gvt;
 
+	mutex_lock(&vgpu->gvt->sched_lock);
 	mutex_lock(&gvt->lock);
 
 	vgpu->active = false;
@@ -230,13 +231,16 @@ void intel_gvt_deactivate_vgpu(struct intel_vgpu *vgpu)
 
 	if (atomic_read(&vgpu->running_workload_num)) {
 		mutex_unlock(&gvt->lock);
+		mutex_unlock(&vgpu->gvt->sched_lock);
 		intel_gvt_wait_vgpu_idle(vgpu);
+		mutex_lock(&vgpu->gvt->sched_lock);
 		mutex_lock(&gvt->lock);
 	}
 
 	intel_vgpu_stop_schedule(vgpu);
 
 	mutex_unlock(&gvt->lock);
+	mutex_unlock(&vgpu->gvt->sched_lock);
 }
 
 /**
@@ -500,7 +504,9 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
 	 */
 	if (scheduler->current_vgpu == NULL) {
 		mutex_unlock(&gvt->lock);
+		mutex_unlock(&vgpu->gvt->sched_lock);
 		intel_gvt_wait_vgpu_idle(vgpu);
+		mutex_lock(&vgpu->gvt->sched_lock);
 		mutex_lock(&gvt->lock);
 	}
 
@@ -541,7 +547,9 @@ void intel_gvt_reset_vgpu_locked(struct intel_vgpu *vgpu, bool dmlr,
  */
 void intel_gvt_reset_vgpu(struct intel_vgpu *vgpu)
 {
+	mutex_lock(&vgpu->gvt->sched_lock);
 	mutex_lock(&vgpu->gvt->lock);
 	intel_gvt_reset_vgpu_locked(vgpu, true, 0);
 	mutex_unlock(&vgpu->gvt->lock);
+	mutex_unlock(&vgpu->gvt->sched_lock);
 }
-- 
2.7.4

