From 8ae576b34497b7c89fc76b2bbdf9e4063ea0c7e1 Mon Sep 17 00:00:00 2001
From: kadarlax <raghuveerx.kadarla@intel.com>
Date: Mon, 6 Sep 2021 19:33:50 +0530
Subject: [PATCH 089/109] misc: xlink-pcie: Add Thunder Bay platform support

- Multi PCIe function support
- Use platform specific reserved memory for BAR's

Signed-off-by: kadarlax <raghuveerx.kadarla@intel.com>
---
 drivers/misc/xlink-pcie/Kconfig            |   2 +-
 drivers/misc/xlink-pcie/common/xpcie.h     |  18 +
 drivers/misc/xlink-pcie/local_host/core.c  |  19 +-
 drivers/misc/xlink-pcie/local_host/dma.c   |   4 +-
 drivers/misc/xlink-pcie/local_host/epf.c   | 362 ++++++++++++++++-----
 drivers/misc/xlink-pcie/local_host/epf.h   |  13 +-
 drivers/misc/xlink-pcie/remote_host/main.c |  14 +-
 drivers/misc/xlink-pcie/remote_host/pci.c  |   4 +
 drivers/misc/xlink-pcie/remote_host/pci.h  |   1 +
 9 files changed, 331 insertions(+), 106 deletions(-)

diff --git a/drivers/misc/xlink-pcie/Kconfig b/drivers/misc/xlink-pcie/Kconfig
index 448b9bfbdfa2..0bc3b9811aef 100644
--- a/drivers/misc/xlink-pcie/Kconfig
+++ b/drivers/misc/xlink-pcie/Kconfig
@@ -11,7 +11,7 @@ config XLINK_PCIE_RH_DRIVER
 
 config XLINK_PCIE_LH_DRIVER
 	tristate "XLink PCIe Local Host driver"
-	depends on PCI_ENDPOINT && ARCH_KEEMBAY
+	depends on PCI_ENDPOINT && (ARCH_KEEMBAY || ARCH_THUNDERBAY)
 	help
 	  This option enables XLink PCIe Local Host driver.
 
diff --git a/drivers/misc/xlink-pcie/common/xpcie.h b/drivers/misc/xlink-pcie/common/xpcie.h
index cb67b00f4038..b39b75b7781c 100644
--- a/drivers/misc/xlink-pcie/common/xpcie.h
+++ b/drivers/misc/xlink-pcie/common/xpcie.h
@@ -19,6 +19,18 @@
 #define PCI_DEVICE_ID_INTEL_KEEMBAY 0x6240
 #endif
 
+#ifndef PCI_DEVICE_ID_INTEL_THB_FULL
+#define PCI_DEVICE_ID_INTEL_THB_FULL 0x4FC0
+#endif
+
+#ifndef PCI_DEVICE_ID_INTEL_THB_PRIME
+#define PCI_DEVICE_ID_INTEL_THB_PRIME 0x4FC1
+#endif
+
+#define KMB_MAX_PCIE_FNS	1
+#define THB_FULL_MAX_PCIE_FNS	8
+#define THB_PRIME_MAX_PCIE_FNS	4
+
 #define XPCIE_IO_COMM_SIZE SZ_16K
 #define XPCIE_MMIO_OFFSET SZ_4K
 
@@ -33,6 +45,8 @@
 #define XPCIE_MAGIC_STRLEN	(16)
 #define XPCIE_MAGIC_YOCTO	"VPUYOCTO"
 
+#define XPCIE_MAX_NAME_LEN	(32)
+
 /* MMIO layout and offsets shared between device and host */
 struct xpcie_mmio {
 	u32 device_status;
@@ -106,6 +120,10 @@ struct xpcie {
 	struct tasklet_struct rx_tasklet;
 	struct hrtimer free_rx_bd_timer;
 #endif
+
+	u32 sw_devid;
+	struct list_head list;
+	char name[XPCIE_MAX_NAME_LEN];
 };
 
 #endif /* XPCIE_HEADER_ */
diff --git a/drivers/misc/xlink-pcie/local_host/core.c b/drivers/misc/xlink-pcie/local_host/core.c
index c8258c7960dd..4993d47f7b11 100644
--- a/drivers/misc/xlink-pcie/local_host/core.c
+++ b/drivers/misc/xlink-pcie/local_host/core.c
@@ -23,8 +23,7 @@ static int intel_xpcie_map_dma(struct xpcie *xpcie, struct xpcie_buf_desc *bd,
 {
 	struct xpcie_epf *xpcie_epf = container_of(xpcie,
 						   struct xpcie_epf, xpcie);
-	struct pci_epf *epf = xpcie_epf->epf;
-	struct device *dma_dev = epf->epc->dev.parent;
+	struct device *dma_dev = xpcie_epf->dma_dev;
 
 	bd->phys = dma_map_single(dma_dev, bd->data, bd->length, direction);
 
@@ -36,8 +35,7 @@ static void intel_xpcie_unmap_dma(struct xpcie *xpcie,
 {
 	struct xpcie_epf *xpcie_epf = container_of(xpcie,
 						   struct xpcie_epf, xpcie);
-	struct pci_epf *epf = xpcie_epf->epf;
-	struct device *dma_dev = epf->epc->dev.parent;
+	struct device *dma_dev = xpcie_epf->dma_dev;
 
 	dma_unmap_single(dma_dev, bd->phys, bd->length, direction);
 }
@@ -74,8 +72,8 @@ static void intel_xpcie_txrx_cleanup(struct xpcie *xpcie)
 {
 	struct xpcie_epf *xpcie_epf = container_of(xpcie,
 						   struct xpcie_epf, xpcie);
-	struct device *dma_dev = xpcie_epf->epf->epc->dev.parent;
 	struct xpcie_interface *inf = &xpcie->interfaces[0];
+	struct device *dma_dev = xpcie_epf->dma_dev;
 	struct xpcie_stream *tx = &xpcie->tx;
 	struct xpcie_stream *rx = &xpcie->rx;
 	struct xpcie_transfer_desc *td;
@@ -121,12 +119,12 @@ static int intel_xpcie_txrx_init(struct xpcie *xpcie,
 {
 	struct xpcie_epf *xpcie_epf = container_of(xpcie,
 						   struct xpcie_epf, xpcie);
-	struct device *dma_dev = xpcie_epf->epf->epc->dev.parent;
+	struct device *dma_dev = xpcie_epf->dma_dev;
 	struct xpcie_stream *tx = &xpcie->tx;
 	struct xpcie_stream *rx = &xpcie->rx;
 	int tx_pool_size, rx_pool_size;
 	struct xpcie_buf_desc *bd;
-	int index, ndesc, rc;
+	int index, ndesc;
 
 	xpcie->txrx = cap;
 	xpcie->fragment_size = cap->fragment_size;
@@ -146,13 +144,6 @@ static int intel_xpcie_txrx_init(struct xpcie *xpcie,
 	rx_pool_size = roundup(SZ_32M, xpcie->fragment_size);
 	ndesc = rx_pool_size / xpcie->fragment_size;
 
-	/* Initialize reserved memory resources */
-	rc = of_reserved_mem_device_init(dma_dev);
-	if (rc) {
-		dev_err(dma_dev, "Could not get reserved memory\n");
-		goto error;
-	}
-
 	for (index = 0; index < ndesc; index++) {
 		bd = intel_xpcie_alloc_bd(xpcie->fragment_size);
 		if (bd) {
diff --git a/drivers/misc/xlink-pcie/local_host/dma.c b/drivers/misc/xlink-pcie/local_host/dma.c
index a8b54a2d3cb7..39e6f38af4e3 100644
--- a/drivers/misc/xlink-pcie/local_host/dma.c
+++ b/drivers/misc/xlink-pcie/local_host/dma.c
@@ -465,7 +465,7 @@ int intel_xpcie_ep_dma_read_ll(struct pci_epf *epf, int chan, int descs_num)
 
 static void intel_xpcie_ep_dma_free_ll_descs_mem(struct xpcie_epf *xpcie_epf)
 {
-	struct device *dma_dev = xpcie_epf->epf->epc->dev.parent;
+	struct device *dma_dev = xpcie_epf->dma_dev;
 	int i;
 
 	for (i = 0; i < DMA_CHAN_NUM; i++) {
@@ -491,7 +491,7 @@ static void intel_xpcie_ep_dma_free_ll_descs_mem(struct xpcie_epf *xpcie_epf)
 
 static int intel_xpcie_ep_dma_alloc_ll_descs_mem(struct xpcie_epf *xpcie_epf)
 {
-	struct device *dma_dev = xpcie_epf->epf->epc->dev.parent;
+	struct device *dma_dev = xpcie_epf->dma_dev;
 	int tx_num = XPCIE_NUM_TX_DESCS + 1;
 	int rx_num = XPCIE_NUM_RX_DESCS + 1;
 	size_t tx_size, rx_size;
diff --git a/drivers/misc/xlink-pcie/local_host/epf.c b/drivers/misc/xlink-pcie/local_host/epf.c
index a7cf70b6a2fa..213735788392 100644
--- a/drivers/misc/xlink-pcie/local_host/epf.c
+++ b/drivers/misc/xlink-pcie/local_host/epf.c
@@ -8,12 +8,13 @@
 #include <linux/of.h>
 #include <linux/platform_device.h>
 #include <linux/reboot.h>
+#include <linux/of_address.h>
+#include <linux/of_device.h>
+#include <linux/of_irq.h>
+#include <linux/of_reserved_mem.h>
 
 #include "epf.h"
 
-#define BAR2_MIN_SIZE			SZ_16K
-#define BAR4_MIN_SIZE			SZ_16K
-
 #define PCIE_REGS_PCIE_INTR_ENABLE	0x18
 #define PCIE_REGS_PCIE_INTR_FLAGS	0x1C
 #define LBC_CII_EVENT_FLAG		BIT(18)
@@ -26,6 +27,16 @@
 #define PCIE_CFG_PBUS_DEV_NUM_OFFSET	16
 #define PCIE_CFG_PBUS_DEV_NUM_MASK	0x1F
 
+#define THB_IRQ_DOORBELL_IDX	2
+#define THB_IRQ_WDMA_IDX	10
+#define THB_IRQ_RDMA_IDX	18
+#define THB_PRIME_RESV_MEM_IDX	8
+#define THB_FULL_RESV_MEM_IDX	16
+
+#define THB_DOORBELL_OFF	0x1000
+#define THB_DOORBELL_CLR_OFF	0x14
+#define THB_DOORBELL_CLR_SZ	0x4
+
 static struct pci_epf_header xpcie_header = {
 	.vendorid = PCI_VENDOR_ID_INTEL,
 	.deviceid = PCI_DEVICE_ID_INTEL_KEEMBAY,
@@ -101,28 +112,37 @@ static irqreturn_t intel_xpcie_host_interrupt(int irq, void *args)
 {
 	struct xpcie_epf *xpcie_epf;
 	struct xpcie *xpcie = args;
+	struct pci_epf *epf;
 	u8 event;
 	u32 val;
 
 	xpcie_epf = container_of(xpcie, struct xpcie_epf, xpcie);
-	val = ioread32(xpcie_epf->apb_base + PCIE_REGS_PCIE_INTR_FLAGS);
-	if (val & LBC_CII_EVENT_FLAG) {
+	epf = xpcie_epf->epf;
+
+	if (epf->header->deviceid == PCI_DEVICE_ID_INTEL_KEEMBAY) {
+		val = ioread32(xpcie_epf->apb_base + PCIE_REGS_PCIE_INTR_FLAGS);
+		if (!(val & LBC_CII_EVENT_FLAG))
+			return IRQ_HANDLED;
+
 		iowrite32(LBC_CII_EVENT_FLAG,
 			  xpcie_epf->apb_base + PCIE_REGS_PCIE_INTR_FLAGS);
+	}
 
-		event = intel_xpcie_get_doorbell(xpcie, TO_DEVICE, DEV_EVENT);
-		if (unlikely(event != NO_OP)) {
-			intel_xpcie_set_doorbell(xpcie, TO_DEVICE,
-						 DEV_EVENT, NO_OP);
-			if (event == REQUEST_RESET)
-				orderly_reboot();
-			return IRQ_HANDLED;
-		}
+	if (xpcie_epf->doorbell_clear)
+		writel(0x1, xpcie_epf->doorbell_clear);
 
-		if (likely(xpcie_epf->core_irq_callback))
-			xpcie_epf->core_irq_callback(irq, xpcie);
+	event = intel_xpcie_get_doorbell(xpcie, TO_DEVICE, DEV_EVENT);
+	if (unlikely(event != NO_OP)) {
+		intel_xpcie_set_doorbell(xpcie, TO_DEVICE,
+					 DEV_EVENT, NO_OP);
+		if (event == REQUEST_RESET)
+			orderly_reboot();
+		return IRQ_HANDLED;
 	}
 
+	if (likely(xpcie_epf->core_irq_callback))
+		xpcie_epf->core_irq_callback(irq, xpcie);
+
 	return IRQ_HANDLED;
 }
 
@@ -151,8 +171,8 @@ static void intel_xpcie_cleanup_bar(struct pci_epf *epf, enum pci_barno barno)
 
 	if (xpcie_epf->vaddr[barno]) {
 		pci_epc_clear_bar(epc, epf->func_no, epf->vfunc_no, &epf->bar[barno]);
-		pci_epf_free_space(epf, xpcie_epf->vaddr[barno], barno,
-				   PRIMARY_INTERFACE);
+		if (xpcie_epf->vaddr_resv[barno])
+			pci_epf_free_space(epf, xpcie_epf->vaddr[barno], barno, PRIMARY_INTERFACE);
 		xpcie_epf->vaddr[barno] = NULL;
 	}
 }
@@ -161,6 +181,7 @@ static void intel_xpcie_cleanup_bars(struct pci_epf *epf)
 {
 	struct xpcie_epf *xpcie_epf = epf_get_drvdata(epf);
 
+	intel_xpcie_cleanup_bar(epf, BAR_0);
 	intel_xpcie_cleanup_bar(epf, BAR_2);
 	intel_xpcie_cleanup_bar(epf, BAR_4);
 	xpcie_epf->xpcie.mmio = NULL;
@@ -173,21 +194,40 @@ static int intel_xpcie_setup_bar(struct pci_epf *epf, enum pci_barno barno,
 	struct xpcie_epf *xpcie_epf = epf_get_drvdata(epf);
 	struct pci_epf_bar *bar = &epf->bar[barno];
 	struct pci_epc *epc = epf->epc;
-	void *vaddr;
+	void *vaddr = NULL;
 	int ret;
 
+	if (!min_size)
+		return 0;
+
 	bar->flags |= PCI_BASE_ADDRESS_MEM_TYPE_64;
 	if (!bar->size)
 		bar->size = min_size;
 
-	if (barno == BAR_4)
+	if (barno == BAR_0)
+		bar->phys_addr = xpcie_epf->doorbell_start;
+
+	if (barno == BAR_2)
+		bar->phys_addr = xpcie_epf->mmr2.start;
+
+	if (barno == BAR_4) {
 		bar->flags |= PCI_BASE_ADDRESS_MEM_PREFETCH;
+		bar->phys_addr = xpcie_epf->mmr4.start;
+	}
 
-	vaddr = pci_epf_alloc_space(epf, bar->size, barno, align,
-				    PRIMARY_INTERFACE);
-	if (!vaddr) {
-		dev_err(&epf->dev, "Failed to map BAR%d\n", barno);
-		return -ENOMEM;
+	if (!bar->phys_addr) {
+		vaddr = pci_epf_alloc_space(epf, bar->size, barno, align,
+					    PRIMARY_INTERFACE);
+		if (!vaddr) {
+			dev_err(&epf->dev, "Failed to map BAR%d\n", barno);
+			return -ENOMEM;
+		}
+	} else {
+		vaddr = (void __force *)devm_ioremap(&epf->dev, bar->phys_addr,
+							bar->size);
+		if (IS_ERR(vaddr))
+			return PTR_ERR(vaddr);
+		xpcie_epf->vaddr_resv[barno] = true;
 	}
 
 	ret = pci_epc_set_bar(epc, epf->func_no, epf->vfunc_no, bar);
@@ -208,13 +248,20 @@ static int intel_xpcie_setup_bars(struct pci_epf *epf, size_t align)
 
 	struct xpcie_epf *xpcie_epf = epf_get_drvdata(epf);
 
-	ret = intel_xpcie_setup_bar(epf, BAR_2, BAR2_MIN_SIZE, align);
+	ret = intel_xpcie_setup_bar(epf, BAR_0, xpcie_epf->bar0_sz, align);
 	if (ret)
 		return ret;
 
-	ret = intel_xpcie_setup_bar(epf, BAR_4, BAR4_MIN_SIZE, align);
+	ret = intel_xpcie_setup_bar(epf, BAR_2, xpcie_epf->bar2_sz, align);
+	if (ret) {
+		intel_xpcie_cleanup_bar(epf, BAR_0);
+		return ret;
+	}
+
+	ret = intel_xpcie_setup_bar(epf, BAR_4, xpcie_epf->bar4_sz, align);
 	if (ret) {
 		intel_xpcie_cleanup_bar(epf, BAR_2);
+		intel_xpcie_cleanup_bar(epf, BAR_0);
 		return ret;
 	}
 
@@ -228,21 +275,112 @@ static int intel_xpcie_setup_bars(struct pci_epf *epf, size_t align)
 	return 0;
 }
 
-static int intel_xpcie_epf_get_platform_data(struct device *dev,
-					     struct xpcie_epf *xpcie_epf)
+static int intel_xpcie_epf_get_thb_pf_data(struct platform_device *pdev,
+					   struct xpcie_epf *xpcie_epf)
+{
+	struct pci_epf *epf = xpcie_epf->epf;
+	struct pci_epc *epc = epf->epc;
+	struct device_node *np;
+	struct device *dma_dev;
+	int resv_mem_idx, ret;
+	resource_size_t start;
+	struct resource *res;
+
+	dma_dev = epc->dev.parent;
+
+	res = platform_get_resource_byname(pdev,
+					   IORESOURCE_MEM,
+					   "doorbell");
+	if (IS_ERR(res))
+		return PTR_ERR(res);
+	start = res->start + (epf->func_no * THB_DOORBELL_OFF);
+	xpcie_epf->doorbell_start = start;
+
+	res = platform_get_resource_byname(pdev,
+					   IORESOURCE_MEM,
+					   "doorbellclr");
+	if (IS_ERR(res))
+		return PTR_ERR(res);
+
+	start = res->start + (epf->func_no * THB_DOORBELL_CLR_OFF);
+	xpcie_epf->doorbell_clear = devm_ioremap(&pdev->dev, start,
+						 THB_DOORBELL_CLR_SZ);
+	if (IS_ERR(xpcie_epf->doorbell_clear))
+		return PTR_ERR(xpcie_epf->doorbell_clear);
+
+	xpcie_epf->irq_doorbell = irq_of_parse_and_map(pdev->dev.of_node,
+						       epf->func_no +
+						       THB_IRQ_DOORBELL_IDX);
+	if (xpcie_epf->irq_doorbell < 0)
+		return xpcie_epf->irq_doorbell;
+	ret = devm_request_irq(&epf->dev, xpcie_epf->irq_doorbell,
+			       &intel_xpcie_host_interrupt, 0,
+			       XPCIE_DRIVER_NAME, &xpcie_epf->xpcie);
+	if (ret) {
+		dev_err(&epf->dev, "failed to request irq\n");
+		return ret;
+	}
+
+	xpcie_epf->irq_wdma = irq_of_parse_and_map(pdev->dev.of_node,
+						   epf->func_no +
+						   THB_IRQ_WDMA_IDX);
+	if (xpcie_epf->irq_wdma < 0)
+		return xpcie_epf->irq_wdma;
+
+	xpcie_epf->irq_rdma = irq_of_parse_and_map(pdev->dev.of_node,
+						   epf->func_no +
+						   THB_IRQ_RDMA_IDX);
+	if (xpcie_epf->irq_rdma < 0)
+		return xpcie_epf->irq_rdma;
+
+	np = of_parse_phandle(pdev->dev.of_node,
+			      "memory-region", epf->func_no * 2);
+	ret = of_address_to_resource(np, 0, &xpcie_epf->mmr2);
+	if (ret)
+		return ret;
+
+	np = of_parse_phandle(pdev->dev.of_node,
+			      "memory-region", (epf->func_no * 2) + 1);
+	ret = of_address_to_resource(np, 0, &xpcie_epf->mmr4);
+	if (ret)
+		return ret;
+
+	if (epf->header->deviceid == PCI_DEVICE_ID_INTEL_THB_PRIME)
+		resv_mem_idx = (epf->func_no >> 1) + THB_PRIME_RESV_MEM_IDX;
+	else
+		resv_mem_idx = (epf->func_no >> 1) + THB_FULL_RESV_MEM_IDX;
+	ret = of_reserved_mem_device_init_by_idx(&epf->dev,
+						 pdev->dev.of_node,
+						 resv_mem_idx);
+	if (ret)
+		return ret;
+
+	xpcie_epf->dma_dev = &epf->dev;
+	epf->dev.dma_mask = dma_dev->dma_mask;
+	epf->dev.coherent_dma_mask = dma_dev->coherent_dma_mask;
+	ret = of_dma_configure(&epf->dev, pdev->dev.of_node, true);
+	if (ret)
+		return ret;
+
+	ret = dma_set_mask_and_coherent(&epf->dev, DMA_BIT_MASK(64));
+	if (ret)
+		return ret;
+
+	return 0;
+}
+
+static int intel_xpcie_epf_get_kmb_pf_data(struct platform_device *pdev,
+					   struct xpcie_epf *xpcie_epf)
 {
-	struct platform_device *pdev = to_platform_device(dev);
 	struct device_node *soc_node, *version_node;
+	struct pci_epf *epf = xpcie_epf->epf;
+	struct pci_epc *epc = epf->epc;
+	struct device *dma_dev;
 	struct resource *res;
+	int prop_size, ret;
 	const char *prop;
-	int prop_size;
 
-	xpcie_epf->irq_dma = platform_get_irq_byname(pdev, "intr");
-	if (xpcie_epf->irq_dma < 0) {
-		dev_err(&xpcie_epf->epf->dev, "failed to get IRQ: %d\n",
-			xpcie_epf->irq_dma);
-		return -EINVAL;
-	}
+	dma_dev = epc->dev.parent;
 
 	xpcie_epf->irq_err = platform_get_irq_byname(pdev, "err_intr");
 	if (xpcie_epf->irq_err < 0) {
@@ -260,19 +398,19 @@ static int intel_xpcie_epf_get_platform_data(struct device *dev,
 
 	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "apb");
 	xpcie_epf->apb_base =
-		devm_ioremap(dev, res->start, resource_size(res));
+		devm_ioremap(dma_dev, res->start, resource_size(res));
 	if (IS_ERR(xpcie_epf->apb_base))
 		return PTR_ERR(xpcie_epf->apb_base);
 
 	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "dbi");
 	xpcie_epf->dbi_base =
-		devm_ioremap(dev, res->start, resource_size(res));
+		devm_ioremap(dma_dev, res->start, resource_size(res));
 	if (IS_ERR(xpcie_epf->dbi_base))
 		return PTR_ERR(xpcie_epf->dbi_base);
 
 	res = platform_get_resource_byname(pdev, IORESOURCE_MEM, "dma");
 	xpcie_epf->dma_base =
-		devm_ioremap(dev, res->start, resource_size(res));
+		devm_ioremap(dma_dev, res->start, resource_size(res));
 	if (IS_ERR(xpcie_epf->dma_base))
 		return PTR_ERR(xpcie_epf->dma_base);
 
@@ -290,23 +428,101 @@ static int intel_xpcie_epf_get_platform_data(struct device *dev,
 		of_node_put(soc_node);
 	}
 
+	if (!strcmp(xpcie_epf->stepping, "A0")) {
+		xpcie_epf->xpcie.legacy_a0 = true;
+		intel_xpcie_iowrite32(1, xpcie_epf->xpcie.mmio +
+					 XPCIE_MMIO_LEGACY_A0);
+	} else {
+		xpcie_epf->xpcie.legacy_a0 = false;
+		intel_xpcie_iowrite32(0, xpcie_epf->xpcie.mmio +
+					 XPCIE_MMIO_LEGACY_A0);
+	}
+
+	/* Enable interrupt */
+	writel(LBC_CII_EVENT_FLAG,
+	       xpcie_epf->apb_base + PCIE_REGS_PCIE_INTR_ENABLE);
+	ret = devm_request_irq(&epf->dev, xpcie_epf->irq,
+			       &intel_xpcie_host_interrupt, 0,
+			       XPCIE_DRIVER_NAME, &xpcie_epf->xpcie);
+	if (ret) {
+		dev_err(&epf->dev, "failed to request irq\n");
+		return ret;
+	}
+
+	ret = devm_request_irq(&epf->dev, xpcie_epf->irq_err,
+			       &intel_xpcie_err_interrupt, 0,
+			       XPCIE_DRIVER_NAME, &xpcie_epf->xpcie);
+	if (ret) {
+		dev_err(&epf->dev, "failed to request error irq\n");
+		return ret;
+	}
+
+	/* Initialize reserved memory resources */
+	xpcie_epf->dma_dev = dma_dev;
+	ret = of_reserved_mem_device_init(dma_dev);
+	if (ret) {
+		dev_err(&epf->dev, "Could not get reserved memory\n");
+		return ret;
+	}
+
 	return 0;
 }
 
+static int intel_xpcie_epf_get_platform_data(struct device *dev,
+					     struct xpcie_epf *xpcie_epf)
+{
+	struct platform_device *pdev = to_platform_device(dev);
+	struct pci_epf *epf = xpcie_epf->epf;
+	struct pci_epc *epc = epf->epc;
+	int ret;
+
+	ret = of_property_read_u8(pdev->dev.of_node,
+				  "max-functions",
+				  &epc->max_functions);
+	if (epc->max_functions == THB_FULL_MAX_PCIE_FNS)
+		epf->header->deviceid = PCI_DEVICE_ID_INTEL_THB_FULL;
+	else if (epc->max_functions == THB_PRIME_MAX_PCIE_FNS)
+		epf->header->deviceid = PCI_DEVICE_ID_INTEL_THB_PRIME;
+
+	if (epf->header->deviceid == PCI_DEVICE_ID_INTEL_KEEMBAY) {
+		xpcie_epf->bar0_sz = 0;
+		xpcie_epf->bar2_sz = SZ_16K;
+		xpcie_epf->bar4_sz = SZ_16K;
+		ret = intel_xpcie_epf_get_kmb_pf_data(pdev, xpcie_epf);
+	} else {
+		xpcie_epf->bar0_sz = SZ_4K;
+		xpcie_epf->bar2_sz = SZ_16K;
+		xpcie_epf->bar4_sz = SZ_8K;
+		ret = intel_xpcie_epf_get_thb_pf_data(pdev, xpcie_epf);
+	}
+
+	return ret;
+}
+
 static int intel_xpcie_epf_bind(struct pci_epf *epf)
 {
 	struct xpcie_epf *xpcie_epf = epf_get_drvdata(epf);
 	const struct pci_epc_features *features;
 	struct pci_epc *epc = epf->epc;
+	size_t align = SZ_16K;
 	u32 bus_num, dev_num;
 	struct device *dev;
-	size_t align = SZ_16K;
 	int ret;
 
 	if (WARN_ON_ONCE(!epc))
 		return -EINVAL;
 
+	/* Only even PCIe functions are used for communication */
+	if ((epf->func_no & 0x1))
+		return 0;
+
 	dev = epc->dev.parent;
+	ret = intel_xpcie_epf_get_platform_data(dev, xpcie_epf);
+	if (ret) {
+		dev_err(&epf->dev, "Unable to get platform data\n");
+		return -EINVAL;
+	}
+
 	features = pci_epc_get_features(epc, epf->func_no, epf->vfunc_no);
 	xpcie_epf->epc_features = features;
 	if (features) {
@@ -320,41 +536,6 @@ static int intel_xpcie_epf_bind(struct pci_epf *epf)
 		return ret;
 	}
 
-	ret = intel_xpcie_epf_get_platform_data(dev, xpcie_epf);
-	if (ret) {
-		dev_err(&epf->dev, "Unable to get platform data\n");
-		return -EINVAL;
-	}
-
-	if (!strcmp(xpcie_epf->stepping, "A0")) {
-		xpcie_epf->xpcie.legacy_a0 = true;
-		intel_xpcie_iowrite32(1, xpcie_epf->xpcie.mmio +
-					 XPCIE_MMIO_LEGACY_A0);
-	} else {
-		xpcie_epf->xpcie.legacy_a0 = false;
-		intel_xpcie_iowrite32(0, xpcie_epf->xpcie.mmio +
-					 XPCIE_MMIO_LEGACY_A0);
-	}
-
-	/* Enable interrupt */
-	writel(LBC_CII_EVENT_FLAG,
-	       xpcie_epf->apb_base + PCIE_REGS_PCIE_INTR_ENABLE);
-	ret = devm_request_irq(&epf->dev, xpcie_epf->irq,
-			       &intel_xpcie_host_interrupt, 0,
-			       XPCIE_DRIVER_NAME, &xpcie_epf->xpcie);
-	if (ret) {
-		dev_err(&epf->dev, "failed to request irq\n");
-		goto err_cleanup_bars;
-	}
-
-	ret = devm_request_irq(&epf->dev, xpcie_epf->irq_err,
-			       &intel_xpcie_err_interrupt, 0,
-			       XPCIE_DRIVER_NAME, &xpcie_epf->xpcie);
-	if (ret) {
-		dev_err(&epf->dev, "failed to request error irq\n");
-		goto err_cleanup_bars;
-	}
-
 	ret = intel_xpcie_ep_dma_init(epf);
 	if (ret) {
 		dev_err(&epf->dev, "DMA initialization failed\n");
@@ -363,18 +544,25 @@ static int intel_xpcie_epf_bind(struct pci_epf *epf)
 
 	intel_xpcie_set_device_status(&xpcie_epf->xpcie, XPCIE_STATUS_READY);
 
-	ret = ioread32(xpcie_epf->apb_base + PCIE_REGS_PCIE_SYS_CFG_CORE);
-	bus_num = (ret >> PCIE_CFG_PBUS_NUM_OFFSET) & PCIE_CFG_PBUS_NUM_MASK;
-	dev_num = (ret >> PCIE_CFG_PBUS_DEV_NUM_OFFSET) &
-			PCIE_CFG_PBUS_DEV_NUM_MASK;
-
-	xlink_sw_id = FIELD_PREP(XLINK_DEV_INF_TYPE_MASK,
-				 XLINK_DEV_INF_PCIE) |
-		      FIELD_PREP(XLINK_DEV_PHYS_ID_MASK,
-				 bus_num << 8 | dev_num) |
-		      FIELD_PREP(XLINK_DEV_TYPE_MASK, XLINK_DEV_TYPE_KMB) |
-		      FIELD_PREP(XLINK_DEV_PCIE_ID_MASK, XLINK_DEV_PCIE_0) |
-		      FIELD_PREP(XLINK_DEV_FUNC_MASK, XLINK_DEV_FUNC_VPU);
+	if (epf->header->deviceid == PCI_DEVICE_ID_INTEL_KEEMBAY) {
+		ret = ioread32(xpcie_epf->apb_base +
+			       PCIE_REGS_PCIE_SYS_CFG_CORE);
+		bus_num = (ret >> PCIE_CFG_PBUS_NUM_OFFSET) &
+			  PCIE_CFG_PBUS_NUM_MASK;
+		dev_num = (ret >> PCIE_CFG_PBUS_DEV_NUM_OFFSET) &
+			  PCIE_CFG_PBUS_DEV_NUM_MASK;
+
+		xlink_sw_id = FIELD_PREP(XLINK_DEV_INF_TYPE_MASK,
+					 XLINK_DEV_INF_PCIE) |
+			      FIELD_PREP(XLINK_DEV_PHYS_ID_MASK,
+					 bus_num << 8 | dev_num) |
+			      FIELD_PREP(XLINK_DEV_TYPE_MASK,
+					 XLINK_DEV_TYPE_KMB) |
+			      FIELD_PREP(XLINK_DEV_PCIE_ID_MASK,
+					 XLINK_DEV_PCIE_0) |
+			      FIELD_PREP(XLINK_DEV_FUNC_MASK,
+					 XLINK_DEV_FUNC_VPU);
+	}
 
 	ret = intel_xpcie_core_init(&xpcie_epf->xpcie);
 	if (ret) {
diff --git a/drivers/misc/xlink-pcie/local_host/epf.h b/drivers/misc/xlink-pcie/local_host/epf.h
index 40bf4ff36580..f16aec2f890f 100644
--- a/drivers/misc/xlink-pcie/local_host/epf.h
+++ b/drivers/misc/xlink-pcie/local_host/epf.h
@@ -55,16 +55,27 @@ struct xpcie_dma_ll_desc_buf {
 struct xpcie_epf {
 	struct pci_epf *epf;
 	void *vaddr[BAR_5 + 1];
+	bool vaddr_resv[BAR_5 + 1];
 	enum pci_barno comm_bar;
 	enum pci_barno bar4;
+	size_t bar0_sz;
+	size_t bar2_sz;
+	size_t bar4_sz;
 	const struct pci_epc_features *epc_features;
 	struct xpcie xpcie;
 	int irq;
-	int irq_dma;
+	int irq_rdma;
+	int irq_wdma;
 	int irq_err;
+	int irq_doorbell;
 	void __iomem *apb_base;
 	void __iomem *dma_base;
 	void __iomem *dbi_base;
+	void __iomem *doorbell_clear;
+	struct resource mmr2;
+	struct resource mmr4;
+	resource_size_t doorbell_start;
+	struct device *dma_dev;
 	char stepping[KEEMBAY_XPCIE_STEPPING_MAXLEN];
 
 	irq_handler_t			core_irq_callback;
diff --git a/drivers/misc/xlink-pcie/remote_host/main.c b/drivers/misc/xlink-pcie/remote_host/main.c
index efc9143a2fac..a2ae33b76c86 100644
--- a/drivers/misc/xlink-pcie/remote_host/main.c
+++ b/drivers/misc/xlink-pcie/remote_host/main.c
@@ -13,18 +13,29 @@
 
 static const struct pci_device_id xpcie_pci_table[] = {
 	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_KEEMBAY), 0 },
+	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_THB_FULL), 0 },
+	{ PCI_DEVICE(PCI_VENDOR_ID_INTEL, PCI_DEVICE_ID_INTEL_THB_PRIME), 0 },
 	{ 0 }
 };
 
 static int intel_xpcie_probe(struct pci_dev *pdev,
 			     const struct pci_device_id *ent)
 {
+	u8 max_functions = KMB_MAX_PCIE_FNS;
+	struct xpcie_dev *xdev = NULL;
 	bool new_device = false;
-	struct xpcie_dev *xdev;
 	u32 sw_devid;
 	u16 hw_id;
 	int ret;
 
+	if (PCI_FUNC(pdev->devfn) & 0x1)
+		return 0;
+
+	if (pdev->device == PCI_DEVICE_ID_INTEL_THB_FULL)
+		max_functions = THB_FULL_MAX_PCIE_FNS;
+	else if (pdev->device == PCI_DEVICE_ID_INTEL_THB_PRIME)
+		max_functions = THB_PRIME_MAX_PCIE_FNS;
+
 	hw_id = FIELD_PREP(HW_ID_HI_MASK, pdev->bus->number) |
 		FIELD_PREP(HW_ID_LO_MASK, PCI_SLOT(pdev->devfn));
 
@@ -43,6 +54,7 @@ static int intel_xpcie_probe(struct pci_dev *pdev,
 
 		new_device = true;
 	}
+	xdev->max_functions = max_functions;
 
 	ret = intel_xpcie_pci_init(xdev, pdev);
 	if (ret) {
diff --git a/drivers/misc/xlink-pcie/remote_host/pci.c b/drivers/misc/xlink-pcie/remote_host/pci.c
index 6a79782b983e..6630e7ff3604 100644
--- a/drivers/misc/xlink-pcie/remote_host/pci.c
+++ b/drivers/misc/xlink-pcie/remote_host/pci.c
@@ -362,6 +362,10 @@ int intel_xpcie_pci_raise_irq(struct xpcie_dev *xdev,
 	intel_xpcie_set_doorbell(&xdev->xpcie, TO_DEVICE, type, value);
 	pci_read_config_word(xdev->pci, PCI_STATUS, &pci_status);
 
+	/* Ring Doorbell */
+	if (xdev->pci->device != PCI_DEVICE_ID_INTEL_KEEMBAY)
+		iowrite32(1, (void __force __iomem *)xdev->xpcie.bar0);
+
 	return 0;
 }
 
diff --git a/drivers/misc/xlink-pcie/remote_host/pci.h b/drivers/misc/xlink-pcie/remote_host/pci.h
index b082bfb73e4f..6be5664fe536 100644
--- a/drivers/misc/xlink-pcie/remote_host/pci.h
+++ b/drivers/misc/xlink-pcie/remote_host/pci.h
@@ -37,6 +37,7 @@ struct xpcie_dev {
 
 	struct xpcie xpcie;
 	xlink_device_event event_fn;
+	u8 max_functions;
 };
 
 static inline struct device *xpcie_to_dev(struct xpcie *xpcie)
-- 
2.25.1

