From 93ad308a7211176b67b02f8ef7e3965db1f4a0ac Mon Sep 17 00:00:00 2001
From: Chris Redpath <chris.redpath@arm.com>
Date: Tue, 19 Dec 2017 19:32:02 +0000
Subject: [PATCH 397/437] ANDROID: sched: fair: Bypass energy-aware wakeup for
 prefer-idle tasks

Use the upstream slow path to find an idle cpu for prefer-idle tasks.
This slow-path is actually faster than the EAS path we are currently
going through (compute_energy()) which is really slow.

No performance degradation is seen with this and it reduces the delta
quite a bit between upstream and out of tree code.

It's not clear yet if using the mainline slow path task placement when
a task has the schedtune attribute prefer_idle=1 is the right thing to
do for products. Put the option to disable this behind a sched feature
so we can try out both options.

Signed-off-by: Joel Fernandes <joelaf@google.com>
(refactored for 4.14 version)
Signed-off-by: Chris Redpath <chris.redpath@arm.com>
(cherry picked from commit c0ff131c88f68e4985793663144b6f9cf77be9d3)
[ - Refactored for 4.17 version
  - Adjusted the commit header to the new function names ]
Signed-off-by: Quentin Perret <quentin.perret@arm.com>
Change-Id: Icf762a101c92c0e3f9e61df0370247fa15455581
---
 kernel/sched/fair.c     | 10 +++++++---
 kernel/sched/features.h |  9 +++++++++
 2 files changed, 16 insertions(+), 3 deletions(-)

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index aee62dd..19014ed 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -7317,15 +7317,19 @@ select_task_rq_fair(struct task_struct *p, int prev_cpu, int sd_flag, int wake_f
 	int new_cpu = prev_cpu;
 	int want_affine = 0, want_energy = 0;
 	int sync = (wake_flags & WF_SYNC) && !(current->flags & PF_EXITING);
+	bool prefer_idle = schedtune_prefer_idle(p);
 
 	rcu_read_lock();
 	if (sd_flag & SD_BALANCE_WAKE) {
 		record_wakee(p);
-		fd = rd_freq_domain(cpu_rq(cpu)->rd);
-		want_energy = fd && !READ_ONCE(cpu_rq(cpu)->rd->overutilized);
-		want_affine = !wake_wide(p, sibling_count_hint) &&
+		if (sync || !prefer_idle || sched_feat(EAS_PREFER_IDLE)) {
+			fd = rd_freq_domain(cpu_rq(cpu)->rd);
+			want_energy = fd &&
+			      !READ_ONCE(cpu_rq(cpu)->rd->overutilized);
+			want_affine = !wake_wide(p, sibling_count_hint) &&
 			      !wake_cap(p, cpu, prev_cpu) &&
 			      cpumask_test_cpu(cpu, &p->cpus_allowed);
+		}
 	}
 
 	if (want_energy) {
diff --git a/kernel/sched/features.h b/kernel/sched/features.h
index 531ebc5..0232a45 100644
--- a/kernel/sched/features.h
+++ b/kernel/sched/features.h
@@ -95,3 +95,12 @@ SCHED_FEAT(UTIL_EST, true)
  * Fast pre-selection of CPU candidates for EAS.
  */
 SCHED_FEAT(FIND_BEST_TARGET, true)
+
+/*
+ * Energy aware scheduling algorithm choices:
+ * EAS_PREFER_IDLE
+ *   Direct tasks in a schedtune.prefer_idle=1 group through
+ *   the EAS path for wakeup task placement. Otherwise, put
+ *   those tasks through the mainline slow path.
+ */
+SCHED_FEAT(EAS_PREFER_IDLE, true)
-- 
2.7.4

