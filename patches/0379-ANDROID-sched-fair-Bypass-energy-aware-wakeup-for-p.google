From 8ef56e4def833bda448fb2c3e3431c0349b30598 Mon Sep 17 00:00:00 2001
From: Chris Redpath <chris.redpath@arm.com>
Date: Tue, 19 Dec 2017 19:32:02 +0000
Subject: [PATCH 379/404] ANDROID: sched: fair: Bypass energy-aware wakeup for
 prefer-idle tasks

Use the upstream slow path to find an idle cpu for prefer-idle tasks.
This slow-path is actually faster than the EAS path we are currently
going through (compute_energy()) which is really slow.

No performance degradation is seen with this and it reduces the delta
quite a bit between upstream and out of tree code.

It's not clear yet if using the mainline slow path task placement when
a task has the schedtune attribute prefer_idle=1 is the right thing to
do for products. Put the option to disable this behind a sched feature
so we can try out both options.

Signed-off-by: Joel Fernandes <joelaf@google.com>
(refactored for 4.14 version)
Signed-off-by: Chris Redpath <chris.redpath@arm.com>
(cherry picked from commit c0ff131c88f68e4985793663144b6f9cf77be9d3)
[ - Refactored for 4.17 version
  - Adjusted the commit header to the new function names ]
Signed-off-by: Quentin Perret <quentin.perret@arm.com>
Change-Id: Icf762a101c92c0e3f9e61df0370247fa15455581
---
 kernel/sched/fair.c     | 14 ++++++++++----
 kernel/sched/features.h |  9 +++++++++
 2 files changed, 19 insertions(+), 4 deletions(-)

diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 28551d0f5376..9e5f9c0cd709 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -7060,17 +7060,23 @@ select_task_rq_fair(struct task_struct *p, int prev_cpu, int sd_flag, int wake_f
 			struct root_domain *rd = cpu_rq(cpu)->rd;
 			struct perf_domain *pd = rcu_dereference(rd->pd);
 
-			if (pd && !READ_ONCE(rd->overutilized)) {
-				new_cpu = find_energy_efficient_cpu(p, prev_cpu, pd, sync);
-				goto unlock;
-			}
+			if (!pd || READ_ONCE(rd->overutilized))
+				goto affine;
+
+			if (schedtune_prefer_idle(p) && !sched_feat(EAS_PREFER_IDLE) && !sync)
+				goto sd_loop;
+
+			new_cpu = find_energy_efficient_cpu(p, prev_cpu, pd, sync);
+			goto unlock;
 		}
 
+affine:
 		want_affine = !wake_wide(p, sibling_count_hint) &&
 			      !wake_cap(p, cpu, prev_cpu) &&
 			      cpumask_test_cpu(cpu, &p->cpus_allowed);
 	}
 
+sd_loop:
 	for_each_domain(cpu, tmp) {
 		if (!(tmp->flags & SD_LOAD_BALANCE))
 			break;
diff --git a/kernel/sched/features.h b/kernel/sched/features.h
index 3fe0fb0b4465..2c33917b2067 100644
--- a/kernel/sched/features.h
+++ b/kernel/sched/features.h
@@ -102,3 +102,12 @@ SCHED_FEAT(ENERGY_AWARE, true)
  * Fast pre-selection of CPU candidates for EAS.
  */
 SCHED_FEAT(FIND_BEST_TARGET, true)
+
+/*
+ * Energy aware scheduling algorithm choices:
+ * EAS_PREFER_IDLE
+ *   Direct tasks in a schedtune.prefer_idle=1 group through
+ *   the EAS path for wakeup task placement. Otherwise, put
+ *   those tasks through the mainline slow path.
+ */
+SCHED_FEAT(EAS_PREFER_IDLE, true)
-- 
2.19.1

