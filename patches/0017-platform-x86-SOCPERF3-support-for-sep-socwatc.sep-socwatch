From b8234f1dc5cebda2a02ac2da7fbcd761da4ac9e9 Mon Sep 17 00:00:00 2001
From: Manisha Chinthapally <manisha.chinthapally@intel.com>
Date: Wed, 1 May 2019 17:21:53 -0700
Subject: [PATCH 17/30] platform/x86: SOCPERF3 support for sep & socwatch

SEP/SOCWATCH are now using version 3 of socperf driver

Signed-off-by: Manisha Chinthapally <manisha.chinthapally@intel.com>
---
 drivers/platform/x86/Kconfig                  |    2 +
 drivers/platform/x86/Makefile                 |    6 +
 drivers/platform/x86/sepdk/Kconfig            |    1 +
 drivers/platform/x86/sepdk/sep/lwpmudrv.c     |    6 +-
 drivers/platform/x86/sepdk/sep/unc_sa.c       |    6 -
 .../x86/sepdk/sep/valleyview_sochap.c         |    6 -
 drivers/platform/x86/socperf/Kconfig          |   10 +
 drivers/platform/x86/socperf/Makefile         |   12 +
 drivers/platform/x86/socperf/control.c        |  739 ++++++
 drivers/platform/x86/socperf/haswellunc_sa.c  |  407 ++++
 drivers/platform/x86/socperf/inc/control.h    |  467 ++++
 .../platform/x86/socperf/inc/ecb_iterators.h  |  130 ++
 .../platform/x86/socperf/inc/haswellunc_sa.h  |   79 +
 drivers/platform/x86/socperf/inc/npk_uncore.h |   76 +
 drivers/platform/x86/socperf/inc/pci.h        |  103 +
 drivers/platform/x86/socperf/inc/soc_uncore.h |   85 +
 drivers/platform/x86/socperf/inc/socperfdrv.h |  191 ++
 drivers/platform/x86/socperf/inc/utility.h    |   61 +
 .../socperf/include/error_reporting_utils.h   |  168 ++
 .../x86/socperf/include/lwpmudrv_chipset.h    |  285 +++
 .../x86/socperf/include/lwpmudrv_defines.h    |  502 ++++
 .../x86/socperf/include/lwpmudrv_ecb.h        | 1095 +++++++++
 .../x86/socperf/include/lwpmudrv_ioctl.h      |  343 +++
 .../x86/socperf/include/lwpmudrv_struct.h     | 2014 +++++++++++++++++
 .../x86/socperf/include/lwpmudrv_types.h      |  158 ++
 .../x86/socperf/include/lwpmudrv_version.h    |  158 ++
 .../x86/socperf/include/rise_errors.h         |  326 +++
 drivers/platform/x86/socperf/npk_uncore.c     |  502 ++++
 drivers/platform/x86/socperf/pci.c            |  188 ++
 drivers/platform/x86/socperf/soc_uncore.c     |  901 ++++++++
 drivers/platform/x86/socperf/socperfdrv.c     | 1560 +++++++++++++
 drivers/platform/x86/socperf/utility.c        |  170 ++
 32 files changed, 10742 insertions(+), 15 deletions(-)
 create mode 100644 drivers/platform/x86/socperf/Kconfig
 create mode 100644 drivers/platform/x86/socperf/Makefile
 create mode 100644 drivers/platform/x86/socperf/control.c
 create mode 100644 drivers/platform/x86/socperf/haswellunc_sa.c
 create mode 100644 drivers/platform/x86/socperf/inc/control.h
 create mode 100644 drivers/platform/x86/socperf/inc/ecb_iterators.h
 create mode 100644 drivers/platform/x86/socperf/inc/haswellunc_sa.h
 create mode 100644 drivers/platform/x86/socperf/inc/npk_uncore.h
 create mode 100644 drivers/platform/x86/socperf/inc/pci.h
 create mode 100644 drivers/platform/x86/socperf/inc/soc_uncore.h
 create mode 100644 drivers/platform/x86/socperf/inc/socperfdrv.h
 create mode 100644 drivers/platform/x86/socperf/inc/utility.h
 create mode 100644 drivers/platform/x86/socperf/include/error_reporting_utils.h
 create mode 100644 drivers/platform/x86/socperf/include/lwpmudrv_chipset.h
 create mode 100644 drivers/platform/x86/socperf/include/lwpmudrv_defines.h
 create mode 100644 drivers/platform/x86/socperf/include/lwpmudrv_ecb.h
 create mode 100644 drivers/platform/x86/socperf/include/lwpmudrv_ioctl.h
 create mode 100644 drivers/platform/x86/socperf/include/lwpmudrv_struct.h
 create mode 100644 drivers/platform/x86/socperf/include/lwpmudrv_types.h
 create mode 100644 drivers/platform/x86/socperf/include/lwpmudrv_version.h
 create mode 100644 drivers/platform/x86/socperf/include/rise_errors.h
 create mode 100644 drivers/platform/x86/socperf/npk_uncore.c
 create mode 100644 drivers/platform/x86/socperf/pci.c
 create mode 100644 drivers/platform/x86/socperf/soc_uncore.c
 create mode 100644 drivers/platform/x86/socperf/socperfdrv.c
 create mode 100644 drivers/platform/x86/socperf/utility.c

diff --git a/drivers/platform/x86/Kconfig b/drivers/platform/x86/Kconfig
index 5d2c0e827ff2..a0b0f20ff034 100644
--- a/drivers/platform/x86/Kconfig
+++ b/drivers/platform/x86/Kconfig
@@ -1358,6 +1358,8 @@ config PMC_ATOM
        def_bool y
        depends on PCI
        select COMMON_CLK
+
+source "drivers/platform/x86/socperf/Kconfig"
 source "drivers/platform/x86/socwatch/Kconfig"
 source "drivers/platform/x86/socwatchhv/Kconfig"
 source "drivers/platform/x86/sepdk/Kconfig"
diff --git a/drivers/platform/x86/Makefile b/drivers/platform/x86/Makefile
index 42d85a00be4e..a80162cbebc1 100644
--- a/drivers/platform/x86/Makefile
+++ b/drivers/platform/x86/Makefile
@@ -105,3 +105,9 @@ obj-$(CONFIG_INTEL_ATOMISP2_PM)	+= intel_atomisp2_pm.o
 obj-$(CONFIG_PCENGINES_APU2)	+= pcengines-apuv2.o
 obj-$(CONFIG_INTEL_SPEED_SELECT_INTERFACE) += intel_speed_select_if/
 obj-$(CONFIG_SYSTEM76_ACPI)	+= system76_acpi.o
+
+# sep and socwatch drivers
+obj-$(CONFIG_INTEL_SOCPERF)     += socperf/
+obj-$(CONFIG_INTEL_SOCWATCH)    += socwatch/ socperf/
+obj-$(CONFIG_INTEL_SOCWATCH_HV) += socwatchhv/
+obj-$(CONFIG_INTEL_SEP)         += sepdk/ socperf/
diff --git a/drivers/platform/x86/sepdk/Kconfig b/drivers/platform/x86/sepdk/Kconfig
index d7dc0f592a96..23a458958c6e 100755
--- a/drivers/platform/x86/sepdk/Kconfig
+++ b/drivers/platform/x86/sepdk/Kconfig
@@ -13,6 +13,7 @@ config SEP
 	tristate "SEP kernel driver"
 	depends on INTEL_SEP
 	depends on ACPI && PCI
+	depends on SOCPERF
 	default m
 
 config SEP_ACRN
diff --git a/drivers/platform/x86/sepdk/sep/lwpmudrv.c b/drivers/platform/x86/sepdk/sep/lwpmudrv.c
index e4b9a80efe9a..ab827edf3e7c 100755
--- a/drivers/platform/x86/sepdk/sep/lwpmudrv.c
+++ b/drivers/platform/x86/sepdk/sep/lwpmudrv.c
@@ -223,7 +223,7 @@ static U8 *prev_set_CR4;
 
 wait_queue_head_t wait_exit;
 
-// extern OS_STATUS SOCPERF_Switch_Group3 (void);
+extern OS_STATUS SOCPERF_Switch_Group3(void);
 
 #if !defined(DRV_USE_UNLOCKED_IOCTL)
 #define MUTEX_INIT(lock)
@@ -1509,7 +1509,7 @@ static VOID lwpmudrv_Switch_To_Next_Group(void)
 					if (pecb_unc &&
 					    ECB_device_type(pecb_unc) ==
 						    DEVICE_UNC_SOCPERF) {
-						// SOCPERF_Switch_Group3();
+						SOCPERF_Switch_Group3();
 					}
 				}
 			}
@@ -2134,7 +2134,7 @@ static OS_STATUS lwpmudrv_Uncore_Switch_Group(void)
 					    (ECB_device_type(ecb_unc) ==
 					     DEVICE_UNC_SOCPERF) &&
 					    (j == 0)) {
-						// SOCPERF_Switch_Group3();
+						SOCPERF_Switch_Group3();
 					}
 					// Post group switch
 					cur_grp = LWPMU_DEVICE_cur_group(
diff --git a/drivers/platform/x86/sepdk/sep/unc_sa.c b/drivers/platform/x86/sepdk/sep/unc_sa.c
index 7345807f9588..8691544e3c13 100755
--- a/drivers/platform/x86/sepdk/sep/unc_sa.c
+++ b/drivers/platform/x86/sepdk/sep/unc_sa.c
@@ -33,12 +33,10 @@
 #include "inc/haswellunc_sa.h"
 #include "inc/utility.h"
 
-#if 0
 extern U64 *read_counter_info;
 extern DRV_CONFIG drv_cfg;
 
 extern VOID SOCPERF_Read_Data3(PVOID data_buffer);
-#endif
 
 /*!
  * @fn         static VOID hswunc_sa_Initialize(PVOID)
@@ -71,7 +69,6 @@ static VOID hswunc_sa_Initialize(VOID *param)
  */
 static VOID hswunc_sa_Trigger_Read(PVOID param, U32 id)
 {
-#if 0
 	U64 *data = (U64 *)param;
 	U32 cur_grp;
 	ECB pecb;
@@ -90,7 +87,6 @@ static VOID hswunc_sa_Trigger_Read(PVOID param, U32 id)
 	SOCPERF_Read_Data3((void*)data);
 
 	SEP_DRV_LOG_TRACE_OUT("");
-#endif
 }
 
 /* ------------------------------------------------------------------------- */
@@ -106,7 +102,6 @@ static VOID hswunc_sa_Trigger_Read(PVOID param, U32 id)
  */
 static VOID hswunc_sa_Read_PMU_Data(PVOID param)
 {
-#if 0
 	U32 j;
 	U64 *buffer = read_counter_info;
 	U32 dev_idx;
@@ -144,7 +139,6 @@ static VOID hswunc_sa_Read_PMU_Data(PVOID param)
 	END_FOR_EACH_PCI_DATA_REG_RAW;
 
 	SEP_DRV_LOG_TRACE_OUT("");
-#endif
 }
 
 /*
diff --git a/drivers/platform/x86/sepdk/sep/valleyview_sochap.c b/drivers/platform/x86/sepdk/sep/valleyview_sochap.c
index 7e1e5eb9c65f..f092e376754c 100755
--- a/drivers/platform/x86/sepdk/sep/valleyview_sochap.c
+++ b/drivers/platform/x86/sepdk/sep/valleyview_sochap.c
@@ -37,10 +37,8 @@ static U64 *uncore_current_data;
 static U64 *uncore_to_read_data;
 extern DRV_CONFIG drv_cfg;
 
-#if 0
 extern U64 *read_counter_info;
 extern VOID SOCPERF_Read_Data3(PVOID data_buffer);
-#endif
 
 /*!
  * @fn         static VOID valleyview_VISA_Initialize(PVOID)
@@ -187,7 +185,6 @@ static VOID valleyview_VISA_Clean_Up(VOID *param)
  */
 static VOID valleyview_VISA_Read_PMU_Data(PVOID param)
 {
-#if 0
 	U32 j;
 	U64 *buffer = read_counter_info;
 	U32 dev_idx;
@@ -236,7 +233,6 @@ static VOID valleyview_VISA_Read_PMU_Data(PVOID param)
 	END_FOR_EACH_REG_UNC_OPERATION;
 
 	SEP_DRV_LOG_TRACE_OUT("");
-#endif
 }
 
 /* ------------------------------------------------------------------------- */
@@ -252,7 +248,6 @@ static VOID valleyview_VISA_Read_PMU_Data(PVOID param)
  */
 static VOID valleyview_Trigger_Read(PVOID param, U32 id)
 {
-#if 0
 	U64 *data = (U64 *)param;
 	U32 cur_grp;
 	ECB pecb;
@@ -271,7 +266,6 @@ static VOID valleyview_Trigger_Read(PVOID param, U32 id)
 	SOCPERF_Read_Data3((void*)data);
 
 	SEP_DRV_LOG_TRACE_OUT("");
-#endif
 }
 
 /*
diff --git a/drivers/platform/x86/socperf/Kconfig b/drivers/platform/x86/socperf/Kconfig
new file mode 100644
index 000000000000..f2edf457877e
--- /dev/null
+++ b/drivers/platform/x86/socperf/Kconfig
@@ -0,0 +1,10 @@
+config INTEL_SOCPERF
+	bool "Socperf kernel driver"
+	depends on X86 || X86_64
+	default y
+
+config SOCPERF
+	tristate "Socperf kernel driver"
+	depends on INTEL_SOCPERF
+	depends on ACPI && PCI
+	default m
diff --git a/drivers/platform/x86/socperf/Makefile b/drivers/platform/x86/socperf/Makefile
new file mode 100644
index 000000000000..a67e6a5c9e1f
--- /dev/null
+++ b/drivers/platform/x86/socperf/Makefile
@@ -0,0 +1,12 @@
+ccflags-y := -I$(src)/include -I$(src)/inc
+
+obj-$(CONFIG_SOCPERF) += socperf3.o
+
+socperf3-y := 	socperfdrv.o	\
+		control.o	\
+		utility.o	\
+		pci.o		\
+		soc_uncore.o	\
+		haswellunc_sa.o	\
+		npk_uncore.o
+
diff --git a/drivers/platform/x86/socperf/control.c b/drivers/platform/x86/socperf/control.c
new file mode 100644
index 000000000000..f526dbb7717e
--- /dev/null
+++ b/drivers/platform/x86/socperf/control.c
@@ -0,0 +1,739 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2011-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2011-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/mm.h>
+#include <linux/mempool.h>
+#include <linux/slab.h>
+#include <linux/vmalloc.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "socperfdrv.h"
+#include "control.h"
+#include <linux/sched.h>
+
+#define SMP_CALL_FUNCTION(func, ctx, retry, wait)                              \
+	smp_call_function((func), (ctx), (wait))
+
+/*
+ *  Global State Nodes - keep here for now.  Abstract out when necessary.
+ */
+GLOBAL_STATE_NODE socperf_driver_state;
+static MEM_TRACKER mem_tr_head; // start of the mem tracker list
+static MEM_TRACKER mem_tr_tail; // end of mem tracker list
+static spinlock_t mem_tr_lock; // spinlock for mem tracker list
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID SOCPERF_Invoke_Cpu (func, ctx, arg)
+ *
+ * @brief    Set up a DPC call and insert it into the queue
+ *
+ * @param    IN cpu_idx  - the core id to dispatch this function to
+ *           IN func     - function to be invoked by the specified core(s)
+ *           IN ctx      - pointer to the parameter block for each function
+ *                         invocation
+ *
+ * @return   None
+ *
+ * <I>Special Notes:</I>
+ *
+ */
+VOID SOCPERF_Invoke_Cpu(int cpu_idx, VOID (*func)(PVOID), PVOID ctx)
+{
+	SOCPERF_Invoke_Parallel(func, ctx);
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID SOCPERF_Invoke_Parallel_Service(func, ctx, blocking, exclude)
+ *
+ * @param    func     - function to be invoked by each core in the system
+ * @param    ctx      - pointer to the parameter block for each function invocation
+ * @param    blocking - Wait for invoked function to complete
+ * @param    exclude  - exclude the current core from executing the code
+ *
+ * @returns  None
+ *
+ * @brief    Service routine to handle all kinds of parallel invoke on all CPU calls
+ *
+ * <I>Special Notes:</I>
+ *           Invoke the function provided in parallel in either a blocking or
+ *           non-blocking mode.  The current core may be excluded if desired.
+ *           NOTE - Do not call this function directly from source code.
+ *           Use the aliases SOCPERF_Invoke_Parallel(), SOCPERF_Invoke_Parallel_NB(),
+ *           or SOCPERF_Invoke_Parallel_XS().
+ *
+ */
+VOID SOCPERF_Invoke_Parallel_Service(VOID (*func)(PVOID), PVOID ctx,
+					    int blocking, int exclude)
+{
+	GLOBAL_STATE_cpu_count(socperf_driver_state) = 0;
+	GLOBAL_STATE_dpc_count(socperf_driver_state) = 0;
+
+	preempt_disable();
+	SMP_CALL_FUNCTION(func, ctx, 0, blocking);
+
+	if (!exclude) {
+		func(ctx);
+	}
+	preempt_enable();
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID control_Memory_Tracker_Delete_Node(mem_tr)
+ *
+ * @param    IN mem_tr    - memory tracker node to delete
+ *
+ * @returns  None
+ *
+ * @brief    Delete specified node in the memory tracker
+ *
+ * <I>Special Notes:</I>
+ *           Assumes mem_tr_lock is already held while calling this function!
+ */
+static VOID control_Memory_Tracker_Delete_Node(MEM_TRACKER mem_tr)
+{
+	MEM_TRACKER prev_tr = NULL;
+	MEM_TRACKER next_tr = NULL;
+	U32 size = MEM_EL_MAX_ARRAY_SIZE * sizeof(MEM_EL_NODE);
+
+	if (!mem_tr) {
+		return;
+	}
+
+	// free the allocated mem_el array (if any)
+	if (MEM_TRACKER_mem(mem_tr)) {
+		if (size < MAX_KMALLOC_SIZE) {
+			kfree(MEM_TRACKER_mem(mem_tr));
+		} else {
+			free_pages((unsigned long)MEM_TRACKER_mem(mem_tr),
+				   get_order(size));
+		}
+	}
+
+	// update the linked list
+	prev_tr = MEM_TRACKER_prev(mem_tr);
+	next_tr = MEM_TRACKER_next(mem_tr);
+	if (prev_tr) {
+		MEM_TRACKER_next(prev_tr) = next_tr;
+	}
+	if (next_tr) {
+		MEM_TRACKER_prev(next_tr) = prev_tr;
+	}
+
+	// free the mem_tracker node
+	kfree(mem_tr);
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID control_Memory_Tracker_Create_Node(void)
+ *
+ * @param    None    - size of the memory to allocate
+ *
+ * @returns  OS_SUCCESS if successful, otherwise error
+ *
+ * @brief    Initialize the memory tracker
+ *
+ * <I>Special Notes:</I>
+ *           Assumes mem_tr_lock is already held while calling this function!
+ *
+ *           Since this function can be called within either GFP_KERNEL or
+ *           GFP_ATOMIC contexts, the most restrictive allocation is used
+ *           (viz., GFP_ATOMIC).
+ */
+static U32 control_Memory_Tracker_Create_Node(void)
+{
+	U32 size = MEM_EL_MAX_ARRAY_SIZE * sizeof(MEM_EL_NODE);
+	PVOID location = NULL;
+	MEM_TRACKER mem_tr = NULL;
+
+	// create a mem tracker node
+	mem_tr = (MEM_TRACKER)kmalloc(sizeof(MEM_TRACKER_NODE), GFP_ATOMIC);
+	if (!mem_tr) {
+		SOCPERF_PRINT_ERROR(
+			"%s: failed to allocate mem tracker node\n", __func__);
+		return OS_FAULT;
+	}
+
+	// create an initial array of mem_el's inside the mem tracker node
+	if (size < MAX_KMALLOC_SIZE) {
+		location = (PVOID)kmalloc(size, GFP_ATOMIC);
+		SOCPERF_PRINT_DEBUG(
+			"%s: allocated small memory (0x%p, %d)\n",
+			__func__, location, (S32)size);
+	} else {
+		location = (PVOID)__get_free_pages(GFP_ATOMIC, get_order(size));
+		SOCPERF_PRINT_DEBUG(
+			"%s: allocated large memory (0x%p, %d)\n",
+			__func__, location, (S32)size);
+	}
+
+	// initialize new mem tracker node
+	MEM_TRACKER_mem(mem_tr) = location;
+	MEM_TRACKER_prev(mem_tr) = NULL;
+	MEM_TRACKER_next(mem_tr) = NULL;
+
+	// if mem_el array allocation failed, then remove node
+	if (!MEM_TRACKER_mem(mem_tr)) {
+		control_Memory_Tracker_Delete_Node(mem_tr);
+		SOCPERF_PRINT_ERROR(
+			"%s: failed to allocate mem_el array in tracker node ... deleting node\n", __func__);
+		return OS_FAULT;
+	}
+
+	// initialize mem_tracker's mem_el array
+	MEM_TRACKER_max_size(mem_tr) = MEM_EL_MAX_ARRAY_SIZE;
+	memset(MEM_TRACKER_mem(mem_tr), 0, size);
+
+	// update the linked list
+	if (!mem_tr_head) {
+		mem_tr_head = mem_tr;
+	} else {
+		MEM_TRACKER_prev(mem_tr) = mem_tr_tail;
+		MEM_TRACKER_next(mem_tr_tail) = mem_tr;
+	}
+	mem_tr_tail = mem_tr;
+	SOCPERF_PRINT_DEBUG(
+		"%s: allocating new node=0x%p, max_elements=%d, size=%d\n",
+		__func__, MEM_TRACKER_mem(mem_tr_tail), MEM_EL_MAX_ARRAY_SIZE, size);
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID control_Memory_Tracker_Add(location, size, vmalloc_flag)
+ *
+ * @param    IN location     - memory location
+ * @param    IN size         - size of the memory to allocate
+ * @param    IN vmalloc_flag - flag that indicates if the allocation was done with vmalloc
+ *
+ * @returns  None
+ *
+ * @brief    Keep track of allocated memory with memory tracker
+ *
+ * <I>Special Notes:</I>
+ *           Starting from first mem_tracker node, the algorithm
+ *           finds the first "hole" in the mem_tracker list and
+ *           tracks the memory allocation there.
+ */
+static U32 control_Memory_Tracker_Add(PVOID location, ssize_t size,
+				      DRV_BOOL vmalloc_flag)
+{
+	S32 i, n;
+	U32 status;
+	DRV_BOOL found;
+	MEM_TRACKER mem_tr;
+
+	spin_lock(&mem_tr_lock);
+
+	// check if there is space in ANY of mem_tracker's nodes for the memory item
+	mem_tr = mem_tr_head;
+	found = FALSE;
+	status = OS_SUCCESS;
+	i = n = 0;
+	while (mem_tr && (!found)) {
+		for (i = 0; i < MEM_TRACKER_max_size(mem_tr); i++) {
+			if (!MEM_TRACKER_mem_address(mem_tr, i)) {
+				SOCPERF_PRINT_DEBUG(
+					"%s: found index %d of %d available\n",
+					__func__, i, MEM_TRACKER_max_size(mem_tr) - 1);
+				n = i;
+				found = TRUE;
+			}
+		}
+		if (!found) {
+			mem_tr = MEM_TRACKER_next(mem_tr);
+		}
+	}
+
+	if (!found) {
+		// extend into (i.e., create new) mem_tracker node ...
+		status = control_Memory_Tracker_Create_Node();
+		if (status != OS_SUCCESS) {
+			SOCPERF_PRINT_ERROR(
+				"Unable to create mem tracker node\n");
+			goto finish_add;
+		}
+		// use mem tracker tail node and first available entry in mem_el array
+		mem_tr = mem_tr_tail;
+		n = 0;
+	}
+
+	// we now have a location in mem tracker to keep track of the memory item
+	MEM_TRACKER_mem_address(mem_tr, n) = location;
+	MEM_TRACKER_mem_size(mem_tr, n) = size;
+	MEM_TRACKER_mem_vmalloc(mem_tr, n) = vmalloc_flag;
+	SOCPERF_PRINT_DEBUG(
+		"%s: tracking (0x%p, %d) in node %d of %d\n",
+		__func__, location, (S32)size, n, MEM_TRACKER_max_size(mem_tr) - 1);
+
+finish_add:
+	spin_unlock(&mem_tr_lock);
+
+	return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID SOCPERF_Memory_Tracker_Init(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Initializes Memory Tracker
+ *
+ * <I>Special Notes:</I>
+ *           This should only be called when the driver is being loaded.
+ */
+VOID SOCPERF_Memory_Tracker_Init(VOID)
+{
+	SOCPERF_PRINT_DEBUG(
+		"%s: initializing mem tracker\n", __func__);
+
+	mem_tr_head = NULL;
+	mem_tr_tail = NULL;
+
+	spin_lock_init(&mem_tr_lock);
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID SOCPERF_Memory_Tracker_Free(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Frees memory used by Memory Tracker
+ *
+ * <I>Special Notes:</I>
+ *           This should only be called when the driver is being unloaded.
+ */
+VOID SOCPERF_Memory_Tracker_Free(VOID)
+{
+	S32 i;
+	MEM_TRACKER temp;
+
+	SOCPERF_PRINT_DEBUG(
+		"%s: destroying mem tracker\n", __func__);
+
+	spin_lock(&mem_tr_lock);
+
+	// check for any memory that was not freed, and free it
+	while (mem_tr_head) {
+		for (i = 0; i < MEM_TRACKER_max_size(mem_tr_head); i++) {
+			if (MEM_TRACKER_mem_address(mem_tr_head, i)) {
+				SOCPERF_PRINT_WARNING(
+					"%s: index %d of %d, not freed (0x%p, %d) ... freeing now\n",
+					__func__, i,
+					MEM_TRACKER_max_size(mem_tr_head) - 1,
+					MEM_TRACKER_mem_address(mem_tr_head, i),
+					MEM_TRACKER_mem_size(mem_tr_head, i));
+				free_pages(
+					(unsigned long)MEM_TRACKER_mem_address(
+						mem_tr_head, i),
+					get_order(MEM_TRACKER_mem_size(
+						mem_tr_head, i)));
+				MEM_TRACKER_mem_address(mem_tr_head, i) = NULL;
+				MEM_TRACKER_mem_size(mem_tr_head, i) = 0;
+				MEM_TRACKER_mem_vmalloc(mem_tr_head, i) = FALSE;
+			}
+		}
+		temp = MEM_TRACKER_next(mem_tr_head);
+		control_Memory_Tracker_Delete_Node(mem_tr_head);
+		mem_tr_head = temp;
+	}
+
+	spin_unlock(&mem_tr_lock);
+
+	SOCPERF_PRINT_DEBUG(
+		"%s: mem tracker destruction complete\n", __func__);
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn VOID SOCPERF_Memory_Tracker_Compaction(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Compacts the memory allocator if holes are detected
+ *
+ * <I>Special Notes:</I>
+ *           The algorithm compacts mem_tracker nodes such that
+ *           node entries are full starting from mem_tr_head
+ *           up until the first empty node is detected, after
+ *           which nodes up to mem_tr_tail will be empty.
+ *           At end of collection (or at other safe sync point),
+ *           we reclaim/compact space used by mem tracker.
+ */
+VOID SOCPERF_Memory_Tracker_Compaction(void)
+{
+	S32 i, j, n, m, c, d;
+	DRV_BOOL found, overlap;
+	MEM_TRACKER mem_tr1, mem_tr2;
+
+	spin_lock(&mem_tr_lock);
+
+	mem_tr1 = mem_tr_head;
+	mem_tr2 = mem_tr_tail;
+
+	// if memory tracker was never used, then no need to compact
+	if (!mem_tr1 || !mem_tr2) {
+		goto finish_compact;
+	}
+
+	i = j = n = c = d = 0;
+	m = MEM_TRACKER_max_size(mem_tr2) - 1;
+	overlap = FALSE;
+	while (!overlap) {
+		// find an empty node
+		found = FALSE;
+		while (!found && !overlap && mem_tr1) {
+			SOCPERF_PRINT_DEBUG(
+				"%s: looking at mem_tr1 0x%p, index=%d\n",
+				__func__, mem_tr1, n);
+			for (i = n; i < MEM_TRACKER_max_size(mem_tr1); i++) {
+				if (!MEM_TRACKER_mem_address(mem_tr1, i)) {
+					SOCPERF_PRINT_DEBUG(
+						"%s: found index %d of %d empty\n",
+						__func__, i,
+						MEM_TRACKER_max_size(mem_tr1) -
+							1);
+					found = TRUE;
+				}
+			}
+			// check for overlap
+			overlap = (mem_tr1 == mem_tr2) && (i >= m);
+
+			// if no overlap and an empty node was not found, then advance to next node
+			if (!found && !overlap) {
+				mem_tr1 = MEM_TRACKER_next(mem_tr1);
+				n = 0;
+			}
+		}
+		// all nodes going in forward direction are full, so exit
+		if (!found || overlap) {
+			goto finish_compact;
+		}
+
+		// find a non-empty node
+		found = FALSE;
+		while (!found && !overlap && mem_tr2) {
+			SOCPERF_PRINT_DEBUG(
+				"%s: looking at mem_tr2 0x%p, index=%d\n",
+				__func__, mem_tr2, m);
+			for (j = m; j >= 0; j--) {
+				if (MEM_TRACKER_mem_address(mem_tr2, j)) {
+					SOCPERF_PRINT_DEBUG(
+						"%s: found index %d of %d non-empty\n",
+						__func__, j,
+						MEM_TRACKER_max_size(mem_tr2) -
+							1);
+					found = TRUE;
+				}
+			}
+			// check for overlap
+			overlap = (mem_tr1 == mem_tr2) && (j <= i);
+
+			// if no overlap and no non-empty node was found, then retreat to prev node
+			if (!found && !overlap) {
+				MEM_TRACKER empty_tr =
+					mem_tr2; // keep track of empty node
+
+				mem_tr2 = MEM_TRACKER_prev(mem_tr2);
+				m = MEM_TRACKER_max_size(mem_tr2) - 1;
+				mem_tr_tail = mem_tr2; // keep track of new tail
+				// reclaim empty mem_tracker node
+				control_Memory_Tracker_Delete_Node(empty_tr);
+				// keep track of number of node deletions performed
+				d++;
+			}
+		}
+		// all nodes going in reverse direction are empty, so exit
+		if (!found || overlap) {
+			goto finish_compact;
+		}
+
+		// swap empty node with non-empty node so that "holes" get bubbled towards the end of list
+		MEM_TRACKER_mem_address(mem_tr1, i) =
+			MEM_TRACKER_mem_address(mem_tr2, j);
+		MEM_TRACKER_mem_size(mem_tr1, i) =
+			MEM_TRACKER_mem_size(mem_tr2, j);
+		MEM_TRACKER_mem_vmalloc(mem_tr1, i) =
+			MEM_TRACKER_mem_vmalloc(mem_tr2, j);
+
+		MEM_TRACKER_mem_address(mem_tr2, j) = NULL;
+		MEM_TRACKER_mem_size(mem_tr2, j) = 0;
+		MEM_TRACKER_mem_vmalloc(mem_tr2, j) = FALSE;
+
+		// keep track of number of memory compactions performed
+		c++;
+
+		// start new search starting from next element in mem_tr1
+		n = i + 1;
+
+		// start new search starting from prev element in mem_tr2
+		m = j - 1;
+	}
+
+finish_compact:
+	spin_unlock(&mem_tr_lock);
+
+	SOCPERF_PRINT_DEBUG(
+		"%s: number of elements compacted = %d, nodes deleted = %d\n",
+		__func__, c, d);
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn PVOID SOCPERF_Allocate_Memory(size)
+ *
+ * @param    IN size     - size of the memory to allocate
+ *
+ * @returns  char*       - pointer to the allocated memory block
+ *
+ * @brief    Allocate and zero memory
+ *
+ * <I>Special Notes:</I>
+ *           Allocate memory in the GFP_KERNEL pool.
+ *
+ *           Use this if memory is to be allocated within a context where
+ *           the allocator can block the allocation (e.g., by putting
+ *           the caller to sleep) while it tries to free up memory to
+ *           satisfy the request.  Otherwise, if the allocation must
+ *           occur atomically (e.g., caller cannot sleep), then use
+ *           SOCPERF_Allocate_KMemory instead.
+ */
+PVOID SOCPERF_Allocate_Memory(size_t size)
+{
+	U32 status;
+	PVOID location;
+
+	if (size <= 0) {
+		return NULL;
+	}
+
+	// determine whether to use mem_tracker or not
+	if (size < MAX_KMALLOC_SIZE) {
+		location = (PVOID)kmalloc(size, GFP_KERNEL);
+		SOCPERF_PRINT_DEBUG(
+			"%s: allocated small memory (0x%p, %d)\n",
+			__func__, location, (S32)size);
+	} else {
+		location = (PVOID)vmalloc(size);
+		if (location) {
+			status = control_Memory_Tracker_Add(location, size,
+							    TRUE);
+			SOCPERF_PRINT_DEBUG(
+				"%s: - allocated *large* memory (0x%p, %d)\n",
+				__func__, location, (S32)size);
+			if (status != OS_SUCCESS) {
+				// failed to track in mem_tracker, so free up memory and return NULL
+				vfree(location);
+				SOCPERF_PRINT_ERROR(
+				"%s: - able to allocate, but failed to track via MEM_TRACKER ... freeing\n",
+				__func__);
+				return NULL;
+			}
+		}
+	}
+
+	if (!location) {
+		SOCPERF_PRINT_ERROR(
+			"%s: failed for size %d bytes\n",
+			__func__, (S32)size);
+		return NULL;
+	}
+
+	memset(location, 0, size);
+
+	return location;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn PVOID SOCPERF_Allocate_KMemory(size)
+ *
+ * @param    IN size     - size of the memory to allocate
+ *
+ * @returns  char*       - pointer to the allocated memory block
+ *
+ * @brief    Allocate and zero memory
+ *
+ * <I>Special Notes:</I>
+ *           Allocate memory in the GFP_ATOMIC pool.
+ *
+ *           Use this if memory is to be allocated within a context where
+ *           the allocator cannot block the allocation (e.g., by putting
+ *           the caller to sleep) as it tries to free up memory to
+ *           satisfy the request.  Examples include interrupt handlers,
+ *           process context code holding locks, etc.
+ */
+PVOID SOCPERF_Allocate_KMemory(size_t size)
+{
+	U32 status;
+	PVOID location;
+
+	if (size <= 0) {
+		return NULL;
+	}
+
+	if (size < MAX_KMALLOC_SIZE) {
+		location = (PVOID)kmalloc(size, GFP_ATOMIC);
+		SOCPERF_PRINT_DEBUG(
+			"%s: allocated small memory (0x%p, %d)\n",
+			__func__, location, (S32)size);
+	} else {
+		location = (PVOID)__get_free_pages(GFP_ATOMIC, get_order(size));
+		status = control_Memory_Tracker_Add(location, size, FALSE);
+		SOCPERF_PRINT_DEBUG(
+			"%s: allocated large memory (0x%p, %d)\n",
+			__func__, location, (S32)size);
+		if (status != OS_SUCCESS) {
+			// failed to track in mem_tracker, so free up memory and return NULL
+			free_pages((unsigned long)location, get_order(size));
+			SOCPERF_PRINT_ERROR(
+				"%s: - able to allocate, but failed to track via MEM_TRACKER ... freeing\n", __func__);
+			return NULL;
+		}
+	}
+
+	if (!location) {
+		SOCPERF_PRINT_ERROR(
+			"%s: failed for size %d bytes\n",
+			__func__, (S32)size);
+		return NULL;
+	}
+
+	memset(location, 0, size);
+
+	return location;
+}
+
+/* ------------------------------------------------------------------------- */
+/*
+ * @fn PVOID SOCPERF_Free_Memory(location)
+ *
+ * @param    IN location  - size of the memory to allocate
+ *
+ * @returns  pointer to the allocated memory block
+ *
+ * @brief    Frees the memory block
+ *
+ * <I>Special Notes:</I>
+ *           Does not try to free memory if fed with a NULL pointer
+ *           Expected usage:
+ *               ptr = SOCPERF_Free_Memory(ptr);
+ *           Does not do compaction ... can have "holes" in
+ *           mem_tracker list after this operation.
+ */
+PVOID SOCPERF_Free_Memory(PVOID location)
+{
+	S32 i;
+	DRV_BOOL found;
+	MEM_TRACKER mem_tr;
+
+	if (!location) {
+		return NULL;
+	}
+
+	spin_lock(&mem_tr_lock);
+
+	// scan through mem_tracker nodes for matching entry (if any)
+	mem_tr = mem_tr_head;
+	found = FALSE;
+	while (mem_tr) {
+		for (i = 0; i < MEM_TRACKER_max_size(mem_tr); i++) {
+			if (location == MEM_TRACKER_mem_address(mem_tr, i)) {
+				SOCPERF_PRINT_DEBUG(
+					"%s: freeing large memory location 0x%p\n",
+					__func__, location);
+				found = TRUE;
+				if (MEM_TRACKER_mem_vmalloc(mem_tr, i)) {
+					vfree(location);
+				} else {
+					free_pages(
+						(unsigned long)location,
+						get_order(MEM_TRACKER_mem_size(
+							mem_tr, i)));
+				}
+				MEM_TRACKER_mem_address(mem_tr, i) = NULL;
+				MEM_TRACKER_mem_size(mem_tr, i) = 0;
+				MEM_TRACKER_mem_vmalloc(mem_tr, i) = FALSE;
+				goto finish_free;
+			}
+		}
+		mem_tr = MEM_TRACKER_next(mem_tr);
+	}
+
+finish_free:
+	spin_unlock(&mem_tr_lock);
+
+	// must have been of smaller than the size limit for mem tracker nodes
+	if (!found) {
+		SOCPERF_PRINT_DEBUG(
+			"%s: freeing small memory location 0x%p\n",
+			__func__, location);
+		kfree(location);
+	}
+
+	return NULL;
+}
diff --git a/drivers/platform/x86/socperf/haswellunc_sa.c b/drivers/platform/x86/socperf/haswellunc_sa.c
new file mode 100644
index 000000000000..9b487b25f101
--- /dev/null
+++ b/drivers/platform/x86/socperf/haswellunc_sa.c
@@ -0,0 +1,407 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2011-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2011-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/wait.h>
+#include <linux/fs.h>
+
+#include "lwpmudrv_types.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "socperfdrv.h"
+#include "control.h"
+#include "haswellunc_sa.h"
+#include "ecb_iterators.h"
+#include "inc/pci.h"
+
+static U64 counter_virtual_address;
+static U32 counter_overflow[HSWUNC_SA_MAX_COUNTERS];
+extern LWPMU_DEVICE device_uncore;
+static U32 device_id;
+
+/*!
+ * @fn          static VOID hswunc_sa_Write_PMU(VOID*)
+ *
+ * @brief       Initial write of PMU registers
+ *              Walk through the entries and write the value of the register accordingly.
+ *              When current_group = 0, then this is the first time this routine is called,
+ *
+ * @param       param - device index
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID hswunc_sa_Write_PMU(VOID *param)
+{
+	U32 dev_idx = *((U32 *)param);
+	U32 cur_grp = LWPMU_DEVICE_cur_group(device_uncore);
+	ECB pecb = LWPMU_DEVICE_PMU_register_data(device_uncore)[cur_grp];
+	DRV_PCI_DEVICE_ENTRY dpden;
+	U32 pci_address;
+	U32 bar_lo;
+	U64 bar_hi;
+	U64 final_bar;
+	U64 physical_address;
+	U32 dev_index = 0;
+	S32 bar_list[HSWUNC_SA_MAX_PCI_DEVICES];
+	U32 bar_index = 0;
+	U64 gdxc_bar = 0;
+	U32 map_size = 0;
+	U64 virtual_address = 0;
+	U64 mmio_offset = 0;
+	U32 bar_name = 0;
+	DRV_PCI_DEVICE_ENTRY curr_pci_entry = NULL;
+	U32 next_bar_offset = 0;
+	U32 i = 0;
+
+	for (dev_index = 0; dev_index < HSWUNC_SA_MAX_PCI_DEVICES;
+	     dev_index++) {
+		bar_list[dev_index] = -1;
+	}
+
+	device_id = dev_idx;
+	// initialize the CHAP per-counter overflow numbers
+	for (i = 0; i < HSWUNC_SA_MAX_COUNTERS; i++) {
+		counter_overflow[i] = 0;
+		socperf_pcb[0].last_uncore_count[i] = 0;
+	}
+
+	ECB_pcidev_entry_list(pecb) = (DRV_PCI_DEVICE_ENTRY)(
+		(S8 *)pecb + ECB_pcidev_list_offset(pecb));
+	dpden = ECB_pcidev_entry_list(pecb);
+
+	if (counter_virtual_address) {
+		for (i = 0; i < ECB_num_entries(pecb); i++) {
+			writel(HSWUNC_SA_CHAP_STOP,
+			       (void __iomem *)(((char *)(UIOP)counter_virtual_address) +
+				       HSWUNC_SA_CHAP_CTRL_REG_OFFSET +
+				       i * 0x10));
+		}
+	}
+
+	for (dev_index = 0; dev_index < ECB_num_pci_devices(pecb);
+	     dev_index++) {
+		curr_pci_entry = &dpden[dev_index];
+		mmio_offset = DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(
+			curr_pci_entry);
+		bar_name = DRV_PCI_DEVICE_ENTRY_bar_name(curr_pci_entry);
+		if (DRV_PCI_DEVICE_ENTRY_config_type(curr_pci_entry) ==
+		    UNC_PCICFG) {
+			pci_address = FORM_PCI_ADDR(
+				DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+				mmio_offset);
+			SOCPERF_PCI_Write_Ulong(
+				pci_address,
+				DRV_PCI_DEVICE_ENTRY_value(curr_pci_entry));
+			continue;
+		}
+		// UNC_MMIO programming
+		if (bar_list[bar_name] != -1) {
+			bar_index = bar_list[bar_name];
+			virtual_address = DRV_PCI_DEVICE_ENTRY_virtual_address(
+				&dpden[bar_index]);
+			DRV_PCI_DEVICE_ENTRY_virtual_address(curr_pci_entry) =
+				DRV_PCI_DEVICE_ENTRY_virtual_address(
+					&dpden[bar_index]);
+			writel(DRV_PCI_DEVICE_ENTRY_value(curr_pci_entry),
+			       (void __iomem *)(((char *)(UIOP)virtual_address) +
+				       mmio_offset));
+			continue;
+		}
+		if (bar_name == UNC_GDXCBAR) {
+			DRV_PCI_DEVICE_ENTRY_bar_address(curr_pci_entry) =
+				gdxc_bar;
+		} else {
+			pci_address = FORM_PCI_ADDR(
+				DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_bar_offset(
+					curr_pci_entry));
+			bar_lo = SOCPERF_PCI_Read_Ulong(pci_address);
+			next_bar_offset = DRV_PCI_DEVICE_ENTRY_bar_offset(
+						  curr_pci_entry) +
+					  HSWUNC_SA_NEXT_ADDR_OFFSET;
+			pci_address = FORM_PCI_ADDR(
+				DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+				next_bar_offset);
+			bar_hi = SOCPERF_PCI_Read_Ulong(pci_address);
+			final_bar =
+				(bar_hi << HSWUNC_SA_BAR_ADDR_SHIFT) | bar_lo;
+			final_bar &= HSWUNC_SA_BAR_ADDR_MASK;
+
+			DRV_PCI_DEVICE_ENTRY_bar_address(curr_pci_entry) =
+				final_bar;
+		}
+		physical_address =
+			DRV_PCI_DEVICE_ENTRY_bar_address(curr_pci_entry);
+
+		if (physical_address) {
+			if (bar_name == UNC_MCHBAR) {
+				map_size = HSWUNC_SA_MCHBAR_MMIO_PAGE_SIZE;
+			} else if (bar_name == UNC_PCIEXBAR) {
+				map_size = HSWUNC_SA_PCIEXBAR_MMIO_PAGE_SIZE;
+			} else {
+				map_size = HSWUNC_SA_OTHER_BAR_MMIO_PAGE_SIZE;
+			}
+			DRV_PCI_DEVICE_ENTRY_virtual_address(curr_pci_entry) =
+				(U64)(UIOP)ioremap_nocache(physical_address,
+							   map_size);
+			virtual_address = DRV_PCI_DEVICE_ENTRY_virtual_address(
+				curr_pci_entry);
+
+			if (!gdxc_bar && bar_name == UNC_MCHBAR) {
+				bar_lo = readl(
+					(void __iomem *)((char *)(UIOP)virtual_address +
+						HSWUNC_SA_GDXCBAR_OFFSET_LO));
+				bar_hi = readl(
+					(void __iomem *)((char *)(UIOP)virtual_address +
+						HSWUNC_SA_GDXCBAR_OFFSET_HI));
+				gdxc_bar =
+					(bar_hi << HSWUNC_SA_BAR_ADDR_SHIFT) |
+					bar_lo;
+				gdxc_bar = gdxc_bar & HSWUNC_SA_GDXCBAR_MASK;
+			}
+			writel((U32)DRV_PCI_DEVICE_ENTRY_value(curr_pci_entry),
+			       (void __iomem *)(((char *)(UIOP)virtual_address) +
+				       mmio_offset));
+			bar_list[bar_name] = dev_index;
+			if (counter_virtual_address == 0 &&
+			    bar_name == UNC_CHAPADR) {
+				counter_virtual_address = virtual_address;
+			}
+		}
+	}
+}
+
+/*!
+ * @fn         static VOID hswunc_sa_Disable_PMU(PVOID)
+ *
+ * @brief      Unmap the virtual address when sampling/driver stops
+ *
+ * @param      param - device index
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID hswunc_sa_Disable_PMU(PVOID param)
+{
+	DRV_PCI_DEVICE_ENTRY dpden;
+	U32 dev_index = 0;
+	U32 cur_grp = LWPMU_DEVICE_cur_group(device_uncore);
+	ECB pecb = LWPMU_DEVICE_PMU_register_data(device_uncore)[cur_grp];
+	U32 i = 0;
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) ==
+	    DRV_STATE_PREPARE_STOP) {
+		if (counter_virtual_address) {
+			for (i = 0; i < ECB_num_entries(pecb); i++) {
+				writel(HSWUNC_SA_CHAP_STOP,
+				       (void __iomem *)(((char *)(UIOP)
+							counter_virtual_address) +
+					       HSWUNC_SA_CHAP_CTRL_REG_OFFSET +
+					       i * 0x10));
+			}
+		}
+
+		dpden = ECB_pcidev_entry_list(pecb);
+		for (dev_index = 0; dev_index < ECB_num_pci_devices(pecb);
+		     dev_index++) {
+			if (DRV_PCI_DEVICE_ENTRY_config_type(
+				    &dpden[dev_index]) == UNC_MMIO &&
+			    DRV_PCI_DEVICE_ENTRY_bar_address(
+				    &dpden[dev_index]) != 0) {
+				iounmap((void __iomem *)(UIOP)(
+					DRV_PCI_DEVICE_ENTRY_virtual_address(
+						&dpden[dev_index])));
+			}
+		}
+		counter_virtual_address = 0;
+	}
+}
+
+/*!
+ * @fn         static VOID hswunc_sa_Initialize(PVOID)
+ *
+ * @brief      Initialize any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID hswunc_sa_Initialize(VOID *param)
+{
+	counter_virtual_address = 0;
+}
+
+/*!
+ * @fn         static VOID hswunc_sa_Clean_Up(PVOID)
+ *
+ * @brief      Reset any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID hswunc_sa_Clean_Up(VOID *param)
+{
+	counter_virtual_address = 0;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn hswunc_sa_Read_Data(param, id)
+ *
+ * @param    data_buffer    data buffer to read data into
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the Uncore count data and store into the buffer param;
+ *
+ */
+static VOID hswunc_sa_Read_Data(PVOID data_buffer)
+{
+	U32 event_id = 0;
+	U64 *data;
+	int data_index;
+	U32 data_val = 0;
+	U64 total_count = 0;
+	U32 cur_grp = LWPMU_DEVICE_cur_group(device_uncore);
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_UNINITIALIZED ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_IDLE ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_RESERVED ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_PREPARE_STOP ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_STOPPED) {
+		SOCPERF_PRINT_ERROR("ERROR: RETURING EARLY from Read_Data\n");
+		return;
+	}
+	if (data_buffer == NULL) {
+		return;
+	}
+	data = (U64 *)data_buffer;
+	data_index = 0;
+	// group id
+	data[data_index] = cur_grp + 1;
+	data_index++;
+
+	FOR_EACH_PCI_DATA_REG_RAW(pecb, i, dev_idx)
+	{
+		//event_id = ECB_entries_event_id_index_local(pecb, i);
+		if (counter_virtual_address) {
+			writel(HSWUNC_SA_CHAP_SAMPLE_DATA,
+			       (void __iomem *)(((char *)(UIOP)counter_virtual_address) +
+				       HSWUNC_SA_CHAP_CTRL_REG_OFFSET +
+				       i * 0x10));
+			data_val = readl((void __iomem *)
+					((char *)(UIOP)(counter_virtual_address) +
+				       ECB_entries_reg_offset(pecb, i)));
+		}
+
+		if (data_val < socperf_pcb[0].last_uncore_count[i]) {
+			counter_overflow[i]++;
+		}
+		socperf_pcb[0].last_uncore_count[i] = data_val;
+
+		total_count =
+			data_val + counter_overflow[i] * HSWUNC_SA_MAX_COUNT;
+		data[data_index + event_id] = total_count;
+		SOCPERF_PRINT_DEBUG("DATA=%u\n", data_val);
+		event_id++;
+	}
+	END_FOR_EACH_PCI_DATA_REG_RAW;
+}
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE socperf_hswunc_sa_dispatch = {
+	.init = hswunc_sa_Initialize, // initialize
+	.fini = NULL, // destroy
+	.write = hswunc_sa_Write_PMU, // write
+	.freeze = hswunc_sa_Disable_PMU, // freeze
+	.restart = NULL, // restart
+	.read_data = NULL, // read
+	.check_overflow = NULL, // check for overflow
+	.swap_group = NULL,
+	.read_lbrs = NULL,
+	.clean_up = hswunc_sa_Clean_Up,
+	.hw_errata = NULL,
+	.read_power = NULL,
+	.check_overflow_errata = NULL,
+	.read_counts = NULL, //read_counts
+	.check_overflow_gp_errata = NULL,
+	.read_power = NULL,
+	.platform_info = NULL,
+	.trigger_read = NULL,
+	.read_current_data = hswunc_sa_Read_Data,
+	.create_mem = NULL,
+	.check_status = NULL,
+	.read_mem = NULL,
+	.stop_mem = NULL
+};
diff --git a/drivers/platform/x86/socperf/inc/control.h b/drivers/platform/x86/socperf/inc/control.h
new file mode 100644
index 000000000000..0f44b85d76dc
--- /dev/null
+++ b/drivers/platform/x86/socperf/inc/control.h
@@ -0,0 +1,467 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#ifndef _CONTROL_H_
+#define _CONTROL_H_
+
+#include <linux/smp.h>
+#include <linux/timer.h>
+#if defined(DRV_IA32)
+#include <asm/apic.h>
+#endif
+#include <asm/io.h>
+#if defined(DRV_IA32)
+#include <asm/msr.h>
+#endif
+#include <asm/atomic.h>
+
+#include "lwpmudrv_defines.h"
+#include "socperfdrv.h"
+#include "lwpmudrv_types.h"
+
+// large memory allocation will be used if the requested size (in bytes) is
+// above this threshold
+#define MAX_KMALLOC_SIZE ((1 << 17) - 1)
+
+// check whether Linux driver should use unlocked ioctls (not protected by BKL)
+#if defined(HAVE_UNLOCKED_IOCTL)
+#define DRV_USE_UNLOCKED_IOCTL
+#endif
+#if defined(DRV_USE_UNLOCKED_IOCTL)
+#define IOCTL_OP .unlocked_ioctl
+#define IOCTL_OP_TYPE long
+#define IOCTL_USE_INODE
+#else
+#define IOCTL_OP .ioctl
+#define IOCTL_OP_TYPE S32
+#define IOCTL_USE_INODE struct inode *inode,
+#endif
+
+// Information about the state of the driver
+typedef struct GLOBAL_STATE_NODE_S GLOBAL_STATE_NODE;
+typedef GLOBAL_STATE_NODE *GLOBAL_STATE;
+struct GLOBAL_STATE_NODE_S {
+	volatile S32 cpu_count;
+	volatile S32 dpc_count;
+
+	S32 num_cpus; // Number of CPUs in the system
+	S32 active_cpus; // Number of active CPUs - some cores can be
+		// deactivated by the user / admin
+	S32 num_em_groups;
+	S32 num_descriptors;
+	volatile S32 current_phase;
+};
+
+// Access Macros
+#define GLOBAL_STATE_num_cpus(x) ((x).num_cpus)
+#define GLOBAL_STATE_active_cpus(x) ((x).active_cpus)
+#define GLOBAL_STATE_cpu_count(x) ((x).cpu_count)
+#define GLOBAL_STATE_dpc_count(x) ((x).dpc_count)
+#define GLOBAL_STATE_num_em_groups(x) ((x).num_em_groups)
+#define GLOBAL_STATE_num_descriptors(x) ((x).num_descriptors)
+#define GLOBAL_STATE_current_phase(x) ((x).current_phase)
+#define GLOBAL_STATE_sampler_id(x) ((x).sampler_id)
+
+/*
+ *
+ *
+ * CPU State data structure and access macros
+ *
+ */
+typedef struct CPU_STATE_NODE_S CPU_STATE_NODE;
+typedef CPU_STATE_NODE * CPU_STATE;
+struct CPU_STATE_NODE_S {
+	S32 apic_id; // Processor ID on the system bus
+	PVOID apic_linear_addr; // linear address of local apic
+	PVOID apic_physical_addr; // physical address of local apic
+
+	PVOID idt_base; // local IDT base address
+	atomic_t in_interrupt;
+
+#if defined(DRV_IA32)
+	U64 saved_ih; // saved perfvector to restore
+#endif
+#if defined(DRV_EM64T)
+	PVOID saved_ih; // saved perfvector to restore
+#endif
+
+	S64 * em_tables; // holds the data that is saved/restored
+		// during event multiplexing
+
+	struct timer_list *em_timer;
+	U32 current_group;
+	S32 trigger_count;
+	S32 trigger_event_num;
+
+	DISPATCH dispatch;
+	PVOID lbr_area;
+	PVOID old_dts_buffer;
+	PVOID dts_buffer;
+	U32 initial_mask;
+	U32 accept_interrupt;
+
+#if defined(BUILD_CHIPSET)
+	// Chipset counter stuff
+	U32 chipset_count_init; // flag to initialize the last MCH and ICH arrays below.
+	U64 last_mch_count[8];
+	U64 last_ich_count[8];
+	U64 last_gmch_count[MAX_CHIPSET_COUNTERS];
+	U64 last_mmio_count
+		[32]; // it's only 9 now but the next generation may have 29.
+#endif
+
+	U64 *pmu_state; // holds PMU state (e.g., MSRs) that will be
+		// saved before and restored after collection
+	S32 socket_master;
+	S32 core_master;
+	S32 thr_master;
+	U64 num_samples;
+	U64 reset_mask;
+	U64 group_swap;
+	U64 last_uncore_count[16];
+};
+
+#define CPU_STATE_apic_id(cpu) ((cpu)->apic_id)
+#define CPU_STATE_apic_linear_addr(cpu) ((cpu)->apic_linear_addr)
+#define CPU_STATE_apic_physical_addr(cpu) ((cpu)->apic_physical_addr)
+#define CPU_STATE_idt_base(cpu) ((cpu)->idt_base)
+#define CPU_STATE_in_interrupt(cpu) ((cpu)->in_interrupt)
+#define CPU_STATE_saved_ih(cpu) ((cpu)->saved_ih)
+#define CPU_STATE_saved_ih_hi(cpu) ((cpu)->saved_ih_hi)
+#define CPU_STATE_dpc(cpu) ((cpu)->dpc)
+#define CPU_STATE_em_tables(cpu) ((cpu)->em_tables)
+#define CPU_STATE_pmu_state(cpu) ((cpu)->pmu_state)
+#define CPU_STATE_em_dpc(cpu) ((cpu)->em_dpc)
+#define CPU_STATE_em_timer(cpu) ((cpu)->em_timer)
+#define CPU_STATE_current_group(cpu) ((cpu)->current_group)
+#define CPU_STATE_trigger_count(cpu) ((cpu)->trigger_count)
+#define CPU_STATE_trigger_event_num(cpu) ((cpu)->trigger_event_num)
+#define CPU_STATE_dispatch(cpu) ((cpu)->dispatch)
+#define CPU_STATE_lbr(cpu) ((cpu)->lbr)
+#define CPU_STATE_old_dts_buffer(cpu) ((cpu)->old_dts_buffer)
+#define CPU_STATE_dts_buffer(cpu) ((cpu)->dts_buffer)
+#define CPU_STATE_initial_mask(cpu) ((cpu)->initial_mask)
+#define CPU_STATE_accept_interrupt(cpu) ((cpu)->accept_interrupt)
+#define CPU_STATE_msr_value(cpu) ((cpu)->msr_value)
+#define CPU_STATE_msr_addr(cpu) ((cpu)->msr_addr)
+#define CPU_STATE_socket_master(cpu) ((cpu)->socket_master)
+#define CPU_STATE_core_master(cpu) ((cpu)->core_master)
+#define CPU_STATE_thr_master(cpu) ((cpu)->thr_master)
+#define CPU_STATE_num_samples(cpu) ((cpu)->num_samples)
+#define CPU_STATE_reset_mask(cpu) ((cpu)->reset_mask)
+#define CPU_STATE_group_swap(cpu) ((cpu)->group_swap)
+
+/*
+ * For storing data for --read/--write-msr command line options
+ */
+typedef struct MSR_DATA_NODE_S MSR_DATA_NODE;
+typedef MSR_DATA_NODE * MSR_DATA;
+struct MSR_DATA_NODE_S {
+	U64 value; // Used for emon, for read/write-msr value
+	U64 addr;
+};
+
+#define MSR_DATA_value(md) ((md)->value)
+#define MSR_DATA_addr(md) ((md)->addr)
+
+/*
+ * Memory Allocation tracker
+ *
+ * Currently used to track large memory allocations
+ */
+
+typedef struct MEM_EL_NODE_S MEM_EL_NODE;
+typedef MEM_EL_NODE * MEM_EL;
+struct MEM_EL_NODE_S {
+	char *address; // pointer to piece of memory we're tracking
+	S32 size; // size (bytes) of the piece of memory
+	DRV_BOOL is_addr_vmalloc; // flag to check if the memory is allocated using vmalloc
+};
+
+// accessors for MEM_EL defined in terms of MEM_TRACKER below
+
+#define MEM_EL_MAX_ARRAY_SIZE 32 // minimum is 1, nominal is 64
+
+typedef struct MEM_TRACKER_NODE_S MEM_TRACKER_NODE;
+typedef MEM_TRACKER_NODE * MEM_TRACKER;
+struct MEM_TRACKER_NODE_S {
+	S32 max_size; // number of elements in the array (default: MEM_EL_MAX_ARRAY_SIZE)
+	MEM_EL mem; // array of large memory items we're tracking
+	MEM_TRACKER prev,
+		next; // enables bi-directional scanning of linked list
+};
+#define MEM_TRACKER_max_size(mt) ((mt)->max_size)
+#define MEM_TRACKER_mem(mt) ((mt)->mem)
+#define MEM_TRACKER_prev(mt) ((mt)->prev)
+#define MEM_TRACKER_next(mt) ((mt)->next)
+#define MEM_TRACKER_mem_address(mt, i) (MEM_TRACKER_mem(mt)[(i)].address)
+#define MEM_TRACKER_mem_size(mt, i) (MEM_TRACKER_mem(mt)[(i)].size)
+#define MEM_TRACKER_mem_vmalloc(mt, i)                                         \
+	(MEM_TRACKER_mem(mt)[(i)].is_addr_vmalloc)
+
+/****************************************************************************
+ ** Global State variables exported
+ ***************************************************************************/
+extern CPU_STATE socperf_pcb;
+extern U64 *tsc_info;
+extern GLOBAL_STATE_NODE socperf_driver_state;
+extern MSR_DATA msr_data;
+extern U32 *core_to_package_map;
+extern U32 num_packages;
+extern U64 *restore_bl_bypass;
+extern U32 **restore_ha_direct2core;
+extern U32 **restore_qpi_direct2core;
+/****************************************************************************
+ **  Handy Short cuts
+ ***************************************************************************/
+
+/*
+ * SOCPERF_THIS_CPU()
+ *     Parameters
+ *         None
+ *     Returns
+ *         CPU number of the processor being executed on
+ *
+ */
+#define SOCPERF_THIS_CPU() smp_processor_id()
+
+/****************************************************************************
+ **  Interface definitions
+ ***************************************************************************/
+
+/*
+ *  Execution Control Functions
+ */
+
+VOID SOCPERF_Invoke_Cpu(S32 cpuid, VOID (*func)(PVOID), PVOID ctx);
+
+/*
+ * @fn VOID SOCPERF_Invoke_Parallel_Service(func, ctx, blocking, exclude)
+ *
+ * @param    func     - function to be invoked by each core in the system
+ * @param    ctx      - pointer to the parameter block for each function invocation
+ * @param    blocking - Wait for invoked function to complete
+ * @param    exclude  - exclude the current core from executing the code
+ *
+ * @returns  none
+ *
+ * @brief    Service routine to handle all kinds of parallel invoke on all CPU calls
+ *
+ * <I>Special Notes:</I>
+ *         Invoke the function provided in parallel in either a blocking/non-blocking mode.
+ *         The current core may be excluded if desired.
+ *         NOTE - Do not call this function directly from source code.  Use the aliases
+ *         SOCPERF_Invoke_Parallel(), SOCPERF_Invoke_Parallel_NB(), SOCPERF_Invoke_Parallel_XS().
+ *
+ */
+extern VOID SOCPERF_Invoke_Parallel_Service(VOID (*func)(PVOID), PVOID ctx,
+					    S32 blocking, S32 exclude);
+
+/*
+ * @fn VOID SOCPERF_Invoke_Parallel(func, ctx)
+ *
+ * @param    func     - function to be invoked by each core in the system
+ * @param    ctx      - pointer to the parameter block for each function invocation
+ *
+ * @returns  none
+ *
+ * @brief    Invoke the named function in parallel. Wait for all the functions to complete.
+ *
+ * <I>Special Notes:</I>
+ *        Invoke the function named in parallel, including the CPU that the control is
+ *        being invoked on
+ *        Macro built on the service routine
+ *
+ */
+#define SOCPERF_Invoke_Parallel(a, b)                                          \
+	SOCPERF_Invoke_Parallel_Service((a), (b), TRUE, FALSE)
+
+/*
+ * @fn VOID SOCPERF_Invoke_Parallel_NB(func, ctx)
+ *
+ * @param    func     - function to be invoked by each core in the system
+ * @param    ctx      - pointer to the parameter block for each function invocation
+ *
+ * @returns  none
+ *
+ * @brief    Invoke the named function in parallel. DO NOT Wait for all the functions to complete.
+ *
+ * <I>Special Notes:</I>
+ *        Invoke the function named in parallel, including the CPU that the control is
+ *        being invoked on
+ *        Macro built on the service routine
+ *
+ */
+#define SOCPERF_Invoke_Parallel_NB(a, b)                                       \
+	SOCPERF_Invoke_Parallel_Service((a), (b), FALSE, FALSE)
+
+/*
+ * @fn VOID SOCPERF_Invoke_Parallel_XS(func, ctx)
+ *
+ * @param    func     - function to be invoked by each core in the system
+ * @param    ctx      - pointer to the parameter block for each function invocation
+ *
+ * @returns  none
+ *
+ * @brief    Invoke the named function in parallel. Wait for all the functions to complete.
+ *
+ * <I>Special Notes:</I>
+ *        Invoke the function named in parallel, excluding the CPU that the control is
+ *        being invoked on
+ *        Macro built on the service routine
+ *
+ */
+#define SOCPERF_Invoke_Parallel_XS(a, b)                                       \
+	SOCPERF_Invoke_Parallel_Service((a), (b), TRUE, TRUE)
+
+/*
+ * @fn VOID SOCPERF_Memory_Tracker_Init(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Initializes Memory Tracker
+ *
+ * <I>Special Notes:</I>
+ *           This should only be called when the
+ *           the driver is being loaded.
+ */
+extern VOID SOCPERF_Memory_Tracker_Init(VOID);
+
+/*
+ * @fn VOID SOCPERF_Memory_Tracker_Free(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Frees memory used by Memory Tracker
+ *
+ * <I>Special Notes:</I>
+ *           This should only be called when the
+ *           driver is being unloaded.
+ */
+extern VOID SOCPERF_Memory_Tracker_Free(VOID);
+
+/*
+ * @fn VOID SOCPERF_Memory_Tracker_Compaction(void)
+ *
+ * @param    None
+ *
+ * @returns  None
+ *
+ * @brief    Compacts the memory allocator if holes are detected
+ *
+ * <I>Special Notes:</I>
+ *           At end of collection (or at other safe sync point),
+ *           reclaim/compact space used by mem tracker
+ */
+extern VOID SOCPERF_Memory_Tracker_Compaction(void);
+
+/*
+ * @fn PVOID SOCPERF_Allocate_Memory(size)
+ *
+ * @param    IN size     - size of the memory to allocate
+ *
+ * @returns  char*       - pointer to the allocated memory block
+ *
+ * @brief    Allocate and zero memory
+ *
+ * <I>Special Notes:</I>
+ *           Allocate memory in the GFP_KERNEL pool.
+ *
+ *           Use this if memory is to be allocated within a context where
+ *           the allocator can block the allocation (e.g., by putting
+ *           the caller to sleep) while it tries to free up memory to
+ *           satisfy the request.  Otherwise, if the allocation must
+ *           occur atomically (e.g., caller cannot sleep), then use
+ *           SOCPERF_Allocate_KMemory instead.
+ */
+extern PVOID SOCPERF_Allocate_Memory(size_t size);
+
+/*
+ * @fn PVOID SOCPERF_Allocate_KMemory(size)
+ *
+ * @param    IN size     - size of the memory to allocate
+ *
+ * @returns  char*       - pointer to the allocated memory block
+ *
+ * @brief    Allocate and zero memory
+ *
+ * <I>Special Notes:</I>
+ *           Allocate memory in the GFP_ATOMIC pool.
+ *
+ *           Use this if memory is to be allocated within a context where
+ *           the allocator cannot block the allocation (e.g., by putting
+ *           the caller to sleep) as it tries to free up memory to
+ *           satisfy the request.  Examples include interrupt handlers,
+ *           process context code holding locks, etc.
+ */
+extern PVOID SOCPERF_Allocate_KMemory(size_t size);
+
+/*
+ * @fn PVOID SOCPERF_Free_Memory(location)
+ *
+ * @param    IN location  - size of the memory to allocate
+ *
+ * @returns  pointer to the allocated memory block
+ *
+ * @brief    Frees the memory block
+ *
+ * <I>Special Notes:</I>
+ *           Does not try to free memory if fed with a NULL pointer
+ *           Expected usage:
+ *               ptr = SOCPERF_Free_Memory(ptr);
+ */
+extern PVOID SOCPERF_Free_Memory(PVOID location);
+
+#endif
diff --git a/drivers/platform/x86/socperf/inc/ecb_iterators.h b/drivers/platform/x86/socperf/inc/ecb_iterators.h
new file mode 100644
index 000000000000..564248909e99
--- /dev/null
+++ b/drivers/platform/x86/socperf/inc/ecb_iterators.h
@@ -0,0 +1,130 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#ifndef _ECB_ITERATORS_H_
+#define _ECB_ITERATORS_H_
+
+#if defined(__cplusplus)
+extern "C" {
+#endif
+
+//
+// Loop macros to walk through the event control block
+// Use for access only in the kernel mode
+// To Do - Control access from kernel mode by a macro
+//
+
+#define FOR_EACH_PCI_DATA_REG_RAW(pecb, i, device_idx)                         \
+	{                                                                      \
+		U32(i) = 0;                                                    \
+		U32(cur_grp) = LWPMU_DEVICE_cur_group(device_uncore);          \
+		ECB(pecb) = LWPMU_DEVICE_PMU_register_data(                    \
+			device_uncore)[(cur_grp)];                             \
+		if ((pecb)) {                                                  \
+			for ((i) = ECB_operations_register_start(              \
+				     pecb, PMU_OPERATION_READ);                \
+			     (i) < ECB_operations_register_start(              \
+					   pecb, PMU_OPERATION_READ) +         \
+					   ECB_operations_register_len(        \
+						   pecb, PMU_OPERATION_READ);  \
+			     (i)++) {                                          \
+				if (ECB_entries_reg_offset((pecb), (i)) ==     \
+				    0) {                                       \
+					continue;                              \
+				}
+
+#define END_FOR_EACH_PCI_DATA_REG_RAW                                          \
+			}                                                      \
+		}                                                              \
+	}
+
+#define FOR_EACH_PCI_REG_RAW(pecb, i, device_idx)                              \
+	{                                                                      \
+		U32(i) = 0;                                                    \
+		U32(cur_grp) = LWPMU_DEVICE_cur_group(device_uncore);          \
+		ECB(pecb) = LWPMU_DEVICE_PMU_register_data(                    \
+			device_uncore)[(cur_grp)];                             \
+		if ((pecb)) {                                                  \
+			for ((i) = 0; (i) < ECB_num_entries(pecb); (i)++) {    \
+				if (ECB_entries_reg_offset((pecb), (i)) ==     \
+				    0) {                                       \
+					continue;                              \
+				}
+
+#define END_FOR_EACH_PCI_REG_RAW                                               \
+			}                                                      \
+		}                                                              \
+	}
+
+#define FOR_EACH_REG_ENTRY_UNC(pecb, device_idx, idx)                          \
+	{                                                                      \
+		U32(idx);                                                      \
+		U32(cur_grp) = LWPMU_DEVICE_cur_group(device_uncore);          \
+		ECB(pecb) = LWPMU_DEVICE_PMU_register_data(                    \
+			device_uncore)[(cur_grp)];                             \
+		if ((pecb)) {                                                  \
+			for ((idx) = 0; (idx) < ECB_num_entries(pecb);         \
+			     (idx)++) {                                        \
+				if (ECB_entries_bus_no((pecb), (idx)) == 0 &&  \
+				    ECB_entries_reg_id((pecb), (idx)) == 0) {  \
+					continue;                              \
+				}
+
+#define END_FOR_EACH_REG_ENTRY_UNC                                             \
+			}                                                      \
+		}                                                              \
+	}
+
+#if defined(__cplusplus)
+}
+#endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/inc/haswellunc_sa.h b/drivers/platform/x86/socperf/inc/haswellunc_sa.h
new file mode 100644
index 000000000000..a5ad8e477170
--- /dev/null
+++ b/drivers/platform/x86/socperf/inc/haswellunc_sa.h
@@ -0,0 +1,79 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2011-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2011-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#ifndef _HSWUNC_SA_H_INC_
+#define _HSWUNC_SA_H_INC_
+
+/*
+ * Local to this architecture: Haswell uncore SA unit
+ *
+ */
+#define HSWUNC_SA_DESKTOP_DID 0x000C04
+#define HSWUNC_SA_NEXT_ADDR_OFFSET 4
+#define HSWUNC_SA_BAR_ADDR_SHIFT 32
+#define HSWUNC_SA_BAR_ADDR_MASK 0x0007FFFFFF000LL
+#define HSWUNC_SA_MAX_PCI_DEVICES 16
+#define HSWUNC_SA_MAX_COUNT 0x00000000FFFFFFFFLL
+#define HSWUNC_SA_MAX_COUNTERS 8
+
+#define HSWUNC_SA_MCHBAR_MMIO_PAGE_SIZE (8 * 4096)
+#define HSWUNC_SA_PCIEXBAR_MMIO_PAGE_SIZE (57 * 4096)
+#define HSWUNC_SA_OTHER_BAR_MMIO_PAGE_SIZE 4096
+#define HSWUNC_SA_GDXCBAR_OFFSET_LO 0x5420
+#define HSWUNC_SA_GDXCBAR_OFFSET_HI 0x5424
+#define HSWUNC_SA_GDXCBAR_MASK 0x7FFFFFF000LL
+#define HSWUNC_SA_CHAP_SAMPLE_DATA 0x00020000
+#define HSWUNC_SA_CHAP_STOP 0x00040000
+#define HSWUNC_SA_CHAP_CTRL_REG_OFFSET 0x0
+
+extern DISPATCH_NODE socperf_hswunc_sa_dispatch;
+
+#endif
diff --git a/drivers/platform/x86/socperf/inc/npk_uncore.h b/drivers/platform/x86/socperf/inc/npk_uncore.h
new file mode 100644
index 000000000000..c70214136886
--- /dev/null
+++ b/drivers/platform/x86/socperf/inc/npk_uncore.h
@@ -0,0 +1,76 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#ifndef _NPK_UNCORE_H_INC_
+#define _NPK_UNCORE_H_INC_
+
+/*
+ * Local to this architecture: uncore SA unit
+ *
+ */
+#define SOC_NPK_UNCORE_NEXT_ADDR_OFFSET 4
+#define SOC_NPK_UNCORE_BAR_ADDR_SHIFT 32
+#define SOC_NPK_UNCORE_BAR_ADDR_MASK 0x00FFFFF00000LL
+#define SOC_NPK_UNCORE_MAX_PCI_DEVICES 16
+#define SOC_NPK_COUNTER_MAX_COUNTERS 16
+#define SOC_NPK_COUNTER_MAX_COUNT 0x00000000FFFFFFFFLL
+#define SOC_NPK_UNCORE_MCHBAR_ADDR_MASK 0x7FFFFF8000LL
+
+#define SOC_NPK_UNCORE_NPK_BAR_MMIO_PAGE_SIZE 0x100000
+#define SOC_NPK_UNCORE_MCHBAR_MMIO_PAGE_SIZE (8 * 4096)
+#define SOC_NPK_UNCORE_SAMPLE_DATA 0x00120000
+#define SOC_NPK_UNCORE_STOP 0x00040000
+#define SOC_NPK_UNCORE_CHAP_START 0x00110000
+#define SOC_NPK_UNCORE_CHAP_CTRL_REG_OFFSET 0x0
+
+extern DISPATCH_NODE npk_dispatch;
+
+#endif
diff --git a/drivers/platform/x86/socperf/inc/pci.h b/drivers/platform/x86/socperf/inc/pci.h
new file mode 100644
index 000000000000..3e67619815b5
--- /dev/null
+++ b/drivers/platform/x86/socperf/inc/pci.h
@@ -0,0 +1,103 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#ifndef _PCI_H_
+#define _PCI_H_
+
+#include "lwpmudrv_defines.h"
+
+/*
+ * PCI Config Address macros
+ */
+#define PCI_ENABLE 0x80000000
+
+#define PCI_ADDR_IO 0xCF8
+#define PCI_DATA_IO 0xCFC
+
+#define BIT0 0x1
+#define BIT1 0x2
+
+/*
+ * Macro for forming a PCI configuration address
+ */
+#define FORM_PCI_ADDR(bus, dev, fun, off)                                      \
+	(((PCI_ENABLE)) | ((bus & 0xFF) << 16) | ((dev & 0x1F) << 11) |        \
+	 ((fun & 0x07) << 8) | ((off & 0xFF) << 0))
+
+#define VENDOR_ID_MASK 0x0000FFFF
+#define DEVICE_ID_MASK 0xFFFF0000
+#define DEVICE_ID_BITSHIFT 16
+#define LOWER_4_BYTES_MASK 0x00000000FFFFFFFF
+#define MAX_BUSNO 256
+#define NEXT_ADDR_OFFSET 4
+#define NEXT_ADDR_SHIFT 32
+#define DRV_IS_PCI_VENDOR_ID_INTEL 0x8086
+
+#define CHECK_IF_GENUINE_INTEL_DEVICE(value, vendor_id, device_id)             \
+	{                                                                      \
+		vendor_id = value & VENDOR_ID_MASK;                            \
+		device_id = (value & DEVICE_ID_MASK) >> DEVICE_ID_BITSHIFT;    \
+		if (vendor_id != DRV_IS_PCI_VENDOR_ID_INTEL) {                 \
+			continue;                                              \
+		}                                                              \
+	}
+
+#if defined(DRV_IA32) || defined(DRV_EM64T)
+extern int SOCPERF_PCI_Read_From_Memory_Address(U32 addr, U32 *val);
+
+extern int SOCPERF_PCI_Write_To_Memory_Address(U32 addr, U32 val);
+
+extern int SOCPERF_PCI_Read_Ulong(U32 pci_address);
+
+extern void SOCPERF_PCI_Write_Ulong(U32 pci_address, U32 value);
+#endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/inc/soc_uncore.h b/drivers/platform/x86/socperf/inc/soc_uncore.h
new file mode 100644
index 000000000000..5cfe9695da79
--- /dev/null
+++ b/drivers/platform/x86/socperf/inc/soc_uncore.h
@@ -0,0 +1,85 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#ifndef _SOC_UNCORE_H_INC_
+#define _SOC_UNCORE_H_INC_
+
+/*
+ * Local to this architecture: SoC uncore unit
+ *
+ */
+#define SOC_UNCORE_DESKTOP_DID 0x000C04
+#define SOC_UNCORE_NEXT_ADDR_OFFSET 4
+#define SOC_UNCORE_BAR_ADDR_SHIFT 32
+#define SOC_UNCORE_BAR_ADDR_MASK 0x000FFFC00000LL
+#define SOC_UNCORE_MAX_PCI_DEVICES 16
+#define SOC_UNCORE_MCR_REG_OFFSET 0xD0
+#define SOC_UNCORE_MDR_REG_OFFSET 0xD4
+#define SOC_UNCORE_MCRX_REG_OFFSET 0xD8
+#define SOC_UNCORE_BYTE_ENABLES 0xF
+#define SOC_UNCORE_OP_CODE_SHIFT 24
+#define SOC_UNCORE_PORT_ID_SHIFT 16
+#define SOC_UNCORE_OFFSET_HI_MASK 0xFFFFFF00
+#define SOC_UNCORE_OFFSET_LO_MASK 0xFF
+#define SOC_COUNTER_PORT_ID 23
+#define SOC_COUNTER_WRITE_OP_CODE 1
+#define SOC_COUNTER_READ_OP_CODE 0
+#define UNCORE_MAX_COUNTERS 8
+#define UNCORE_MAX_COUNT 0x00000000FFFFFFFFLL
+
+#define SOC_UNCORE_OTHER_BAR_MMIO_PAGE_SIZE 4096
+#define SOC_UNCORE_SAMPLE_DATA 0x00020000
+#define SOC_UNCORE_STOP 0x00040000
+#define SOC_UNCORE_CTRL_REG_OFFSET 0x0
+
+extern DISPATCH_NODE soc_uncore_dispatch;
+
+#endif
diff --git a/drivers/platform/x86/socperf/inc/socperfdrv.h b/drivers/platform/x86/socperf/inc/socperfdrv.h
new file mode 100644
index 000000000000..f90f344edb66
--- /dev/null
+++ b/drivers/platform/x86/socperf/inc/socperfdrv.h
@@ -0,0 +1,191 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+#ifndef _SOCPERFDRV_H_
+#define _SOCPERFDRV_H_
+
+#include <linux/version.h>
+#include <linux/kernel.h>
+#include <linux/compat.h>
+#include <asm/uaccess.h>
+#include "lwpmudrv_defines.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "lwpmudrv_types.h"
+#include "lwpmudrv_version.h"
+
+/*
+ * Print macros for driver messages
+ */
+
+#if defined(MYDEBUG)
+#define SOCPERF_PRINT_DEBUG(fmt, args...)                                      \
+	{                                                                      \
+		printk(KERN_INFO SOCPERF_MSG_PREFIX " [DEBUG] " fmt, ##args);  \
+	}
+#else
+#define SOCPERF_PRINT_DEBUG(fmt, args...)                                      \
+	{                                                                      \
+		;                                                              \
+	}
+#endif
+
+#define SOCPERF_PRINT(fmt, args...)                                            \
+	{                                                                      \
+		printk(KERN_INFO SOCPERF_MSG_PREFIX " " fmt, ##args);          \
+	}
+
+#define SOCPERF_PRINT_WARNING(fmt, args...)                                    \
+	{                                                                      \
+		printk(KERN_ALERT SOCPERF_MSG_PREFIX " [Warning] " fmt,        \
+		       ##args);                                                \
+	}
+
+#define SOCPERF_PRINT_ERROR(fmt, args...)                                      \
+	{                                                                      \
+		printk(KERN_CRIT SOCPERF_MSG_PREFIX " [ERROR] " fmt, ##args);  \
+	}
+
+// Macro to return the thread group id
+#define GET_CURRENT_TGID() (current->tgid)
+
+#if defined(DRV_IA32) || defined(DRV_EM64T)
+#define OVERFLOW_ARGS U64 *, U64 *
+#elif defined(DRV_IA64)
+#define OVERFLOW_ARGS U64 *, U64 *, U64 *, U64 *, U64 *, U64 *
+#endif
+
+/*
+ *  Dispatch table for virtualized functions.
+ *  Used to enable common functionality for different
+ *  processor microarchitectures
+ */
+typedef struct DISPATCH_NODE_S DISPATCH_NODE;
+typedef DISPATCH_NODE *DISPATCH;
+
+struct DISPATCH_NODE_S {
+	VOID (*init)(PVOID);
+	VOID (*fini)(PVOID);
+	VOID (*write)(PVOID);
+	VOID (*freeze)(PVOID);
+	VOID (*restart)(PVOID);
+	VOID (*read_data)(PVOID);
+	VOID (*check_overflow)(VOID);
+	VOID (*swap_group)(DRV_BOOL);
+	VOID (*read_lbrs)(PVOID);
+	VOID (*clean_up)(PVOID);
+	VOID (*hw_errata)(VOID);
+	VOID (*read_power)(PVOID);
+	U64 (*check_overflow_errata)(ECB, U32, U64);
+	VOID (*read_counts)(PVOID, U32);
+	U64 (*check_overflow_gp_errata)(ECB, U64 *);
+	VOID (*read_ro)(PVOID, U32, U32);
+	U64 (*platform_info)(VOID);
+	VOID (*trigger_read)(VOID);
+	// Counter reads triggered/initiated by User mode timer
+	VOID (*read_current_data)(PVOID);
+	VOID (*create_mem)(U32, U64 *);
+	VOID (*check_status)(U64 *, U32 *);
+	VOID (*read_mem)(U64, U64 *, U32);
+	VOID (*stop_mem)(VOID);
+};
+
+extern DISPATCH dispatch;
+
+extern VOID **PMU_register_data;
+extern VOID **desc_data;
+extern U64 *prev_counter_data;
+extern U64 *cur_counter_data;
+
+/*!
+ * @struct LWPMU_DEVICE_NODE_S
+ * @brief  Struct to hold fields per device
+ *           PMU_register_data_unc - MSR info
+ *           dispatch_unc          - dispatch table
+ *           em_groups_counts_unc  - # groups
+ *           pcfg_unc              - config struct
+ */
+typedef struct LWPMU_DEVICE_NODE_S LWPMU_DEVICE_NODE;
+typedef LWPMU_DEVICE_NODE * LWPMU_DEVICE;
+
+struct LWPMU_DEVICE_NODE_S {
+	VOID **PMU_register_data_unc;
+	DISPATCH dispatch_unc;
+	S32 em_groups_count_unc;
+	VOID *pcfg_unc;
+	U64 **acc_per_thread;
+	U64 **prev_val_per_thread;
+	U64 counter_mask;
+	U64 num_events;
+	U32 num_units;
+	VOID *ec;
+	S32 cur_group;
+};
+
+#define LWPMU_DEVICE_PMU_register_data(dev) ((dev)->PMU_register_data_unc)
+#define LWPMU_DEVICE_dispatch(dev) ((dev)->dispatch_unc)
+#define LWPMU_DEVICE_em_groups_count(dev) ((dev)->em_groups_count_unc)
+#define LWPMU_DEVICE_pcfg(dev) ((dev)->pcfg_unc)
+#define LWPMU_DEVICE_acc_per_thread(dev) ((dev)->acc_per_thread)
+#define LWPMU_DEVICE_prev_val_per_thread(dev) ((dev)->prev_val_per_thread)
+#define LWPMU_DEVICE_counter_mask(dev) ((dev)->counter_mask)
+#define LWPMU_DEVICE_num_events(dev) ((dev)->num_events)
+#define LWPMU_DEVICE_num_units(dev) ((dev)->num_units)
+#define LWPMU_DEVICE_ec(dev) ((dev)->ec)
+#define LWPMU_DEVICE_cur_group(dev) ((dev)->cur_group)
+
+extern U32 num_devices;
+extern U32 cur_devices;
+extern LWPMU_DEVICE device_uncore;
+extern U64 *pmu_state;
+
+// Handy macro
+#define TSC_SKEW(this_cpu) (tsc_info[this_cpu] - tsc_info[0])
+
+#endif
diff --git a/drivers/platform/x86/socperf/inc/utility.h b/drivers/platform/x86/socperf/inc/utility.h
new file mode 100644
index 000000000000..6b3bc07fc0ed
--- /dev/null
+++ b/drivers/platform/x86/socperf/inc/utility.h
@@ -0,0 +1,61 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+#ifndef _UTILITY_H_
+#define _UTILITY_H_
+
+extern void SOCPERF_UTILITY_Read_TSC(U64 *pTsc);
+
+extern void SOCPERF_UTILITY_Read_Cpuid(U64 cpuid_function, U64 *rax_value,
+				       U64 *rbx_value, U64 *rcx_value,
+				       U64 *rdx_value);
+
+extern DISPATCH SOCPERF_UTILITY_Configure_CPU(U32);
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/error_reporting_utils.h b/drivers/platform/x86/socperf/include/error_reporting_utils.h
new file mode 100644
index 000000000000..4490303f7cf8
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/error_reporting_utils.h
@@ -0,0 +1,168 @@
+/***
+ * -------------------------------------------------------------------------
+ *               INTEL CORPORATION PROPRIETARY INFORMATION
+ *  This software is supplied under the terms of the accompanying license
+ *  agreement or nondisclosure agreement with Intel Corporation and may not
+ *  be copied or disclosed except in accordance with the terms of that
+ *  agreement.
+ *        Copyright(C) 2002-2019 Intel Corporation. All Rights Reserved.
+ * -------------------------------------------------------------------------
+***/
+
+#ifndef __ERROR_REPORTING_UTILS_H__
+#define __ERROR_REPORTING_UTILS_H__
+
+#define DRV_ASSERT_N_RET_VAL(ret_val)                                          \
+	do {                                                                   \
+		DRV_ASSERT((ret_val) == VT_SUCCESS);                           \
+		DRV_CHECK_N_RETURN_N_FAIL(ret_val);                            \
+	} while (0)
+
+
+#define DRV_ASSERT_N_CONTINUE(ret_val)                                         \
+	do {                                                                   \
+		if ((ret_val) != VT_SUCCESS) {                                 \
+			LOG_ERR1(VTSA_T("Operation failed with error code "),  \
+				 (ret_val));                                   \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_N_RETURN_N_FAIL(ret_val)                                     \
+	do {                                                                   \
+		if ((ret_val) != VT_SUCCESS) {                                 \
+			LOG_ERR1(VTSA_T("Operation failed with error code "),  \
+				 (ret_val));                                   \
+			return ret_val;                                        \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_N_RETURN_NO_RETVAL(ret_val)                                  \
+	do  {                                                                  \
+		if ((ret_val) != VT_SUCCESS) {                                 \
+			LOG_ERR1(VTSA_T("Operation failed with error code "),  \
+				 (ret_val));                                   \
+			return;                                                \
+		}                                                              \
+	} while (0)
+
+
+#define DRV_CHECK_PTR_N_RET_VAL(ptr)                                           \
+	do {                                                                   \
+		if ((ptr) == NULL) {                                           \
+			LOG_ERR0(VTSA_T("Encountered null pointer"));          \
+			return VT_SAM_ERROR;                                   \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_PTR_N_RET_NULL(ptr)                                          \
+	do {                                                                   \
+		if ((ptr) == NULL) {                                           \
+			LOG_ERR0(VTSA_T("Encountered null pointer"));          \
+			return NULL;                                           \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_PTR_N_LOG_NO_RETURN(ptr)                                     \
+	do {                                                                   \
+		if ((ptr) == NULL) {                                           \
+			LOG_ERR0(VTSA_T("Encountered null pointer"));          \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_N_LOG_NO_RETURN(ret_val)                                     \
+	do {                                                                   \
+		if ((ret_val) != VT_SUCCESS) {                                 \
+			LOG_ERR1(VTSA_T("Operation failed with error code "),  \
+				 (ret_val));                                   \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_N_RET_NEG_ONE(ret_val)                                       \
+	do {                                                                   \
+		if ((ret_val) == -1) {                                         \
+			LOG_ERR0(VTSA_T(                                       \
+				"Operation failed with error code = -1"));     \
+			return VT_SAM_ERROR;                                   \
+		}                                                              \
+	} while (0)
+
+#define DRV_REQUIRES_TRUE_COND_RET_N_FAIL(cond)                                \
+	do {                                                                   \
+		if (!(cond)) {                                                 \
+			LOG_ERR0(VTSA_T("Condition check failed"));            \
+			return VT_SAM_ERROR;                                   \
+		}                                                              \
+	} while (0)
+
+#define DRV_REQUIRES_TRUE_COND_RET_ASSIGNED_VAL(cond, ret_val)                 \
+	do {                                                                   \
+		if (!(cond)) {                                                 \
+			LOG_ERR0(VTSA_T("Condition check failed"));            \
+			return ret_val;                                        \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_N_ERR_LOG_ERR_STRNG_N_RET(rise_err)                          \
+	do {                                                                   \
+		if (rise_err != VT_SUCCESS) {                                          \
+			PVOID rise_ptr = NULL;                                         \
+			const VTSA_CHAR *error_str = NULL;                             \
+			RISE_open(&rise_ptr);                                          \
+			RISE_translate_err_code(rise_ptr, rise_err, &error_str);       \
+			LogItW(LOG_LEVEL_ERROR | LOG_AREA_GENERAL,                     \
+			       L"Operation failed with error [ %d ] = %s\n", rise_err, \
+			       error_str);                                             \
+			RISE_close(rise_ptr);                                          \
+			return rise_err;                                               \
+		}                                                                   \
+	} while (0)
+
+#define DRV_CHECK_PTR_N_CLEANUP(ptr, gotolabel, ret_val)                       \
+	do {                                                                   \
+		if ((ptr) == NULL) {                                           \
+			LOG_ERR0(VTSA_T("Encountered null pointer"));          \
+			ret_val = VT_SAM_ERROR;                                \
+			goto gotolabel;                                        \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_ON_FAIL_CLEANUP_N_RETURN(ret_val, gotolabel)                 \
+	do {                                                                   \
+		if ((ret_val) != VT_SUCCESS) {                                 \
+			DRV_CHECK_N_LOG_NO_RETURN(ret_val);                    \
+			goto gotolabel;                                        \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_N_CLEANUP_N_RETURN_RET_NEG_ONE(ret_val, gotolabel)           \
+	do {                                                                   \
+		if ((ret_val) == -1) {                                         \
+			DRV_CHECK_N_LOG_NO_RETURN(ret_val);                    \
+			goto gotolabel;                                        \
+		}                                                              \
+	} while (0)
+
+#define DRV_CHECK_PTR_ON_NULL_CLEANUP_N_RETURN(ptr, gotolabel)                 \
+	do {                                                                   \
+		if ((ptr) == NULL) {                                           \
+			DRV_CHECK_PTR_N_LOG_NO_RETURN(ptr);                    \
+			goto gotolabel;                                        \
+		}                                                              \
+	} while (0)
+
+#define FREE_N_SET_NULL(ptr)                                                   \
+	do {                                                                   \
+		if (ptr != NULL) {                                             \
+			free(ptr);                                             \
+			ptr = NULL;                                            \
+		}                                                              \
+	} while (0)
+
+#define DELETE_N_SET_NULL(ptr)                                                 \
+	do {                                                                   \
+		delete ptr;                                                    \
+		ptr = NULL;                                                    \
+	} while (0)
+
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/lwpmudrv_chipset.h b/drivers/platform/x86/socperf/include/lwpmudrv_chipset.h
new file mode 100644
index 000000000000..90cef28f08c2
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/lwpmudrv_chipset.h
@@ -0,0 +1,285 @@
+/***
+ * -------------------------------------------------------------------------
+ *               INTEL CORPORATION PROPRIETARY INFORMATION
+ *  This software is supplied under the terms of the accompanying license
+ *  agreement or nondisclosure agreement with Intel Corporation and may not
+ *  be copied or disclosed except in accordance with the terms of that
+ *  agreement.
+ *        Copyright(C) 2007-2019 Intel Corporation.  All Rights Reserved.
+ * -------------------------------------------------------------------------
+***/
+
+#ifndef _LWPMUDRV_CHIPSET_UTILS_H_
+#define _LWPMUDRV_CHIPSET_UTILS_H_
+
+#if defined(__cplusplus)
+extern "C" {
+#endif
+
+#define MAX_CHIPSET_EVENT_NAME 64
+#define MAX_CHIPSET_COUNTERS  5
+		// TODO: this covers 1 fixed counter                           \
+		// plus 4 general counters on GMCH;                            \
+		// for other chipset devices, this                             \
+		// can vary from 8 to 32; might consider                       \
+		// making this per-chipset-type since                          \
+		// event-multiplexing is currently not                         \
+		// supported for chipset collections
+
+#if defined(_NTDDK_)
+#define CHIPSET_PHYS_ADDRESS PHYSICAL_ADDRESS
+#else
+#define CHIPSET_PHYS_ADDRESS U64
+#endif
+
+// possible values for whether chipset data is valid or not
+enum { DATA_IS_VALID, DATA_IS_INVALID, DATA_OUT_OF_RANGE };
+
+typedef struct CHIPSET_PCI_ARG_NODE_S CHIPSET_PCI_ARG_NODE;
+typedef CHIPSET_PCI_ARG_NODE * CHIPSET_PCI_ARG;
+
+struct CHIPSET_PCI_ARG_NODE_S {
+	U32 address;
+	U32 value;
+};
+
+#define CHIPSET_PCI_ARG_address(chipset_pci) ((chipset_pci)->address)
+#define CHIPSET_PCI_ARG_value(chipset_pci) ((chipset_pci)->value)
+
+typedef struct CHIPSET_PCI_SEARCH_ADDR_NODE_S CHIPSET_PCI_SEARCH_ADDR_NODE;
+typedef CHIPSET_PCI_SEARCH_ADDR_NODE * CHIPSET_PCI_SEARCH_ADDR;
+
+struct CHIPSET_PCI_SEARCH_ADDR_NODE_S {
+	U32 start;
+	U32 stop;
+	U32 increment;
+	U32 addr;
+};
+
+#define CHIPSET_PCI_SEARCH_ADDR_start(pci_search_addr) ((pci_search_addr)->start)
+#define CHIPSET_PCI_SEARCH_ADDR_stop(pci_search_addr) ((pci_search_addr)->stop)
+#define CHIPSET_PCI_SEARCH_ADDR_increment(pci_search_addr)                     \
+	((pci_search_addr)->increment)
+#define CHIPSET_PCI_SEARCH_ADDR_address(pci_search_addr) ((pci_search_addr)->addr)
+
+typedef struct CHIPSET_PCI_CONFIG_NODE_S CHIPSET_PCI_CONFIG_NODE;
+typedef CHIPSET_PCI_CONFIG_NODE * CHIPSET_PCI_CONFIG;
+
+struct CHIPSET_PCI_CONFIG_NODE_S {
+	U32 bus;
+	U32 device;
+	U32 function;
+	U32 offset;
+	U32 value;
+};
+
+#define CHIPSET_PCI_CONFIG_bus(pci_config) ((pci_config)->bus)
+#define CHIPSET_PCI_CONFIG_device(pci_config) ((pci_config)->device)
+#define CHIPSET_PCI_CONFIG_function(pci_config) ((pci_config)->function)
+#define CHIPSET_PCI_CONFIG_offset(pci_config) ((pci_config)->offset)
+#define CHIPSET_PCI_CONFIG_value(pci_config) ((pci_config)->value)
+
+typedef struct CHIPSET_MARKER_NODE_S CHIPSET_MARKER_NODE;
+typedef CHIPSET_MARKER_NODE * CHIPSET_MARKER;
+
+struct CHIPSET_MARKER_NODE_S {
+	U32 processor_number;
+	U32 rsvd;
+	U64 tsc;
+};
+
+#define CHIPSET_MARKER_processor_number(chipset_marker)                        \
+	((pci_config)->processor_number)
+#define CHIPSET_MARKER_tsc(chipset_marker) ((pci_config)->tsc)
+
+typedef struct CHAP_INTERFACE_NODE_S CHAP_INTERFACE_NODE;
+typedef CHAP_INTERFACE_NODE * CHAP_INTERFACE;
+
+// CHAP chipset registers
+// The offsets for registers are command-0x00, event-0x04, status-0x08, data-0x0C
+struct CHAP_INTERFACE_NODE_S {
+	U32 command_register;
+	U32 event_register;
+	U32 status_register;
+	U32 data_register;
+};
+
+#define CHAP_INTERFACE_command_register(chap) ((chap)->command_register)
+#define CHAP_INTERFACE_event_register(chap) ((chap)->event_register)
+#define CHAP_INTERFACE_status_register(chap) ((chap)->status_register)
+#define CHAP_INTERFACE_data_register(chap) ((chap)->data_register)
+
+/**************************************************************************
+ * GMCH Registers and Offsets
+ **************************************************************************
+ */
+
+// Counter registers - each counter has 4 registers
+#define GMCH_MSG_CTRL_REG 0xD0 // message control register (MCR) 0xD0-0xD3
+#define GMCH_MSG_DATA_REG 0xD4 // message data register (MDR) 0xD4-0xD7
+
+// Counter register offsets
+#define GMCH_PMON_CAPABILITIES                                                 \
+	0x0005F0F0 // when read, bit 0 enabled means GMCH counters are available
+#define GMCH_PMON_GLOBAL_CTRL                                                  \
+	0x0005F1F0 // simultaneously enables or disables fixed and general counters
+
+// Fixed counters (32-bit)
+#define GMCH_PMON_FIXED_CTR_CTRL                                               \
+	0x0005F4F0 // enables and filters the fixed counters
+#define GMCH_PMON_FIXED_CTR0                                                   \
+	0x0005E8F0 // 32-bit fixed counter for GMCH_CORE_CLKS event
+#define GMCH_PMON_FIXED_CTR_OVF_VAL                                            \
+	0xFFFFFFFFLL // overflow value for GMCH fixed counters
+
+// General counters (38-bit)
+// NOTE: lower order bits on GP counters must be read before the higher bits!
+#define GMCH_PMON_GP_CTR0_L 0x0005F8F0 // GMCH GP counter 0, low bits
+#define GMCH_PMON_GP_CTR0_H 0x0005FCF0 // GMCH GP counter 0, high bits
+#define GMCH_PMON_GP_CTR1_L 0x0005F9F0
+#define GMCH_PMON_GP_CTR1_H 0x0005FDF0
+#define GMCH_PMON_GP_CTR2_L 0x0005FAF0
+#define GMCH_PMON_GP_CTR2_H 0x0005FEF0
+#define GMCH_PMON_GP_CTR3_L 0x0005FBF0
+#define GMCH_PMON_GP_CTR3_H 0x0005FFF0
+#define GMCH_PMON_GP_CTR_OVF_VAL                                               \
+	0x3FFFFFFFFFLL // overflow value for GMCH general counters
+
+/* other counter register offsets ...
+#define GMCH_PMON_GLOBAL_STATUS         0x0005F2F0  // bit 16 indicates overflow on fixed counter 0; bits 0-3 indicate overflows on GP counters 0-3
+#define GMCH_PMON_GLOBAL_OVF_CTRL       0x0005F3F0  // on CDV, it is write-only psuedo-register that always returns 0 when read
+#define GMCH_PMON_PERFEVTSEL0           0x0005E0F0  // this is used for selecting which event in GP counter 0 to count
+#define GMCH_PMON_PERFEVTSEL1           0x0005E1F0  // this is used for selecting which event in GP counter 1 to count
+#define GMCH_PMON_PERFEVTSEL2           0x0005E2F0  // this is used for selecting which event in GP counter 2 to count
+#define GMCH_PMON_PERFEVTSEL3           0x0005E3F0  // this is used for selecting which event in GP counter 3 to count
+#define GMCH_PERF_ADDR_LIMIT_H          0x0001E8F0  // used for qualifying upper address limit for DRAM_PAGE_STATUS event
+#define GMCH_PERF_ADDR_LIMIT_L          0x0001E9F0  // used for qualifying lower address limit for DRAM_PAGE_STATUS event
+#define GMCH_PERF_BANK_SEL              0x0001EAF0  // used for addtional qualification of DRAM_PAGE_STATUS event
+*/
+
+// Register offsets for LNC
+#define LNC_GMCH_REGISTER_READ 0xD0000000
+#define LNC_GMCH_REGISTER_WRITE 0xE0000000
+
+// Register offsets for SLT
+#define SLT_GMCH_REGISTER_READ 0x10000000
+#define SLT_GMCH_REGISTER_WRITE 0x11000000
+
+// Register offsets for CDV
+#define CDV_GMCH_REGISTER_READ 0x10000000
+#define CDV_GMCH_REGISTER_WRITE 0x11000000
+
+// possible values for whether chipset data is valid or not
+/*enum {
+	DATA_IS_VALID,
+	DATA_IS_INVALID,
+	DATA_OUT_OF_RANGE
+};
+*/
+typedef struct CHIPSET_EVENT_NODE_S CHIPSET_EVENT_NODE;
+typedef CHIPSET_EVENT_NODE * CHIPSET_EVENT;
+
+//chipset event
+struct CHIPSET_EVENT_NODE_S {
+	U32 event_id;
+	U32 group_id;
+	char name[MAX_CHIPSET_EVENT_NAME];
+	U32 pm;
+	U32 counter;
+};
+
+#define CHIPSET_EVENT_event_id(chipset_event) ((chipset_event)->event_id)
+#define CHIPSET_EVENT_group_id(chipset_event) ((chipset_event)->group_id)
+#define CHIPSET_EVENT_name(chipset_event) ((chipset_event)->name)
+#define CHIPSET_EVENT_pm(chipset_event) ((chipset_event)->pm)
+#define CHIPSET_EVENT_counter(chipset_event) ((chipset_event)->counter)
+
+typedef struct CHIPSET_SEGMENT_NODE_S CHIPSET_SEGMENT_NODE;
+typedef CHIPSET_SEGMENT_NODE * CHIPSET_SEGMENT;
+
+//chipset segment data
+struct CHIPSET_SEGMENT_NODE_S {
+	CHIPSET_PHYS_ADDRESS physical_address;
+	U64 virtual_address;
+	U16 size;
+	U16 number_of_counters;
+	U16 total_events;
+	U16 start_register; // (see driver for details)
+	U32 read_register; // read register offset (model dependent)
+	U32 write_register; // write register offset (model dependent)
+	CHIPSET_EVENT_NODE events[MAX_CHIPSET_COUNTERS];
+};
+
+#define CHIPSET_SEGMENT_physical_address(chipset_segment)                      \
+	((chipset_segment)->physical_address)
+#define CHIPSET_SEGMENT_virtual_address(chipset_segment)                       \
+	((chipset_segment)->virtual_address)
+#define CHIPSET_SEGMENT_size(chipset_segment) ((chipset_segment)->size)
+#define CHIPSET_SEGMENT_num_counters(chipset_segment)                          \
+	((chipset_segment)->number_of_counters)
+#define CHIPSET_SEGMENT_total_events(chipset_segment)                          \
+	((chipset_segment)->total_events)
+#define CHIPSET_SEGMENT_start_register(chipset_segment)                        \
+	((chipset_segment)->start_register)
+#define CHIPSET_SEGMENT_read_register(chipset_segment)                         \
+	((chipset_segment)->read_register)
+#define CHIPSET_SEGMENT_write_register(chipset_segment)                        \
+	((chipset_segment)->write_register)
+#define CHIPSET_SEGMENT_events(chipset_segment) ((chipset_segment)->events)
+
+typedef struct CHIPSET_CONFIG_NODE_S CHIPSET_CONFIG_NODE;
+typedef CHIPSET_CONFIG_NODE * CHIPSET_CONFIG;
+
+//chipset struct used for communication between user mode and kernel
+struct CHIPSET_CONFIG_NODE_S {
+	U32 length; // length of this entire area
+	U32 major_version;
+	U32 minor_version;
+	U32 rsvd;
+	U64 cpu_counter_mask;
+	struct {
+		U64 processor : 1; // Processor PMU
+		U64 mch_chipset : 1; // MCH Chipset
+		U64 ich_chipset : 1; // ICH Chipset
+		U64 motherboard_time_flag : 1; // Motherboard_Time requested.
+		U64 host_processor_run : 1; // Each processor should manage the MCH counts they see.
+			// Turn off for Gen 4 (NOA) runs.
+		U64 mmio_noa_registers : 1; // NOA
+		U64 bnb_chipset : 1; // BNB Chipset
+		U64 gmch_chipset : 1; // GMCH Chipset
+		U64 rsvd : 56;
+	} config_flags;
+	CHIPSET_SEGMENT_NODE mch;
+	CHIPSET_SEGMENT_NODE ich;
+	CHIPSET_SEGMENT_NODE mmio;
+	CHIPSET_SEGMENT_NODE bnb;
+	CHIPSET_SEGMENT_NODE gmch;
+};
+
+#define CHIPSET_CONFIG_length(chipset) ((chipset)->length)
+#define CHIPSET_CONFIG_major_version(chipset) ((chipset)->major_version)
+#define CHIPSET_CONFIG_minor_version(chipset) ((chipset)->minor_version)
+#define CHIPSET_CONFIG_cpu_counter_mask(chipset) ((chipset)->cpu_counter_mask)
+#define CHIPSET_CONFIG_processor(chipset) ((chipset)->config_flags.processor)
+#define CHIPSET_CONFIG_mch_chipset(chipset) ((chipset)->config_flags.mch_chipset)
+#define CHIPSET_CONFIG_ich_chipset(chipset) ((chipset)->config_flags.ich_chipset)
+#define CHIPSET_CONFIG_motherboard_time(chipset)                               \
+	((chipset)->config_flags.motherboard_time_flag)
+#define CHIPSET_CONFIG_host_proc_run(chipset)                                  \
+	((chipset)->config_flags.host_processor_run)
+#define CHIPSET_CONFIG_noa_chipset(chipset)                                    \
+	((chipset)->config_flags.mmio_noa_registers)
+#define CHIPSET_CONFIG_bnb_chipset(chipset) ((chipset)->config_flags.bnb_chipset)
+#define CHIPSET_CONFIG_gmch_chipset(chipset)                                   \
+	((chipset)->config_flags.gmch_chipset)
+#define CHIPSET_CONFIG_mch(chipset) ((chipset)->mch)
+#define CHIPSET_CONFIG_ich(chipset) ((chipset)->ich)
+#define CHIPSET_CONFIG_noa(chipset) ((chipset)->mmio)
+#define CHIPSET_CONFIG_bnb(chipset) ((chipset)->bnb)
+#define CHIPSET_CONFIG_gmch(chipset) ((chipset)->gmch)
+
+#if defined(__cplusplus)
+}
+#endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/lwpmudrv_defines.h b/drivers/platform/x86/socperf/include/lwpmudrv_defines.h
new file mode 100644
index 000000000000..322c33b125c4
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/lwpmudrv_defines.h
@@ -0,0 +1,502 @@
+/***
+ * -------------------------------------------------------------------------
+ *               INTEL CORPORATION PROPRIETARY INFORMATION
+ *  This software is supplied under the terms of the accompanying license
+ *  agreement or nondisclosure agreement with Intel Corporation and may not
+ *  be copied or disclosed except in accordance with the terms of that
+ *  agreement.
+ *        Copyright(C) 2007-2019 Intel Corporation.  All Rights Reserved.
+ * -------------------------------------------------------------------------
+***/
+
+#ifndef _LWPMUDRV_DEFINES_H_
+#define _LWPMUDRV_DEFINES_H_
+
+#if defined(__cplusplus)
+extern "C" {
+#endif
+//
+// Start off with none of the OS'es are defined
+//
+#undef DRV_OS_WINDOWS
+#undef DRV_OS_LINUX
+#undef DRV_OS_SOLARIS
+#undef DRV_OS_MAC
+#undef DRV_OS_ANDROID
+#undef DRV_OS_UNIX
+
+//
+// Make sure none of the architectures is defined here
+//
+#undef DRV_IA32
+#undef DRV_EM64T
+
+//
+// Make sure one (and only one) of the OS'es gets defined here
+//
+// Unfortunately entirex defines _WIN32 so we need to check for linux
+// first.  The definition of these flags is one and only one
+// _OS_xxx is allowed to be defined.
+//
+#if defined(__ANDROID__)
+#define DRV_OS_ANDROID
+#define DRV_OS_UNIX
+#elif defined(__linux__)
+#define DRV_OS_LINUX
+#define DRV_OS_UNIX
+#elif defined(sun)
+#define DRV_OS_SOLARIS
+#define DRV_OS_UNIX
+#elif defined(_WIN32)
+#define DRV_OS_WINDOWS
+#elif defined(__APPLE__)
+#define DRV_OS_MAC
+#define DRV_OS_UNIX
+#elif defined(__FreeBSD__)
+#define DRV_OS_FREEBSD
+#define DRV_OS_UNIX
+#else
+#error "Compiling for an unknown OS"
+#endif
+
+//
+// Make sure one (and only one) architecture is defined here
+// as well as one (and only one) pointer__ size
+//
+#if defined(_M_IX86) || defined(__i386__)
+#define DRV_IA32
+#elif defined(_M_AMD64) || defined(__x86_64__)
+#define DRV_EM64T
+#else
+#error "Unknown architecture for compilation"
+#endif
+
+//
+// Add a well defined definition of compiling for release (free) vs.
+// debug (checked). Once again, don't assume these are the only two values,
+// always have an else clause in case we want to expand this.
+//
+#if defined(DRV_OS_UNIX)
+#define WINAPI
+#endif
+
+/*
+ *  Add OS neutral defines for file processing.  This is needed in both
+ *  the user code and the kernel code for cleanliness
+ */
+#undef DRV_FILE_DESC
+#undef DRV_INVALID_FILE_DESC_VALUE
+#define DRV_ASSERT assert
+
+#if defined(DRV_OS_WINDOWS)
+
+#define DRV_FILE_DESC HANDLE
+#define DRV_INVALID_FILE_DESC_VALUE INVALID_HANDLE_VALUE
+
+#elif defined(DRV_OS_LINUX) || defined(DRV_OS_SOLARIS) ||                      \
+	defined(DRV_OS_ANDROID)
+
+#define DRV_IOCTL_FILE_DESC SIOP
+#define DRV_FILE_DESC SIOP
+#define DRV_INVALID_FILE_DESC_VALUE -1
+
+#elif defined(DRV_OS_FREEBSD)
+
+#define DRV_IOCTL_FILE_DESC S64
+#define DRV_FILE_DESC S64
+#define DRV_INVALID_FILE_DESC_VALUE -1
+
+#elif defined(DRV_OS_MAC)
+#if defined __LP64__
+#define DRV_IOCTL_FILE_DESC S64
+#define DRV_FILE_DESC S64
+#define DRV_INVALID_FILE_DESC_VALUE (S64)(-1)
+#else
+#define DRV_IOCTL_FILE_DESC S32
+#define DRV_FILE_DESC S32
+#define DRV_INVALID_FILE_DESC_VALUE (S32)(-1)
+#endif
+
+#else
+
+#error "Compiling for an unknown OS"
+
+#endif
+
+#define OUT
+#define IN
+#define INOUT
+
+//
+// VERIFY_SIZEOF let's you insert a compile-time check that the size of a data
+// type (e.g. a struct) is what you think it should be.  Usually it is
+// important to know what the actual size of your struct is, and to make sure
+// it is the same across all platforms.  So this will prevent the code from
+// compiling if something happens that you didn't expect, whether it's because
+// you counted wring, or more often because the compiler inserted padding that
+// you don't want.
+//
+// NOTE: 'elem' and 'size' must both be identifier safe, e.g. matching the
+// regular expression /^[0-9a-zA-Z_]$/.
+//
+// Example:
+//   typedef struct { void *ptr; int data; } mytype;
+//   VERIFY_SIZEOF(mytype, 8);
+//                         ^-- this is correct on 32-bit platforms, but fails
+//                             on 64-bit platforms, indicating a possible
+//                             portability issue.
+//
+#define VERIFY_SIZEOF(type, size)                                              \
+	{ enum { sizeof_##type##_eq_##size = 1 / (int)(sizeof(type) == size) } }
+
+#if defined(DRV_OS_WINDOWS)
+#define DRV_DLLIMPORT __declspec(dllimport)
+#define DRV_DLLEXPORT __declspec(dllexport)
+#endif
+#if defined(DRV_OS_UNIX)
+#define DRV_DLLIMPORT
+#define DRV_DLLEXPORT
+#endif
+
+#if defined(DRV_OS_WINDOWS)
+#define FSI64RAW "I64"
+#define DRV_PATH_SEPARATOR "\\"
+#define L_DRV_PATH_SEPARATOR L"\\"
+#endif
+
+#if defined(DRV_OS_UNIX)
+#define FSI64RAW "ll"
+#define DRV_PATH_SEPARATOR "/"
+#define L_DRV_PATH_SEPARATOR L"/"
+#endif
+
+#define FSS64 "%" FSI64RAW "d"
+#define FSU64 "%" FSI64RAW "u"
+#define FSX64 "%" FSI64RAW "x"
+
+#if defined(DRV_OS_WINDOWS)
+#define DRV_RTLD_NOW 0
+#endif
+#if defined(DRV_OS_UNIX)
+#if defined(DRV_OS_FREEBSD)
+#define DRV_RTLD_NOW 0
+#else
+#define DRV_RTLD_NOW RTLD_NOW
+#endif
+#endif
+
+// #define DRV_STRLEN (U32)strlen
+// #define DRV_WCSLEN (U32)wcslen
+#define DRV_STRCSPN strcspn
+#define DRV_STRCHR strchr
+#define DRV_STRRCHR strrchr
+#define DRV_WCSRCHR wcsrchr
+
+// #if defined(DRV_OS_WINDOWS)
+// #define DRV_STCHARLEN DRV_WCSLEN
+// #else
+// #define DRV_STCHARLEN DRV_STRLEN
+// #endif
+
+#if defined(DRV_OS_WINDOWS)
+#define DRV_STRCPY strcpy_s
+#define DRV_STRNCPY strncpy_s
+#define DRV_STRICMP _stricmp
+#define DRV_STRNCMP strncmp
+#define DRV_STRNICMP _strnicmp
+#define DRV_STRDUP _strdup
+#define DRV_WCSDUP _wcsdup
+#define DRV_STRCMP strcmp
+#define DRV_WCSCMP wcscmp
+#define DRV_SNPRINTF _snprintf_s
+#define DRV_SNWPRINTF _snwprintf_s
+#define DRV_VSNPRINTF _vsnprintf_s
+#define DRV_SSCANF sscanf_s
+#define DRV_STRCAT strcat_s
+#define DRV_STRNCAT strncat_s
+#define DRV_MEMCPY memcpy_s
+#define DRV_WMEMCPY wmemcpy_s
+#define DRV_STRTOK strtok_s
+#define DRV_STRTOUL strtoul
+#define DRV_STRTOULL _strtoui64
+#define DRV_STRTOQ _strtoui64
+#define DRV_FOPEN(fp, name, mode) fopen_s(&(fp), (name), (mode))
+#define DRV_WFOPEN(fp, name, mode) _wfopen_s(&(fp), (name), (mode))
+#define DRV_FCLOSE(fp)                                                         \
+	do {                                                                   \
+		if ((fp) != NULL) {                                            \
+			fclose((fp));                                          \
+		}                                                              \
+	} while (0)
+#define DRV_WCSCPY wcscpy_s
+#define DRV_WCSNCPY wcsncpy_s
+#define DRV_WCSCAT wcscat_s
+#define DRV_WCSNCAT wcsncat_s
+#define DRV_WCSTOK wcstok_s
+#define DRV_WCSSTR wcsstr
+#define DRV_STRERROR strerror_s
+#define DRV_SPRINTF sprintf_s
+#define DRV_VSPRINTF vsprintf_s
+#define DRV_VSWPRINTF vswprintf_s
+#define DRV_GETENV_S getenv_s
+#define DRV_WGETENV_S wgetenv_s
+#define DRV_PUTENV(name) _putenv(name)
+#define DRV_USTRCMP(X, Y) DRV_WCSCMP(X, Y)
+#define DRV_USTRDUP(X) DRV_WCSDUP(X)
+#define DRV_ACCESS(X) _access_s(X, 4)
+#define DRV_STRSTR strstr
+
+#define DRV_STCHAR_COPY DRV_WCSNCPY
+
+#define DRV_GETENV(buf, buf_size, name) _dupenv_s(&(buf), &(buf_size), (name))
+#define DRV_WGETENV(buf, buf_size, name) _wdupenv_s(&(buf), &(buf_size), (name))
+#define DRV_SCLOSE(fp) _close(fp)
+#define DRV_WRITE(fp, buf, buf_size) _write(fp, buf, buf_size);
+#define DRV_SOPEN_S(fp, name, oflag, shflag, pmode)                            \
+	_sopen_s((fp), (name), (oflag), (shflag), (pmode))
+#endif
+
+#if defined(DRV_OS_UNIX)
+/*
+   Note: Many of the following macros have a "size" as the second argument.  Generally
+		 speaking, this is for compatibility with the _s versions available on Windows.
+		 On Linux/Solaris/Mac, it is ignored.  On Windows, it is the size of the destination
+		 buffer and is used wrt memory checking features available in the C runtime in debug
+		 mode.  Do not confuse it with the number of bytes to be copied, or such.
+
+		 On Windows, this size should correspond to the number of allocated characters
+		 (char or wchar_t) pointed to by the first argument.  See MSDN for more details.
+*/
+#define DRV_STRICMP strcasecmp
+#define DRV_STRDUP strdup
+#define DRV_STRNDUP strndup
+#define DRV_STRCMP strcmp
+#define DRV_STRNCMP strncmp
+#define DRV_STRSTR strstr
+#define DRV_SNPRINTF(buf, buf_size, length, args...)                           \
+	snprintf((buf), (length), ##args)
+#define DRV_SNWPRINTF(buf, buf_size, length, args...)                          \
+	snwprintf((buf), (length), ##args)
+#define DRV_VSNPRINTF(buf, buf_size, length, args...)                          \
+	vsnprintf((buf), (length), ##args)
+#define DRV_SSCANF sscanf
+#define DRV_STRCPY(dst, dst_size, src) strcpy((dst), (src))
+#define DRV_STRNCPY(dst, dst_size, src, n) strncpy((dst), (src), (n))
+#define DRV_STRCAT(dst, dst_size, src) strcat((dst), (src))
+#define DRV_STRNCAT(dst, dst_size, src, n) strncat((dst), (src), (n))
+#define DRV_MEMCPY(dst, dst_size, src, n) memcpy((dst), (src), (n))
+#define DRV_STRTOK(tok, delim, context) strtok((tok), (delim))
+#define DRV_STRTOUL strtoul
+#define DRV_STRTOULL strtoull
+#define DRV_STRTOL strtol
+#define DRV_FOPEN(fp, name, mode)  { (fp) = fopen((name), (mode)) }
+#define DRV_FCLOSE(fp)                                                         \
+	do {                                                                   \
+		if ((fp) != NULL) {                                            \
+			fclose((fp));                                          \
+		}                                                              \
+	} while (0)
+#define DRV_WCSCPY(dst, dst_size, src) wcscpy((dst), (const wchar_t *)(src))
+#define DRV_WCSNCPY(dst, dst_size, src, count)                                 \
+	wcsncpy((dst), (const wchar_t *)(src), (count))
+#define DRV_WCSCAT(dst, dst_size, src) wcscat((dst), (const wchar_t *)(src))
+#define DRV_WCSTOK(tok, delim, context)                                        \
+	wcstok((tok), (const wchar_t *)(delim), (context))
+#define DRV_STRERROR strerror
+#define DRV_SPRINTF(dst, dst_size, args...) sprintf((dst), ##args)
+#define DRV_VSPRINTF(dst, dst_size, length, args...)                           \
+	vsprintf((dst), (length), ##args)
+#define DRV_VSWPRINTF(dst, dst_size, length, args...)                          \
+	vswprintf((dst), (length), ##args)
+#define DRV_GETENV_S(dst, dst_size) getenv(dst)
+#define DRV_WGETENV_S(dst, dst_size) wgetenv(dst)
+#define DRV_PUTENV(name) putenv(name)
+#define DRV_GETENV(buf, buf_size, name) ((buf) = getenv((name)))
+#define DRV_USTRCMP(X, Y) DRV_STRCMP(X, Y)
+#define DRV_USTRDUP(X) DRV_STRDUP(X)
+#define DRV_ACCESS(X) access(X, X_OK)
+
+#define DRV_STCHAR_COPY DRV_STRNCPY
+#endif
+
+#if defined(DRV_OS_WINDOWS)
+#define DRV_STRTOK_R(tok, delim, context) strtok_s((tok), (delim), (context))
+#else
+#define DRV_STRTOK_R(tok, delim, context) strtok_r((tok), (delim), (context))
+#endif
+
+#if defined(DRV_OS_LINUX) || defined(DRV_OS_MAC) || defined(DRV_OS_FREEBSD)
+#define DRV_STRTOQ strtoq
+#endif
+
+#if defined(DRV_OS_ANDROID)
+#define DRV_STRTOQ strtol
+#endif
+
+#if defined(DRV_OS_SOLARIS)
+#define DRV_STRTOQ strtoll
+#endif
+
+#if defined(DRV_OS_LINUX) || defined(DRV_OS_FREEBSD) || defined(DRV_OS_MAC)
+#define DRV_WCSDUP wcsdup
+#endif
+
+#if defined(DRV_OS_SOLARIS)
+#define DRV_WCSDUP solaris_wcsdup
+#endif
+
+#if defined(DRV_OS_ANDROID)
+#define DRV_WCSDUP android_wcsdup
+#endif
+
+/*
+ * Windows uses wchar_t and linux uses char for strings.
+ * Need an extra level of abstraction to standardize it.
+ */
+#if defined(DRV_OS_WINDOWS)
+#define DRV_STDUP DRV_WCSDUP
+#define DRV_FORMAT_STRING(x) L##x
+#define DRV_PRINT_STRING(stream, format, ...)                                  \
+	fwprintf((stream), (format), __VA_ARGS__)
+#else
+#define DRV_STDUP DRV_STRDUP
+#define DRV_FORMAT_STRING(x) x
+#define DRV_PRINT_STRING(stream, format, ...)                                  \
+	fprintf((stream), (format), __VA_ARGS__)
+#endif
+
+/*
+ * OS return types
+ */
+#if defined(DRV_OS_UNIX)
+#define OS_STATUS int
+#define OS_SUCCESS 0
+#if defined(BUILD_DRV_ESX)
+#define OS_ILLEGAL_IOCTL -1
+#define OS_NO_MEM -2
+#define OS_FAULT -3
+#define OS_INVALID -4
+#define OS_NO_SYSCALL -5
+#define OS_RESTART_SYSCALL -6
+#define OS_IN_PROGRESS -7
+#else
+#define OS_ILLEGAL_IOCTL -ENOTTY
+#define OS_NO_MEM -ENOMEM
+#define OS_FAULT -EFAULT
+#define OS_INVALID -EINVAL
+#define OS_NO_SYSCALL -ENOSYS
+#define OS_RESTART_SYSCALL -ERESTARTSYS
+#define OS_IN_PROGRESS -EALREADY
+#endif
+#endif
+#if defined(DRV_OS_WINDOWS)
+#define OS_STATUS NTSTATUS
+#define OS_SUCCESS STATUS_SUCCESS
+#define OS_ILLEGAL_IOCTL STATUS_UNSUCCESSFUL
+#define OS_NO_MEM STATUS_UNSUCCESSFUL
+#define OS_FAULT STATUS_UNSUCCESSFUL
+#define OS_INVALID STATUS_UNSUCCESSFUL
+#define OS_NO_SYSCALL STATUS_UNSUCCESSFUL
+#define OS_RESTART_SYSCALL STATUS_UNSUCCESSFUL
+#define OS_IN_PROGRESS STATUS_UNSUCCESSFUL
+#endif
+
+/****************************************************************************
+ **  Driver State definitions
+ ***************************************************************************/
+#define DRV_STATE_UNINITIALIZED 0
+#define DRV_STATE_RESERVED 1
+#define DRV_STATE_IDLE 2
+#define DRV_STATE_PAUSED 3
+#define DRV_STATE_STOPPED 4
+#define DRV_STATE_RUNNING 5
+#define DRV_STATE_PAUSING 6
+#define DRV_STATE_PREPARE_STOP 7
+#define DRV_STATE_TERMINATING 8
+
+#define MATCHING_STATE_BIT(state) ((U32)1 << state)
+#define STATE_BIT_UNINITIALIZED MATCHING_STATE_BIT(DRV_STATE_UNINITIALIZED)
+#define STATE_BIT_RESERVED MATCHING_STATE_BIT(DRV_STATE_RESERVED)
+#define STATE_BIT_IDLE MATCHING_STATE_BIT(DRV_STATE_IDLE)
+#define STATE_BIT_PAUSED MATCHING_STATE_BIT(DRV_STATE_PAUSED)
+#define STATE_BIT_STOPPED MATCHING_STATE_BIT(DRV_STATE_STOPPED)
+#define STATE_BIT_RUNNING MATCHING_STATE_BIT(DRV_STATE_RUNNING)
+#define STATE_BIT_PAUSING MATCHING_STATE_BIT(DRV_STATE_PAUSING)
+#define STATE_BIT_PREPARE_STOP MATCHING_STATE_BIT(DRV_STATE_PREPARE_STOP)
+#define STATE_BIT_TERMINATING MATCHING_STATE_BIT(DRV_STATE_TERMINATING)
+#define STATE_BIT_ANY ((U32)-1)
+
+#define IS_COLLECTING_STATE(state)                                             \
+	(!!(MATCHING_STATE_BIT(state) &                                        \
+	    (STATE_BIT_RUNNING | STATE_BIT_PAUSING | STATE_BIT_PAUSED)))
+
+/*
+ *  Stop codes
+ */
+#define DRV_STOP_BASE 0
+#define DRV_STOP_NORMAL 1
+#define DRV_STOP_ASYNC 2
+#define DRV_STOP_CANCEL 3
+
+#define SEP_FREE(loc)                                                          \
+	do {                                                                   \
+		if ((loc)) {                                                   \
+			free(loc);                                             \
+			loc = NULL;                                            \
+		}                                                              \
+	} while (0)
+
+#define MAX_EVENTS 256 // Limiting maximum multiplexing events to 256.
+#if defined(DRV_OS_UNIX)
+#define UNREFERENCED_PARAMETER(p) ((p) = (p))
+#endif
+
+/*
+ * Global marker names
+ */
+#define START_MARKER_NAME "SEP_START_MARKER"
+#define PAUSE_MARKER_NAME "SEP_PAUSE_MARKER"
+#define RESUME_MARKER_NAME "SEP_RESUME_MARKER"
+
+#define DRV_SOC_STRING_LEN (100 + MAX_MARKER_LENGTH)
+
+/*
+ * Temp path
+ */
+#define SEP_TMPDIR "SEP_TMP_DIR"
+#if defined(DRV_OS_WINDOWS)
+#define OS_TMPDIR "TEMP"
+#define GET_DEFAULT_TMPDIR(dir, size)                                          \
+	{                                                                      \
+		GetTempPath((U32)size, dir);                                   \
+	}
+#else
+#define OS_TMPDIR "TMPDIR"
+/*
+ * Unix has default tmp dir
+ */
+#if defined(DRV_OS_ANDROID)
+#define TEMP_PATH "/data"
+#else
+#define TEMP_PATH "/tmp"
+#endif
+#define GET_DEFAULT_TMPDIR(dir, size)                                          \
+	{                                                                      \
+		DRV_STRCPY((STCHAR *)dir, (U32)size, (STCHAR *)TEMP_PATH);     \
+	}
+#endif
+
+#define OS_ID_UNKNOWN -1
+#define OS_ID_NATIVE 0
+#define OS_ID_VMM 0
+#define OS_ID_MODEM 1
+#define OS_ID_ANDROID 2
+#define OS_ID_SECVM 3
+#define OS_ID_ACORN ((U32)-1)
+
+#define PERF_HW_VER4 (5)
+#if defined(__cplusplus)
+}
+#endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/lwpmudrv_ecb.h b/drivers/platform/x86/socperf/include/lwpmudrv_ecb.h
new file mode 100644
index 000000000000..ac1c09f95214
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/lwpmudrv_ecb.h
@@ -0,0 +1,1095 @@
+/***
+ * -------------------------------------------------------------------------
+ *               INTEL CORPORATION PROPRIETARY INFORMATION
+ *  This software is supplied under the terms of the accompanying license
+ *  agreement or nondisclosure agreement with Intel Corporation and may not
+ *  be copied or disclosed except in accordance with the terms of that
+ *  agreement.
+ *        Copyright(C) 2007-2019 Intel Corporation.  All Rights Reserved.
+ * -------------------------------------------------------------------------
+***/
+
+#ifndef _LWPMUDRV_ECB_UTILS_H_
+#define _LWPMUDRV_ECB_UTILS_H_
+
+#if defined(DRV_OS_WINDOWS)
+#pragma warning(disable : 4200)
+#endif
+
+#if defined(__cplusplus)
+extern "C" {
+#endif
+
+// control register types
+#define CCCR 1 // counter configuration control register
+#define ESCR 2 // event selection control register
+#define DATA 4 // collected as snapshot of current value
+#define DATA_RO_DELTA 8 // read-only counter collected as current-previous
+#define DATA_RO_SS                                                             \
+	16 // read-only counter collected as snapshot of current value
+#define METRICS 32 // hardware metrics
+
+// event multiplexing modes
+#define EM_DISABLED -1
+#define EM_TIMER_BASED 0
+#define EM_EVENT_BASED_PROFILING 1
+#define EM_TRIGGER_BASED 2
+
+// ***************************************************************************
+
+/*!\struct EVENT_DESC_NODE
+ * \var    sample_size                   - size of buffer in bytes to hold the sample + extras
+ * \var    max_gp_events                 - max number of General Purpose events per EM group
+ * \var    pebs_offset                   - offset in the sample to locate the pebs capture information
+ * \var    lbr_offset                    - offset in the sample to locate the lbr information
+ * \var    lbr_num_regs                  - offset in the sample to locate the number of lbr register information
+ * \var    latency_offset_in_sample      - offset in the sample to locate the latency information
+ * \var    latency_size_in_sample        - size of latency records in the sample
+ * \var    latency_size_from_pebs_record - size of the latency data from pebs record in the sample
+ * \var    latency_offset_in_pebs_record - offset in the sample to locate the latency information
+ *                                         in pebs record
+ * \var    power_offset_in_sample        - offset in the sample to locate the power information
+ * \var    ebc_offset                    - offset in the sample to locate the ebc count information
+ * \var    uncore_ebc_offset             - offset in the sample to locate the uncore ebc count information
+ *
+ * \var    ro_offset                     - offset of RO data in the sample
+ * \var    ro_count                      - total number of RO entries (including all of IEAR/DEAR/BTB/IPEAR)
+ * \var    iear_offset                   - offset into RO data at which IEAR entries begin
+ * \var    dear_offset                   - offset into RO data at which DEAR entries begin
+ * \var    btb_offset                    - offset into RO data at which BTB entries begin (these use the same PMDs)
+ * \var    ipear_offset                  - offset into RO data at which IPEAR entries begin (these use the same PMDs)
+ * \var    iear_count                    - number of IEAR entries
+ * \var    dear_count                    - number of DEAR entries
+ * \var    btb_count                     - number of BTB entries
+ * \var    ipear_count                   - number of IPEAR entries
+ *
+ * \var    pwr_offset                    - offset in the sample to locate the pwr count information
+ * \var    p_state_offset                - offset in the sample to locate the p_state information (APERF/MPERF)
+ *
+ * \brief  Data structure to describe the events and the mode
+ *
+ */
+
+typedef struct EVENT_DESC_NODE_S EVENT_DESC_NODE;
+typedef EVENT_DESC_NODE * EVENT_DESC;
+
+struct EVENT_DESC_NODE_S {
+	U32 sample_size;
+	U32 pebs_offset;
+	U32 pebs_size;
+	U32 lbr_offset;
+	U32 lbr_num_regs;
+	U32 latency_offset_in_sample;
+	U32 latency_size_in_sample;
+	U32 latency_size_from_pebs_record;
+	U32 latency_offset_in_pebs_record;
+	U32 power_offset_in_sample;
+	U32 ebc_offset;
+	U32 uncore_ebc_offset;
+	U32 eventing_ip_offset;
+	U32 hle_offset;
+	U32 pwr_offset;
+	U32 callstack_offset;
+	U32 callstack_size;
+	U32 p_state_offset;
+	U32 pebs_tsc_offset;
+	U32 perfmetrics_offset;
+	U32 perfmetrics_size;
+	/* ----------ADAPTIVE PEBS FIELDS --------- */
+	U16 applicable_counters_offset;
+	U16 gpr_info_offset;
+	U16 gpr_info_size;
+	U16 xmm_info_offset;
+	U16 xmm_info_size;
+	U16 lbr_info_size;
+	/*------------------------------------------*/
+	U32 reserved2;
+	U64 reserved3;
+};
+
+//
+// Accessor macros for EVENT_DESC node
+//
+#define EVENT_DESC_sample_size(ec) ((ec)->sample_size)
+#define EVENT_DESC_pebs_offset(ec) ((ec)->pebs_offset)
+#define EVENT_DESC_pebs_size(ec) ((ec)->pebs_size)
+#define EVENT_DESC_lbr_offset(ec) ((ec)->lbr_offset)
+#define EVENT_DESC_lbr_num_regs(ec) ((ec)->lbr_num_regs)
+#define EVENT_DESC_latency_offset_in_sample(ec) ((ec)->latency_offset_in_sample)
+#define EVENT_DESC_latency_size_from_pebs_record(ec)                           \
+	((ec)->latency_size_from_pebs_record)
+#define EVENT_DESC_latency_offset_in_pebs_record(ec)                           \
+	((ec)->latency_offset_in_pebs_record)
+#define EVENT_DESC_latency_size_in_sample(ec) ((ec)->latency_size_in_sample)
+#define EVENT_DESC_power_offset_in_sample(ec) ((ec)->power_offset_in_sample)
+#define EVENT_DESC_ebc_offset(ec) ((ec)->ebc_offset)
+#define EVENT_DESC_uncore_ebc_offset(ec) ((ec)->uncore_ebc_offset)
+#define EVENT_DESC_eventing_ip_offset(ec) ((ec)->eventing_ip_offset)
+#define EVENT_DESC_hle_offset(ec) ((ec)->hle_offset)
+#define EVENT_DESC_pwr_offset(ec) ((ec)->pwr_offset)
+#define EVENT_DESC_callstack_offset(ec) ((ec)->callstack_offset)
+#define EVENT_DESC_callstack_size(ec) ((ec)->callstack_size)
+#define EVENT_DESC_perfmetrics_offset(ec) ((ec)->perfmetrics_offset)
+#define EVENT_DESC_perfmetrics_size(ec) ((ec)->perfmetrics_size)
+#define EVENT_DESC_p_state_offset(ec) ((ec)->p_state_offset)
+#define EVENT_DESC_pebs_tsc_offset(ec) ((ec)->pebs_tsc_offset)
+#define EVENT_DESC_applicable_counters_offset(ec)                              \
+	((ec)->applicable_counters_offset)
+#define EVENT_DESC_gpr_info_offset(ec) ((ec)->gpr_info_offset)
+#define EVENT_DESC_gpr_info_size(ec) ((ec)->gpr_info_size)
+#define EVENT_DESC_xmm_info_offset(ec) ((ec)->xmm_info_offset)
+#define EVENT_DESC_xmm_info_size(ec) ((ec)->xmm_info_size)
+#define EVENT_DESC_lbr_info_size(ec) ((ec)->lbr_info_size)
+
+// ***************************************************************************
+
+/*!\struct EVENT_CONFIG_NODE
+ * \var    num_groups      -  The number of groups being programmed
+ * \var    em_mode         -  Is EM valid?  If so how?
+ * \var    em_time_slice   -  EM valid?  time slice in milliseconds
+ * \var    sample_size     -  size of buffer in bytes to hold the sample + extras
+ * \var    max_gp_events   -  Max number of General Purpose events per EM group
+ * \var    pebs_offset     -  offset in the sample to locate the pebs capture information
+ * \var    lbr_offset      -  offset in the sample to locate the lbr information
+ * \var    lbr_num_regs    -  offset in the sample to locate the lbr information
+ * \var    latency_offset_in_sample      -  offset in the sample to locate the latency information
+ * \var    latency_size_in_sample        -  size of latency records in the sample
+ * \var    latency_size_from_pebs_record -  offset in the sample to locate the latency
+ *                                          size from pebs record
+ * \var    latency_offset_in_pebs_record -  offset in the sample to locate the latency information
+ *                                          in pebs record
+ * \var    power_offset_in_sample        -  offset in the sample to locate the power information
+ * \var    ebc_offset                    -  offset in the sample to locate the ebc count information
+ *
+ * \var    pwr_offset                    -  offset in the sample to locate the pwr count information
+ * \var    p_state_offset                -  offset in the sample to locate the p_state information (APERF/MPERF)
+ *
+ * \brief  Data structure to describe the events and the mode
+ *
+ */
+
+typedef struct EVENT_CONFIG_NODE_S EVENT_CONFIG_NODE;
+typedef EVENT_CONFIG_NODE * EVENT_CONFIG;
+
+struct EVENT_CONFIG_NODE_S {
+	U32 num_groups;
+	S32 em_mode;
+	S32 em_factor;
+	S32 em_event_num;
+	U32 sample_size;
+	U32 max_gp_events;
+	U32 max_fixed_counters;
+	U32 max_ro_counters; // maximum read-only counters
+	U32 pebs_offset;
+	U32 pebs_size;
+	U32 lbr_offset;
+	U32 lbr_num_regs;
+	U32 latency_offset_in_sample;
+	U32 latency_size_in_sample;
+	U32 latency_size_from_pebs_record;
+	U32 latency_offset_in_pebs_record;
+	U32 power_offset_in_sample;
+	U32 ebc_offset;
+	U32 num_groups_unc;
+	U32 ebc_offset_unc;
+	U32 sample_size_unc;
+	U32 eventing_ip_offset;
+	U32 hle_offset;
+	U32 pwr_offset;
+	U32 callstack_offset;
+	U32 callstack_size;
+	U32 p_state_offset;
+	U32 pebs_tsc_offset;
+	U64 reserved1;
+	U64 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+
+//
+// Accessor macros for EVENT_CONFIG node
+//
+#define EVENT_CONFIG_num_groups(ec) ((ec)->num_groups)
+#define EVENT_CONFIG_mode(ec) ((ec)->em_mode)
+#define EVENT_CONFIG_em_factor(ec) ((ec)->em_factor)
+#define EVENT_CONFIG_em_event_num(ec) ((ec)->em_event_num)
+#define EVENT_CONFIG_sample_size(ec) ((ec)->sample_size)
+#define EVENT_CONFIG_max_gp_events(ec) ((ec)->max_gp_events)
+#define EVENT_CONFIG_max_fixed_counters(ec) ((ec)->max_fixed_counters)
+#define EVENT_CONFIG_max_ro_counters(ec) ((ec)->max_ro_counters)
+#define EVENT_CONFIG_pebs_offset(ec) ((ec)->pebs_offset)
+#define EVENT_CONFIG_pebs_size(ec) ((ec)->pebs_size)
+#define EVENT_CONFIG_lbr_offset(ec) ((ec)->lbr_offset)
+#define EVENT_CONFIG_lbr_num_regs(ec) ((ec)->lbr_num_regs)
+#define EVENT_CONFIG_latency_offset_in_sample(ec) ((ec)->latency_offset_in_sample)
+#define EVENT_CONFIG_latency_size_from_pebs_record(ec)                         \
+	((ec)->latency_size_from_pebs_record)
+#define EVENT_CONFIG_latency_offset_in_pebs_record(ec)                         \
+	((ec)->latency_offset_in_pebs_record)
+#define EVENT_CONFIG_latency_size_in_sample(ec) ((ec)->latency_size_in_sample)
+#define EVENT_CONFIG_power_offset_in_sample(ec) ((ec)->power_offset_in_sample)
+#define EVENT_CONFIG_ebc_offset(ec) ((ec)->ebc_offset)
+#define EVENT_CONFIG_num_groups_unc(ec) ((ec)->num_groups_unc)
+#define EVENT_CONFIG_ebc_offset_unc(ec) ((ec)->ebc_offset_unc)
+#define EVENT_CONFIG_sample_size_unc(ec) ((ec)->sample_size_unc)
+#define EVENT_CONFIG_eventing_ip_offset(ec) ((ec)->eventing_ip_offset)
+#define EVENT_CONFIG_hle_offset(ec) ((ec)->hle_offset)
+#define EVENT_CONFIG_pwr_offset(ec) ((ec)->pwr_offset)
+#define EVENT_CONFIG_callstack_offset(ec) ((ec)->callstack_offset)
+#define EVENT_CONFIG_callstack_size(ec) ((ec)->callstack_size)
+#define EVENT_CONFIG_p_state_offset(ec) ((ec)->p_state_offset)
+#define EVENT_CONFIG_pebs_tsc_offset(ec) ((ec)->pebs_tsc_offset)
+
+typedef enum { UNC_MUX = 1, UNC_COUNTER } UNC_SA_PROG_TYPE;
+
+typedef enum {
+	UNC_PCICFG = 1,
+	UNC_MMIO,
+	UNC_STOP,
+	UNC_MEMORY,
+	UNC_STATUS
+} UNC_SA_CONFIG_TYPE;
+
+typedef enum {
+	UNC_MCHBAR = 1,
+	UNC_DMIBAR,
+	UNC_PCIEXBAR,
+	UNC_GTTMMADR,
+	UNC_GDXCBAR,
+	UNC_CHAPADR,
+	UNC_SOCPCI,
+	UNC_NPKBAR
+} UNC_SA_BAR_TYPE;
+
+typedef enum { UNC_OP_READ = 1, UNC_OP_WRITE, UNC_OP_RMW } UNC_SA_OPERATION;
+
+typedef enum {
+	STATIC_COUNTER = 1,
+	FREERUN_COUNTER,
+	PROG_FREERUN_COUNTER
+} COUNTER_TYPES;
+
+typedef enum {
+	PACKAGE_EVENT = 1,
+	MODULE_EVENT,
+	THREAD_EVENT,
+	SYSTEM_EVENT
+} EVENT_SCOPE_TYPES;
+
+typedef enum {
+	DEVICE_CORE = 1, // CORE DEVICE
+	DEVICE_HETERO,
+	DEVICE_UNC_CBO = 10, // UNCORE DEVICES START
+	DEVICE_UNC_HA,
+	DEVICE_UNC_IMC,
+	DEVICE_UNC_IRP,
+	DEVICE_UNC_NCU,
+	DEVICE_UNC_PCU,
+	DEVICE_UNC_POWER,
+	DEVICE_UNC_QPI,
+	DEVICE_UNC_R2PCIE,
+	DEVICE_UNC_R3QPI,
+	DEVICE_UNC_SBOX,
+	DEVICE_UNC_GT,
+	DEVICE_UNC_UBOX,
+	DEVICE_UNC_WBOX,
+	DEVICE_UNC_COREI7,
+	DEVICE_UNC_CHA,
+	DEVICE_UNC_EDC,
+	DEVICE_UNC_IIO,
+	DEVICE_UNC_M2M,
+	DEVICE_UNC_EDRAM,
+	DEVICE_UNC_FPGA_CACHE,
+	DEVICE_UNC_FPGA_FAB,
+	DEVICE_UNC_FPGA_THERMAL,
+	DEVICE_UNC_FPGA_POWER,
+	DEVICE_UNC_FPGA_GB,
+	DEVICE_UNC_TELEMETRY = 150, // TELEMETRY DEVICE
+	DEVICE_UNC_CHAP = 200, // CHIPSET DEVICES START
+	DEVICE_UNC_GMCH,
+	DEVICE_UNC_GFX,
+	DEVICE_UNC_SOCPERF = 300, // UNCORE VISA DEVICES START
+	DEVICE_UNC_HFI_RXE = 400, // STL HFI
+	DEVICE_UNC_HFI_TXE,
+} DEVICE_TYPES;
+
+typedef enum {
+	LBR_ENTRY_TOS = 0,
+	LBR_ENTRY_FROM_IP,
+	LBR_ENTRY_TO_IP,
+	LBR_ENTRY_INFO
+} LBR_ENTRY_TYPE;
+
+// ***************************************************************************
+
+/*!\struct EVENT_REG_ID_NODE
+ * \var    reg_id      -  MSR index to r/w
+ * \var    pci_id     PCI based register and its details to operate on
+ */
+typedef struct EVENT_REG_ID_NODE_S EVENT_REG_ID_NODE;
+typedef EVENT_REG_ID_NODE * EVENT_REG_ID;
+
+struct EVENT_REG_ID_NODE_S {
+	U32 reg_id;
+	U32 pci_bus_no;
+	U32 pci_dev_no;
+	U32 pci_func_no;
+	U32 data_size;
+	U32 bar_index; // Points to the index (MMIO_INDEX_LIST)
+		// of bar memory map list to be used in mmio_bar_list of ECB
+	U32 reserved1;
+	U32 reserved2;
+	U64 reserved3;
+};
+
+// ***************************************************************************
+
+typedef enum {
+	PMU_REG_RW_READ = 1,
+	PMU_REG_RW_WRITE,
+	PMU_REG_RW_READ_WRITE,
+} PMU_REG_RW_TYPES;
+
+typedef enum {
+	PMU_REG_PROG_MSR = 1,
+	PMU_REG_PROG_PCI,
+	PMU_REG_PROG_MMIO,
+} PMU_REG_PROG_TYPES;
+
+typedef enum {
+	PMU_REG_GLOBAL_CTRL = 1,
+	PMU_REG_UNIT_CTRL,
+	PMU_REG_UNIT_STATUS,
+	PMU_REG_DATA,
+	PMU_REG_EVENT_SELECT,
+	PMU_REG_FILTER,
+	PMU_REG_FIXED_CTRL,
+} PMU_REG_TYPES;
+
+/*!\struct EVENT_REG_NODE
+ * \var    reg_type             - register type
+ * \var    event_id_index       - event ID index
+ * \var    event_reg_id         - register ID/pci register details
+ * \var    desc_id              - desc ID
+ * \var    flags                - flags
+ * \var    reg_value            - register value
+ * \var    max_bits             - max bits
+ * \var    scheduled            - boolean to specify if this event node has been scheduled already
+ * \var    bus_no               - PCI bus number
+ * \var    dev_no               - PCI device number
+ * \var    func_no              - PCI function number
+ * \var    counter_type         - Event counter type - static/freerun
+ * \var    event_scope          - Event scope - package/module/thread
+ * \var    reg_prog_type        - Register Programming type
+ * \var    reg_rw_type          - Register Read/Write type
+ * \var    reg_order            - Register order in the programming sequence
+ * \var
+ * \brief  Data structure to describe the event registers
+ *
+ */
+
+typedef struct EVENT_REG_NODE_S EVENT_REG_NODE;
+typedef EVENT_REG_NODE * EVENT_REG;
+
+struct EVENT_REG_NODE_S {
+	U8 reg_type;
+	U8 unit_id;
+	U16 event_id_index;
+	U16 counter_event_offset;
+	U16 reserved1;
+	EVENT_REG_ID_NODE event_reg_id;
+	U64 reg_value;
+	U16 desc_id;
+	U16 flags;
+	U32 reserved2;
+	U64 max_bits;
+	U8 scheduled;
+	S8 secondary_pci_offset_shift;
+	U16 secondary_pci_offset_offset; // offset of the offset...
+	U32 counter_type;
+	U32 event_scope;
+	U8 reg_prog_type;
+	U8 reg_rw_type;
+	U8 reg_order;
+	U8 bit_position;
+	U64 secondary_pci_offset_mask;
+	U32 core_event_id;
+	U32 uncore_buffer_offset_in_package;
+	U32 uncore_buffer_offset_in_system;
+	U32 reserved3;
+	U64 reserved4;
+	U64 reserved5;
+	U64 reserved6;
+};
+
+//
+// Accessor macros for EVENT_REG node
+// Note: the flags field is not directly addressible to prevent hackery
+//
+#define EVENT_REG_reg_type(x, i) ((x)[(i)].reg_type)
+#define EVENT_REG_event_id_index(x, i) ((x)[(i)].event_id_index)
+#define EVENT_REG_unit_id(x, i) ((x)[(i)].unit_id)
+#define EVENT_REG_counter_event_offset(x, i) ((x)[(i)].counter_event_offset)
+#define EVENT_REG_reg_id(x, i) ((x)[(i)].event_reg_id.reg_id)
+#define EVENT_REG_bus_no(x, i) ((x)[(i)].event_reg_id.pci_bus_no)
+#define EVENT_REG_dev_no(x, i) ((x)[(i)].event_reg_id.pci_dev_no)
+#define EVENT_REG_func_no(x, i) ((x)[(i)].event_reg_id.pci_func_no)
+#define EVENT_REG_offset(x, i)                                                 \
+	((x)[(i)].event_reg_id.reg_id) // points to the reg_id
+#define EVENT_REG_data_size(x, i) ((x)[(i)].event_reg_id.data_size)
+#define EVENT_REG_desc_id(x, i) ((x)[(i)].desc_id)
+#define EVENT_REG_flags(x, i) ((x)[(i)].flags)
+#define EVENT_REG_reg_value(x, i) ((x)[(i)].reg_value)
+#define EVENT_REG_max_bits(x, i) ((x)[(i)].max_bits)
+#define EVENT_REG_scheduled(x, i) ((x)[(i)].scheduled)
+#define EVENT_REG_secondary_pci_offset_shift(x, i)                             \
+	((x)[(i)].secondary_pci_offset_shift)
+#define EVENT_REG_secondary_pci_offset_offset(x, i)                            \
+	((x)[(i)].secondary_pci_offset_offset)
+#define EVENT_REG_secondary_pci_offset_mask(x, i)                              \
+	((x)[(i)].secondary_pci_offset_mask)
+
+#define EVENT_REG_counter_type(x, i) ((x)[(i)].counter_type)
+#define EVENT_REG_event_scope(x, i) ((x)[(i)].event_scope)
+#define EVENT_REG_reg_prog_type(x, i) ((x)[(i)].reg_prog_type)
+#define EVENT_REG_reg_rw_type(x, i) ((x)[(i)].reg_rw_type)
+#define EVENT_REG_reg_order(x, i) ((x)[(i)].reg_order)
+#define EVENT_REG_bit_position(x, i) ((x)[(i)].bit_position)
+
+#define EVENT_REG_core_event_id(x, i) ((x)[(i)].core_event_id)
+#define EVENT_REG_uncore_buffer_offset_in_package(x, i)                        \
+	((x)[(i)].uncore_buffer_offset_in_package)
+#define EVENT_REG_uncore_buffer_offset_in_system(x, i)                         \
+	((x)[(i)].uncore_buffer_offset_in_system)
+
+//
+// Config bits
+//
+#define EVENT_REG_precise_bit 0x00000001
+#define EVENT_REG_global_bit 0x00000002
+#define EVENT_REG_uncore_bit 0x00000004
+#define EVENT_REG_uncore_q_rst_bit 0x00000008
+#define EVENT_REG_latency_bit 0x00000010
+#define EVENT_REG_is_gp_reg_bit 0x00000020
+#define EVENT_REG_clean_up_bit 0x00000040
+#define EVENT_REG_em_trigger_bit 0x00000080
+#define EVENT_REG_lbr_value_bit 0x00000100
+#define EVENT_REG_fixed_reg_bit 0x00000200
+#define EVENT_REG_multi_pkg_evt_bit 0x00001000
+#define EVENT_REG_branch_evt_bit 0x00002000
+
+//
+// Accessor macros for config bits
+//
+#define EVENT_REG_precise_get(x, i) ((x)[(i)].flags & EVENT_REG_precise_bit)
+#define EVENT_REG_precise_set(x, i) ((x)[(i)].flags |= EVENT_REG_precise_bit)
+#define EVENT_REG_precise_clear(x, i) ((x)[(i)].flags &= ~EVENT_REG_precise_bit)
+
+#define EVENT_REG_global_get(x, i) ((x)[(i)].flags & EVENT_REG_global_bit)
+#define EVENT_REG_global_set(x, i) ((x)[(i)].flags |= EVENT_REG_global_bit)
+#define EVENT_REG_global_clear(x, i) ((x)[(i)].flags &= ~EVENT_REG_global_bit)
+
+#define EVENT_REG_uncore_get(x, i) ((x)[(i)].flags & EVENT_REG_uncore_bit)
+#define EVENT_REG_uncore_set(x, i) ((x)[(i)].flags |= EVENT_REG_uncore_bit)
+#define EVENT_REG_uncore_clear(x, i) ((x)[(i)].flags &= ~EVENT_REG_uncore_bit)
+
+#define EVENT_REG_uncore_q_rst_get(x, i)                                       \
+	((x)[(i)].flags & EVENT_REG_uncore_q_rst_bit)
+#define EVENT_REG_uncore_q_rst_set(x, i)                                       \
+	((x)[(i)].flags |= EVENT_REG_uncore_q_rst_bit)
+#define EVENT_REG_uncore_q_rst_clear(x, i)                                     \
+	((x)[(i)].flags &= ~EVENT_REG_uncore_q_rst_bit)
+
+#define EVENT_REG_latency_get(x, i) ((x)[(i)].flags & EVENT_REG_latency_bit)
+#define EVENT_REG_latency_set(x, i) ((x)[(i)].flags |= EVENT_REG_latency_bit)
+#define EVENT_REG_latency_clear(x, i) ((x)[(i)].flags &= ~EVENT_REG_latency_bit)
+
+#define EVENT_REG_is_gp_reg_get(x, i) ((x)[(i)].flags & EVENT_REG_is_gp_reg_bit)
+#define EVENT_REG_is_gp_reg_set(x, i)                                          \
+	((x)[(i)].flags |= EVENT_REG_is_gp_reg_bit)
+#define EVENT_REG_is_gp_reg_clear(x, i)                                        \
+	((x)[(i)].flags &= ~EVENT_REG_is_gp_reg_bit)
+
+#define EVENT_REG_lbr_value_get(x, i) ((x)[(i)].flags & EVENT_REG_lbr_value_bit)
+#define EVENT_REG_lbr_value_set(x, i)                                          \
+	((x)[(i)].flags |= EVENT_REG_lbr_value_bit)
+#define EVENT_REG_lbr_value_clear(x, i)                                        \
+	((x)[(i)].flags &= ~EVENT_REG_lbr_value_bit)
+
+#define EVENT_REG_fixed_reg_get(x, i) ((x)[(i)].flags & EVENT_REG_fixed_reg_bit)
+#define EVENT_REG_fixed_reg_set(x, i)                                          \
+	((x)[(i)].flags |= EVENT_REG_fixed_reg_bit)
+#define EVENT_REG_fixed_reg_clear(x, i)                                        \
+	((x)[(i)].flags &= ~EVENT_REG_fixed_reg_bit)
+
+#define EVENT_REG_multi_pkg_evt_bit_get(x, i)                                  \
+	((x)[(i)].flags & EVENT_REG_multi_pkg_evt_bit)
+#define EVENT_REG_multi_pkg_evt_bit_set(x, i)                                  \
+	((x)[(i)].flags |= EVENT_REG_multi_pkg_evt_bit)
+#define EVENT_REG_multi_pkg_evt_bit_clear(x, i)                                \
+	((x)[(i)].flags &= ~EVENT_REG_multi_pkg_evt_bit)
+
+#define EVENT_REG_clean_up_get(x, i) ((x)[(i)].flags & EVENT_REG_clean_up_bit)
+#define EVENT_REG_clean_up_set(x, i) ((x)[(i)].flags |= EVENT_REG_clean_up_bit)
+#define EVENT_REG_clean_up_clear(x, i)                                         \
+	((x)[(i)].flags &= ~EVENT_REG_clean_up_bit)
+
+#define EVENT_REG_em_trigger_get(x, i)                                         \
+	((x)[(i)].flags & EVENT_REG_em_trigger_bit)
+#define EVENT_REG_em_trigger_set(x, i)                                         \
+	((x)[(i)].flags |= EVENT_REG_em_trigger_bit)
+#define EVENT_REG_em_trigger_clear(x, i)                                       \
+	((x)[(i)].flags &= ~EVENT_REG_em_trigger_bit)
+
+#define EVENT_REG_branch_evt_get(x, i)                                         \
+	((x)[(i)].flags & EVENT_REG_branch_evt_bit)
+#define EVENT_REG_branch_evt_set(x, i)                                         \
+	((x)[(i)].flags |= EVENT_REG_branch_evt_bit)
+#define EVENT_REG_branch_evt_clear(x, i)                                       \
+	((x)[(i)].flags &= ~EVENT_REG_branch_evt_bit)
+
+// ***************************************************************************
+
+/*!\struct DRV_PCI_DEVICE_ENTRY_NODE_S
+ * \var    bus_no          -  PCI bus no to read
+ * \var    dev_no          -  PCI device no to read
+ * \var    func_no            PCI device no to read
+ * \var    bar_offset         BASE Address Register offset of the PCI based PMU
+ * \var    bit_offset         Bit offset of the same
+ * \var    size               size of read/write
+ * \var    bar_address        the actual BAR present
+ * \var    enable_offset      Offset info to enable/disable
+ * \var    enabled            Status of enable/disable
+ * \brief  Data structure to describe the PCI Device
+ *
+ */
+
+typedef struct DRV_PCI_DEVICE_ENTRY_NODE_S DRV_PCI_DEVICE_ENTRY_NODE;
+typedef DRV_PCI_DEVICE_ENTRY_NODE * DRV_PCI_DEVICE_ENTRY;
+
+struct DRV_PCI_DEVICE_ENTRY_NODE_S {
+	U32 bus_no;
+	U32 dev_no;
+	U32 func_no;
+	U32 bar_offset;
+	U64 bar_mask;
+	U32 bit_offset;
+	U32 size;
+	U64 bar_address;
+	U32 enable_offset;
+	U32 enabled;
+	U32 base_offset_for_mmio;
+	U32 operation;
+	U32 bar_name;
+	U32 prog_type;
+	U32 config_type;
+	S8 bar_shift; // positive shifts right, negative shifts left
+	U8 reserved0;
+	U16 reserved1;
+	U64 value;
+	U64 mask;
+	U64 virtual_address;
+	U32 port_id;
+	U32 op_code;
+	U32 device_id;
+	U16 bar_num;
+	U16 feature_id;
+	U64 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+
+//
+// Accessor macros for DRV_PCI_DEVICE_NODE node
+//
+#define DRV_PCI_DEVICE_ENTRY_bus_no(x) ((x)->bus_no)
+#define DRV_PCI_DEVICE_ENTRY_dev_no(x) ((x)->dev_no)
+#define DRV_PCI_DEVICE_ENTRY_func_no(x) ((x)->func_no)
+#define DRV_PCI_DEVICE_ENTRY_bar_offset(x) ((x)->bar_offset)
+#define DRV_PCI_DEVICE_ENTRY_bar_mask(x) ((x)->bar_mask)
+#define DRV_PCI_DEVICE_ENTRY_bit_offset(x) ((x)->bit_offset)
+#define DRV_PCI_DEVICE_ENTRY_size(x) ((x)->size)
+#define DRV_PCI_DEVICE_ENTRY_bar_address(x) ((x)->bar_address)
+#define DRV_PCI_DEVICE_ENTRY_enable_offset(x) ((x)->enable_offset)
+#define DRV_PCI_DEVICE_ENTRY_enable(x) ((x)->enabled)
+#define DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(x) ((x)->base_offset_for_mmio)
+#define DRV_PCI_DEVICE_ENTRY_operation(x) ((x)->operation)
+#define DRV_PCI_DEVICE_ENTRY_bar_name(x) ((x)->bar_name)
+#define DRV_PCI_DEVICE_ENTRY_prog_type(x) ((x)->prog_type)
+#define DRV_PCI_DEVICE_ENTRY_config_type(x) ((x)->config_type)
+#define DRV_PCI_DEVICE_ENTRY_bar_shift(x) ((x)->bar_shift)
+#define DRV_PCI_DEVICE_ENTRY_value(x) ((x)->value)
+#define DRV_PCI_DEVICE_ENTRY_mask(x) ((x)->mask)
+#define DRV_PCI_DEVICE_ENTRY_virtual_address(x) ((x)->virtual_address)
+#define DRV_PCI_DEVICE_ENTRY_port_id(x) ((x)->port_id)
+#define DRV_PCI_DEVICE_ENTRY_op_code(x) ((x)->op_code)
+#define DRV_PCI_DEVICE_ENTRY_device_id(x) ((x)->device_id)
+#define DRV_PCI_DEVICE_ENTRY_bar_num(x) ((x)->bar_num)
+#define DRV_PCI_DEVICE_ENTRY_feature_id(x) ((x)->feature_id)
+
+// ***************************************************************************
+typedef enum {
+	PMU_OPERATION_INITIALIZE = 0,
+	PMU_OPERATION_WRITE,
+	PMU_OPERATION_ENABLE,
+	PMU_OPERATION_DISABLE,
+	PMU_OPERATION_READ,
+	PMU_OPERATION_CLEANUP,
+	PMU_OPERATION_READ_LBRS,
+	PMU_OPERATION_GLOBAL_REGS,
+	PMU_OPERATION_CTRL_GP,
+	PMU_OPERATION_DATA_FIXED,
+	PMU_OPERATION_DATA_GP,
+	PMU_OPERATION_OCR,
+	PMU_OPERATION_HW_ERRATA,
+	PMU_OPERATION_CHECK_OVERFLOW_GP_ERRATA,
+	PMU_OPERATION_CHECK_OVERFLOW_ERRATA,
+	PMU_OPERATION_ALL_REG,
+	PMU_OPERATION_DATA_ALL,
+	PMU_OPERATION_GLOBAL_STATUS,
+	PMU_OPERATION_METRICS,
+} PMU_OPERATION_TYPES;
+#define MAX_OPERATION_TYPES 32
+
+/*!\struct PMU_OPERATIONS_NODE
+ * \var    operation_type -    Type of operation from enumeration PMU_OPERATION_TYPES
+ * \var    register_start -    Start index of the registers for a specific operation
+ * \var    register_len   -    Number of registers for a specific operation
+ *
+ * \brief
+ * Structure for defining start and end indices in the ECB entries array for
+ * each type of operation performed in the driver
+ * initialize, write, read, enable, disable, etc.
+ */
+typedef struct PMU_OPERATIONS_NODE_S PMU_OPERATIONS_NODE;
+typedef PMU_OPERATIONS_NODE * PMU_OPERATIONS;
+struct PMU_OPERATIONS_NODE_S {
+	U32 operation_type;
+	U32 register_start;
+	U32 register_len;
+	U32 reserved1;
+	U32 reserved2;
+	U32 reserved3;
+};
+#define PMU_OPERATIONS_operation_type(x) ((x)->operation_type)
+#define PMU_OPERATIONS_register_start(x) ((x)->register_start)
+#define PMU_OPERATIONS_register_len(x) ((x)->register_len)
+#define PMU_OPER_operation_type(x, i) ((x)[(i)].operation_type)
+#define PMU_OPER_register_start(x, i) ((x)[(i)].register_start)
+#define PMU_OPER_register_len(x, i) ((x)[(i)].register_len)
+
+typedef enum {
+	ECB_MMIO_BAR1 = 1,
+	ECB_MMIO_BAR2 = 2,
+	ECB_MMIO_BAR3 = 3,
+	ECB_MMIO_BAR4 = 4,
+	ECB_MMIO_BAR5 = 5,
+	ECB_MMIO_BAR6 = 6,
+	ECB_MMIO_BAR7 = 7,
+	ECB_MMIO_BAR8 = 8,
+} MMIO_INDEX_LIST;
+#define MAX_MMIO_BARS 8
+
+/*!\struct MMIO_BAR_INFO_NODE
+ */
+typedef struct MMIO_BAR_INFO_NODE_S MMIO_BAR_INFO_NODE;
+typedef MMIO_BAR_INFO_NODE * MMIO_BAR_INFO;
+
+struct MMIO_BAR_INFO_NODE_S {
+	U32 bus_no;
+	U32 dev_no;
+	U32 func_no;
+	U32 offset;
+	U32 addr_size;
+	U32 map_size;
+	S8 bar_shift;
+	U8 reserved1;
+	U16 reserved2;
+	U32 reserved3;
+	U32 reserved4;
+	U32 reserved5;
+	U64 bar_mask;
+	U64 base_mmio_offset;
+	U64 physical_address;
+	U64 virtual_address;
+	U64 reserved6;
+	U64 reserved7;
+};
+
+/*!\struct ECB_NODE_S
+ * \var    num_entries -       Total number of entries in "entries".
+ * \var    group_id    -       Group ID.
+ * \var    num_events  -       Number of events in this group.
+ * \var    cccr_start  -       Starting index of counter configuration control registers in "entries".
+ * \var    cccr_pop    -       Number of counter configuration control registers in "entries".
+ * \var    escr_start  -       Starting index of event selection control registers in "entries".
+ * \var    escr_pop    -       Number of event selection control registers in "entries".
+ * \var    data_start  -       Starting index of data registers in "entries".
+ * \var    data_pop    -       Number of data registers in "entries".
+ * \var    pcidev_entry_node   PCI device details for one device
+ * \var    entries     - .     All the register nodes required for programming
+ *
+ * \brief
+ */
+
+typedef struct ECB_NODE_S ECB_NODE;
+typedef ECB_NODE * ECB;
+
+struct ECB_NODE_S {
+	U8 version;
+	U8 reserved1;
+	U16 reserved2;
+	U32 num_entries;
+	U32 group_id;
+	U32 num_events;
+	U32 cccr_start;
+	U32 cccr_pop;
+	U32 escr_start;
+	U32 escr_pop;
+	U32 data_start;
+	U32 data_pop;
+	U16 flags;
+	U8 pmu_timer_interval;
+	U8 reserved3;
+	U32 size_of_allocation;
+	U32 group_offset;
+	U32 reserved4;
+	DRV_PCI_DEVICE_ENTRY_NODE pcidev_entry_node;
+	U32 num_pci_devices;
+	U32 pcidev_list_offset;
+	DRV_PCI_DEVICE_ENTRY pcidev_entry_list;
+	U32 device_type;
+	U32 dev_node;
+	PMU_OPERATIONS_NODE operations[MAX_OPERATION_TYPES];
+	U32 descriptor_id;
+	U32 reserved5;
+	U32 metric_start;
+	U32 metric_pop;
+	MMIO_BAR_INFO_NODE mmio_bar_list[MAX_MMIO_BARS];
+	U64 reserved6;
+	U64 reserved7;
+	U64 reserved8;
+	EVENT_REG_NODE entries[];
+};
+
+//
+// Accessor macros for ECB node
+//
+#define ECB_version(x) ((x)->version)
+#define ECB_num_entries(x) ((x)->num_entries)
+#define ECB_group_id(x) ((x)->group_id)
+#define ECB_num_events(x) ((x)->num_events)
+#define ECB_cccr_start(x) ((x)->cccr_start)
+#define ECB_cccr_pop(x) ((x)->cccr_pop)
+#define ECB_escr_start(x) ((x)->escr_start)
+#define ECB_escr_pop(x) ((x)->escr_pop)
+#define ECB_data_start(x) ((x)->data_start)
+#define ECB_data_pop(x) ((x)->data_pop)
+#define ECB_metric_start(x) ((x)->metric_start)
+#define ECB_metric_pop(x) ((x)->metric_pop)
+#define ECB_pcidev_entry_node(x) ((x)->pcidev_entry_node)
+#define ECB_num_pci_devices(x) ((x)->num_pci_devices)
+#define ECB_pcidev_list_offset(x) ((x)->pcidev_list_offset)
+#define ECB_pcidev_entry_list(x) ((x)->pcidev_entry_list)
+#define ECB_flags(x) ((x)->flags)
+#define ECB_pmu_timer_interval(x) ((x)->pmu_timer_interval)
+#define ECB_size_of_allocation(x) ((x)->size_of_allocation)
+#define ECB_group_offset(x) ((x)->group_offset)
+#define ECB_device_type(x) ((x)->device_type)
+#define ECB_dev_node(x) ((x)->dev_node)
+#define ECB_operations(x) ((x)->operations)
+#define ECB_descriptor_id(x) ((x)->descriptor_id)
+#define ECB_entries(x) ((x)->entries)
+
+// for flag bit field
+#define ECB_direct2core_bit 0x0001
+#define ECB_bl_bypass_bit 0x0002
+#define ECB_pci_id_offset_bit 0x0003
+#define ECB_pcu_ccst_debug 0x0004
+
+#define ECB_VERSION 2
+
+#define ECB_CONSTRUCT(x, num_entries, group_id, cccr_start, escr_start,        \
+		      data_start, size_of_allocation)                          \
+	{                                                                      \
+		ECB_num_entries((x)) = (num_entries);                          \
+		ECB_group_id((x)) = (group_id);                                \
+		ECB_cccr_start((x)) = (cccr_start);                            \
+		ECB_cccr_pop((x)) = 0;                                         \
+		ECB_escr_start((x)) = (escr_start);                            \
+		ECB_escr_pop((x)) = 0;                                         \
+		ECB_data_start((x)) = (data_start);                            \
+		ECB_data_pop((x)) = 0;                                         \
+		ECB_metric_start((x)) = 0;                                     \
+		ECB_metric_pop((x)) = 0;                                       \
+		ECB_num_pci_devices((x)) = 0;                                  \
+		ECB_version((x)) = ECB_VERSION;                                \
+		ECB_size_of_allocation((x)) = (size_of_allocation);            \
+	}
+
+#define ECB_CONSTRUCT2(x, num_entries, group_id, size_of_allocation)           \
+	{                                                                      \
+		ECB_num_entries((x)) = (num_entries);                          \
+		ECB_group_id((x)) = (group_id);                                \
+		ECB_num_pci_devices((x)) = 0;                                  \
+		ECB_version((x)) = ECB_VERSION;                                \
+		ECB_size_of_allocation((x)) = (size_of_allocation);            \
+	}
+
+
+#define ECB_CONSTRUCT1(x, num_entries, group_id, cccr_start, escr_start,       \
+		       data_start, num_pci_devices, size_of_allocation)        \
+	{                                                                      \
+		ECB_num_entries((x)) = (num_entries);                          \
+		ECB_group_id((x)) = (group_id);                                \
+		ECB_cccr_start((x)) = (cccr_start);                            \
+		ECB_cccr_pop((x)) = 0;                                         \
+		ECB_escr_start((x)) = (escr_start);                            \
+		ECB_escr_pop((x)) = 0;                                         \
+		ECB_data_start((x)) = (data_start);                            \
+		ECB_data_pop((x)) = 0;                                         \
+		ECB_metric_start((x)) = 0;                                     \
+		ECB_metric_pop((x)) = 0;                                       \
+		ECB_num_pci_devices((x)) = (num_pci_devices);                  \
+		ECB_version((x)) = ECB_VERSION;                                \
+		ECB_size_of_allocation((x)) = (size_of_allocation);            \
+	}
+
+
+//
+// Accessor macros for ECB node entries
+//
+#define ECB_entries_reg_type(x, i) EVENT_REG_reg_type((ECB_entries(x)), (i))
+#define ECB_entries_event_id_index(x, i)                                       \
+	EVENT_REG_event_id_index((ECB_entries(x)), (i))
+#define ECB_entries_unit_id(x, i) EVENT_REG_unit_id((ECB_entries(x)), (i))
+#define ECB_entries_counter_event_offset(x, i)                                 \
+	EVENT_REG_counter_event_offset((ECB_entries(x)), (i))
+#define ECB_entries_reg_id(x, i) EVENT_REG_reg_id((ECB_entries(x)), (i))
+#define ECB_entries_reg_prog_type(x, i)                                        \
+	EVENT_REG_reg_prog_type((ECB_entries(x)), (i))
+#define ECB_entries_reg_offset(x, i) EVENT_REG_offset((ECB_entries(x)), (i))
+#define ECB_entries_reg_data_size(x, i)                                        \
+	EVENT_REG_data_size((ECB_entries(x)), (i))
+#define ECB_entries_desc_id(x, i) EVENT_REG_desc_id((ECB_entries(x)), i)
+#define ECB_entries_flags(x, i) EVENT_REG_flags((ECB_entries(x)), i)
+#define ECB_entries_reg_order(x, i) EVENT_REG_reg_order((ECB_entries(x)), i)
+#define ECB_entries_reg_value(x, i) EVENT_REG_reg_value((ECB_entries(x)), (i))
+#define ECB_entries_max_bits(x, i) EVENT_REG_max_bits((ECB_entries(x)), (i))
+#define ECB_entries_scheduled(x, i) EVENT_REG_scheduled((ECB_entries(x)), (i))
+#define ECB_entries_counter_event_offset(x, i)                                 \
+	EVENT_REG_counter_event_offset((ECB_entries(x)), (i))
+#define ECB_entries_bit_position(x, i)                                         \
+	EVENT_REG_bit_position((ECB_entries(x)), (i))
+// PCI config-specific fields
+#define ECB_entries_bus_no(x, i) EVENT_REG_bus_no((ECB_entries(x)), (i))
+#define ECB_entries_dev_no(x, i) EVENT_REG_dev_no((ECB_entries(x)), (i))
+#define ECB_entries_func_no(x, i) EVENT_REG_func_no((ECB_entries(x)), (i))
+#define ECB_entries_counter_type(x, i)                                         \
+	EVENT_REG_counter_type((ECB_entries(x)), (i))
+#define ECB_entries_event_scope(x, i)                                          \
+	EVENT_REG_event_scope((ECB_entries(x)), (i))
+#define ECB_entries_precise_get(x, i)                                          \
+	EVENT_REG_precise_get((ECB_entries(x)), (i))
+#define ECB_entries_global_get(x, i) EVENT_REG_global_get((ECB_entries(x)), (i))
+#define ECB_entries_uncore_get(x, i) EVENT_REG_uncore_get((ECB_entries(x)), (i))
+#define ECB_entries_uncore_q_rst_get(x, i)                                     \
+	EVENT_REG_uncore_q_rst_get((ECB_entries(x)), (i))
+#define ECB_entries_is_gp_reg_get(x, i)                                        \
+	EVENT_REG_is_gp_reg_get((ECB_entries(x)), (i))
+#define ECB_entries_lbr_value_get(x, i)                                        \
+	EVENT_REG_lbr_value_get((ECB_entries(x)), (i))
+#define ECB_entries_fixed_reg_get(x, i)                                        \
+	EVENT_REG_fixed_reg_get((ECB_entries(x)), (i))
+#define ECB_entries_is_multi_pkg_bit_set(x, i)                                 \
+	EVENT_REG_multi_pkg_evt_bit_get((ECB_entries(x)), (i))
+#define ECB_entries_clean_up_get(x, i)                                         \
+	EVENT_REG_clean_up_get((ECB_entries(x)), (i))
+#define ECB_entries_em_trigger_get(x, i)                                       \
+	EVENT_REG_em_trigger_get((ECB_entries(x)), (i))
+#define ECB_entries_branch_evt_get(x, i)                                       \
+	EVENT_REG_branch_evt_get((ECB_entries(x)), (i))
+#define ECB_entries_reg_rw_type(x, i)                                          \
+	EVENT_REG_reg_rw_type((ECB_entries(x)), (i))
+#define ECB_entries_secondary_pci_offset_offset(x, i)                          \
+	EVENT_REG_secondary_pci_offset_offset((ECB_entries(x)), (i))
+#define ECB_entries_secondary_pci_offset_shift(x, i)                           \
+	EVENT_REG_secondary_pci_offset_shift((ECB_entries(x)), (i))
+#define ECB_entries_secondary_pci_offset_mask(x, i)                            \
+	EVENT_REG_secondary_pci_offset_mask((ECB_entries(x)), (i))
+#define ECB_operations_operation_type(x, i)                                    \
+	PMU_OPER_operation_type((ECB_operations(x)), (i))
+#define ECB_operations_register_start(x, i)                                    \
+	PMU_OPER_register_start((ECB_operations(x)), (i))
+#define ECB_operations_register_len(x, i)                                      \
+	PMU_OPER_register_len((ECB_operations(x)), (i))
+
+#define ECB_entries_core_event_id(x, i)                                        \
+	EVENT_REG_core_event_id((ECB_entries(x)), (i))
+#define ECB_entries_uncore_buffer_offset_in_package(x, i)                      \
+	EVENT_REG_uncore_buffer_offset_in_package((ECB_entries(x)), (i))
+#define ECB_entries_uncore_buffer_offset_in_system(x, i)                       \
+	EVENT_REG_uncore_buffer_offset_in_system((ECB_entries(x)), (i))
+
+#define ECB_SET_OPERATIONS(x, operation_type, start, len)                      \
+	{                                                                      \
+		ECB_operations_operation_type(x, operation_type) = operation_type;     \
+		ECB_operations_register_start(x, operation_type) = start;              \
+		ECB_operations_register_len(x, operation_type) = len;          \
+	}
+
+
+// ***************************************************************************
+
+/*!\struct  LBR_ENTRY_NODE_S
+ * \var     etype       TOS = 0; FROM = 1; TO = 2
+ * \var     type_index
+ * \var     reg_id
+ */
+
+typedef struct LBR_ENTRY_NODE_S LBR_ENTRY_NODE;
+typedef LBR_ENTRY_NODE * LBR_ENTRY;
+
+struct LBR_ENTRY_NODE_S {
+	U16 etype;
+	U16 type_index;
+	U32 reg_id;
+};
+
+//
+// Accessor macros for LBR entries
+//
+#define LBR_ENTRY_NODE_etype(lentry) ((lentry).etype)
+#define LBR_ENTRY_NODE_type_index(lentry) ((lentry).type_index)
+#define LBR_ENTRY_NODE_reg_id(lentry) ((lentry).reg_id)
+
+// ***************************************************************************
+
+/*!\struct LBR_NODE_S
+ * \var    num_entries     -  The number of entries
+ * \var    entries         -  The entries in the list
+ *
+ * \brief  Data structure to describe the LBR registers that need to be read
+ *
+ */
+
+typedef struct LBR_NODE_S LBR_NODE;
+typedef LBR_NODE * LBR;
+
+struct LBR_NODE_S {
+	U32 size;
+	U32 num_entries;
+	LBR_ENTRY_NODE entries[];
+};
+
+//
+// Accessor macros for LBR node
+//
+#define LBR_size(lbr) ((lbr)->size)
+#define LBR_num_entries(lbr) ((lbr)->num_entries)
+#define LBR_entries_etype(lbr, idx) ((lbr)->entries[idx].etype)
+#define LBR_entries_type_index(lbr, idx) ((lbr)->entries[idx].type_index)
+#define LBR_entries_reg_id(lbr, idx) ((lbr)->entries[idx].reg_id)
+
+// ***************************************************************************
+
+/*!\struct  PWR_ENTRY_NODE_S
+ * \var     etype       none as yet
+ * \var     type_index
+ * \var     reg_id
+ */
+
+typedef struct PWR_ENTRY_NODE_S PWR_ENTRY_NODE;
+typedef PWR_ENTRY_NODE * PWR_ENTRY;
+
+struct PWR_ENTRY_NODE_S {
+	U16 etype;
+	U16 type_index;
+	U32 reg_id;
+};
+
+//
+// Accessor macros for PWR entries
+//
+#define PWR_ENTRY_NODE_etype(lentry) ((lentry).etype)
+#define PWR_ENTRY_NODE_type_index(lentry) ((lentry).type_index)
+#define PWR_ENTRY_NODE_reg_id(lentry) ((lentry).reg_id)
+
+// ***************************************************************************
+
+/*!\struct PWR_NODE_S
+ * \var    num_entries     -  The number of entries
+ * \var    entries         -  The entries in the list
+ *
+ * \brief  Data structure to describe the PWR registers that need to be read
+ *
+ */
+
+typedef struct PWR_NODE_S PWR_NODE;
+typedef PWR_NODE * PWR;
+
+struct PWR_NODE_S {
+	U32 size;
+	U32 num_entries;
+	PWR_ENTRY_NODE entries[];
+};
+
+//
+// Accessor macros for PWR node
+//
+#define PWR_size(lentry) ((lentry)->size)
+#define PWR_num_entries(lentry) ((lentry)->num_entries)
+#define PWR_entries_etype(lentry, idx) ((lentry)->entries[idx].etype)
+#define PWR_entries_type_index(lentry, idx) ((lentry)->entries[idx].type_index)
+#define PWR_entries_reg_id(lentry, idx) ((lentry)->entries[idx].reg_id)
+
+// ***************************************************************************
+
+/*!\struct  RO_ENTRY_NODE_S
+ * \var     type       - DEAR, IEAR, BTB.
+ */
+
+typedef struct RO_ENTRY_NODE_S RO_ENTRY_NODE;
+typedef RO_ENTRY_NODE * RO_ENTRY;
+
+struct RO_ENTRY_NODE_S {
+	U32 reg_id;
+};
+
+//
+// Accessor macros for RO entries
+//
+#define RO_ENTRY_NODE_reg_id(lentry) ((lentry).reg_id)
+
+// ***************************************************************************
+
+/*!\struct RO_NODE_S
+ * \var    size            - The total size including header and entries.
+ * \var    num_entries     - The number of entries.
+ * \var    entries         - The entries in the list.
+ *
+ * \brief  Data structure to describe the RO registers that need to be read.
+ *
+ */
+
+typedef struct RO_NODE_S RO_NODE;
+typedef RO_NODE * RO;
+
+struct RO_NODE_S {
+	U32 size;
+	U32 num_entries;
+	RO_ENTRY_NODE entries[];
+};
+
+//
+// Accessor macros for RO node
+//
+#define RO_size(ro) ((ro)->size)
+#define RO_num_entries(ro) ((ro)->num_entries)
+#define RO_entries_reg_id(ro, idx) ((ro)->entries[idx].reg_id)
+
+#if defined(__cplusplus)
+}
+#endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/lwpmudrv_ioctl.h b/drivers/platform/x86/socperf/include/lwpmudrv_ioctl.h
new file mode 100644
index 000000000000..0b1ee130c8b5
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/lwpmudrv_ioctl.h
@@ -0,0 +1,343 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2007-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2007-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#ifndef _LWPMUDRV_IOCTL_H_
+#define _LWPMUDRV_IOCTL_H_
+
+#if defined(__cplusplus)
+extern "C" {
+#endif
+
+//SEP Driver Operation defines
+//
+#define DRV_OPERATION_START 1
+#define DRV_OPERATION_STOP 2
+#define DRV_OPERATION_INIT_PMU 3
+#define DRV_OPERATION_GET_NORMALIZED_TSC 4
+#define DRV_OPERATION_TSC_SKEW_INFO 5
+#define DRV_OPERATION_PAUSE 6
+#define DRV_OPERATION_RESUME 7
+#define DRV_OPERATION_TERMINATE 8
+#define DRV_OPERATION_RESERVE 9
+#define DRV_OPERATION_VERSION 10
+#define DRV_OPERATION_SWITCH_GROUP 11
+#define DRV_OPERATION_GET_DRIVER_STATE 12
+#define DRV_OPERATION_INIT_UNCORE 13
+#define DRV_OPERATION_EM_GROUPS_UNCORE 14
+#define DRV_OPERATION_EM_CONFIG_NEXT_UNCORE 15
+#define DRV_OPERATION_READ_UNCORE_DATA 16
+#define DRV_OPERATION_STOP_MEM 17
+#define DRV_OPERATION_CREATE_MEM 18
+#define DRV_OPERATION_READ_MEM 19
+#define DRV_OPERATION_CHECK_STATUS 20
+#define DRV_OPERATION_TIMER_TRIGGER_READ 21
+#define DRV_OPERATION_INIT_DRIVER 22
+
+// IOCTL_SETUP
+//
+
+#if defined(DRV_OS_WINDOWS)
+
+//
+// NtDeviceIoControlFile IoControlCode values for this device.
+//
+// Warning:  Remember that the low two bits of the code specify how the
+//           buffers are passed to the driver!
+//
+// 16 bit device type. 12 bit function codes
+#define LWPMUDRV_IOCTL_DEVICE_TYPE                                             \
+	0xA000 // values 0-32768 reserved for Microsoft
+#define LWPMUDRV_IOCTL_FUNCTION 0x0A00 // values 0-2047  reserved for Microsoft
+
+//
+// Basic CTL CODE macro to reduce typographical errors
+// Use for FILE_READ_ACCESS
+//
+#define LWPMUDRV_CTL_READ_CODE(x)                                              \
+	CTL_CODE(LWPMUDRV_IOCTL_DEVICE_TYPE, LWPMUDRV_IOCTL_FUNCTION + (x),    \
+		 METHOD_BUFFERED, FILE_READ_ACCESS)
+
+#define LWPMUDRV_IOCTL_START LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_START)
+#define LWPMUDRV_IOCTL_STOP LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_STOP)
+#define LWPMUDRV_IOCTL_INIT_PMU LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_INIT_PMU)
+#define LWPMUDRV_IOCTL_GET_NORMALIZED_TSC                                      \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_GET_NORMALIZED_TSC)
+#define LWPMUDRV_IOCTL_TSC_SKEW_INFO                                           \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_TSC_SKEW_INFO)
+#define LWPMUDRV_IOCTL_PAUSE LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_PAUSE)
+#define LWPMUDRV_IOCTL_RESUME LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_RESUME)
+#define LWPMUDRV_IOCTL_TERMINATE LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_TERMINATE)
+#define LWPMUDRV_IOCTL_RESERVE LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_RESERVE)
+#define LWPMUDRV_IOCTL_VERSION LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_VERSION)
+#define LWPMUDRV_IOCTL_SWITCH_GROUP                                            \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_SWITCH_GROUP)
+#define LWPMUDRV_IOCTL_GET_DRIVER_STATE                                        \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_GET_DRIVER_STATE)
+#define LWPMUDRV_IOCTL_INIT_UNCORE                                             \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_INIT_UNCORE)
+#define LWPMUDRV_IOCTL_EM_GROUPS_UNCORE                                        \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_EM_GROUPS_UNCORE)
+#define LWPMUDRV_IOCTL_EM_CONFIG_NEXT_UNCORE                                   \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_EM_CONFIG_NEXT_UNCORE)
+#define LWPMUDRV_IOCTL_READ_UNCORE_DATA                                        \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_READ_UNCORE_DATA)
+#define LWPMUDRV_IOCTL_STOP_MEM LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_STOP_MEM)
+#define LWPMUDRV_IOCTL_CREATE_MEM                                              \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_CREATE_MEM)
+#define LWPMUDRV_IOCTL_READ_MEM LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_READ_MEM)
+#define LWPMUDRV_IOCTL_CHECK_STATUS                                            \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_CHECK_STATUS)
+#define LWPMUDRV_IOCTL_TIMER_TRIGGER_READ                                      \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_TIMER_TRIGGER_READ)
+#define LWPMUDRV_IOCTL_INIT_DRIVER                                             \
+	LWPMUDRV_CTL_READ_CODE(DRV_OPERATION_INIT_DRIVER)
+
+#elif defined(DRV_OS_LINUX) || defined(DRV_OS_SOLARIS) ||                      \
+	defined(DRV_OS_ANDROID)
+// IOCTL_ARGS
+typedef struct IOCTL_ARGS_NODE_S IOCTL_ARGS_NODE;
+typedef IOCTL_ARGS_NODE * IOCTL_ARGS;
+struct IOCTL_ARGS_NODE_S {
+	U64 len_drv_to_usr;
+	U64 len_usr_to_drv;
+	char *buf_drv_to_usr;
+	char *buf_usr_to_drv;
+};
+
+// COMPAT IOCTL_ARGS
+#if defined(CONFIG_COMPAT) && defined(DRV_EM64T)
+typedef struct IOCTL_COMPAT_ARGS_NODE_S IOCTL_COMPAT_ARGS_NODE;
+typedef IOCTL_COMPAT_ARGS_NODE * IOCTL_COMPAT_ARGS;
+struct IOCTL_COMPAT_ARGS_NODE_S {
+	U64 len_drv_to_usr;
+	U64 len_usr_to_drv;
+	compat_uptr_t buf_drv_to_usr;
+	compat_uptr_t buf_usr_to_drv;
+};
+#endif
+
+#define LWPMU_IOC_MAGIC 99
+
+// IOCTL_SETUP
+//
+#define LWPMUDRV_IOCTL_START _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_START)
+#define LWPMUDRV_IOCTL_STOP _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_STOP)
+#define LWPMUDRV_IOCTL_INIT_PMU                                                \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_INIT_PMU, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_GET_NORMALIZED_TSC                                      \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_GET_NORMALIZED_TSC, int)
+#define LWPMUDRV_IOCTL_TSC_SKEW_INFO                                           \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_TSC_SKEW_INFO, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_PAUSE _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_PAUSE)
+#define LWPMUDRV_IOCTL_RESUME _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_RESUME)
+#define LWPMUDRV_IOCTL_TERMINATE _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_TERMINATE)
+#define LWPMUDRV_IOCTL_RESERVE                                                 \
+	_IOR(LWPMU_IOC_MAGIC, DRV_OPERATION_RESERVE, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_VERSION                                                 \
+	_IOR(LWPMU_IOC_MAGIC, DRV_OPERATION_VERSION, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_SWITCH_GROUP                                            \
+	_IO(LWPMU_IOC_MAGIC, DRV_OPERATION_SWITCH_GROUP)
+#define LWPMUDRV_IOCTL_GET_DRIVER_STATE                                        \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_GET_DRIVER_STATE, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_INIT_UNCORE                                             \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_INIT_UNCORE, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_EM_GROUPS_UNCORE                                        \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_EM_GROUPS_UNCORE, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_EM_CONFIG_NEXT_UNCORE                                   \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_EM_CONFIG_NEXT_UNCORE, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_READ_UNCORE_DATA                                        \
+	_IOR(LWPMU_IOC_MAGIC, DRV_OPERATION_READ_UNCORE_DATA, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_STOP_MEM _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_STOP_MEM)
+#define LWPMUDRV_IOCTL_CREATE_MEM                                              \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_CREATE_MEM, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_READ_MEM                                                \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_READ_MEM, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_CHECK_STATUS                                            \
+	_IOR(LWPMU_IOC_MAGIC, DRV_OPERATION_CHECK_STATUS, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_TIMER_TRIGGER_READ                                      \
+	_IO(LWPMU_IOC_MAGIC, DRV_OPERATION_TIMER_TRIGGER_READ)
+#define LWPMUDRV_IOCTL_INIT_DRIVER                                             \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_INIT_DRIVER, IOCTL_ARGS)
+
+#elif defined(DRV_OS_FREEBSD)
+
+// IOCTL_ARGS
+typedef struct IOCTL_ARGS_NODE_S IOCTL_ARGS_NODE;
+typedef IOCTL_ARGS_NODE * IOCTL_ARGS;
+struct IOCTL_ARGS_NODE_S {
+	U64 len_drv_to_usr;
+	char *buf_drv_to_usr;
+	U64 len_usr_to_drv;
+	char *buf_usr_to_drv;
+};
+
+// IOCTL_SETUP
+//
+#define LWPMU_IOC_MAGIC 99
+
+/* FreeBSD is very strict about IOR/IOW/IOWR specifications on IOCTLs.
+ * Since these IOCTLs all pass down the real read/write buffer lengths
+ *  and addresses inside of an IOCTL_ARGS_NODE data structure, we
+ *  need to specify all of these as _IOW so that the kernel will
+ *  view it as userspace passing the data to the driver, rather than
+ *  the reverse.  There are also some cases where Linux is passing
+ *  a smaller type than IOCTL_ARGS_NODE, even though its really
+ *  passing an IOCTL_ARGS_NODE.  These needed to be fixed for FreeBSD.
+ */
+#define LWPMUDRV_IOCTL_START _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_START)
+#define LWPMUDRV_IOCTL_STOP _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_STOP)
+#define LWPMUDRV_IOCTL_INIT_PMU _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_INIT_PMU)
+#define LWPMUDRV_IOCTL_GET_NORMALIZED_TSC                                      \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_GET_NORMALIZED_TSC, IOCTL_ARGS_NODE)
+#define LWPMUDRV_IOCTL_TSC_SKEW_INFO                                           \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_TSC_SKEW_INFO, IOCTL_ARGS_NODE)
+#define LWPMUDRV_IOCTL_PAUSE _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_PAUSE)
+#define LWPMUDRV_IOCTL_RESUME _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_RESUME)
+#define LWPMUDRV_IOCTL_TERMINATE _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_TERMINATE)
+#define LWPMUDRV_IOCTL_RESERVE                                                 \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_RESERVE, IOCTL_ARGS_NODE)
+#define LWPMUDRV_IOCTL_VERSION                                                 \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_VERSION, IOCTL_ARGS_NODE)
+#define LWPMUDRV_IOCTL_SWITCH_GROUP                                            \
+	_IO(LWPMU_IOC_MAGIC, DRV_OPERATION_SWITCH_GROUP)
+#define LWPMUDRV_IOCTL_GET_DRIVER_STATE                                        \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_GET_DRIVER_STATE, IOCTL_ARGS_NODE)
+#define LWPMUDRV_IOCTL_INIT_UNCORE                                             \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_INIT_UNCORE, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_EM_GROUPS_UNCORE                                        \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_EM_GROUPS_UNCORE, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_EM_CONFIG_NEXT_UNCORE                                   \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_EM_CONFIG_NEXT_UNCORE, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_READ_UNCORE_DATA                                        \
+	_IOR(LWPMU_IOC_MAGIC, DRV_OPERATION_READ_UNCORE_DATA, IOCTL_ARGS)
+#define LWPMUDRV_IOCTL_STOP_MEM _IO(LWPMU_IOC_MAGIC, DRV_OPERATION_STOP_MEM)
+#define LWPMUDRV_IOCTL_CREATE_MEM                                              \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_CREATE_MEM, IOCTL_ARGS_NODE)
+#define LWPMUDRV_IOCTL_READ_MEM                                                \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_READ_MEM, IOCTL_ARGS_NODE)
+#define LWPMUDRV_IOCTL_CHECK_STATUS                                            \
+	_IOR(LWPMU_IOC_MAGIC, DRV_OPERATION_CHECK_STATUS, IOCTL_ARGS_NODE)
+#define LWPMUDRV_IOCTL_TIMER_TRIGGER_READ                                      \
+	_IO(LWPMU_IOC_MAGIC, DRV_OPERATION_TIMER_TRIGGER_READ)
+#define LWPMUDRV_IOCTL_INIT_DRIVER                                             \
+	_IOW(LWPMU_IOC_MAGIC, DRV_OPERATION_INIT_DRIVER, IOCTL_ARGS)
+
+#elif defined(DRV_OS_MAC)
+
+// IOCTL_ARGS
+typedef struct IOCTL_ARGS_NODE_S IOCTL_ARGS_NODE;
+typedef IOCTL_ARGS_NODE * IOCTL_ARGS;
+struct IOCTL_ARGS_NODE_S {
+	U64 len_drv_to_usr;
+	char *buf_drv_to_usr;
+	U64 len_usr_to_drv;
+	char *buf_usr_to_drv;
+	U32 command;
+};
+
+typedef struct CPU_ARGS_NODE_S CPU_ARGS_NODE;
+typedef CPU_ARGS_NODE * CPU_ARGS;
+struct CPU_ARGS_NODE_S {
+	U64 len_drv_to_usr;
+	char *buf_drv_to_usr;
+	U32 command;
+	U32 CPU_ID;
+	U32 BUCKET_ID;
+};
+
+// IOCTL_SETUP
+//
+#define LWPMU_IOC_MAGIC 99
+#define OS_SUCCESS 0
+#define OS_STATUS int
+#define OS_ILLEGAL_IOCTL -ENOTTY
+#define OS_NO_MEM -ENOMEM
+#define OS_FAULT -EFAULT
+
+// Task file Opcodes.
+// keeping the definitions as IOCTL but in MAC OSX
+// these are really OpCodes consumed by Execute command.
+#define LWPMUDRV_IOCTL_START DRV_OPERATION_START
+#define LWPMUDRV_IOCTL_STOP DRV_OPERATION_STOP
+#define LWPMUDRV_IOCTL_INIT_PMU DRV_OPERATION_INIT_PMU
+#define LWPMUDRV_IOCTL_GET_NORMALIZED_TSC DRV_OPERATION_GET_NORMALIZED_TSC
+#define LWPMUDRV_IOCTL_TSC_SKEW_INFO DRV_OPERATION_TSC_SKEW_INFO
+#define LWPMUDRV_IOCTL_PAUSE DRV_OPERATION_PAUSE
+#define LWPMUDRV_IOCTL_RESUME DRV_OPERATION_RESUME
+#define LWPMUDRV_IOCTL_TERMINATE DRV_OPERATION_TERMINATE
+#define LWPMUDRV_IOCTL_RESERVE DRV_OPERATION_RESERVE
+#define LWPMUDRV_IOCTL_VERSION DRV_OPERATION_VERSION
+#define LWPMUDRV_IOCTL_SWITCH_GROUP DRV_OPERATION_SWITCH_GROUP
+#define LWPMUDRV_IOCTL_GET_DRIVER_STATE DRV_OPERATION_GET_DRIVER_STATE
+#define LWPMUDRV_IOCTL_INIT_UNCORE DRV_OPERATION_INIT_UNCORE
+#define LWPMUDRV_IOCTL_EM_GROUPS_UNCORE DRV_OPERATION_EM_GROUPS_UNCORE
+#define LWPMUDRV_IOCTL_EM_CONFIG_NEXT_UNCORE DRV_OPERATION_EM_CONFIG_NEXT_UNCORE
+#define LWPMUDRV_IOCTL_READ_UNCORE_DATA DRV_OPERATION_READ_UNCORE_DATA
+#define LWPMUDRV_IOCTL_STOP_MEM DRV_OPERATION_STOP_MEM
+#define LWPMUDRV_IOCTL_CREATE_MEM DRV_OPERATION_CREATE_MEM
+#define LWPMUDRV_IOCTL_READ_MEM DRV_OPERATION_READ_MEM
+#define LWPMUDRV_IOCTL_CHECK_STATUS DRV_OPERATION_CHECK_STATUS
+#define LWPMUDRV_IOCTL_TIMER_TRIGGER_READ DRV_OPERATION_TIMER_TRIGGER_READ
+#define LWPMUDRV_IOCTL_INIT_DRIVER DRV_OPERATION_INIT_DRIVER
+
+// This is only for MAC OSX
+#define LWPMUDRV_IOCTL_SET_OSX_VERSION 998
+#define LWPMUDRV_IOCTL_PROVIDE_FUNCTION_PTRS 999
+
+#else
+#error "unknown OS in lwpmudrv_ioctl.h"
+#endif
+
+#if defined(__cplusplus)
+}
+#endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/lwpmudrv_struct.h b/drivers/platform/x86/socperf/include/lwpmudrv_struct.h
new file mode 100644
index 000000000000..1966e6282149
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/lwpmudrv_struct.h
@@ -0,0 +1,2014 @@
+/***
+ * -------------------------------------------------------------------------
+ *               INTEL CORPORATION PROPRIETARY INFORMATION
+ *  This software is supplied under the terms of the accompanying license
+ *  agreement or nondisclosure agreement with Intel Corporation and may not
+ *  be copied or disclosed except in accordance with the terms of that
+ *  agreement.
+ *        Copyright(C) 2007-2019 Intel Corporation.  All Rights Reserved.
+ * -------------------------------------------------------------------------
+***/
+
+#ifndef _LWPMUDRV_STRUCT_UTILS_H_
+#define _LWPMUDRV_STRUCT_UTILS_H_
+
+#if defined(__cplusplus)
+extern "C" {
+#endif
+
+// processor execution modes
+#define MODE_UNKNOWN 99
+// the following defines must start at 0
+#define MODE_64BIT 3
+#define MODE_32BIT 2
+#define MODE_16BIT 1
+#define MODE_V86 0
+
+// sampling methods
+#define SM_RTC 2020 // real time clock
+#define SM_VTD 2021 // OS Virtual Timer Device
+#define SM_NMI 2022 // non-maskable interrupt time based
+#define SM_EBS 2023 // event based sampling
+#define SM_EBC 2024 // event based counting
+
+// sampling mechanism bitmap definitions
+#define INTERRUPT_RTC 0x1
+#define INTERRUPT_VTD 0x2
+#define INTERRUPT_NMI 0x4
+#define INTERRUPT_EBS 0x8
+
+// Device types
+#define DEV_CORE 0x01
+#define DEV_UNC 0x02
+
+// eflags defines
+#define EFLAGS_VM 0x00020000 // V86 mode
+#define EFLAGS_IOPL0 0
+#define EFLAGS_IOPL1 0x00001000
+#define EFLAGS_IOPL2 0x00002000
+#define EFLAGS_IOPL3 0x00003000
+#define MAX_EMON_GROUPS 1000
+#define MAX_PCI_BUSNO 256
+#define MAX_DEVICES 30
+#define MAX_REGS 64
+#define MAX_EMON_GROUPS 1000
+#define MAX_PCI_DEVNO 32
+#define MAX_PCI_FUNCNO 8
+#define MAX_PCI_DEVUNIT 16
+#define MAX_TURBO_VALUES 32
+#define REG_BIT_MASK 0xFFFFFFFFFFFFFFFFULL
+
+extern float freq_multiplier;
+
+// Enumeration for invoking dispatch on multiple cpus or not
+typedef enum { DRV_MULTIPLE_INSTANCE = 0, DRV_SINGLE_INSTANCE } DRV_PROG_TYPE;
+
+typedef struct DRV_CONFIG_NODE_S DRV_CONFIG_NODE;
+typedef DRV_CONFIG_NODE * DRV_CONFIG;
+
+struct DRV_CONFIG_NODE_S {
+	U32 size;
+	U16 version;
+	U16 reserved1;
+	U32 num_events;
+	U32 num_chipset_events;
+	U32 chipset_offset;
+	S32 seed_name_len;
+	union {
+		S8 *seed_name;
+		U64 dummy1;
+	} u1;
+	union {
+		S8 *cpu_mask;
+		U64 dummy2;
+	} u2;
+	union {
+		U64 collection_config;
+		struct {
+			U64 start_paused : 1;
+			U64 counting_mode : 1;
+			U64 enable_chipset : 1;
+			U64 enable_gfx : 1;
+			U64 enable_pwr : 1;
+			U64 emon_mode : 1;
+			U64 debug_inject : 1;
+			U64 virt_phys_translation : 1;
+			U64 enable_p_state : 1;
+			U64 enable_cp_mode : 1;
+			U64 read_pstate_msrs : 1;
+			U64 use_pcl : 1;
+			U64 enable_ebc : 1;
+			U64 enable_tbc : 1;
+			U64 ds_area_available : 1;
+			U64 per_cpu_tsc : 1;
+			U64 reserved_field1 : 48;
+		} s1;
+	} u3;
+	U64 target_pid;
+	U32 os_of_interest;
+	U16 unc_timer_interval;
+	U16 unc_em_factor;
+	S32 p_state_trigger_index;
+	DRV_BOOL multi_pebs_enabled;
+	U32 reserved2;
+	U32 reserved3;
+	U64 reserved4;
+	U64 reserved5;
+	U64 reserved6;
+};
+
+#define DRV_CONFIG_size(cfg) ((cfg)->size)
+#define DRV_CONFIG_version(cfg) ((cfg)->version)
+#define DRV_CONFIG_num_events(cfg) ((cfg)->num_events)
+#define DRV_CONFIG_num_chipset_events(cfg) ((cfg)->num_chipset_events)
+#define DRV_CONFIG_chipset_offset(cfg) ((cfg)->chipset_offset)
+
+#define DRV_CONFIG_seed_name(cfg) ((cfg)->u1.seed_name)
+#define DRV_CONFIG_seed_name_len(cfg) ((cfg)->seed_name_len)
+#define DRV_CONFIG_cpu_mask(cfg) ((cfg)->u2.cpu_mask)
+#define DRV_CONFIG_start_paused(cfg) ((cfg)->u3.s1.start_paused)
+#define DRV_CONFIG_counting_mode(cfg) ((cfg)->u3.s1.counting_mode)
+#define DRV_CONFIG_enable_chipset(cfg) ((cfg)->u3.s1.enable_chipset)
+#define DRV_CONFIG_enable_gfx(cfg) ((cfg)->u3.s1.enable_gfx)
+#define DRV_CONFIG_enable_pwr(cfg) ((cfg)->u3.s1.enable_pwr)
+#define DRV_CONFIG_emon_mode(cfg) ((cfg)->u3.s1.emon_mode)
+#define DRV_CONFIG_debug_inject(cfg) ((cfg)->u3.s1.debug_inject)
+#define DRV_CONFIG_virt_phys_translation(cfg) ((cfg)->u3.s1.virt_phys_translation)
+#define DRV_CONFIG_enable_p_state(cfg) ((cfg)->u3.s1.enable_p_state)
+#define DRV_CONFIG_enable_cp_mode(cfg) ((cfg)->u3.s1.enable_cp_mode)
+#define DRV_CONFIG_read_pstate_msrs(cfg) ((cfg)->u3.s1.read_pstate_msrs)
+#define DRV_CONFIG_use_pcl(cfg) ((cfg)->u3.s1.use_pcl)
+#define DRV_CONFIG_event_based_counts(cfg) ((cfg)->u3.s1.enable_ebc)
+#define DRV_CONFIG_timer_based_counts(cfg) ((cfg)->u3.s1.enable_tbc)
+#define DRV_CONFIG_ds_area_available(cfg) ((cfg)->u3.s1.ds_area_available)
+#define DRV_CONFIG_per_cpu_tsc(cfg) ((cfg)->u3.s1.per_cpu_tsc)
+#define DRV_CONFIG_target_pid(cfg) ((cfg)->target_pid)
+#define DRV_CONFIG_os_of_interest(cfg) ((cfg)->os_of_interest)
+#define DRV_CONFIG_unc_timer_interval(cfg) ((cfg)->unc_timer_interval)
+#define DRV_CONFIG_unc_em_factor(cfg) ((cfg)->unc_em_factor)
+#define DRV_CONFIG_p_state_trigger_index(cfg) ((cfg)->p_state_trigger_index)
+#define DRV_CONFIG_multi_pebs_enabled(cfg) ((cfg)->multi_pebs_enabled)
+
+#define DRV_CONFIG_VERSION 1
+
+typedef struct DEV_CONFIG_NODE_S DEV_CONFIG_NODE;
+typedef DEV_CONFIG_NODE * DEV_CONFIG;
+
+struct DEV_CONFIG_NODE_S {
+	U16 size;
+	U16 version;
+	U32 dispatch_id;
+	U32 pebs_mode;
+	U32 pebs_record_num;
+	U32 results_offset; // this is to store the offset for this device's results
+	U32 max_gp_counters;
+	U32 device_type;
+	U32 core_type;
+	union {
+		U64 enable_bit_fields;
+		struct {
+			U64 pebs_capture : 1;
+			U64 collect_lbrs : 1;
+			U64 collect_callstacks : 1;
+			U64 collect_kernel_callstacks : 1;
+			U64 latency_capture : 1;
+			U64 power_capture : 1;
+			U64 htoff_mode : 1;
+			U64 eventing_ip_capture : 1;
+			U64 hle_capture : 1;
+			U64 precise_ip_lbrs : 1;
+			U64 store_lbrs : 1;
+			U64 tsc_capture : 1;
+			U64 enable_perf_metrics : 1;
+			U64 enable_adaptive_pebs : 1;
+			U64 apebs_collect_mem_info : 1;
+			U64 apebs_collect_gpr : 1;
+			U64 apebs_collect_xmm : 1;
+			U64 apebs_collect_lbrs : 1;
+			U64 collect_fixed_counter_pebs : 1;
+			U64 collect_os_callstacks : 1;
+			U64 reserved_field1 : 44;
+		} s1;
+	} u1;
+	U32 emon_unc_offset[MAX_EMON_GROUPS];
+	U32 ebc_group_id_offset;
+	U8 num_perf_metrics;
+	U8 apebs_num_lbr_entries;
+	U16 emon_perf_metrics_offset;
+	U32 device_scope;
+	U32 reserved1;
+	U64 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+
+#define DEV_CONFIG_dispatch_id(cfg) ((cfg)->dispatch_id)
+#define DEV_CONFIG_pebs_mode(cfg) ((cfg)->pebs_mode)
+#define DEV_CONFIG_pebs_record_num(cfg) ((cfg)->pebs_record_num)
+#define DEV_CONFIG_results_offset(cfg) ((cfg)->results_offset)
+#define DEV_CONFIG_max_gp_counters(cfg) ((cfg)->max_gp_counters)
+
+#define DEV_CONFIG_device_type(cfg) ((cfg)->device_type)
+#define DEV_CONFIG_core_type(cfg) ((cfg)->core_type)
+
+#define DEV_CONFIG_pebs_capture(cfg) ((cfg)->u1.s1.pebs_capture)
+#define DEV_CONFIG_collect_lbrs(cfg) ((cfg)->u1.s1.collect_lbrs)
+#define DEV_CONFIG_collect_callstacks(cfg) ((cfg)->u1.s1.collect_callstacks)
+#define DEV_CONFIG_collect_kernel_callstacks(cfg)                              \
+	((cfg)->u1.s1.collect_kernel_callstacks)
+#define DEV_CONFIG_latency_capture(cfg) ((cfg)->u1.s1.latency_capture)
+#define DEV_CONFIG_power_capture(cfg) ((cfg)->u1.s1.power_capture)
+#define DEV_CONFIG_htoff_mode(cfg) ((cfg)->u1.s1.htoff_mode)
+#define DEV_CONFIG_eventing_ip_capture(cfg) ((cfg)->u1.s1.eventing_ip_capture)
+#define DEV_CONFIG_hle_capture(cfg) ((cfg)->u1.s1.hle_capture)
+#define DEV_CONFIG_precise_ip_lbrs(cfg) ((cfg)->u1.s1.precise_ip_lbrs)
+#define DEV_CONFIG_store_lbrs(cfg) ((cfg)->u1.s1.store_lbrs)
+#define DEV_CONFIG_tsc_capture(cfg) ((cfg)->u1.s1.tsc_capture)
+#define DEV_CONFIG_enable_perf_metrics(cfg) ((cfg)->u1.s1.enable_perf_metrics)
+#define DEV_CONFIG_enable_adaptive_pebs(cfg) ((cfg)->u1.s1.enable_adaptive_pebs)
+#define DEV_CONFIG_apebs_collect_mem_info(cfg)                                 \
+	((cfg)->u1.s1.apebs_collect_mem_info)
+#define DEV_CONFIG_apebs_collect_gpr(cfg) ((cfg)->u1.s1.apebs_collect_gpr)
+#define DEV_CONFIG_apebs_collect_xmm(cfg) ((cfg)->u1.s1.apebs_collect_xmm)
+#define DEV_CONFIG_apebs_collect_lbrs(cfg) ((cfg)->u1.s1.apebs_collect_lbrs)
+#define DEV_CONFIG_collect_fixed_counter_pebs(cfg)                             \
+	((cfg)->u1.s1.collect_fixed_counter_pebs)
+#define DEV_CONFIG_collect_os_callstacks(cfg) ((cfg)->u1.s1.collect_os_callstacks)
+#define DEV_CONFIG_enable_bit_fields(cfg) ((cfg)->u1.enable_bit_fields)
+#define DEV_CONFIG_emon_unc_offset(cfg, grp_num) ((cfg)->emon_unc_offset[grp_num])
+#define DEV_CONFIG_ebc_group_id_offset(cfg) ((cfg)->ebc_group_id_offset)
+#define DEV_CONFIG_num_perf_metrics(cfg) ((cfg)->num_perf_metrics)
+#define DEV_CONFIG_apebs_num_lbr_entries(cfg) ((cfg)->apebs_num_lbr_entries)
+#define DEV_CONFIG_emon_perf_metrics_offset(cfg) ((cfg)->emon_perf_metrics_offset)
+#define DEV_CONFIG_device_scope(cfg) ((cfg)->device_scope)
+
+typedef struct DEV_UNC_CONFIG_NODE_S DEV_UNC_CONFIG_NODE;
+typedef DEV_UNC_CONFIG_NODE * DEV_UNC_CONFIG;
+
+struct DEV_UNC_CONFIG_NODE_S {
+	U16 size;
+	U16 version;
+	U32 dispatch_id;
+	U32 results_offset;
+	U32 device_type;
+	U32 device_scope;
+	U32 reserved1;
+	U32 emon_unc_offset[MAX_EMON_GROUPS];
+	U64 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+
+#define DEV_UNC_CONFIG_dispatch_id(cfg) ((cfg)->dispatch_id)
+#define DEV_UNC_CONFIG_results_offset(cfg) ((cfg)->results_offset)
+#define DEV_UNC_CONFIG_emon_unc_offset(cfg, grp_num)                           \
+	((cfg)->emon_unc_offset[grp_num])
+#define DEV_UNC_CONFIG_device_type(cfg) ((cfg)->device_type)
+#define DEV_UNC_CONFIG_device_scope(cfg) ((cfg)->device_scope)
+
+/*
+ *    X86 processor code descriptor
+ */
+typedef struct CodeDescriptor_s {
+	union {
+		U32 lowWord; // low dword of descriptor
+		struct { // low broken out by fields
+			U16 limitLow; // segment limit 15:00
+			U16 baseLow; // segment base 15:00
+		} s1;
+	} u1;
+	union {
+		U32 highWord; // high word of descriptor
+		struct { // high broken out by bit fields
+			U32 baseMid : 8; // base 23:16
+			U32 accessed : 1; // accessed
+			U32 readable : 1; // readable
+			U32 conforming : 1; // conforming code segment
+			U32 oneOne : 2; // always 11
+			U32 dpl : 2; // Dpl
+			U32 pres : 1; // present bit
+			U32 limitHi : 4; // limit 19:16
+			U32 sys : 1; // available for use by system
+			U32 reserved_0 : 1; // reserved, always 0
+			U32 default_size : 1; // default operation size (1=32bit, 0=16bit)
+			U32 granularity : 1; // granularity (1=32 bit, 0=20 bit)
+			U32 baseHi : 8; // base hi 31:24
+		} s2;
+	} u2;
+} CodeDescriptor;
+
+/*
+ *  Module record.  These are emitted whenever a DLL or EXE is loaded or unloaded.
+ *  The filename fields may be 0 on an unload.  The records reperesent a module for a
+ *  certain span of time, delineated by the load / unload samplecounts.
+ *  Note:
+ *  The structure contains 64 bit fields which may cause the compiler to pad the
+ *  length of the structure to an 8 byte boundary.
+ */
+typedef struct ModuleRecord_s {
+	U16 recLength; // total length of this record (including this length,
+		// always U32 multiple)  output from sampler is variable
+		// length (pathname at end of record) sampfile builder moves
+		// path names to a separate "literal pool" area
+		// so that these records become fixed length, and can be treated
+		// as an array see modrecFixedLen in header
+
+	U16 segmentType : 2; // V86, 16, 32, 64 (see MODE_ defines), maybe inaccurate for Win95
+		// .. a 16 bit module may become a 32 bit module, inferred by
+		// ..looking at 1st sample record that matches the module selector
+	U16 loadEvent : 1; // 0 for load, 1 for unload
+	U16 processed : 1; // 0 for load, 1 for unload
+	U16 reserved0 : 12;
+
+	U16 selector; // code selector or V86 segment
+	U16 segmentNameLength; // length of the segment name if the segmentNameSet bit is set
+	U32 segmentNumber; // segment number, Win95 (and now Java) can have multiple pieces for one module
+	union {
+		U32 flags; // all the flags as one dword
+		struct {
+			U32 exe : 1; // this module is an exe
+			U32 globalModule : 1; // globally loaded module.  There may be multiple
+				// module records for a global module, but the samples
+				// will only point to the 1st one, the others will be
+				// ignored.  NT's Kernel32 is an example of this.
+				// REVISIT this??
+			U32 bogusWin95 : 1; // "bogus" win95 module.  By bogus, we mean a
+				// module that has a pid of 0, no length and no base.
+				// Selector actually used as a 32 bit module.
+			U32 pidRecIndexRaw : 1; // pidRecIndex is raw OS pid
+			U32 sampleFound : 1; // at least one sample referenced this module
+			U32 tscUsed : 1; // tsc set when record written
+			U32 duplicate : 1; // 1st pass analysis has determined this is a
+				// duplicate load
+			U32 globalModuleTB5 : 1; // module mapped into all processes on system
+			U32 segmentNameSet : 1; // set if the segment name was collected
+				// (initially done for xbox collections)
+			U32 firstModuleRecInProcess : 1; // if the pidCreatesTrackedInModuleRecs flag is set
+				//  in the SampleHeaderEx struct and this flag
+				//  is set, the associated module indicates
+				//  the beginning of a new process
+			U32 source : 1; // 0 for path in target system, 1 for path in host system (offloaded)
+			U32 unknownLoadAddress : 1; // for 0 valid loadAddr64 value, 1 for invalid loadAddr64 value
+			U32 reserved1 : 20;
+		} s1;
+	} u2;
+	U64 length64; // module length
+	U64 loadAddr64; // load address
+	U32 pidRecIndex; // process ID rec index (index into  start of pid record section).
+		// .. (see pidRecIndexRaw).  If pidRecIndex == 0 and pidRecIndexRaw == 1
+		// ..then this is a kernel or global module.  Can validly
+		// ..be 0 if not raw (array index).  Use ReturnPid() to access this
+		// ..field
+	U32 osid; // OS identifier
+	U64 unloadTsc; // TSC collected on an unload event
+	U32 path; // module path name (section offset on disk)
+		// ..when initally written by sampler name is at end of this
+		// ..struct, when merged with main file names are pooled at end
+		// ..of ModuleRecord Section so ModulesRecords can be
+		// ..fixed length
+	U16 pathLength; // path name length (inludes terminating \0)
+	U16 filenameOffset; // offset into path name of base filename
+	U32 segmentName; // offset to the segmentName from the beginning of the
+		//  module section in a processed module section
+		//  (s/b 0 in a raw module record)
+		// in a raw module record, the segment name will follow the
+		//  module name and the module name's terminating NULL char
+	U32 page_offset_high;
+	U64 tsc; // time stamp counter module event occurred
+	U32 parent_pid; // Parent PID of the process
+	U32 page_offset_low;
+} ModuleRecord;
+
+#define MR_unloadTscSet(x, y) ((x)->unloadTsc = (y))
+#define MR_unloadTscGet(x) ((x)->unloadTsc)
+
+#define MR_page_offset_Set(x, y)                                               \
+{                                                                              \
+	(x)->page_offset_low = (y)&0xFFFFFFFF;                                 \
+	(x)->page_offset_high = ((y) >> 32) & 0xFFFFFFFF;                      \
+}
+
+#define MR_page_offset_Get(x)                                                  \
+	((((U64)(x)->page_offset_high) << 32) | (x)->page_offset_low)
+
+// Accessor macros for ModuleRecord
+#define MODULE_RECORD_rec_length(x) ((x)->recLength)
+#define MODULE_RECORD_segment_type(x) ((x)->segmentType)
+#define MODULE_RECORD_load_event(x) ((x)->loadEvent)
+#define MODULE_RECORD_processed(x) ((x)->processed)
+#define MODULE_RECORD_selector(x) ((x)->selector)
+#define MODULE_RECORD_segment_name_length(x) ((x)->segmentNameLength)
+#define MODULE_RECORD_segment_number(x) ((x)->segmentNumber)
+#define MODULE_RECORD_flags(x) ((x)->u2.flags)
+#define MODULE_RECORD_exe(x) ((x)->u2.s1.exe)
+#define MODULE_RECORD_global_module(x) ((x)->u2.s1.globalModule)
+#define MODULE_RECORD_bogus_win95(x) ((x)->u2.s1.bogusWin95)
+#define MODULE_RECORD_pid_rec_index_raw(x) ((x)->u2.s1.pidRecIndexRaw)
+#define MODULE_RECORD_sample_found(x) ((x)->u2.s1.sampleFound)
+#define MODULE_RECORD_tsc_used(x) ((x)->u2.s1.tscUsed)
+#define MODULE_RECORD_duplicate(x) ((x)->u2.s1.duplicate)
+#define MODULE_RECORD_global_module_tb5(x) ((x)->u2.s1.globalModuleTB5)
+#define MODULE_RECORD_segment_name_set(x) ((x)->u2.s1.segmentNameSet)
+#define MODULE_RECORD_first_module_rec_in_process(x)                           \
+	((x)->u2.s1.firstModuleRecInProcess)
+#define MODULE_RECORD_source(x) ((x)->u2.s1.source)
+#define MODULE_RECORD_unknown_load_address(x) ((x)->u2.s1.unknownLoadAddress)
+#define MODULE_RECORD_length64(x) ((x)->length64)
+#define MODULE_RECORD_load_addr64(x) ((x)->loadAddr64)
+#define MODULE_RECORD_pid_rec_index(x) ((x)->pidRecIndex)
+#define MODULE_RECORD_load_sample_count(x) ((x)->u5.s2.loadSampleCount)
+#define MODULE_RECORD_unload_sample_count(x) ((x)->u5.s2.unloadSampleCount)
+#define MODULE_RECORD_unload_tsc(x) ((x)->unloadTsc)
+#define MODULE_RECORD_path(x) ((x)->path)
+#define MODULE_RECORD_path_length(x) ((x)->pathLength)
+#define MODULE_RECORD_filename_offset(x) ((x)->filenameOffset)
+#define MODULE_RECORD_segment_name(x) ((x)->segmentName)
+#define MODULE_RECORD_tsc(x) ((x)->tsc)
+#define MODULE_RECORD_parent_pid(x) ((x)->parent_pid)
+#define MODULE_RECORD_osid(x) ((x)->osid)
+
+/*
+ *  Sample record.  Size can be determined by looking at the header record.
+ *  There can be up to 3 sections.  The SampleFileHeader defines the presence
+ *  of sections and their offsets. Within a sample file, all of the sample
+ *  records have the same number of sections and the same size.  However,
+ *  different sample record sections and sizes can exist in different
+ *  sample files.  Since recording counters and the time stamp counter for
+ *  each sample can be space consuming, the user can determine whether or not
+ *  this information is kept at sample collection time.
+ */
+
+typedef struct SampleRecordPC_s { // Program Counter section
+	U32 descriptor_id;
+	U32 osid; // OS identifier
+	union {
+		struct {
+			U64 iip; // IA64 interrupt instruction pointer
+			U64 ipsr; // IA64 interrupt processor status register
+		} s1;
+		struct {
+			U32 eip; // IA32 instruction pointer
+			U32 eflags; // IA32 eflags
+			CodeDescriptor csd; // IA32 code seg descriptor (8 bytes)
+		} s2;
+	} u1;
+	U16 cs; // IA32 cs (0 for IA64)
+	union {
+		U16 cpuAndOS; // cpu and OS info as one word
+		struct { // cpu and OS info broken out
+			U16 cpuNum : 12; // cpu number (0 - 4096)
+			U16 notVmid0 : 1; // win95, vmid0 flag (1 means NOT vmid 0)
+			U16 codeMode : 2; // processor mode, see MODE_ defines
+			U16 uncore_valid : 1; // identifies if the uncore count is valid
+		} s3;
+	} u2;
+	U32 tid; // OS thread ID  (may get reused, see tidIsRaw)
+	U32 pidRecIndex; // process ID rec index (index into start of pid
+		// record section) .. can validly be 0 if not raw
+		// (array index).  Use ReturnPid() to
+		// ..access this field .. (see pidRecIndexRaw)
+	union {
+		U32 bitFields2;
+		struct {
+			U32 mrIndex : 20; // module record index (index into start of
+				// module rec section) .. (see mrIndexNone)
+			U32 eventIndex : 8; // index into the Events section
+			U32 tidIsRaw : 1; // tid is raw OS tid
+			U32 IA64PC : 1; // TRUE=this is a IA64 PC sample record
+			U32 pidRecIndexRaw : 1; // pidRecIndex is raw OS pid
+			U32 mrIndexNone : 1; // no mrIndex (unknown module)
+		} s4;
+	} u3;
+	U64 tsc; // processor timestamp counter
+} SampleRecordPC, *PSampleRecordPC;
+
+#define SAMPLE_RECORD_descriptor_id(x) ((x)->descriptor_id)
+#define SAMPLE_RECORD_osid(x) ((x)->osid)
+#define SAMPLE_RECORD_iip(x) ((x)->u1.s1.iip)
+#define SAMPLE_RECORD_ipsr(x) ((x)->u1.s1.ipsr)
+#define SAMPLE_RECORD_eip(x) ((x)->u1.s2.eip)
+#define SAMPLE_RECORD_eflags(x) ((x)->u1.s2.eflags)
+#define SAMPLE_RECORD_csd(x) ((x)->u1.s2.csd)
+#define SAMPLE_RECORD_cs(x) ((x)->cs)
+#define SAMPLE_RECORD_cpu_and_os(x) ((x)->u2.cpuAndOS)
+#define SAMPLE_RECORD_cpu_num(x) ((x)->u2.s3.cpuNum)
+#define SAMPLE_RECORD_uncore_valid(x) ((x)->u2.s3.uncore_valid)
+#define SAMPLE_RECORD_not_vmid0(x) ((x)->u2.s3.notVmid0)
+#define SAMPLE_RECORD_code_mode(x) ((x)->u2.s3.codeMode)
+#define SAMPLE_RECORD_tid(x) ((x)->tid)
+#define SAMPLE_RECORD_pid_rec_index(x) ((x)->pidRecIndex)
+#define SAMPLE_RECORD_bit_fields2(x) ((x)->u3.bitFields2)
+#define SAMPLE_RECORD_mr_index(x) ((x)->u3.s4.mrIndex)
+#define SAMPLE_RECORD_event_index(x) ((x)->u3.s4.eventIndex)
+#define SAMPLE_RECORD_tid_is_raw(x) ((x)->u3.s4.tidIsRaw)
+#define SAMPLE_RECORD_ia64_pc(x) ((x)->u3.s4.IA64PC)
+#define SAMPLE_RECORD_pid_rec_index_raw(x) ((x)->u3.s4.pidRecIndexRaw)
+#define SAMPLE_RECORD_mr_index_none(x) ((x)->u3.s4.mrIndexNone)
+#define SAMPLE_RECORD_tsc(x) ((x)->tsc)
+
+// end of SampleRecord sections
+
+/* Uncore Sample Record definition. This is a skinny sample record used by uncore boxes
+   to record samples. The sample record consists of a descriptor id, cpu info and timestamp.*/
+
+typedef struct UncoreSampleRecordPC_s {
+	U32 descriptor_id;
+	U32 osid;
+	U16 cpuNum;
+	U16 pkgNum;
+	union {
+		U32 flags;
+		struct {
+			U32 uncore_valid : 1; // identifies if the uncore count is valid
+			U32 reserved1 : 31;
+		} s1;
+	} u1;
+	U64 reserved2;
+	U64 tsc; // processor timestamp counter
+} UncoreSampleRecordPC, *PUnocreSampleRecordPC;
+
+#define UNCORE_SAMPLE_RECORD_descriptor_id(x) ((x)->descriptor_id)
+#define UNCORE_SAMPLE_RECORD_osid(x) ((x)->osid)
+#define UNCORE_SAMPLE_RECORD_cpu_num(x) ((x)->cpuNum)
+#define UNCORE_SAMPLE_RECORD_pkg_num(x) ((x)->pkgNum)
+#define UNCORE_SAMPLE_RECORD_uncore_valid(x) ((x)->u1.s1.uncore_valid)
+#define UNCORE_SAMPLE_RECORD_tsc(x) ((x)->tsc)
+
+// end of UncoreSampleRecord section
+
+// Definitions for user markers data
+// The instances of these structures will be written to the user markers temp file.
+#define MARKER_DEFAULT_TYPE "Default_Marker"
+#define MARKER_DEFAULT_ID 0
+#define MAX_MARKER_LENGTH 136
+
+#define MARK_ID 4
+#define MARK_DATA 2
+#define THREAD_INFO 8
+
+/* do not use it at ths moment
+typedef enum {
+		SMRK_USER_DEFINED = 0,
+		SMRK_THREAD_NAME,
+		SMRK_WALLCLOCK,
+		SMRK_TEXT,
+		SMRK_TYPE_ID
+}  SMRK_TYPE;
+*/
+
+/*
+ *  Common Register descriptions
+ */
+
+/*
+ *  Bits used in the debug control register
+ */
+#define DEBUG_CTL_LBR 0x0000001
+#define DEBUG_CTL_BTF 0x0000002
+#define DEBUG_CTL_TR 0x0000040
+#define DEBUG_CTL_BTS 0x0000080
+#define DEBUG_CTL_BTINT 0x0000100
+#define DEBUG_CTL_BT_OFF_OS 0x0000200
+#define DEBUG_CTL_BTS_OFF_USR 0x0000400
+#define DEBUG_CTL_FRZ_LBR_ON_PMI 0x0000800
+#define DEBUG_CTL_FRZ_PMON_ON_PMI 0x0001000
+#define DEBUG_CTL_ENABLE_UNCORE_PMI_BIT 0x0002000
+
+#define DEBUG_CTL_NODE_lbr_get(reg) ((reg) & DEBUG_CTL_LBR)
+#define DEBUG_CTL_NODE_lbr_set(reg) ((reg) |= DEBUG_CTL_LBR)
+#define DEBUG_CTL_NODE_lbr_clear(reg) ((reg) &= ~DEBUG_CTL_LBR)
+
+#define DEBUG_CTL_NODE_btf_get(reg) ((reg) & DEBUG_CTL_BTF)
+#define DEBUG_CTL_NODE_btf_set(reg) ((reg) |= DEBUG_CTL_BTF)
+#define DEBUG_CTL_NODE_btf_clear(reg) ((reg) &= ~DEBUG_CTL_BTF)
+
+#define DEBUG_CTL_NODE_tr_get(reg) ((reg) & DEBUG_CTL_TR)
+#define DEBUG_CTL_NODE_tr_set(reg) ((reg) |= DEBUG_CTL_TR)
+#define DEBUG_CTL_NODE_tr_clear(reg) ((reg) &= ~DEBUG_CTL_TR)
+
+#define DEBUG_CTL_NODE_bts_get(reg) ((reg) & DEBUG_CTL_BTS)
+#define DEBUG_CTL_NODE_bts_set(reg) ((reg) |= DEBUG_CTL_BTS)
+#define DEBUG_CTL_NODE_bts_clear(reg) ((reg) &= ~DEBUG_CTL_BTS)
+
+#define DEBUG_CTL_NODE_btint_get(reg) ((reg) & DEBUG_CTL_BTINT)
+#define DEBUG_CTL_NODE_btint_set(reg) ((reg) |= DEBUG_CTL_BTINT)
+#define DEBUG_CTL_NODE_btint_clear(reg) ((reg) &= ~DEBUG_CTL_BTINT)
+
+#define DEBUG_CTL_NODE_bts_off_os_get(reg) ((reg) & DEBUG_CTL_BTS_OFF_OS)
+#define DEBUG_CTL_NODE_bts_off_os_set(reg) ((reg) |= DEBUG_CTL_BTS_OFF_OS)
+#define DEBUG_CTL_NODE_bts_off_os_clear(reg) ((reg) &= ~DEBUG_CTL_BTS_OFF_OS)
+
+#define DEBUG_CTL_NODE_bts_off_usr_get(reg) ((reg) & DEBUG_CTL_BTS_OFF_USR)
+#define DEBUG_CTL_NODE_bts_off_usr_set(reg) ((reg) |= DEBUG_CTL_BTS_OFF_USR)
+#define DEBUG_CTL_NODE_bts_off_usr_clear(reg) ((reg) &= ~DEBUG_CTL_BTS_OFF_USR)
+
+#define DEBUG_CTL_NODE_frz_lbr_on_pmi_get(reg) ((reg) & DEBUG_CTL_FRZ_LBR_ON_PMI)
+#define DEBUG_CTL_NODE_frz_lbr_on_pmi_set(reg) ((reg) |= DEBUG_CTL_FRZ_LBR_ON_PMI)
+#define DEBUG_CTL_NODE_frz_lbr_on_pmi_clear(reg)                               \
+	((reg) &= ~DEBUG_CTL_FRZ_LBR_ON_PMI)
+
+#define DEBUG_CTL_NODE_frz_pmon_on_pmi_get(reg)                                \
+	((reg) & DEBUG_CTL_FRZ_PMON_ON_PMI)
+#define DEBUG_CTL_NODE_frz_pmon_on_pmi_set(reg)                                \
+	((reg) |= DEBUG_CTL_FRZ_PMON_ON_PMI)
+#define DEBUG_CTL_NODE_frz_pmon_on_pmi_clear(reg)                              \
+	((reg) &= ~DEBUG_CTL_FRZ_PMON_ON_PMI)
+
+#define DEBUG_CTL_NODE_enable_uncore_pmi_get(reg)                              \
+	((reg) & DEBUG_CTL_ENABLE_UNCORE_PMI)
+#define DEBUG_CTL_NODE_enable_uncore_pmi_set(reg)                              \
+	((reg) |= DEBUG_CTL_ENABLE_UNCORE_PMI)
+#define DEBUG_CTL_NODE_enable_uncore_pmi_clear(reg)                            \
+	((reg) &= ~DEBUG_CTL_ENABLE_UNCORE_PMI)
+
+/*
+ * @macro SEP_VERSION_NODE_S
+ * @brief
+ * This structure supports versioning in Sep. The field major indicates the major version,
+ * minor indicates the minor version and api indicates the api version for the current
+ * sep build. This structure is initialized at the time when the driver is loaded.
+ */
+
+typedef struct SEP_VERSION_NODE_S SEP_VERSION_NODE;
+typedef SEP_VERSION_NODE * SEP_VERSION;
+
+struct SEP_VERSION_NODE_S {
+	union {
+		U32 sep_version;
+		struct {
+			S32 major : 8;
+			S32 minor : 8;
+			S32 api : 8;
+			S32 update : 8;
+		} s1;
+	} u1;
+};
+
+#define SEP_VERSION_NODE_sep_version(version) ((version)->u1.sep_version)
+#define SEP_VERSION_NODE_major(version) ((version)->u1.s1.major)
+#define SEP_VERSION_NODE_minor(version) ((version)->u1.s1.minor)
+#define SEP_VERSION_NODE_api(version) ((version)->u1.s1.api)
+#define SEP_VERSION_NODE_update(version) ((version)->u1.s1.update)
+
+/*
+ *  The VTSA_SYS_INFO_STRUCT information that is shared across kernel mode
+ *  and user mode code, very specifically for tb5 file generation
+ */
+
+typedef enum {
+	GT_UNK = 0,
+	GT_PER_CPU,
+	GT_PER_CHIPSET,
+	GT_CPUID,
+	GT_NODE,
+	GT_SYSTEM,
+	GT_SAMPLE_RECORD_INFO
+} GEN_ENTRY_TYPES;
+
+typedef enum {
+	GST_UNK = 0,
+	GST_X86,
+	GST_ITANIUM,
+	GST_SA, //strong arm
+	GST_XSC,
+	GST_EM64T,
+	GST_CS860
+} GEN_ENTRY_SUBTYPES;
+
+typedef struct __fixed_size_pointer {
+	union {
+		U64 fs_force_alignment;
+		struct {
+			U32 fs_unused;
+			U32 is_ptr : 1;
+		} s1;
+	} u1;
+	union {
+		U64 fs_offset;
+		void *fs_ptr;
+	} u2;
+} VTSA_FIXED_SIZE_PTR;
+
+#define VTSA_FIXED_SIZE_PTR_is_ptr(fsp) ((fsp)->u1.s1.is_ptr)
+#define VTSA_FIXED_SIZE_PTR_fs_offset(fsp) ((fsp)->u2.fs_offset)
+#define VTSA_FIXED_SIZE_PTR_fs_ptr(fsp) ((fsp)->u2.fs_ptr)
+
+typedef struct __generic_array_header {
+	//
+	// Information realted to the generic header
+	//
+	U32 hdr_size; // size of this generic header
+		// (for versioning and real data starts
+		//  after the header)
+
+	U32 next_field_hdr_padding; // make sure the next field is 8-byte aligned
+
+	//
+	// VTSA_FIXED_SIZE_PTR should always be on an 8-byte boundary...
+	//
+	// pointer to the next generic header if there is one
+	//
+	VTSA_FIXED_SIZE_PTR hdr_next_gen_hdr;
+
+	U32 hdr_reserved[7]; // padding for future use - force to 64 bytes...
+
+	//
+	// Information related to the array this header is describing
+	//
+	U32 array_num_entries;
+	U32 array_entry_size;
+	U16 array_type; // from the GEN_ENTRY_TYPES enumeration
+	U16 array_subtype; // from the GEN_ENTRY_SUBTYPES enumeration
+} VTSA_GEN_ARRAY_HDR;
+
+#define VTSA_GEN_ARRAY_HDR_hdr_size(gah) ((gah)->hdr_size)
+#define VTSA_GEN_ARRAY_HDR_hdr_next_gen_hdr(gah) ((gah)->hdr_next_gen_hdr)
+#define VTSA_GEN_ARRAY_HDR_array_num_entries(gah) ((gah)->array_num_entries)
+#define VTSA_GEN_ARRAY_HDR_array_entry_size(gah) ((gah)->array_entry_size)
+#define VTSA_GEN_ARRAY_HDR_array_type(gah) ((gah)->array_type)
+#define VTSA_GEN_ARRAY_HDR_array_subtype(gah) ((gah)->array_subtype)
+
+typedef struct __cpuid_x86 {
+	U32 cpuid_eax_input;
+	U32 cpuid_eax;
+	U32 cpuid_ebx;
+	U32 cpuid_ecx;
+	U32 cpuid_edx;
+} VTSA_CPUID_X86;
+
+#define VTSA_CPUID_X86_cpuid_eax_input(cid) ((cid)->cpuid_eax_input)
+#define VTSA_CPUID_X86_cpuid_eax(cid) ((cid)->cpuid_eax)
+#define VTSA_CPUID_X86_cpuid_ebx(cid) ((cid)->cpuid_ebx)
+#define VTSA_CPUID_X86_cpuid_ecx(cid) ((cid)->cpuid_ecx)
+#define VTSA_CPUID_X86_cpuid_edx(cid) ((cid)->cpuid_edx)
+
+typedef struct __cpuid_ipf {
+	U64 cpuid_select;
+	U64 cpuid_val;
+} VTSA_CPUID_IPF;
+
+#define VTSA_CPUID_IPF_cpuid_select(cid) ((cid)->cpuid_select)
+#define VTSA_CPUID_IPF_cpuid_val(cid) ((cid)->cpuid_val)
+
+typedef struct __generic_per_cpu {
+	//
+	// per cpu information
+	//
+	U32 cpu_number; // cpu number (as defined by the OS)
+	U32 cpu_speed_mhz; // cpu speed (in Mhz)
+	U32 cpu_fsb_mhz; // Front Side Bus speed (in Mhz) (if known)
+	U32 cpu_cache_L2; // ??? USER: cpu L2 (marketing definition) cache size (if known)
+
+	//
+	// And pointer to other structures. Keep this on an 8-byte boundary
+	//
+	// "pointer" to generic array header that should contain
+	// cpuid information for this cpu
+	//
+	VTSA_FIXED_SIZE_PTR cpu_cpuid_array;
+
+	S64 cpu_tsc_offset; // TSC offset from CPU 0 computed as (TSC CPU N - TSC CPU 0)
+	//
+	// intel processor number (from mkting).
+	// Currently 3 decimal digits (3xx, 5xx and 7xx)
+	//
+	U32 cpu_intel_processor_number;
+
+	U32 cpu_cache_L3; // ??? USER: cpu L3 (marketing definition) cache size (if known)
+
+	U64 platform_id;
+
+	//
+	// package/mapping information
+	//
+	// The hierarchy for uniquely identifying a logical processor
+	// in a system is node number/id (from the node structure),
+	// package number, core number, and thread number.
+	// Core number is for identifying a core within a package.
+	//
+	// Actually, on Itanium getting all this information is
+	// pretty involved with complicated algorithm using PAL calls.
+	// I don't know how important all this stuff is to the user.
+	// Maybe we can just have the place holder now and figure out
+	// how to fill them later.
+	//
+	U16 cpu_package_num; // package number for this cpu (if known)
+	U16 cpu_core_num; // core number (if known)
+	U16 cpu_hw_thread_num; // hw thread number inside the core (if known)
+
+	U16 cpu_threads_per_core; // total number of h/w threads per core (if known)
+	U16 cpu_module_id; // Processor module number
+	U16 cpu_num_modules; // Number of processor modules
+	U32 cpu_core_type; // Core type for hetero
+	U32 arch_perfmon_ver;
+	U32 num_gp_counters;
+	U32 num_fixed_counters;
+	U32 reserved1;
+	U64 reserved2;
+	U64 reserved3;
+
+} VTSA_GEN_PER_CPU;
+
+#define VTSA_GEN_PER_CPU_cpu_number(p_cpu) ((p_cpu)->cpu_number)
+#define VTSA_GEN_PER_CPU_cpu_speed_mhz(p_cpu) ((p_cpu)->cpu_speed_mhz)
+#define VTSA_GEN_PER_CPU_cpu_fsb_mhz(p_cpu) ((p_cpu)->cpu_fsb_mhz)
+#define VTSA_GEN_PER_CPU_cpu_cache_L2(p_cpu) ((p_cpu)->cpu_cache_L2)
+#define VTSA_GEN_PER_CPU_cpu_cpuid_array(p_cpu) ((p_cpu)->cpu_cpuid_array)
+#define VTSA_GEN_PER_CPU_cpu_tsc_offset(p_cpu) ((p_cpu)->cpu_tsc_offset)
+#define VTSA_GEN_PER_CPU_cpu_intel_processor_number(p_cpu)                     \
+	((p_cpu)->cpu_intel_processor_number)
+#define VTSA_GEN_PER_CPU_cpu_cache_L3(p_cpu) ((p_cpu)->cpu_cache_L3)
+#define VTSA_GEN_PER_CPU_platform_id(p_cpu) ((p_cpu)->platform_id)
+#define VTSA_GEN_PER_CPU_cpu_package_num(p_cpu) ((p_cpu)->cpu_package_num)
+#define VTSA_GEN_PER_CPU_cpu_core_num(p_cpu) ((p_cpu)->cpu_core_num)
+#define VTSA_GEN_PER_CPU_cpu_hw_thread_num(p_cpu) ((p_cpu)->cpu_hw_thread_num)
+#define VTSA_GEN_PER_CPU_cpu_threads_per_core(p_cpu)                           \
+	((p_cpu)->cpu_threads_per_core)
+#define VTSA_GEN_PER_CPU_cpu_module_num(p_cpu) ((p_cpu)->cpu_module_id)
+#define VTSA_GEN_PER_CPU_cpu_num_modules(p_cpu) ((p_cpu)->cpu_num_modules)
+#define VTSA_GEN_PER_CPU_cpu_core_type(p_cpu) ((p_cpu)->cpu_core_type)
+#define VTSA_GEN_PER_CPU_arch_perfmon_ver(p_cpu) ((p_cpu)->arch_perfmon_ver)
+#define VTSA_GEN_PER_CPU_num_gp_counters(p_cpu) ((p_cpu)->num_gp_counters)
+#define VTSA_GEN_PER_CPU_num_fixed_counters(p_cpu) ((p_cpu)->num_fixed_counters)
+
+typedef struct __node_info {
+	U32 node_type_from_shell;
+	U32 node_id; // The node number/id (if known)
+
+	U32 node_num_available; // total number cpus on this node
+	U32 node_num_used; // USER: number used based on cpu mask at time of run
+
+	U64 node_physical_memory; // amount of physical memory (bytes) on this node
+
+	//
+	// pointer to the first generic header that
+	// contains the per-cpu information
+	//
+	// Keep the VTSA_FIXED_SIZE_PTR on an 8-byte boundary...
+	//
+	VTSA_FIXED_SIZE_PTR node_percpu_array;
+
+	U32 node_reserved[2]; // leave some space
+
+} VTSA_NODE_INFO;
+
+#define VTSA_NODE_INFO_node_type_from_shell(vni) ((vni)->node_type_from_shell)
+#define VTSA_NODE_INFO_node_id(vni) ((vni)->node_id)
+#define VTSA_NODE_INFO_node_num_available(vni) ((vni)->node_num_available)
+#define VTSA_NODE_INFO_node_num_used(vni) ((vni)->node_num_used)
+#define VTSA_NODE_INFO_node_physical_memory(vni) ((vni)->node_physical_memory)
+#define VTSA_NODE_INFO_node_percpu_array(vni) ((vni)->node_percpu_array)
+
+typedef struct __sys_info {
+	//
+	// Keep this on an 8-byte boundary
+	//
+	VTSA_FIXED_SIZE_PTR node_array; // the per-node information
+
+	U64 min_app_address; // USER: lower allowed user space address (if known)
+	U64 max_app_address; // USER: upper allowed user space address (if known)
+	U32 page_size; // Current page size
+	U32 allocation_granularity; // USER: Granularity of allocation requests (if known)
+	U32 reserved1; // added for future fields
+	U32 reserved2; // alignment purpose
+	U64 reserved3[3]; // added for future fields
+
+} VTSA_SYS_INFO;
+
+#define VTSA_SYS_INFO_node_array(sys_info) ((sys_info)->node_array)
+#define VTSA_SYS_INFO_min_app_address(sys_info) ((sys_info)->min_app_address)
+#define VTSA_SYS_INFO_max_app_address(sys_info) ((sys_info)->max_app_address)
+#define VTSA_SYS_INFO_page_size(sys_info) ((sys_info)->page_size)
+#define VTSA_SYS_INFO_allocation_granularity(sys_info)                         \
+	((sys_info)->allocation_granularity)
+
+typedef struct DRV_TOPOLOGY_INFO_NODE_S DRV_TOPOLOGY_INFO_NODE;
+typedef DRV_TOPOLOGY_INFO_NODE * DRV_TOPOLOGY_INFO;
+
+struct DRV_TOPOLOGY_INFO_NODE_S {
+	U32 cpu_number; // cpu number (as defined by the OS)
+	U16 cpu_package_num; // package number for this cpu (if known)
+	U16 cpu_core_num; // core number (if known)
+	U16 cpu_hw_thread_num; // T0 or T1 if HT enabled
+	U16 reserved1;
+	S32 socket_master;
+	S32 core_master;
+	S32 thr_master;
+	U32 cpu_module_num;
+	U32 cpu_module_master;
+	U32 cpu_num_modules;
+	U32 cpu_core_type;
+	U32 arch_perfmon_ver;
+	U32 num_gp_counters;
+	U32 num_fixed_counters;
+	U32 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+
+#define DRV_TOPOLOGY_INFO_cpu_number(dti) ((dti)->cpu_number)
+#define DRV_TOPOLOGY_INFO_cpu_package_num(dti) ((dti)->cpu_package_num)
+#define DRV_TOPOLOGY_INFO_cpu_core_num(dti) ((dti)->cpu_core_num)
+#define DRV_TOPOLOGY_INFO_socket_master(dti) ((dti)->socket_master)
+#define DRV_TOPOLOGY_INFO_core_master(dti) ((dti)->core_master)
+#define DRV_TOPOLOGY_INFO_thr_master(dti) ((dti)->thr_master)
+#define DRV_TOPOLOGY_INFO_cpu_hw_thread_num(dti) ((dti)->cpu_hw_thread_num)
+#define DRV_TOPOLOGY_INFO_cpu_module_num(dti) ((dti)->cpu_module_num)
+#define DRV_TOPOLOGY_INFO_cpu_module_master(dti) ((dti)->cpu_module_master)
+#define DRV_TOPOLOGY_INFO_cpu_num_modules(dti) ((dti)->cpu_num_modules)
+#define DRV_TOPOLOGY_INFO_cpu_core_type(dti) ((dti)->cpu_core_type)
+#define DRV_TOPOLOGY_INFO_arch_perfmon_ver(dti) ((dti)->arch_perfmon_ver)
+#define DRV_TOPOLOGY_INFO_num_gp_counters(dti) ((dti)->num_gp_counters)
+#define DRV_TOPOLOGY_INFO_num_fixed_counters(dti) ((dti)->num_fixed_counters)
+
+#define VALUE_TO_BE_DISCOVERED 0
+
+// dimm information
+typedef struct DRV_DIMM_INFO_NODE_S DRV_DIMM_INFO_NODE;
+typedef DRV_DIMM_INFO_NODE  * DRV_DIMM_INFO;
+
+struct DRV_DIMM_INFO_NODE_S {
+	U32 platform_id;
+	U32 channel_num;
+	U32 rank_num;
+	U32 value;
+	U8 mc_num;
+	U8 dimm_valid;
+	U8 valid_value;
+	U8 rank_value;
+	U8 density_value;
+	U8 width_value;
+	U16 socket_num;
+	U64 reserved1;
+	U64 reserved2;
+};
+
+#define DRV_DIMM_INFO_platform_id(di) ((di)->platform_id)
+#define DRV_DIMM_INFO_channel_num(di) ((di)->channel_num)
+#define DRV_DIMM_INFO_rank_num(di) ((di)->rank_num)
+#define DRV_DIMM_INFO_value(di) ((di)->value)
+#define DRV_DIMM_INFO_mc_num(di) ((di)->mc_num)
+#define DRV_DIMM_INFO_dimm_valid(di) ((di)->dimm_valid)
+#define DRV_DIMM_INFO_valid_value(di) ((di)->valid_value)
+#define DRV_DIMM_INFO_rank_value(di) ((di)->rank_value)
+#define DRV_DIMM_INFO_density_value(di) ((di)->density_value)
+#define DRV_DIMM_INFO_width_value(di) ((di)->width_value)
+#define DRV_DIMM_INFO_socket_num(di) ((di)->socket_num)
+
+//platform information. need to get from driver
+#define MAX_PACKAGES 16
+#define MAX_CHANNELS 8
+#define MAX_RANKS 3
+
+typedef struct DRV_PLATFORM_INFO_NODE_S DRV_PLATFORM_INFO_NODE;
+typedef DRV_PLATFORM_INFO_NODE * DRV_PLATFORM_INFO;
+
+struct DRV_PLATFORM_INFO_NODE_S {
+	U64 info; // platform info
+	U64 ddr_freq_index; // freq table index
+	U8 misc_valid; // misc enabled valid bit
+	U8 reserved1; // added for alignment purpose
+	U16 reserved2;
+	U32 vmm_timer_freq; // timer frequency from VMM on SoFIA (in HZ)
+	U64 misc_info; // misc enabled info
+	U64 ufs_freq; // ufs frequency (HSX only)
+	DRV_DIMM_INFO_NODE dimm_info[MAX_PACKAGES * MAX_CHANNELS * MAX_RANKS];
+	U64 energy_multiplier; // Value of energy multiplier
+	U64 reserved3;
+	U64 reserved4;
+	U64 reserved5;
+	U64 reserved6;
+};
+
+#define DRV_PLATFORM_INFO_info(data) ((data)->info)
+#define DRV_PLATFORM_INFO_ddr_freq_index(data) ((data)->ddr_freq_index)
+#define DRV_PLATFORM_INFO_misc_valid(data) ((data)->misc_valid)
+#define DRV_PLATFORM_INFO_misc_info(data) ((data)->misc_info)
+#define DRV_PLATFORM_INFO_ufs_freq(data) ((data)->ufs_freq)
+#define DRV_PLATFORM_INFO_dimm_info(data) ((data)->dimm_info)
+#define DRV_PLATFORM_INFO_energy_multiplier(data) ((data)->energy_multiplier)
+#define DRV_PLATFORM_INFO_vmm_timer_freq(data) ((data)->vmm_timer_freq)
+
+//platform information. need to get from Platform picker
+typedef struct PLATFORM_FREQ_INFO_NODE_S PLATFORM_FREQ_INFO_NODE;
+typedef PLATFORM_FREQ_INFO_NODE * PLATFORM_FREQ_INFO;
+
+struct PLATFORM_FREQ_INFO_NODE_S {
+	float multiplier; // freq multiplier
+	double *table; // freq table
+	U32 table_size; // freq table size
+	U64 reserved1;
+	U64 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+#define PLATFORM_FREQ_INFO_multiplier(data) ((data)->multiplier)
+#define PLATFORM_FREQ_INFO_table(data) ((data)->table)
+#define PLATFORM_FREQ_INFO_table_size(data) ((data)->table_size)
+
+typedef struct DEVICE_INFO_NODE_S DEVICE_INFO_NODE;
+typedef DEVICE_INFO_NODE * DEVICE_INFO; //NEEDED in PP
+
+struct DEVICE_INFO_NODE_S {
+	S8 *dll_name;
+	PVOID dll_handle;
+	S8 *cpu_name;
+	S8 *pmu_name;
+	DRV_STCHAR *event_db_file_name;
+	//PLATFORM_IDENTITY plat_identity;  // this is undefined right now. Please take this as structure containing U64
+	U32 plat_type; // device type (e.g., DEVICE_INFO_CORE, etc. ... see enum below)
+	U32 plat_sub_type; // cti_type (e.g., CTI_Sandybridge, etc., ... see env_info_types.h)
+	S32 dispatch_id; // this will be set in user mode dlls and will be unique across all IPF, IA32 (including MIDS).
+	ECB *ecb;
+	EVENT_CONFIG ec;
+	DEV_CONFIG pcfg;
+	DEV_UNC_CONFIG pcfg_unc;
+	U32 num_of_groups;
+	U32 size_of_alloc; // size of each event control block
+	PVOID drv_event;
+	U32 num_events;
+	U32 event_id_index; // event id index of device (basically how many events processed before this device)
+	U32 num_counters;
+	U32 group_index;
+	U32 num_packages;
+	U32 num_units;
+	U32 device_type;
+	U32 core_type;
+	U32 pmu_clone_id; // cti_type of platform to impersonate in device DLLs
+	U32 device_scope;
+	U32 reserved1;
+	U64 reserved2;
+	U64 reserved3;
+};
+
+#define MAX_EVENT_NAME_LENGTH 256
+
+#define DEVICE_INFO_dll_name(pdev) ((pdev)->dll_name)
+#define DEVICE_INFO_dll_handle(pdev) ((pdev)->dll_handle)
+#define DEVICE_INFO_cpu_name(pdev) ((pdev)->cpu_name)
+#define DEVICE_INFO_pmu_name(pdev) ((pdev)->pmu_name)
+#define DEVICE_INFO_event_db_file_name(pdev) ((pdev)->event_db_file_name)
+#define DEVICE_INFO_plat_type(pdev) ((pdev)->plat_type)
+#define DEVICE_INFO_plat_sub_type(pdev) ((pdev)->plat_sub_type)
+#define DEVICE_INFO_pmu_clone_id(pdev) ((pdev)->pmu_clone_id)
+#define DEVICE_INFO_dispatch_id(pdev) ((pdev)->dispatch_id)
+#define DEVICE_INFO_ecb(pdev) ((pdev)->ecb)
+#define DEVICE_INFO_ec(pdev) ((pdev)->ec)
+#define DEVICE_INFO_pcfg(pdev) ((pdev)->pcfg)
+#define DEVICE_INFO_pcfg_unc(pdev) ((pdev)->pcfg_unc)
+#define DEVICE_INFO_num_groups(pdev) ((pdev)->num_of_groups)
+#define DEVICE_INFO_size_of_alloc(pdev) ((pdev)->size_of_alloc)
+#define DEVICE_INFO_drv_event(pdev) ((pdev)->drv_event)
+#define DEVICE_INFO_num_events(pdev) ((pdev)->num_events)
+#define DEVICE_INFO_event_id_index(pdev) ((pdev)->event_id_index)
+#define DEVICE_INFO_num_counters(pdev) ((pdev)->num_counters)
+#define DEVICE_INFO_group_index(pdev) ((pdev)->group_index)
+#define DEVICE_INFO_num_packages(pdev) ((pdev)->num_packages)
+#define DEVICE_INFO_num_units(pdev) ((pdev)->num_units)
+#define DEVICE_INFO_device_type(pdev) ((pdev)->device_type)
+#define DEVICE_INFO_core_type(pdev) ((pdev)->core_type)
+#define DEVICE_INFO_device_scope(pdev) ((pdev)->device_scope)
+
+typedef struct DEVICE_INFO_DATA_NODE_S DEVICE_INFO_DATA_NODE;
+typedef DEVICE_INFO_DATA_NODE * DEVICE_INFO_DATA; //NEEDED in PP
+
+struct DEVICE_INFO_DATA_NODE_S {
+	DEVICE_INFO pdev_info;
+	U32 num_elements;
+	U32 num_allocated;
+	U64 reserved1;
+	U64 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+
+#define DEVICE_INFO_DATA_pdev_info(d) ((d)->pdev_info)
+#define DEVICE_INFO_DATA_num_elements(d) ((d)->num_elements)
+#define DEVICE_INFO_DATA_num_allocated(d) ((d)->num_allocated)
+
+typedef enum {
+	DEVICE_INFO_CORE = 0,
+	DEVICE_INFO_UNCORE = 1,
+	DEVICE_INFO_CHIPSET = 2,
+	DEVICE_INFO_GFX = 3,
+	DEVICE_INFO_PWR = 4,
+	DEVICE_INFO_TELEMETRY = 5
+} DEVICE_INFO_TYPE;
+
+typedef enum {
+	INVALID_TERMINATE_TYPE = 0,
+	STOP_TERMINATE,
+	CANCEL_TERMINATE
+} ABNORMAL_TERMINATE_TYPE;
+
+typedef enum {
+	DEVICE_SCOPE_PACKAGE = 0,
+	DEVICE_SCOPE_SYSTEM = 1
+} DEVICE_SCOPE_TYPE;
+
+typedef struct PCIFUNC_INFO_NODE_S PCIFUNC_INFO_NODE;
+typedef PCIFUNC_INFO_NODE * PCIFUNC_INFO;
+
+struct PCIFUNC_INFO_NODE_S {
+	U32 valid;
+	U32 num_entries; // the number of entries found with same <dev_no, func_no> but difference bus_no.
+	U64 deviceId;
+	U64 reserved1;
+	U64 reserved2;
+};
+
+#define PCIFUNC_INFO_NODE_funcno(x) ((x)->funcno)
+#define PCIFUNC_INFO_NODE_valid(x) ((x)->valid)
+#define PCIFUNC_INFO_NODE_deviceId(x) ((x)->deviceId)
+#define PCIFUNC_INFO_NODE_num_entries(x) ((x)->num_entries)
+
+typedef struct PCIDEV_INFO_NODE_S PCIDEV_INFO_NODE;
+typedef PCIDEV_INFO_NODE * PCIDEV_INFO;
+
+struct PCIDEV_INFO_NODE_S {
+	PCIFUNC_INFO_NODE func_info[MAX_PCI_FUNCNO];
+	U32 valid;
+	U32 dispatch_id;
+	U64 reserved1;
+	U64 reserved2;
+};
+
+#define PCIDEV_INFO_NODE_func_info(x, i) ((x).func_info[i])
+#define PCIDEV_INFO_NODE_valid(x) ((x).valid)
+
+typedef struct UNCORE_PCIDEV_NODE_S UNCORE_PCIDEV_NODE;
+
+struct UNCORE_PCIDEV_NODE_S {
+	PCIDEV_INFO_NODE pcidev[MAX_PCI_DEVNO];
+	U32 dispatch_id;
+	U32 scan;
+	U32 num_uncore_units;
+	U32 num_deviceid_entries;
+	U8 dimm_device1;
+	U8 dimm_device2;
+	U16 reserved1;
+	U32 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+	U32 deviceid_list[MAX_PCI_DEVNO];
+};
+
+// Structure used to perform uncore device discovery
+
+typedef struct UNCORE_TOPOLOGY_INFO_NODE_S UNCORE_TOPOLOGY_INFO_NODE;
+typedef UNCORE_TOPOLOGY_INFO_NODE * UNCORE_TOPOLOGY_INFO;
+
+struct UNCORE_TOPOLOGY_INFO_NODE_S {
+	UNCORE_PCIDEV_NODE device[MAX_DEVICES];
+};
+
+#define UNCORE_TOPOLOGY_INFO_device(x, dev_index) ((x)->device[dev_index])
+#define UNCORE_TOPOLOGY_INFO_device_dispatch_id(x, dev_index)                  \
+	((x)->device[dev_index].dispatch_id)
+#define UNCORE_TOPOLOGY_INFO_device_scan(x, dev_index)                         \
+	((x)->device[dev_index].scan)
+#define UNCORE_TOPOLOGY_INFO_pcidev_valid(x, dev_index, devno)                 \
+	((x)->device[dev_index].pcidev[devno].valid)
+#define UNCORE_TOPOLOGY_INFO_pcidev_dispatch_id(x, dev_index, devno)           \
+	((x)->device[dev_index].pcidev[devno].dispatch_id)
+#define UNCORE_TOPOLOGY_INFO_pcidev(x, dev_index, devno)                       \
+	((x)->device[dev_index].pcidev[devno])
+#define UNCORE_TOPOLOGY_INFO_num_uncore_units(x, dev_index)                    \
+	((x)->device[dev_index].num_uncore_units)
+#define UNCORE_TOPOLOGY_INFO_num_deviceid_entries(x, dev_index)                \
+	((x)->device[dev_index].num_deviceid_entries)
+#define UNCORE_TOPOLOGY_INFO_dimm_device1(x, dev_index)                        \
+	((x)->device[dev_index].dimm_device1)
+#define UNCORE_TOPOLOGY_INFO_dimm_device2(x, dev_index)                        \
+	((x)->device[dev_index].dimm_device2)
+#define UNCORE_TOPOLOGY_INFO_deviceid(x, dev_index, deviceid_idx)              \
+	((x)->device[dev_index].deviceid_list[deviceid_idx])
+#define UNCORE_TOPOLOGY_INFO_pcidev_set_funcno_valid(x, dev_index, devno,      \
+						     funcno)                   \
+	((x)->device[dev_index].pcidev[devno].func_info[funcno].valid = 1)
+#define UNCORE_TOPOLOGY_INFO_pcidev_is_found_in_platform(x, dev_index, devno,  \
+							 funcno)               \
+	((x)->device[dev_index].pcidev[devno].func_info[funcno].num_entries)
+#define UNCORE_TOPOLOGY_INFO_pcidev_is_devno_funcno_valid(x, dev_index, devno, \
+							  funcno)              \
+	((x)->device[dev_index].pcidev[devno].func_info[funcno].valid ? TRUE : \
+									FALSE)
+#define UNCORE_TOPOLOGY_INFO_pcidev_is_device_found(x, dev_index, devno,       \
+						    funcno)                    \
+	((x)->device[dev_index].pcidev[devno].func_info[funcno].num_entries > 0)
+
+#define UNCORE_TOPOLOGY_INFO_pcidev_num_entries_found(x, dev_index, devno,     \
+						      funcno)                  \
+	((x)->device[dev_index].pcidev[devno].func_info[funcno].num_entries)
+
+typedef enum {
+	CORE_TOPOLOGY_NODE = 0,
+	UNCORE_TOPOLOGY_NODE_IMC = 1,
+	UNCORE_TOPOLOGY_NODE_UBOX = 2,
+	UNCORE_TOPOLOGY_NODE_QPI = 3,
+	MAX_TOPOLOGY_DEV = 4,
+	// When you adding new topo node to this enum, make sue MAX_TOPOLOGY_DEV is always the last one.
+} UNCORE_TOPOLOGY_NODE_INDEX_TYPE;
+
+typedef struct PLATFORM_TOPOLOGY_REG_NODE_S PLATFORM_TOPOLOGY_REG_NODE;
+typedef PLATFORM_TOPOLOGY_REG_NODE * PLATFORM_TOPOLOGY_REG;
+
+struct PLATFORM_TOPOLOGY_REG_NODE_S {
+	U32 bus;
+	U32 device;
+	U32 function;
+	U32 reg_id;
+	U64 reg_mask;
+	U64 reg_value[MAX_PACKAGES];
+	U8 reg_type;
+	U8 device_valid;
+	U16 reserved1;
+	U32 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+
+#define PLATFORM_TOPOLOGY_REG_bus(x, i) ((x)[(i)].bus)
+#define PLATFORM_TOPOLOGY_REG_device(x, i) ((x)[(i)].device)
+#define PLATFORM_TOPOLOGY_REG_function(x, i) ((x)[(i)].function)
+#define PLATFORM_TOPOLOGY_REG_reg_id(x, i) ((x)[(i)].reg_id)
+#define PLATFORM_TOPOLOGY_REG_reg_mask(x, i) ((x)[(i)].reg_mask)
+#define PLATFORM_TOPOLOGY_REG_reg_type(x, i) ((x)[(i)].reg_type)
+#define PLATFORM_TOPOLOGY_REG_device_valid(x, i) ((x)[(i)].device_valid)
+#define PLATFORM_TOPOLOGY_REG_reg_value(x, i, package_no)                      \
+	((x)[(i)].reg_value[package_no])
+
+typedef struct PLATFORM_TOPOLOGY_DISCOVERY_NODE_S
+	PLATFORM_TOPOLOGY_DISCOVERY_NODE;
+typedef PLATFORM_TOPOLOGY_DISCOVERY_NODE * PLATFORM_TOPOLOGY_DISCOVERY;
+
+struct PLATFORM_TOPOLOGY_DISCOVERY_NODE_S {
+	U32 device_index;
+	U32 device_id;
+	U32 num_registers;
+	U8 scope;
+	U8 prog_valid;
+	U16 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+	U64 reserved5;
+	PLATFORM_TOPOLOGY_REG_NODE topology_regs[MAX_REGS];
+};
+
+//Structure used to discover the uncore device topology_device
+
+typedef struct PLATFORM_TOPOLOGY_PROG_NODE_S PLATFORM_TOPOLOGY_PROG_NODE;
+typedef PLATFORM_TOPOLOGY_PROG_NODE * PLATFORM_TOPOLOGY_PROG;
+
+struct PLATFORM_TOPOLOGY_PROG_NODE_S {
+	U32 num_devices;
+	PLATFORM_TOPOLOGY_DISCOVERY_NODE topology_device[MAX_TOPOLOGY_DEV];
+};
+
+#define PLATFORM_TOPOLOGY_PROG_num_devices(x) ((x)->num_devices)
+#define PLATFORM_TOPOLOGY_PROG_topology_device(x, dev_index)                   \
+	((x)->topology_device[dev_index])
+#define PLATFORM_TOPOLOGY_PROG_topology_device_device_index(x, dev_index)      \
+	((x)->topology_device[dev_index].device_index)
+#define PLATFORM_TOPOLOGY_PROG_topology_device_device_id(x, dev_index)         \
+	((x)->topology_device[dev_index].device_id)
+#define PLATFORM_TOPOLOGY_PROG_topology_device_scope(x, dev_index)             \
+	((x)->topology_device[dev_index].scope)
+#define PLATFORM_TOPOLOGY_PROG_topology_device_num_registers(x, dev_index)     \
+	((x)->topology_device[dev_index].num_registers)
+#define PLATFORM_TOPOLOGY_PROG_topology_device_prog_valid(x, dev_index)        \
+	((x)->topology_device[dev_index].prog_valid)
+#define PLATFORM_TOPOLOGY_PROG_topology_topology_regs(x, dev_index)            \
+	((x)->topology_device[dev_index].topology_regs)
+
+typedef struct FPGA_GB_DISCOVERY_NODE_S FPGA_GB_DISCOVERY_NODE;
+
+struct FPGA_GB_DISCOVERY_NODE_S {
+	U16 bar_num;
+	U16 feature_id;
+	U32 device_id;
+	U64 afu_id_l;
+	U64 afu_id_h;
+	U32 feature_offset;
+	U32 feature_len;
+	U8 scan;
+	U8 valid;
+	U16 reserved1;
+	U32 reserved2;
+};
+
+typedef struct FPGA_GB_DEV_NODE_S FPGA_GB_DEV_NODE;
+typedef FPGA_GB_DEV_NODE * FPGA_GB_DEV;
+
+struct FPGA_GB_DEV_NODE_S {
+	U32 num_devices;
+	FPGA_GB_DISCOVERY_NODE fpga_gb_device[MAX_DEVICES];
+};
+
+#define FPGA_GB_DEV_num_devices(x) ((x)->num_devices)
+#define FPGA_GB_DEV_device(x, dev_index) ((x)->fpga_gb_device[dev_index])
+#define FPGA_GB_DEV_bar_num(x, dev_index) ((x)->fpga_gb_device[dev_index].bar_num)
+#define FPGA_GB_DEV_feature_id(x, dev_index)                                   \
+	((x)->fpga_gb_device[dev_index].feature_id)
+#define FPGA_GB_DEV_device_id(x, dev_index)                                    \
+	((x)->fpga_gb_device[dev_index].device_id)
+#define FPGA_GB_DEV_afu_id_low(x, dev_index)                                   \
+	((x)->fpga_gb_device[dev_index].afu_id_l)
+#define FPGA_GB_DEV_afu_id_high(x, dev_index)                                  \
+	((x)->fpga_gb_device[dev_index].afu_id_h)
+#define FPGA_GB_DEV_feature_offset(x, dev_index)                               \
+	((x)->fpga_gb_device[dev_index].feature_offset)
+#define FPGA_GB_DEV_feature_len(x, dev_index)                                  \
+	((x)->fpga_gb_device[dev_index].feature_len)
+#define FPGA_GB_DEV_scan(x, dev_index) ((x)->fpga_gb_device[dev_index].scan)
+#define FPGA_GB_DEV_valid(x, dev_index) ((x)->fpga_gb_device[dev_index].valid)
+
+typedef enum {
+	UNCORE_TOPOLOGY_INFO_NODE_IMC = 0,
+	UNCORE_TOPOLOGY_INFO_NODE_QPILL = 1,
+	UNCORE_TOPOLOGY_INFO_NODE_HA = 2,
+	UNCORE_TOPOLOGY_INFO_NODE_R3 = 3,
+	UNCORE_TOPOLOGY_INFO_NODE_R2 = 4,
+	UNCORE_TOPOLOGY_INFO_NODE_IRP = 5,
+	UNCORE_TOPOLOGY_INFO_NODE_IMC_UCLK = 6,
+	UNCORE_TOPOLOGY_INFO_NODE_EDC_ECLK = 7,
+	UNCORE_TOPOLOGY_INFO_NODE_EDC_UCLK = 8,
+	UNCORE_TOPOLOGY_INFO_NODE_M2M = 9,
+	UNCORE_TOPOLOGY_INFO_NODE_HFI_RXE = 10,
+	UNCORE_TOPOLOGY_INFO_NODE_HFI_TXE = 11,
+	UNCORE_TOPOLOGY_INFO_NODE_FPGA_CACHE = 12,
+	UNCORE_TOPOLOGY_INFO_NODE_FPGA_FAB = 13,
+	UNCORE_TOPOLOGY_INFO_NODE_FPGA_THERMAL = 14,
+	UNCORE_TOPOLOGY_INFO_NODE_FPGA_POWER = 15,
+} UNCORE_TOPOLOGY_INFO_NODE_INDEX_TYPE;
+
+typedef struct SIDEBAND_INFO_NODE_S SIDEBAND_INFO_NODE;
+typedef SIDEBAND_INFO_NODE * SIDEBAND_INFO;
+
+struct SIDEBAND_INFO_NODE_S {
+	U32 tid;
+	U32 pid;
+	U64 tsc;
+};
+
+#define SIDEBAND_INFO_pid(x) ((x)->pid)
+#define SIDEBAND_INFO_tid(x) ((x)->tid)
+#define SIDEBAND_INFO_tsc(x) ((x)->tsc)
+
+typedef struct SAMPLE_DROP_NODE_S SAMPLE_DROP_NODE;
+typedef SAMPLE_DROP_NODE * SAMPLE_DROP;
+
+struct SAMPLE_DROP_NODE_S {
+	U32 os_id;
+	U32 cpu_id;
+	U32 sampled;
+	U32 dropped;
+};
+
+#define SAMPLE_DROP_os_id(x) ((x)->os_id)
+#define SAMPLE_DROP_cpu_id(x) ((x)->cpu_id)
+#define SAMPLE_DROP_sampled(x) ((x)->sampled)
+#define SAMPLE_DROP_dropped(x) ((x)->dropped)
+
+#define MAX_SAMPLE_DROP_NODES 20
+
+typedef struct SAMPLE_DROP_INFO_NODE_S SAMPLE_DROP_INFO_NODE;
+typedef SAMPLE_DROP_INFO_NODE * SAMPLE_DROP_INFO;
+
+struct SAMPLE_DROP_INFO_NODE_S {
+	U32 size;
+	SAMPLE_DROP_NODE drop_info[MAX_SAMPLE_DROP_NODES];
+};
+
+#define SAMPLE_DROP_INFO_size(x) ((x)->size)
+#define SAMPLE_DROP_INFO_drop_info(x, index) ((x)->drop_info[index])
+
+#define IS_PEBS_SAMPLE_RECORD(sample_record)                                   \
+	((SAMPLE_RECORD_pid_rec_index(sample_record) == (U32)-1) &&            \
+	 (SAMPLE_RECORD_tid(sample_record) == (U32)-1))
+
+/*
+ *  VMM vendor information
+ */
+#define KVM_SIGNATURE "KVMKVMKVM\0\0\0"
+#define XEN_SIGNATURE "XenVMMXenVMM"
+#define VMWARE_SIGNATURE "VMwareVMware"
+#define HYPERV_SIGNATURE "Microsoft Hv"
+
+#define DRV_VMM_UNKNOWN 0
+#define DRV_VMM_MOBILEVISOR 1
+#define DRV_VMM_KVM 2
+#define DRV_VMM_XEN 3
+#define DRV_VMM_HYPERV 4
+#define DRV_VMM_VMWARE 5
+#define DRV_VMM_ACRN 6
+
+/*
+ * @macro DRV_SETUP_INFO_NODE_S
+ * @brief
+ * This structure supports driver information such as NMI profiling mode.
+ */
+
+typedef struct DRV_SETUP_INFO_NODE_S DRV_SETUP_INFO_NODE;
+typedef DRV_SETUP_INFO_NODE * DRV_SETUP_INFO;
+
+struct DRV_SETUP_INFO_NODE_S {
+	union {
+		U64 modes;
+		struct {
+			U64 nmi_mode : 1;
+			U64 vmm_mode : 1;
+			U64 vmm_vendor : 8;
+			U64 vmm_guest_vm : 1;
+			U64 pebs_accessible : 1;
+			U64 cpu_hotplug_mode : 1;
+			U64 matrix_inaccessible : 1;
+			U64 page_table_isolation : 2;
+			U64 pebs_ignored_by_pti : 1;
+			U64 reserved1 : 47;
+		} s1;
+	} u1;
+	U64 reserved2;
+	U64 reserved3;
+	U64 reserved4;
+};
+
+#define DRV_SETUP_INFO_nmi_mode(info) ((info)->u1.s1.nmi_mode)
+#define DRV_SETUP_INFO_vmm_mode(info) ((info)->u1.s1.vmm_mode)
+#define DRV_SETUP_INFO_vmm_vendor(info) ((info)->u1.s1.vmm_vendor)
+#define DRV_SETUP_INFO_vmm_guest_vm(info) ((info)->u1.s1.vmm_guest_vm)
+#define DRV_SETUP_INFO_pebs_accessible(info) ((info)->u1.s1.pebs_accessible)
+#define DRV_SETUP_INFO_cpu_hotplug_mode(info) ((info)->u1.s1.cpu_hotplug_mode)
+#define DRV_SETUP_INFO_matrix_inaccessible(info)                               \
+	((info)->u1.s1.matrix_inaccessible)
+#define DRV_SETUP_INFO_page_table_isolation(info)                              \
+	((info)->u1.s1.page_table_isolation)
+#define DRV_SETUP_INFO_pebs_ignored_by_pti(info)                               \
+	((info)->u1.s1.pebs_ignored_by_pti)
+
+#define DRV_SETUP_INFO_PTI_DISABLED 0
+#define DRV_SETUP_INFO_PTI_KPTI 1
+#define DRV_SETUP_INFO_PTI_KAISER 2
+#define DRV_SETUP_INFO_PTI_VA_SHADOW 3
+#define DRV_SETUP_INFO_PTI_UNKNOWN 4
+
+/*
+  Type: task_info_t
+  Description:
+	  Represents the equivalent of a Linux Thread.
+  Fields:
+	  o  id: A unique identifier. May be `NULL_TASK_ID`.
+	  o  name: Human-readable name for this task
+	  o  executable_name: Literal path to the binary elf that this task's
+			  entry point is executing from.
+	  o  address_space_id: The unique ID for the address space this task is
+			  running in.
+  */
+struct task_info_node_s {
+	U64 id;
+	char name[32];
+	U64 address_space_id;
+};
+
+/*
+  Type: REMOTE_SWITCH
+  Description:
+	  Collection switch set on target
+*/
+typedef struct REMOTE_SWITCH_NODE_S REMOTE_SWITCH_NODE;
+typedef REMOTE_SWITCH_NODE * REMOTE_SWITCH;
+
+struct REMOTE_SWITCH_NODE_S {
+	U32 auto_mode : 1;
+	U32 adv_hotspot : 1;
+	U32 lbr_callstack : 2;
+	U32 full_pebs : 1;
+	U32 uncore_supported : 1;
+	U32 agent_mode : 2;
+	U32 sched_switch_enabled : 1;
+	U32 data_transfer_mode : 1;
+	U32 reserved1 : 22;
+	U32 reserved2;
+};
+
+#define REMOTE_SWITCH_auto_mode(x) ((x).auto_mode)
+#define REMOTE_SWITCH_adv_hotspot(x) ((x).adv_hotspot)
+#define REMOTE_SWITCH_lbr_callstack(x) ((x).lbr_callstack)
+#define REMOTE_SWITCH_full_pebs(x) ((x).full_pebs)
+#define REMOTE_SWITCH_uncore_supported(x) ((x).uncore_supported)
+#define REMOTE_SWITCH_agent_mode(x) ((x).agent_mode)
+#define REMOTE_SWITCH_sched_switch_enabled(x) ((x).sched_switch_enabled)
+#define REMOTE_SWITCH_data_transfer_mode(x) ((x).data_transfer_mode)
+
+/*
+  Type: REMOTE_OS_INFO
+  Description:
+	  Remote target OS system information
+*/
+#define OSINFOLEN 64
+typedef struct REMOTE_OS_INFO_NODE_S REMOTE_OS_INFO_NODE;
+typedef REMOTE_OS_INFO_NODE * REMOTE_OS_INFO;
+
+struct REMOTE_OS_INFO_NODE_S {
+	U32 os_family;
+	U32 reserved1;
+	S8 sysname[OSINFOLEN];
+	S8 release[OSINFOLEN];
+	S8 version[OSINFOLEN];
+};
+
+#define REMOTE_OS_INFO_os_family(x) ((x).os_family)
+#define REMOTE_OS_INFO_sysname(x) ((x).sysname)
+#define REMOTE_OS_INFO_release(x) ((x).release)
+#define REMOTE_OS_INFO_version(x) ((x).version)
+
+/*
+  Type: REMOTE_HARDWARE_INFO
+  Description:
+	  Remote target hardware information
+*/
+typedef struct REMOTE_HARDWARE_INFO_NODE_S REMOTE_HARDWARE_INFO_NODE;
+typedef REMOTE_HARDWARE_INFO_NODE * REMOTE_HARDWARE_INFO;
+
+struct REMOTE_HARDWARE_INFO_NODE_S {
+	U32 num_cpus;
+	U32 family;
+	U32 model;
+	U32 stepping;
+	U64 tsc_freq;
+	U64 reserved2;
+	U64 reserved3;
+};
+
+#define REMOTE_HARDWARE_INFO_num_cpus(x) ((x).num_cpus)
+#define REMOTE_HARDWARE_INFO_family(x) ((x).family)
+#define REMOTE_HARDWARE_INFO_model(x) ((x).model)
+#define REMOTE_HARDWARE_INFO_stepping(x) ((x).stepping)
+#define REMOTE_HARDWARE_INFO_tsc_frequency(x) ((x).tsc_freq)
+
+/*
+  Type: SEP_AGENT_MODE
+  Description:
+	  SEP mode on target agent
+*/
+typedef enum {
+	NATIVE_AGENT = 0,
+	HOST_VM_AGENT, // Service OS in ACRN
+	GUEST_VM_AGENT // User OS in ACRN
+} SEP_AGENT_MODE;
+
+/*
+  Type: DATA_TRANSFER_MODE
+  Description:
+	 Data transfer mode from target agent to remote host
+*/
+typedef enum {
+	IMMEDIATE_TRANSFER = 0,
+	DELAYED_TRANSFER // Send after collection is done
+} DATA_TRANSFER_MODE;
+
+#define MAX_NUM_OS_ALLOWED 6
+#define TARGET_IP_NAMELEN 64
+
+typedef struct TARGET_INFO_NODE_S TARGET_INFO_NODE;
+typedef TARGET_INFO_NODE * TARGET_INFO;
+
+struct TARGET_INFO_NODE_S {
+	U32 num_of_agents;
+	U32 reserved;
+	U32 os_id[MAX_NUM_OS_ALLOWED];
+	S8 ip_address[MAX_NUM_OS_ALLOWED][TARGET_IP_NAMELEN];
+	REMOTE_OS_INFO_NODE os_info[MAX_NUM_OS_ALLOWED];
+	REMOTE_HARDWARE_INFO_NODE hardware_info[MAX_NUM_OS_ALLOWED];
+	REMOTE_SWITCH_NODE remote_switch[MAX_NUM_OS_ALLOWED];
+};
+
+#define TARGET_INFO_num_of_agents(x) ((x)->num_of_agents)
+#define TARGET_INFO_os_id(x, i) ((x)->os_id[i])
+#define TARGET_INFO_os_info(x, i) ((x)->os_info[i])
+#define TARGET_INFO_ip_address(x, i) ((x)->ip_address[i])
+#define TARGET_INFO_hardware_info(x, i) ((x)->hardware_info[i])
+#define TARGET_INFO_remote_switch(x, i) ((x)->remote_switch[i])
+
+typedef struct CPU_MAP_TRACE_NODE_S CPU_MAP_TRACE_NODE;
+typedef CPU_MAP_TRACE_NODE * CPU_MAP_TRACE;
+
+struct CPU_MAP_TRACE_NODE_S {
+	U64 tsc;
+	U32 os_id;
+	U32 vcpu_id;
+	U32 pcpu_id;
+	U8 is_static : 1;
+	U8 initial : 1;
+	U8 reserved1 : 6;
+	U8 reserved2;
+	U16 reserved3;
+	U64 reserved4;
+};
+
+#define CPU_MAP_TRACE_tsc(x) ((x)->tsc)
+#define CPU_MAP_TRACE_os_id(x) ((x)->os_id)
+#define CPU_MAP_TRACE_vcpu_id(x) ((x)->vcpu_id)
+#define CPU_MAP_TRACE_pcpu_id(x) ((x)->pcpu_id)
+#define CPU_MAP_TRACE_is_static(x) ((x)->is_static)
+#define CPU_MAP_TRACE_initial(x) ((x)->initial)
+
+typedef struct VM_SWITCH_TRACE_NODE_S VM_SWITCH_TRACE_NODE;
+typedef VM_SWITCH_TRACE_NODE * VM_SWITCH_TRACE;
+
+struct VM_SWITCH_TRACE_NODE_S {
+	U64 tsc;
+	U32 from_os_id;
+	U32 to_os_id;
+	U64 reason;
+	U64 reserved1;
+	U64 reserved2;
+};
+
+#define VM_SWITCH_TRACE_tsc(x) ((x)->tsc)
+#define VM_SWITCH_TRACE_from_os_id(x) ((x)->from_os_id)
+#define VM_SWITCH_TRACE_to_os_id(x) ((x)->to_os_id)
+#define VM_SWITCH_TRACE_reason(x) ((x)->reason)
+
+typedef struct EMON_BUFFER_DRIVER_HELPER_NODE_S EMON_BUFFER_DRIVER_HELPER_NODE;
+typedef EMON_BUFFER_DRIVER_HELPER_NODE * EMON_BUFFER_DRIVER_HELPER;
+
+struct EMON_BUFFER_DRIVER_HELPER_NODE_S {
+	U32 num_entries_per_package;
+	U32 num_cpu;
+	U32 power_num_package_events;
+	U32 power_num_module_events;
+	U32 power_num_thread_events;
+	U32 power_device_offset_in_package;
+	U32 core_num_events;
+	U32 core_index_to_thread_offset_map[];
+};
+
+#define EMON_BUFFER_DRIVER_HELPER_num_entries_per_package(x)                   \
+	((x)->num_entries_per_package)
+#define EMON_BUFFER_DRIVER_HELPER_num_cpu(x) ((x)->num_cpu)
+#define EMON_BUFFER_DRIVER_HELPER_power_num_package_events(x)                  \
+	((x)->power_num_package_events)
+#define EMON_BUFFER_DRIVER_HELPER_power_num_module_events(x)                   \
+	((x)->power_num_module_events)
+#define EMON_BUFFER_DRIVER_HELPER_power_num_thread_events(x)                   \
+	((x)->power_num_thread_events)
+#define EMON_BUFFER_DRIVER_HELPER_power_device_offset_in_package(x)            \
+	((x)->power_device_offset_in_package)
+#define EMON_BUFFER_DRIVER_HELPER_core_num_events(x) ((x)->core_num_events)
+#define EMON_BUFFER_DRIVER_HELPER_core_index_to_thread_offset_map(x)           \
+	((x)->core_index_to_thread_offset_map)
+
+// EMON counts buffer follow this hardware topology: package -> device -> unit/thread -> event
+
+// Calculate the CORE thread offset
+// Using for initialization: calculate the cpu_index_to_thread_offset_map in emon_Create_Emon_Buffer_Descriptor()
+// EMON_BUFFER_CORE_THREAD_OFFSET =
+//      package_id * num_entries_per_package                        +  //package offset
+//      device_offset_in_package                                    +  //device base offset
+//      (core_id * threads_per_core + thread_id)  * num_core_events +  //thread offset
+#define EMON_BUFFER_CORE_THREAD_OFFSET(package_id, num_entries_per_package,    \
+				       device_offset_in_package, core_id,      \
+				       threads_per_core, thread_id,            \
+				       num_core_events)                        \
+	(package_id * num_entries_per_package + device_offset_in_package +     \
+	(core_id * threads_per_core + thread_id) * num_core_events)
+
+// Take cpu_index and cpu_index_to_thread_offset_map to get thread_offset, and calculate the CORE event offset
+// Using for kernel and emon_output.c printing function
+// EMON_BUFFER_CORE_EVENT_OFFSET =
+//      cpu_index_to_thread_offset +  //thread offset
+//      core_event_id                 //event_offset
+#define EMON_BUFFER_CORE_EVENT_OFFSET(cpu_index_to_thread_offset,              \
+				      core_event_id)                           \
+	(cpu_index_to_thread_offset + core_event_id)
+
+// Calculate the device level to UNCORE event offset
+// Using for kernel and emon_output.c printing function
+// EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET_IN_PACKAGE =
+//      device_offset_in_package         +  //device_offset_in_package
+//      device_unit_id * num_unit_events +  //unit_offset
+//      device_event_id                     //event_offset
+#define EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET_IN_PACKAGE(                    \
+	device_offset_in_package, device_unit_id, num_unit_events,             \
+	device_event_id)                                                       \
+	(device_offset_in_package + device_unit_id * num_unit_events +         \
+		device_event_id)
+
+// Take 'device level to UNCORE event offset' and package_id, calculate the UNCORE package level event offset
+// Using for emon_output.c printing function
+// EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET =
+//      package_id * num_entries_per_package +  //package_offset
+//      uncore_offset_in_package;               //offset_in_package
+#define EMON_BUFFER_UNCORE_PACKAGE_EVENT_OFFSET(                               \
+	package_id, num_entries_per_package, uncore_offset_in_package)         \
+	(package_id * num_entries_per_package + uncore_offset_in_package)
+
+// Take 'device level to UNCORE event offset', calculate the UNCORE system level event offset
+// Using for emon_output.c printing function
+// EMON_BUFFER_UNCORE_SYSTEM_EVENT_OFFSET =
+//      device_offset_in_system            +  //device_offset_in_system
+//      device_unit_id * num_system_events +  //device_unit_offset
+//      device_event_id                       //event_offset
+#define EMON_BUFFER_UNCORE_SYSTEM_EVENT_OFFSET(device_offset_in_system,        \
+					       device_unit_id,                 \
+					       num_system_events,              \
+					       device_event_id)                \
+	(device_offset_in_system + device_unit_id * num_system_events +        \
+		device_event_id)
+
+// Calculate the package level power event offset
+// Using for kernel and emon_output.c printing function
+// EMON_BUFFER_UNCORE_PACKAGE_POWER_EVENT_OFFSET =
+//      package_id * num_entries_per_package + //package offset
+//      device_offset_in_package             + //device offset
+//      package_event_offset                   //power package event offset
+#define EMON_BUFFER_UNCORE_PACKAGE_POWER_EVENT_OFFSET(                         \
+	package_id, num_entries_per_package, device_offset_in_package,         \
+	device_event_offset)                                                   \
+	(package_id * num_entries_per_package + device_offset_in_package +     \
+		device_event_offset)
+
+// Calculate the module level power event offset
+// Using for kernel and emon_output.c printing function
+// EMON_BUFFER_UNCORE_MODULE_POWER_EVENT_OFFSET =
+//      package_id * num_entries_per_package + //package offset
+//      device_offset_in_package             + //device offset
+//      num_package_events                   + //package event offset
+//      module_id * num_module_events        + //module offset
+//      module_event_offset                    //power module event offset
+#define EMON_BUFFER_UNCORE_MODULE_POWER_EVENT_OFFSET(                          \
+	package_id, num_entries_per_package, device_offset_in_package,         \
+	num_package_events, module_id, num_module_events, device_event_offset) \
+	(package_id * num_entries_per_package + device_offset_in_package +     \
+		num_package_events + module_id * num_module_events +           \
+		device_event_offset)
+
+// Calculate the package level power event offset
+// Using for kernel and emon_output.c printing function
+// EMON_BUFFER_UNCORE_THREAD_POWER_EVENT_OFFSET =
+//      package_id * num_entries_per_package                          + //package offset
+//      device_offset_in_package                                      + //device offset
+//      num_package_events                                            + //package offset
+//      num_modules_per_package * num_module_events                   + //module offset
+//      (core_id * threads_per_core + thread_id) * num_thread_events  + //thread offset
+//      thread_event_offset                                             //power thread event offset
+#define EMON_BUFFER_UNCORE_THREAD_POWER_EVENT_OFFSET(                          \
+	package_id, num_entries_per_package, device_offset_in_package,         \
+	num_package_events, num_modules_per_package, num_module_events,        \
+	core_id, threads_per_core, thread_id, num_unit_events,                 \
+	device_event_offset)                                                   \
+	(package_id * num_entries_per_package + device_offset_in_package +     \
+		num_package_events +                                           \
+		num_modules_per_package * num_module_events +                  \
+		(core_id * threads_per_core + thread_id) * num_unit_events +   \
+		device_event_offset)
+
+/*
+ ************************************
+ *  DRIVER LOG BUFFER DECLARATIONS  *
+ ************************************
+ */
+
+#define DRV_MAX_NB_LOG_CATEGORIES 256 // Must be a multiple of 8
+#define DRV_NB_LOG_CATEGORIES 14
+#define DRV_LOG_CATEGORY_LOAD 0
+#define DRV_LOG_CATEGORY_INIT 1
+#define DRV_LOG_CATEGORY_DETECTION 2
+#define DRV_LOG_CATEGORY_ERROR 3
+#define DRV_LOG_CATEGORY_STATE_CHANGE 4
+#define DRV_LOG_CATEGORY_MARK 5
+#define DRV_LOG_CATEGORY_DEBUG 6
+#define DRV_LOG_CATEGORY_FLOW 7
+#define DRV_LOG_CATEGORY_ALLOC 8
+#define DRV_LOG_CATEGORY_INTERRUPT 9
+#define DRV_LOG_CATEGORY_TRACE 10
+#define DRV_LOG_CATEGORY_REGISTER 11
+#define DRV_LOG_CATEGORY_NOTIFICATION 12
+#define DRV_LOG_CATEGORY_WARNING 13
+
+#define LOG_VERBOSITY_UNSET 0xFF
+#define LOG_VERBOSITY_DEFAULT 0xFE
+#define LOG_VERBOSITY_NONE 0
+
+#define LOG_CHANNEL_MEMLOG 0x1
+#define LOG_CHANNEL_AUXMEMLOG 0x2
+#define LOG_CHANNEL_PRINTK 0x4
+#define LOG_CHANNEL_TRACEK 0x8
+#define LOG_CHANNEL_MOSTWHERE                                                  \
+	(LOG_CHANNEL_MEMLOG | LOG_CHANNEL_AUXMEMLOG | LOG_CHANNEL_PRINTK)
+#define LOG_CHANNEL_EVERYWHERE                                                 \
+	(LOG_CHANNEL_MEMLOG | LOG_CHANNEL_AUXMEMLOG | LOG_CHANNEL_PRINTK |     \
+	 LOG_CHANNEL_TRACEK)
+#define LOG_CHANNEL_MASK LOG_CATEGORY_VERBOSITY_EVERYWHERE
+
+#define LOG_CONTEXT_REGULAR 0x10
+#define LOG_CONTEXT_INTERRUPT 0x20
+#define LOG_CONTEXT_NOTIFICATION 0x40
+#define LOG_CONTEXT_ALL                                                        \
+	(LOG_CONTEXT_REGULAR | LOG_CONTEXT_INTERRUPT | LOG_CONTEXT_NOTIFICATION)
+#define LOG_CONTEXT_MASK LOG_CONTEXT_ALL
+#define LOG_CONTEXT_SHIFT 4
+
+#define DRV_LOG_NOTHING 0
+#define DRV_LOG_FLOW_IN 1
+#define DRV_LOG_FLOW_OUT 2
+
+/*
+ * @macro DRV_LOG_ENTRY_NODE_S
+ * @brief
+ * This structure is used to store a log message from the driver.
+ */
+
+#define DRV_LOG_MESSAGE_LENGTH 64
+#define DRV_LOG_FUNCTION_NAME_LENGTH 32
+
+typedef struct DRV_LOG_ENTRY_NODE_S DRV_LOG_ENTRY_NODE;
+typedef DRV_LOG_ENTRY_NODE * DRV_LOG_ENTRY;
+struct DRV_LOG_ENTRY_NODE_S {
+	char function_name[DRV_LOG_FUNCTION_NAME_LENGTH];
+	char message[DRV_LOG_MESSAGE_LENGTH];
+
+	U16 temporal_tag;
+	U16 integrity_tag;
+
+	U8 category;
+	U8 secondary_info; // Secondary attribute:
+		// former driver state for STATE category
+		// 'ENTER' or 'LEAVE' for FLOW and TRACE categories
+	U16 processor_id; // NB: not guaranteed to be accurate (due to preemption / core migration)
+
+	U64 tsc;
+
+	U16 nb_active_interrupts; // never 100% accurate, merely indicative
+	U8 active_drv_operation; // only 100% accurate for IOCTL-called functions
+	U8 driver_state;
+
+	U16 line_number; // as per the __LINE__ macro
+
+	U16 nb_active_notifications;
+
+	U64 reserved; // need padding to reach 128 bytes
+}; // this structure should be exactly 128-byte long
+
+#define DRV_LOG_ENTRY_temporal_tag(ent) ((ent)->temporal_tag)
+#define DRV_LOG_ENTRY_integrity_tag(ent) ((ent)->integrity_tag)
+#define DRV_LOG_ENTRY_category(ent) ((ent)->category)
+#define DRV_LOG_ENTRY_secondary_info(ent) ((ent)->secondary_info)
+#define DRV_LOG_ENTRY_processor_id(ent) ((ent)->processor_id)
+#define DRV_LOG_ENTRY_tsc(ent) ((ent)->tsc)
+#define DRV_LOG_ENTRY_driver_state(ent) ((ent)->driver_state)
+#define DRV_LOG_ENTRY_active_drv_operation(ent) ((ent)->active_drv_operation)
+#define DRV_LOG_ENTRY_nb_active_interrupts(ent) ((ent)->nb_active_interrupts)
+#define DRV_LOG_ENTRY_nb_active_notifications(ent)                             \
+	((ent)->nb_active_notifications)
+#define DRV_LOG_ENTRY_line_number(ent) ((ent)->line_number)
+#define DRV_LOG_ENTRY_message(ent) ((ent)->message)
+#define DRV_LOG_ENTRY_function_name(ent) ((ent)->function_name)
+
+/*
+ * @macro DRV_LOG_BUFFER_NODE_S
+ * @brief
+ * Circular buffer structure storing the latest DRV_LOG_MAX_NB_ENTRIES driver messages
+ */
+
+#define DRV_LOG_SIGNATURE_SIZE 8 // Must be a multiple of 8
+#define DRV_LOG_SIGNATURE_0 'S'
+#define DRV_LOG_SIGNATURE_1 'e'
+#define DRV_LOG_SIGNATURE_2 'P'
+#define DRV_LOG_SIGNATURE_3 'd'
+#define DRV_LOG_SIGNATURE_4 'R'
+#define DRV_LOG_SIGNATURE_5 'v'
+#define DRV_LOG_SIGNATURE_6 '5'
+#define DRV_LOG_SIGNATURE_7 '\0'
+// The signature is "SePdRv4";
+// not declared as string on purpose to avoid false positives when trying to identify the log buffer in a crash dump
+
+#define DRV_LOG_VERSION 1
+#define DRV_LOG_FILLER_BYTE 1
+
+#define DRV_LOG_DRIVER_VERSION_SIZE 64 // Must be a multiple of 8
+#define DRV_LOG_MAX_NB_PRI_ENTRIES   (8192 * 2)
+		// 2MB buffer [*HAS TO BE* a power of 2!] [8192 entries = 1 MB]
+#define DRV_LOG_MAX_NB_AUX_ENTRIES  (8192)
+		// 1MB buffer [*HAS TO BE* a power of 2!]
+#define DRV_LOG_MAX_NB_ENTRIES                                                 \
+	(DRV_LOG_MAX_NB_PRI_ENTRIES + DRV_LOG_MAX_NB_AUX_ENTRIES)
+
+typedef struct DRV_LOG_BUFFER_NODE_S DRV_LOG_BUFFER_NODE;
+typedef DRV_LOG_BUFFER_NODE * DRV_LOG_BUFFER;
+struct DRV_LOG_BUFFER_NODE_S {
+	char header_signature[DRV_LOG_SIGNATURE_SIZE];
+	// some signature to be able to locate the log even without -g; ASCII would help
+	// should we change the signature for each log's version instead of keeping it in a
+	// dedicated field?
+
+	U32 log_size; // filled with sizeof(this structure) at init.
+	U32 max_nb_pri_entries; // filled with the driver's "DRV_LOG_MAX_NB_PRIM_ENTRIES" at init.
+
+	U32 max_nb_aux_entries; // filled with the driver's "DRV_LOG_MAX_NB_AUX_ENTRIES" at init.
+	U32 reserved1;
+
+	U64 init_time; // primary log disambiguator
+
+	U32 disambiguator;
+	// used to differentiate the driver's version of the log when a full memory dump can contain some from userland
+
+	U32 log_version; // 0 at first, increase when format changes?
+
+	U32 pri_entry_index;
+	// should be incremented *atomically* as a means to (re)allocate the next primary log entry.
+
+	U32 aux_entry_index;
+	// should be incremented *atomically* as a means to (re)allocate the next auxiliary log entry.
+
+	char driver_version[DRV_LOG_DRIVER_VERSION_SIZE];
+
+	U8 driver_state;
+	U8 active_drv_operation;
+	U16 reserved2;
+	U32 nb_drv_operations;
+
+	U32 nb_interrupts;
+	U16 nb_active_interrupts;
+	U16 nb_active_notifications;
+
+	U32 nb_notifications;
+	U32 nb_driver_state_transitions;
+
+	U8 contiguous_physical_memory;
+	U8 reserved3;
+	U16 reserved4;
+	U32 reserved5;
+
+	U8 verbosities[DRV_MAX_NB_LOG_CATEGORIES];
+
+	DRV_LOG_ENTRY_NODE entries[DRV_LOG_MAX_NB_ENTRIES];
+
+	char footer_signature[DRV_LOG_SIGNATURE_SIZE];
+};
+
+#define DRV_LOG_BUFFER_pri_entry_index(log) ((log)->pri_entry_index)
+#define DRV_LOG_BUFFER_aux_entry_index(log) ((log)->aux_entry_index)
+#define DRV_LOG_BUFFER_header_signature(log) ((log)->header_signature)
+#define DRV_LOG_BUFFER_footer_signature(log) ((log)->footer_signature)
+#define DRV_LOG_BUFFER_log_size(log) ((log)->log_size)
+#define DRV_LOG_BUFFER_driver_version(log) ((log)->driver_version)
+#define DRV_LOG_BUFFER_driver_state(log) ((log)->driver_state)
+#define DRV_LOG_BUFFER_active_drv_operation(log) ((log)->active_drv_operation)
+#define DRV_LOG_BUFFER_nb_interrupts(log) ((log)->nb_interrupts)
+#define DRV_LOG_BUFFER_nb_active_interrupts(log) ((log)->nb_active_interrupts)
+#define DRV_LOG_BUFFER_nb_notifications(log) ((log)->nb_notifications)
+#define DRV_LOG_BUFFER_nb_active_notifications(log)                            \
+	((log)->nb_active_notifications)
+#define DRV_LOG_BUFFER_nb_driver_state_transitions(log)                        \
+	((log)->nb_driver_state_transitions)
+#define DRV_LOG_BUFFER_nb_drv_operations(log) ((log)->nb_drv_operations)
+#define DRV_LOG_BUFFER_max_nb_pri_entries(log) ((log)->max_nb_pri_entries)
+#define DRV_LOG_BUFFER_max_nb_aux_entries(log) ((log)->max_nb_aux_entries)
+#define DRV_LOG_BUFFER_init_time(log) ((log)->init_time)
+#define DRV_LOG_BUFFER_disambiguator(log) ((log)->disambiguator)
+#define DRV_LOG_BUFFER_log_version(log) ((log)->log_version)
+#define DRV_LOG_BUFFER_entries(log) ((log)->entries)
+#define DRV_LOG_BUFFER_contiguous_physical_memory(log)                         \
+	((log)->contiguous_physical_memory)
+#define DRV_LOG_BUFFER_verbosities(log) ((log)->verbosities)
+
+#define DRV_LOG_CONTROL_MAX_DATA_SIZE                                          \
+	DRV_MAX_NB_LOG_CATEGORIES // Must be a multiple of 8
+
+typedef struct DRV_LOG_CONTROL_NODE_S DRV_LOG_CONTROL_NODE;
+typedef DRV_LOG_CONTROL_NODE * DRV_LOG_CONTROL;
+
+struct DRV_LOG_CONTROL_NODE_S {
+	U32 command;
+	U32 reserved1;
+	U8 data[DRV_LOG_CONTROL_MAX_DATA_SIZE];
+	// only DRV_NB_LOG_CATEGORIES elements will be used, but let's plan for backwards compatibility
+	// if LOG_CATEGORY_UNSET, then READ instead of WRITE
+
+	U64 reserved2;
+	// may later want to add support for resizing the buffer, or only log 100 first interrupts, etc.
+
+	U64 reserved3;
+	U64 reserved4;
+	U64 reserved5;
+};
+
+#define DRV_LOG_CONTROL_command(x) ((x)->command)
+#define DRV_LOG_CONTROL_verbosities(x) ((x)->data)
+#define DRV_LOG_CONTROL_message(x)   ((x)->data)
+		// Userland 'MARK' messages use the 'data' field too.
+#define DRV_LOG_CONTROL_log_size(x) (*((U32 *)((x)->data)))
+
+#define DRV_LOG_CONTROL_COMMAND_NONE 0
+#define DRV_LOG_CONTROL_COMMAND_ADJUST_VERBOSITY 1
+#define DRV_LOG_CONTROL_COMMAND_MARK 2
+#define DRV_LOG_CONTROL_COMMAND_QUERY_SIZE 3
+#define DRV_LOG_CONTROL_COMMAND_BENCHMARK 4
+
+#if defined(__cplusplus)
+}
+#endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/lwpmudrv_types.h b/drivers/platform/x86/socperf/include/lwpmudrv_types.h
new file mode 100644
index 000000000000..85f3d1a9e1e7
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/lwpmudrv_types.h
@@ -0,0 +1,158 @@
+/***
+ * -------------------------------------------------------------------------
+ *               INTEL CORPORATION PROPRIETARY INFORMATION
+ *  This software is supplied under the terms of the accompanying license
+ *  agreement or nondisclosure agreement with Intel Corporation and may not
+ *  be copied or disclosed except in accordance with the terms of that
+ *  agreement.
+ *        Copyright(C) 2007-2019 Intel Corporation.  All Rights Reserved.
+ * -------------------------------------------------------------------------
+***/
+
+#ifndef _LWPMUDRV_TYPES_H_
+#define _LWPMUDRV_TYPES_H_
+
+#if defined(__cplusplus)
+extern "C" {
+#endif
+
+#if defined(BUILD_DRV_ESX)
+//SR: added size_t def
+typedef unsigned long size_t;
+typedef unsigned long ssize_t;
+#endif
+
+typedef unsigned char U8;
+typedef char S8;
+typedef short S16;
+typedef unsigned short U16;
+typedef unsigned int U32;
+typedef int S32;
+#if defined(DRV_OS_WINDOWS)
+typedef unsigned __int64 U64;
+typedef __int64 S64;
+#elif defined(DRV_OS_LINUX) || defined(DRV_OS_SOLARIS) ||                      \
+	defined(DRV_OS_MAC) || defined(DRV_OS_ANDROID) ||                      \
+	defined(DRV_OS_FREEBSD)
+typedef unsigned long long U64;
+typedef long long S64;
+typedef unsigned long ULONG;
+typedef void VOID;
+typedef void *LPVOID;
+
+#if defined(BUILD_DRV_ESX)
+//SR: added UWORD64 def
+typedef union _UWORD64 {
+	struct {
+		U32 low;
+		S32 hi;
+	} c;
+	S64 qword;
+} UWORD64, *PWORD64;
+#endif
+#else
+#error "Undefined OS"
+#endif
+
+#if defined(DRV_IA32)
+typedef S32 SIOP;
+typedef U32 UIOP;
+#elif defined(DRV_EM64T)
+typedef S64 SIOP;
+typedef U64 UIOP;
+#else
+#error "Unexpected Architecture seen"
+#endif
+
+typedef U32 DRV_BOOL;
+typedef void *PVOID;
+
+#if !defined(__DEFINE_STCHAR__)
+#define __DEFINE_STCHAR__
+#if defined(UNICODE)
+typedef wchar_t STCHAR;
+#define VTSA_T(x) L##x
+#else
+typedef char STCHAR;
+#define VTSA_T(x) x
+#endif
+#endif
+
+#if defined(DRV_OS_WINDOWS)
+#include <wchar.h>
+typedef wchar_t DRV_STCHAR;
+typedef wchar_t VTSA_CHAR;
+#else
+typedef char DRV_STCHAR;
+#endif
+
+//
+// Handy Defines
+//
+typedef U32 DRV_STATUS;
+
+#define MAX_STRING_LENGTH 1024
+#define MAXNAMELEN 256
+
+#if defined(DRV_OS_WINDOWS)
+#define UNLINK _unlink
+#define RENAME rename
+#define WCSDUP _wcsdup
+#endif
+#if defined(DRV_OS_LINUX) || defined(DRV_OS_SOLARIS) || defined(DRV_OS_MAC) || \
+	defined(DRV_OS_ANDROID) || defined(DRV_OS_FREEBSD)
+#define UNLINK unlink
+#define RENAME rename
+#endif
+
+#if defined(DRV_OS_SOLARIS) && !defined(_KERNEL)
+//wcsdup is missing on Solaris
+#include <stdlib.h>
+#include <wchar.h>
+
+static inline wchar_t *solaris_wcsdup(const wchar_t *wc)
+{
+	wchar_t *tmp = (wchar_t *)malloc((wcslen(wc) + 1) * sizeof(wchar_t));
+	wcscpy(tmp, wc);
+	return tmp;
+}
+#define WCSDUP solaris_wcsdup
+#endif
+
+#if defined(DRV_OS_LINUX) || defined(DRV_OS_FREEBSD) || defined(DRV_OS_MAC)
+#define WCSDUP wcsdup
+#endif
+
+#if !defined(_WCHAR_T_DEFINED)
+#if defined(DRV_OS_LINUX) || defined(DRV_OS_ANDROID) || defined(DRV_OS_SOLARIS)
+#if !defined(_GNU_SOURCE)
+#define _GNU_SOURCE
+#endif
+#endif
+#endif
+
+#if (defined(DRV_OS_LINUX) || defined(DRV_OS_ANDROID)) && !defined(__KERNEL__)
+#include <wchar.h>
+typedef wchar_t VTSA_CHAR;
+#endif
+
+#if (defined(DRV_OS_MAC) || defined(DRV_OS_FREEBSD) ||                         \
+     defined(DRV_OS_SOLARIS)) &&                                               \
+	!defined(_KERNEL)
+#include <wchar.h>
+typedef wchar_t VTSA_CHAR;
+#endif
+
+#define TRUE 1
+#define FALSE 0
+
+#define ALIGN_4(x) (((x) + 3) & ~3)
+#define ALIGN_8(x) (((x) + 7) & ~7)
+#define ALIGN_16(x) (((x) + 15) & ~15)
+#define ALIGN_32(x) (((x) + 31) & ~31)
+
+#if defined(__cplusplus)
+}
+#endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/lwpmudrv_version.h b/drivers/platform/x86/socperf/include/lwpmudrv_version.h
new file mode 100644
index 000000000000..c8f709162a56
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/lwpmudrv_version.h
@@ -0,0 +1,158 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2010-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2010-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+/*
+ *  File  : lwpmudrv_version.h
+ */
+
+#ifndef _LWPMUDRV_VERSION_H_
+#define _LWPMUDRV_VERSION_H_
+
+#if defined(__cplusplus)
+extern "C" {
+#endif
+
+/*
+ * @macro SOCPERF_VERSION_NODE_S
+ * @brief
+ * This structure supports versioning in Sep. The field major indicates the major version,
+ * minor indicates the minor version and api indicates the api version for the current
+ * sep build. This structure is initialized at the time when the driver is loaded.
+ */
+
+typedef struct SOCPERF_VERSION_NODE_S SOCPERF_VERSION_NODE;
+typedef SOCPERF_VERSION_NODE * SOCPERF_VERSION;
+
+struct SOCPERF_VERSION_NODE_S {
+	union {
+		U32 socperf_version;
+		struct {
+			S32 major : 8;
+			S32 minor : 8;
+			S32 api : 8;
+			S32 update : 8;
+		} s1;
+	} u1;
+};
+
+#define SOCPERF_VERSION_NODE_socperf_version(version)                          \
+	((version)->u1.socperf_version)
+#define SOCPERF_VERSION_NODE_major(version) ((version)->u1.s1.major)
+#define SOCPERF_VERSION_NODE_minor(version) ((version)->u1.s1.minor)
+#define SOCPERF_VERSION_NODE_api(version) ((version)->u1.s1.api)
+#define SEP_VERSION_NODE_update(version) ((version)->u1.s1.update)
+
+#if defined(__cplusplus)
+}
+#endif
+
+// SOCPERF VERSIONING
+
+#define _STRINGIFY(x) #x
+#define STRINGIFY(x) _STRINGIFY(x)
+#define _STRINGIFY_W(x) L#x
+#define STRINGIFY_W(x) _STRINGIFY_W(x)
+
+#define SOCPERF_MAJOR_VERSION 3
+#define SOCPERF_MINOR_VERSION 0
+#define SOCPERF_API_VERSION 0
+#define SOCPERF_UPDATE_VERSION 0
+#if SOCPERF_UPDATE_VERSION > 0
+#define SOCPERF_UPDATE_STRING " Update " STRINGIFY(SOCPERF_UPDATE_VERSION)
+#else
+#define SOCPERF_UPDATE_STRING ""
+#endif
+
+#define SOCPERF_PRODUCT_NAME "Sampling Enabling Product"
+#define PRODUCT_VERSION_DATE __DATE__ " at " __TIME__
+#define PRODUCT_COPYRIGHT                                                      \
+	"Copyright (C) 2011-2018 Intel Corporation. All rights reserved."
+#define PRODUCT_DISCLAIMER                                                                  \
+	"Warning: This computer program is protected under U.S. and international\n"        \
+	"copyright laws, and may only be used or copied in accordance with the terms\n"     \
+	"of the license agreement. Except as permitted by such license, no part\n"          \
+	"of this computer program may be reproduced, stored in a retrieval system,\n"       \
+	"or transmitted in any form or by any means without the express written consent\n"  \
+	"of Intel Corporation."
+
+#define PRODUCT_VERSION "5.0"
+
+#define SOCPERF_NAME "socperf"
+#define SOCPERF_NAME_W L"socperf"
+
+#define SOCPERF_MSG_PREFIX                                                     \
+	SOCPERF_NAME "" STRINGIFY(SOCPERF_MAJOR_VERSION) "_" STRINGIFY(        \
+		SOCPERF_MINOR_VERSION) ":"
+#define SOCPERF_VERSION_STR                                                    \
+	STRINGIFY(SOCPERF_MAJOR_VERSION)                                       \
+	"." STRINGIFY(SOCPERF_MINOR_VERSION) "." STRINGIFY(                    \
+		SOCPERF_API_VERSION)
+
+// #if defined(DRV_OS_WINDOWS)
+// #define SOCPERF_DRIVER_NAME SOCPERF_NAME STRINGIFY(SOCPERF_MAJOR_VERSION)
+// #define SOCPERF_DRIVER_NAME_W SOCPERF_NAME_W STRINGIFY_W(SOCPERF_MAJOR_VERSION)
+// #define SOCPERF_DEVICE_NAME SOCPERF_DRIVER_NAME
+// #endif
+
+#if defined(DRV_OS_LINUX) || defined(DRV_OS_SOLARIS) ||                        \
+	defined(DRV_OS_ANDROID) || defined(DRV_OS_FREEBSD)
+#define SOCPERF_DRIVER_NAME SOCPERF_NAME "" STRINGIFY(SOCPERF_MAJOR_VERSION)
+#define SOCPERF_SAMPLES_NAME SOCPERF_DRIVER_NAME "_s"
+#define SOCPERF_DEVICE_NAME "/dev/" SOCPERF_DRIVER_NAME
+#endif
+
+// #if defined(DRV_OS_MAC)
+// #define SOCPERF_DRIVER_NAME SOCPERF_NAME "" STRINGIFY(SOCPERF_MAJOR_VERSION)
+// #define SOCPERF_SAMPLES_NAME SOCPERF_DRIVER_NAME "_s"
+// #define SOCPERF_DEVICE_NAME SOCPERF_DRIVER_NAME
+// #endif
+
+#endif
diff --git a/drivers/platform/x86/socperf/include/rise_errors.h b/drivers/platform/x86/socperf/include/rise_errors.h
new file mode 100644
index 000000000000..18e9561156e0
--- /dev/null
+++ b/drivers/platform/x86/socperf/include/rise_errors.h
@@ -0,0 +1,326 @@
+/***
+ * -------------------------------------------------------------------------
+ *               INTEL CORPORATION PROPRIETARY INFORMATION
+ *  This software is supplied under the terms of the accompanying license
+ *  agreement or nondisclosure agreement with Intel Corporation and may not
+ *  be copied or disclosed except in accordance with the terms of that
+ *  agreement.
+ *        Copyright(C) 2004-2019 Intel Corporation.  All Rights Reserved.
+ * -------------------------------------------------------------------------
+***/
+
+#ifndef _RISE_ERRORS_H_
+#define _RISE_ERRORS_H_
+
+//
+// NOTE:
+//
+// 1) Before adding an error code, first make sure the error code doesn't
+// already exist. If it does, use that, don't create a new one just because...
+//
+// 2) When adding an error code, add it to the end of the list. Don't insert
+// error numbers in the middle of the list! For backwards compatibility,
+// we don't want the numbers changing unless we really need them
+// to for some reason (like we want to switch to negative error numbers)
+//
+// 3) Change the VT_LAST_ERROR_CODE macro to point to the (newly added)
+// last error. This is done so SW can verify the number of error codes
+// possible matches the number of error strings it has
+//
+// 4) Don't forget to update the error string table to include your
+// error code (rise.c). Since the goal is something human readable
+// you don't need to use abbreviations in there (ie. don't say "bad param",
+// say "bad parameter" or "illegal parameter passed in")
+//
+// 5) Compile and run the test_rise app (in the test_rise directory) to
+// verify things are still working
+//
+//
+
+#define VT_SUCCESS 0
+#define VT_FAILURE -1
+
+/*************************************************************/
+
+#define VT_INVALID_MAX_SAMP 1
+#define VT_INVALID_SAMP_PER_BUFF 2
+#define VT_INVALID_SAMP_INTERVAL 3
+#define VT_INVALID_PATH 4
+#define VT_TB5_IN_USE 5
+#define VT_INVALID_NUM_EVENTS 6
+#define VT_INTERNAL_ERROR 8
+#define VT_BAD_EVENT_NAME 9
+#define VT_NO_SAMP_SESSION 10
+#define VT_NO_EVENTS 11
+#define VT_MULTIPLE_RUNS 12
+#define VT_NO_SAM_PARAMS 13
+#define VT_SDB_ALREADY_EXISTS 14
+#define VT_SAMPLING_ALREADY_STARTED 15
+#define VT_TBS_NOT_SUPPORTED 16
+#define VT_INVALID_SAMPARAMS_SIZE 17
+#define VT_INVALID_EVENT_SIZE 18
+#define VT_ALREADY_PROCESSES 19
+#define VT_INVALID_EVENTS_PATH 20
+#define VT_INVALID_LICENSE 21
+
+/******************************************************/
+//SEP error codes
+
+#define VT_SAM_ERROR 22
+#define VT_SAMPLE_FILE_ALREADY_MAPPED 23
+#define VT_INVALID_SAMPLE_FILE 24
+#define VT_UNKNOWN_SECTION_NUMBER 25
+#define VT_NO_MEMORY 26
+#define VT_ENV_VAR_NOT_FOUND 27
+#define VT_SAMPLE_FILE_NOT_MAPPED 28
+#define VT_BUFFER_OVERFLOW 29
+#define VT_USER_OP_COMPLETED 30
+#define VT_BINARY_NOT_FOUND 31
+#define VT_ISM_NOT_INITIALIZED 32
+#define VT_NO_SYMBOLS 33
+#define VT_SAMPLE_FILE_MAPPING_ERROR 34
+#define VT_BUFFER_NULL 35
+#define VT_UNEXPECTED_NULL_PTR 36
+#define VT_BINARY_LOAD_FAILED 37
+#define VT_FUNCTION_NOT_FOUND_IN_BINARY 38
+#define VT_ENTRY_NOT_FOUND 39
+#define VT_SEP_SYNTAX_ERROR 40
+#define VT_SEP_OPTIONS_ERROR 41
+#define VT_BAD_EVENT_MODIFIER 42
+#define VT_INCOMPATIBLE_PARAMS 43
+#define VT_FILE_OPEN_FAILED 44
+#define VT_EARLY_EXIT 45
+#define VT_TIMEOUT_RETURN 46
+#define VT_NO_CHILD_PROCESS 47
+#define VT_DRIVER_RUNNING 48
+#define VT_DRIVER_STOPPED 49
+#define VT_MULTIPLE_RUNS_NEEDED 50
+#define VT_QUIT_IMMEDIATE 51
+#define VT_DRIVER_INIT_FAILED 52
+#define VT_NO_TB5_CREATED 53
+#define VT_NO_WRITE_PERMISSION 54
+#define VT_DSA_INIT_FAILED 55
+#define VT_INVALID_CPU_MASK 56
+#define VT_SAMP_IN_RUNNING_STATE 57
+#define VT_SAMP_IN_PAUSE_STATE 58
+#define VT_SAMP_IN_STOP_STATE 59
+#define VT_SAMP_NO_SESSION 60
+#define VT_NOT_CONFIGURED 61
+#define VT_LAUNCH_BUILD64_FAILED 62
+#define VT_BAD_PARAMETER 63
+#define VT_ISM_INIT_FAILED 64
+#define VT_INVALID_STATE_TRANS 65
+#define VT_EARLY_EXIT_N_CANCEL 66
+#define VT_EVT_MGR_NOT_INIT 67
+#define VT_ISM_SECTION_ENUM_FAILED 68
+#define VT_VG_PARSER_ERROR 69
+#define VT_MISSING_VALUE_FOR_TOKEN 70
+#define VT_EMPTY_SAMPLE_FILE_NAME 71
+#define VT_UNEXPECTED_VALUE 72
+#define VT_NOT_IMPLEMENTED 73
+#define VT_MISSING_COL_DEPNDNCIES 74
+#define VT_DEP_COL_NOT_LIB_DEFINED 75
+#define VT_COL_NOT_REG_WITH_LIB 76
+#define VT_SECTION_ALREADY_IN_USE 77
+#define VT_SECTION_NOT_EXIST 78
+#define VT_STREAM_NOT_EXIST 79
+#define VT_INVALID_STREAM 80
+#define VT_STREAM_ALREADY_IN_USE 81
+#define VT_DATA_DESC_NOT_EXIST 82
+#define VT_INVALID_ERROR_CODE 83
+#define VT_INCOMPATIBLE_VERSION 84
+#define VT_LEGACY_DATA_NOT_EXIST 85
+#define VT_INVALID_READ_START 86
+#define VT_DRIVER_OPEN_FAILED 87
+#define VT_DRIVER_IOCTL_FAILED 88
+#define VT_SAMP_FILE_CREATE_FAILED 89
+#define VT_MODULE_FILE_CREATE_FAILED 90
+#define VT_INVALID_SAMPLE_FILE_NAME 91
+#define VT_INVALID_MODULE_FILE_NAME 92
+#define VT_FORK_CHILD_PROCESS_FAILED 93
+#define VT_UNEXPECTED_MISMATCH_IN_STRING_TYPES 94
+#define VT_INCOMPLETE_TB5_ENCOUNTERED 95
+#define VT_ERR_CONVERSION_FROM_STRING_2_NUMBER 96
+#define VT_INVALID_STRING 97
+#define VT_UNSUPPORTED_DATA_SIZE 98
+#define VT_TBRW_INIT_FAILED 99
+#define VT_PLUGIN_UNLOAD 100
+#define VT_PLUGIN_ENTRY_NULL 101
+#define VT_UNKNOWN_PLUGIN 102
+#define VT_BUFFER_TOO_SMALL 103
+#define VT_CANNOT_MODIFY_COLUMN 104
+#define VT_MULT_FILTERS_NOT_ALLOWED 105
+#define VT_ADDRESS_IN_USE 106
+#define VT_NO_MORE_MMAPS 107
+#define VT_MAX_PAGES_IN_DS_EXCEEDED 108
+#define VT_INVALID_COL_TYPE_IN_GROUP_INFO 109
+#define VT_AGG_FN_ON_VARCHAR_NOT_SUPP 110
+#define VT_INVALID_ACCESS_PERMS 111
+#define VT_NO_DATA_TO_DISPLAY 112
+#define VT_TB5_IS_NOT_BOUND 113
+#define VT_MISSING_GROUP_BY_COLUMN 114
+#define VT_SMRK_MAX_STREAMS_EXCEEDED 115
+#define VT_SMRK_STREAM_NOT_CREATED 116
+#define VT_SMRK_NOT_IMPL 117
+#define VT_SMRK_TYPE_NOT_IMPL 118
+#define VT_SMRK_TYPE_ALREADY_SET 119
+#define VT_SMRK_NO_STREAM 120
+#define VT_SMRK_INVALID_STREAM_TYPE 121
+#define VT_SMRK_STREAM_NOT_FOUND 122
+#define VT_SMRK_FAIL 123
+#define VT_SECTION_NOT_READABLE 124
+#define VT_SECTION_NOT_WRITEABLE 125
+#define VT_GLOBAL_SECTION_NOT_CLOSED 126
+#define VT_STREAM_SECTION_NOT_CLOSED 127
+#define VT_STREAM_NOT_CLOSED 128
+#define VT_STREAM_NOT_BOUND 129
+#define VT_NO_COLS_SPECIFIED 130
+#define VT_NOT_ALL_SECTIONS_CLOSED 131
+#define VT_SMRK_INVALID_PTR 132
+#define VT_UNEXPECTED_BIND_MISMATCH 133
+#define VT_WIN_TIMER_ERROR 134
+#define VT_ONLY_SNGL_DEPNDT_COL_ALLWD 135
+#define VT_BAD_MODULE 136
+#define VT_INPUT_SOURCE_INFO_NOT_SET 137
+#define VT_UNSUPPORTED_TIME_GRAN 138
+#define VT_NO_SAMPLES_COLLECTED 139
+#define VT_INVALID_CPU_TYPE_VERSION 140
+#define VT_BIND_UNEXPECTED_1STMODREC 141
+#define VT_BIND_MODULES_NOT_SORTED 142
+#define VT_UNEXPECTED_NUM_CPUIDS 143
+#define VT_UNSUPPORTED_ARCH_TYPE 144
+#define VT_NO_DATA_TO_WRITE 145
+#define VT_EM_TIME_SLICE_TOO_SMALL 146
+#define VT_EM_TOO_MANY_EVENT_GROUPS 147
+#define VT_EM_ZERO_GROUPS 148
+#define VT_EM_NOT_SUPPORTED 149
+#define VT_PMU_IN_USE 150
+#define VT_TOO_MANY_INTERRUPTS 151
+#define VT_MAX_SAMPLES_REACHED 152
+#define VT_MODULE_COLLECTION_FAILED 153
+#define VT_INCOMPATIBLE_DRIVER 154
+#define VT_UNABLE_LOCATE_TRIGGER_EVENT 155
+#define VT_COMMAND_NOT_HANDLED 156
+#define VT_DRIVER_VERSION_MISMATCH 157
+#define VT_MAX_MARKERS 158
+#define VT_DRIVER_COMM_FAILED 159
+#define VT_CHIPSET_CONFIG_FAILED 160
+#define VT_BAD_DATA_BASE 161
+#define VT_PAX_SERVICE_NOT_CONNECTED 162
+#define VT_PAX_SERVICE_ERROR 163
+#define VT_PAX_PMU_RESERVE_FAILED 164
+#define VT_INVALID_CPU_INFO_TYPE 165
+#define VT_CACHE_DOESNT_EXIST 166
+#define VT_UNSUPPORTED_UNCORE_ARCH_TYPE 167
+#define VT_EXCEEDED_MAX_EVENTS 168
+#define VT_MARKER_TIMER_FAILED 169
+#define VT_PAX_PMU_UNRESERVE_FAILED 170
+#define VT_MULTIPLE_PROCESSES_FOUND 171
+#define VT_NO_SUCH_PROCESS_FOUND 172
+#define VT_PCL_NOT_ENABLED 173
+#define VT_PCL_UID_CHECK 174
+#define VT_DEL_RESULTS_DIR_FAILED 175
+#define VT_NO_VALID_EVENTS 176
+#define VT_INVALID_EVENT 177
+#define VT_EVENTS_COUNTED 178
+#define VT_EVENTS_COLLECTED 179
+#define VT_UNSUPPORTED_GFX_ARCH_TYPE 180
+#define VT_GFX_CONFIG_FAILED 181
+#define VT_UNSUPPORTED_NON_NATIVE_MODE 182
+#define VT_INVALID_DEVICE 183
+#define VT_ENV_SETUP_FAILED 184
+#define VT_RESUME_NOT_RECEIVED 185
+#define VT_UNSUPPORTED_PWR_ARCH_TYPE 186
+#define VT_PWR_CONFIG_FAILED 187
+#define VT_NMI_WATCHDOG_FOUND 188
+#define VT_NO_PMU_RESOURCES 189
+#define VT_MIC_CARD_NOT_ONLINE 190
+#define VT_FREEZE_ON_PMI_NOT_AVAIL 191
+#define VT_FLUSH_FAILED 192
+#define VT_FLUSH_SUCCESS 193
+#define VT_WRITE_ERROR 194
+#define VT_NO_SPACE 195
+#define VT_MSR_ACCESS_ERROR 196
+#define VT_PEBS_NOT_SUPPORTED 197
+#define VT_LUA_PARSE_ERROR 198
+#define VT_COMM_CONNECTION_CLOSED_BY_REMOTE 199
+#define VT_COMM_LISTEN_ERROR 200
+#define VT_COMM_BIND_ERROR 201
+#define VT_COMM_ACCEPT_ERROR 202
+#define VT_COMM_SEND_ERROR 203
+#define VT_COMM_RECV_ERROR 204
+#define VT_COMM_SOCKET_ERROR 205
+#define VT_COMM_CONNECT_ERROR 206
+#define VT_TARGET_COLLECTION_MISMATCH 207
+#define VT_INVALID_SEP_DRIVER_LOG 208
+#define VT_COMM_PROTOCOL_VERSION_MISTMATCH 209
+#define VT_SAMP_IN_UNEXPECTED_STATE 210
+#define VT_COMM_RECV_BUF_RESIZE_ERROR 211
+
+/*
+ * define error code for checking on async marker request
+ */
+#define VT_INVALID_MARKER_ID -1
+
+/*
+ * ************************************************************
+ * NOTE: after adding new error code(s), remember to also
+ *       update the following:
+ *           1) VT_LAST_ERROR_CODE below
+ *           2) viewer/sampling_utils/src/rise.c
+ *           3) collector/controller/sep_msg_catalog.xmc
+ *           4) qnx_kernel/sepdk/include/rise_errors.h
+ *
+ * ************************************************************
+ */
+
+//
+// To make error checking easier, the special VT_LAST_ERROR_CODE
+// should be set to whatever is the last error on the list above
+//
+#define VT_LAST_ERROR_CODE VT_COMM_RECV_BUF_RESIZE_ERROR
+
+//
+// Define a macro to determine success or failure. Users of this
+// error header file should use the macros instead of direct
+// checks so that we can change the error numbers in the future
+// (such as making negative numbers be an error indication and positive
+// numbers being a success with a value indication)
+//
+#define VTSA_SUCCESS(x) ((x) == VT_SUCCESS)
+#define VTSA_FAILED(x) (!VTSA_SUCCESS(x))
+
+//
+// These should be deprecated, but we'll keep them here just in case
+//
+#define SEP_IS_SUCCESS(x) VTSA_SUCCESS(x)
+#define SEP_IS_FAILED(x) VTSA_FAILED(x)
+
+/*************************************************************
+ * API Error Codes
+ *************************************************************/
+#define VTAPI_INVALID_MAX_SAMP VT_INVALID_MAX_SAMP
+#define VTAPI_INVALID_SAMP_PER_BUFF VT_INVALID_SAMP_PER_BUFF
+#define VTAPI_INVALID_SAMP_INTERVAL VT_INVALID_SAMP_INTERVAL
+#define VTAPI_INVALID_PATH VT_INVALID_PATH
+#define VTAPI_TB5_IN_USE VT_TB5_IN_USE
+#define VTAPI_INVALID_NUM_EVENTS VT_INVALID_NUM_EVENTS
+#define VTAPI_INTERNAL_ERROR VT_INTERNAL_ERROR
+#define VTAPI_BAD_EVENT_NAME VT_BAD_EVENT_NAME
+#define VTAPI_NO_SAMP_SESSION VT_NO_SAMP_SESSION
+#define VTAPI_NO_EVENTS VT_NO_EVENTS
+#define VTAPI_MULTIPLE_RUNS VT_MULTIPLE_RUNS
+#define VTAPI_NO_SAM_PARAMS VT_NO_SAM_PARAMS
+#define VTAPI_SDB_ALREADY_EXISTS VT_SDB_ALREADY_EXISTS
+#define VTAPI_SAMPLING_ALREADY_STARTED VT_SAMPLING_ALREADY_STARTED
+#define VTAPI_TBS_NOT_SUPPORTED VT_TBS_NOT_SUPPORTED
+#define VTAPI_INVALID_SAMPARAMS_SIZE VT_INVALID_SAMPARAMS_SIZE
+#define VTAPI_INVALID_EVENT_SIZE VT_INVALID_EVENT_SIZE
+#define VTAPI_ALREADY_PROCESSES VT_ALREADY_PROCESSES
+#define VTAPI_INVALID_EVENTS_PATH VT_INVALID_EVENTS_PATH
+#define VTAPI_INVALID_LICENSE VT_INVALID_LICENSE
+
+typedef int RISE_ERROR;
+typedef void *RISE_PTR;
+
+#endif
diff --git a/drivers/platform/x86/socperf/npk_uncore.c b/drivers/platform/x86/socperf/npk_uncore.c
new file mode 100644
index 000000000000..d8b3bf040453
--- /dev/null
+++ b/drivers/platform/x86/socperf/npk_uncore.c
@@ -0,0 +1,502 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/wait.h>
+#include <linux/fs.h>
+
+#include "lwpmudrv_types.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "inc/socperfdrv.h"
+#include "inc/ecb_iterators.h"
+#include "inc/pci.h"
+#include "inc/control.h"
+#include "inc/npk_uncore.h"
+
+extern LWPMU_DEVICE device_uncore;
+static U32 counter_overflow[SOC_NPK_COUNTER_MAX_COUNTERS];
+static U64 counter_virtual_address;
+static U64 mchbar_virtual_address;
+static U64 mchbar_offset;
+
+/*!
+ * @fn          static ULONG read_From_Register(U64  bar_virtual_address,
+												U64  mmio_offset,
+												U32 *data_val)
+ *
+ * @brief       Reads register programming info
+ *
+ * @param       bar_virtual_address - memory address
+ *              mmio_offset         - offset of the register
+ *              data_val            - register value read
+ *
+ * @return      data from the counter register
+ *
+ * <I>Special Notes:</I>
+ */
+static void read_From_Register(U64 bar_virtual_address, U64 mmio_offset,
+			       U32 *data_val)
+{
+	if (data_val) {
+		*data_val = readl((void __iomem *)((char *)(UIOP)(bar_virtual_address) +
+					  mmio_offset));
+	}
+}
+
+/*!
+ * @fn          static ULONG write_To_Register(U64  bar_virtual_address,
+											   U64  mmio_offset,
+											   U32  value)
+ *
+ * @brief       Write register programming info
+ *
+ * @param       bar_virtual_address - memory address
+ *              mmio_offset         - offset of the register
+ *              value               - register value to be written
+ *
+ * @return      none
+ *
+ * <I>Special Notes:</I>
+ */
+static void write_To_Register(U64 bar_virtual_address, U64 mmio_offset,
+			      ULONG value)
+{
+	U32 read_reg = 0;
+
+	writel(value,
+	       (void __iomem *)(((char *)(UIOP)bar_virtual_address) + mmio_offset));
+	read_From_Register(bar_virtual_address, mmio_offset, &read_reg);
+}
+
+/*!
+ * @fn          static VOID uncore_Reset_Counters(U32 dev_idx)
+ *
+ * @brief       Reset counters
+ *
+ * @param       dev_idx - device index
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Reset_Counters(U32 dev_idx)
+{
+	U32 data_reg = 0;
+
+	if (counter_virtual_address) {
+		FOR_EACH_PCI_REG_RAW(pecb, i, dev_idx)
+		{
+			if (ECB_entries_reg_type(pecb, i) ==
+			    PMU_REG_EVENT_SELECT) {
+				data_reg =
+					i + ECB_operations_register_len(
+						    pecb, PMU_OPERATION_WRITE);
+				if (ECB_entries_reg_type(pecb, data_reg) ==
+				    PMU_REG_DATA) {
+					write_To_Register(
+						counter_virtual_address,
+						ECB_entries_reg_offset(
+							pecb, data_reg),
+						(ULONG)0);
+				}
+				write_To_Register(counter_virtual_address,
+						  ECB_entries_reg_offset(pecb,
+									 i),
+						  (ULONG)SOC_NPK_UNCORE_STOP);
+			}
+		}
+		END_FOR_EACH_PCI_REG_RAW;
+	}
+}
+
+/*!
+ * @fn          static VOID uncore_Write_PMU(VOID*)
+ *
+ * @brief       Initial write of PMU registers
+ *              Walk through the entries and write the value of the register accordingly.
+ *              When current_group = 0, then this is the first time this routine is called,
+ *
+ * @param       param - device index
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Write_PMU(VOID *param)
+{
+	U32 dev_idx = *((U32 *)param);
+	ECB pecb;
+	DRV_PCI_DEVICE_ENTRY dpden;
+	U32 pci_address;
+	U32 bar_lo;
+	U64 bar_hi;
+	U64 final_bar;
+	U64 physical_address;
+	U32 dev_index = 0;
+	S32 bar_list[SOC_NPK_UNCORE_MAX_PCI_DEVICES];
+	U32 bar_index = 0;
+	U64 virtual_address = 0;
+	U32 bar_name = 0;
+	DRV_PCI_DEVICE_ENTRY curr_pci_entry = NULL;
+	U32 next_bar_offset = 0;
+	U64 mmio_offset = 0;
+	U32 i = 0;
+	U32 map_size = 0;
+	U32 cur_grp;
+
+	if (device_uncore == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: NULL device_uncore!\n");
+		return;
+	}
+	cur_grp = LWPMU_DEVICE_cur_group(device_uncore);
+
+	pecb = (ECB)LWPMU_DEVICE_PMU_register_data(device_uncore)[cur_grp];
+	if (pecb == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: null pecb!\n");
+		return;
+	}
+
+	for (dev_index = 0; dev_index < SOC_NPK_UNCORE_MAX_PCI_DEVICES;
+	     dev_index++) {
+		bar_list[dev_index] = -1;
+	}
+
+	// initialize the per-counter overflow numbers
+	for (i = 0; i < SOC_NPK_COUNTER_MAX_COUNTERS; i++) {
+		counter_overflow[i] = 0;
+		socperf_pcb[0].last_uncore_count[i] = 0;
+	}
+
+	ECB_pcidev_entry_list(pecb) = (DRV_PCI_DEVICE_ENTRY)(
+		(S8 *)pecb + ECB_pcidev_list_offset(pecb));
+	dpden = ECB_pcidev_entry_list(pecb);
+
+	uncore_Reset_Counters(dev_idx);
+
+	SOCPERF_PRINT_DEBUG(
+		"Inside VISA Driver Write PMU: Number of entries=%d\n",
+		ECB_num_pci_devices(pecb));
+	for (dev_index = 0; dev_index < ECB_num_pci_devices(pecb);
+	     dev_index++) {
+		curr_pci_entry = &dpden[dev_index];
+		bar_name = DRV_PCI_DEVICE_ENTRY_bar_name(curr_pci_entry);
+		mmio_offset = DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(
+			curr_pci_entry);
+
+		// UNC_MMIO programming
+		if (bar_list[bar_name] != -1) {
+			bar_index = bar_list[bar_name];
+			virtual_address = DRV_PCI_DEVICE_ENTRY_virtual_address(
+				&dpden[bar_index]);
+			DRV_PCI_DEVICE_ENTRY_virtual_address(curr_pci_entry) =
+				DRV_PCI_DEVICE_ENTRY_virtual_address(
+					&dpden[bar_index]);
+			write_To_Register(virtual_address, mmio_offset,
+					  (U32)DRV_PCI_DEVICE_ENTRY_value(
+						  curr_pci_entry));
+			continue;
+		}
+
+		pci_address = FORM_PCI_ADDR(
+			DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_bar_offset(curr_pci_entry));
+		bar_lo = SOCPERF_PCI_Read_Ulong(pci_address);
+		SOCPERF_PRINT_DEBUG(
+			"The bus=%x device=%x function=%x offset=%x\n",
+			DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_bar_offset(curr_pci_entry));
+		next_bar_offset =
+			DRV_PCI_DEVICE_ENTRY_bar_offset(curr_pci_entry) +
+			SOC_NPK_UNCORE_NEXT_ADDR_OFFSET;
+		pci_address = FORM_PCI_ADDR(
+			DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+			next_bar_offset);
+		bar_hi = SOCPERF_PCI_Read_Ulong(pci_address);
+		SOCPERF_PRINT_DEBUG(
+			"The bus=%x device=%x function=%x offset=%x\n",
+			DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+			next_bar_offset);
+		final_bar = (bar_hi << SOC_NPK_UNCORE_BAR_ADDR_SHIFT) | bar_lo;
+		if (bar_name == UNC_MCHBAR) {
+			final_bar &= SOC_NPK_UNCORE_MCHBAR_ADDR_MASK;
+			map_size = SOC_NPK_UNCORE_MCHBAR_MMIO_PAGE_SIZE;
+		} else {
+			final_bar &= SOC_NPK_UNCORE_BAR_ADDR_MASK;
+			map_size = SOC_NPK_UNCORE_NPK_BAR_MMIO_PAGE_SIZE;
+		}
+		DRV_PCI_DEVICE_ENTRY_bar_address(curr_pci_entry) = final_bar;
+		physical_address =
+			DRV_PCI_DEVICE_ENTRY_bar_address(curr_pci_entry);
+
+		if (physical_address) {
+			DRV_PCI_DEVICE_ENTRY_virtual_address(curr_pci_entry) =
+				(U64)(UIOP)ioremap_nocache(physical_address,
+							   map_size);
+			virtual_address = DRV_PCI_DEVICE_ENTRY_virtual_address(
+				curr_pci_entry);
+
+			write_To_Register(virtual_address, mmio_offset,
+					  (U32)DRV_PCI_DEVICE_ENTRY_value(
+						  curr_pci_entry));
+			bar_list[bar_name] = dev_index;
+			if (counter_virtual_address == 0) {
+				counter_virtual_address = virtual_address;
+			}
+			if (mchbar_virtual_address == 0 &&
+			    bar_name == UNC_MCHBAR) {
+				mchbar_virtual_address = virtual_address;
+				mchbar_offset = mmio_offset;
+			}
+		}
+	}
+}
+
+/*!
+ * @fn         static VOID uncore_Disable_PMU(PVOID)
+ *
+ * @brief      Unmap the virtual address when sampling/driver stops
+ *
+ * @param      param - device index
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Disable_PMU(PVOID param)
+{
+	U32 dev_idx = *((U32 *)param);
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) ==
+	    DRV_STATE_PREPARE_STOP) {
+		uncore_Reset_Counters(dev_idx);
+		if (mchbar_virtual_address) {
+			write_To_Register(mchbar_virtual_address, mchbar_offset,
+					  0x0);
+			iounmap((void __iomem *)(UIOP)(mchbar_virtual_address));
+			SOCPERF_PRINT_DEBUG("Unmapping MCHBAR address=%x\n",
+					    mchbar_virtual_address);
+		}
+		if (counter_virtual_address) {
+			iounmap((void __iomem *)(UIOP)(counter_virtual_address));
+			SOCPERF_PRINT_DEBUG("Unmapping NPKBAR address=%x\n",
+					    counter_virtual_address);
+		}
+		counter_virtual_address = 0;
+		mchbar_virtual_address = 0;
+		mchbar_offset = 0;
+	}
+}
+
+/*!
+ * @fn         static VOID uncore_Initialize(PVOID)
+ *
+ * @brief      Initialize any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Initialize(VOID *param)
+{
+	counter_virtual_address = 0;
+	mchbar_virtual_address = 0;
+	mchbar_offset = 0;
+}
+
+/*!
+ * @fn         static VOID uncore_Clean_Up(PVOID)
+ *
+ * @brief      Reset any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Clean_Up(VOID *param)
+{
+	counter_virtual_address = 0;
+	mchbar_virtual_address = 0;
+	mchbar_offset = 0;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn uncore_Read_Data()
+ *
+ * @param    None
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the counters
+ *
+ */
+static VOID uncore_Read_Data(PVOID data_buffer)
+{
+	U32 event_id = 0;
+	U64 *data;
+	int data_index;
+	U32 data_val = 0;
+	U32 data_reg = 0;
+	U64 total_count = 0;
+	U32 event_index = 0;
+	U32 cur_grp;
+
+	if (device_uncore == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: NULL device_uncore!\n");
+		return;
+	}
+	cur_grp = LWPMU_DEVICE_cur_group(device_uncore);
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_UNINITIALIZED ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_IDLE ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_RESERVED ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_PREPARE_STOP ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_STOPPED) {
+		SOCPERF_PRINT_ERROR("ERROR: RETURING EARLY from Read_Data\n");
+		return;
+	}
+
+	if (data_buffer == NULL) {
+		return;
+	}
+
+	data = (U64 *)data_buffer;
+	data_index = 0;
+
+	// Write GroupID
+	data[data_index] = cur_grp + 1;
+	// Increment the data index as the event id starts from zero
+	data_index++;
+
+	FOR_EACH_PCI_REG_RAW(pecb, i, dev_idx)
+	{
+		if (ECB_entries_reg_type(pecb, i) == PMU_REG_EVENT_SELECT) {
+			write_To_Register(counter_virtual_address,
+					  ECB_entries_reg_offset(pecb, i),
+					  (ULONG)SOC_NPK_UNCORE_SAMPLE_DATA);
+
+			data_reg = i + ECB_operations_register_len(
+					       pecb, PMU_OPERATION_WRITE);
+			if (ECB_entries_reg_type(pecb, data_reg) ==
+			    PMU_REG_DATA) {
+				read_From_Register(
+					counter_virtual_address,
+					ECB_entries_reg_offset(pecb, data_reg),
+					&data_val);
+				if (data_val <
+				    socperf_pcb[0]
+					    .last_uncore_count[event_index]) {
+					counter_overflow[event_index]++;
+				}
+				socperf_pcb[0].last_uncore_count[event_index] =
+					data_val;
+				total_count = data_val +
+					      counter_overflow[event_index] *
+						      SOC_NPK_COUNTER_MAX_COUNT;
+				event_index++;
+				data[data_index + event_id] = total_count;
+				SOCPERF_PRINT_DEBUG("DATA[%d]=%llu\n", event_id,
+						    total_count);
+				event_id++;
+			}
+		}
+	}
+	END_FOR_EACH_PCI_REG_RAW;
+}
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE npk_dispatch = {
+	.init = uncore_Initialize, // initialize
+	.fini = NULL, // destroy
+	.write = uncore_Write_PMU, // write
+	.freeze = uncore_Disable_PMU, // freeze
+	.restart = NULL, // restart
+	.read_data = NULL, // read
+	.check_overflow = NULL, // check for overflow
+	.swap_group = NULL,
+	.read_lbrs = NULL,
+	.clean_up = uncore_Clean_Up,
+	.hw_errata = NULL,
+	.read_power = NULL,
+	.check_overflow_errata = NULL,
+	.read_counts = NULL, //read_counts
+	.check_overflow_gp_errata = NULL,
+	.read_power = NULL,
+	.platform_info = NULL,
+	.trigger_read = NULL,
+	.read_current_data = uncore_Read_Data,
+	.create_mem = NULL,
+	.check_status = NULL,
+	.read_mem = NULL,
+	.stop_mem = NULL
+};
diff --git a/drivers/platform/x86/socperf/pci.c b/drivers/platform/x86/socperf/pci.c
new file mode 100644
index 000000000000..c41fc4cfc20a
--- /dev/null
+++ b/drivers/platform/x86/socperf/pci.c
@@ -0,0 +1,188 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+#include "lwpmudrv_defines.h"
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <asm/page.h>
+#include <asm/io.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "socperfdrv.h"
+#include "pci.h"
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern int SOCPERF_PCI_Read_From_Memory_Address(addr, val)
+ *
+ * @param    addr    - physical address in mmio
+ * @param   *value  - value at this address
+ *
+ * @return  status
+ *
+ * @brief   Read memory mapped i/o physical location
+ *
+ */
+int SOCPERF_PCI_Read_From_Memory_Address(U32 addr, U32 *val)
+{
+	U32 aligned_addr, offset, value;
+	PVOID base;
+
+	if (addr <= 0) {
+		return OS_INVALID;
+	}
+
+	SOCPERF_PRINT_DEBUG(
+		"SOCPERF_PCI_Read_From_Memory_Address: reading physical address:%x\n",
+		addr);
+	offset = addr & ~PAGE_MASK;
+	aligned_addr = addr & PAGE_MASK;
+	SOCPERF_PRINT_DEBUG(
+		"SOCPERF_PCI_Read_From_Memory_Address: aligned physical address:%x,offset:%x\n",
+		aligned_addr, offset);
+
+	base = (PVOID)ioremap_nocache(aligned_addr, PAGE_SIZE);
+	if (base == NULL) {
+		return OS_INVALID;
+	}
+
+	value = readl((void __iomem *)(base + offset));
+	*val = value;
+	SOCPERF_PRINT_DEBUG(
+		"SOCPERF_PCI_Read_From_Memory_Address: value at this physical address:%x\n",
+		value);
+
+	iounmap((void __iomem *)base);
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern int SOCPERF_PCI_Write_To_Memory_Address(addr, val)
+ *
+ * @param   addr   - physical address in mmio
+ * @param   value  - value to be written
+ *
+ * @return  status
+ *
+ * @brief   Write to memory mapped i/o physical location
+ *
+ */
+int SOCPERF_PCI_Write_To_Memory_Address(U32 addr, U32 val)
+{
+	U32 aligned_addr, offset;
+	PVOID base;
+
+	if (addr <= 0) {
+		return OS_INVALID;
+	}
+
+	SOCPERF_PRINT_DEBUG(
+		"SOCPERF_PCI_Write_To_Memory_Address: writing physical address:%x with value:%x\n",
+		addr, val);
+	offset = addr & ~PAGE_MASK;
+	aligned_addr = addr & PAGE_MASK;
+	SOCPERF_PRINT_DEBUG(
+		"SOCPERF_PCI_Write_To_Memory_Address: aligned physical address:%x,offset:%x\n",
+		aligned_addr, offset);
+
+	base = (PVOID)ioremap_nocache(aligned_addr, PAGE_SIZE);
+	if (base == NULL) {
+		return OS_INVALID;
+	}
+
+	writel(val, (void __iomem *)(base + offset));
+
+	iounmap((void __iomem *)base);
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern int SOCPERF_PCI_Read_Ulong(pci_address)
+ *
+ * @param    pci_address - PCI configuration address
+ *
+ * @return  value at this location
+ *
+ * @brief   Reads a ULONG from PCI configuration space
+ *
+ */
+int SOCPERF_PCI_Read_Ulong(U32 pci_address)
+{
+	U32 temp_ulong = 0;
+
+	outl(pci_address, PCI_ADDR_IO);
+	temp_ulong = inl(PCI_DATA_IO);
+
+	return temp_ulong;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn extern int SOCPERF_PCI_Write_Ulong(addr, val)
+ *
+ * @param    pci_address - PCI configuration address
+ * @param    value - Value to be written
+ *
+ * @return  status
+ *
+ * @brief   Writes a ULONG to PCI configuration space
+ *
+ */
+void SOCPERF_PCI_Write_Ulong(U32 pci_address, U32 value)
+{
+	outl(pci_address, PCI_ADDR_IO);
+	outl(value, PCI_DATA_IO);
+}
diff --git a/drivers/platform/x86/socperf/soc_uncore.c b/drivers/platform/x86/socperf/soc_uncore.c
new file mode 100644
index 000000000000..8313dc754a08
--- /dev/null
+++ b/drivers/platform/x86/socperf/soc_uncore.c
@@ -0,0 +1,901 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2013-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/fs.h>
+
+#include "lwpmudrv_types.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+
+#include "socperfdrv.h"
+#include "control.h"
+#include "soc_uncore.h"
+#include "inc/ecb_iterators.h"
+#include "inc/pci.h"
+
+#if defined(PCI_HELPERS_API)
+#include <asm/intel_mid_pcihelpers.h>
+#elif defined(DRV_CHROMEOS)
+#include <linux/pci.h>
+static struct pci_dev *pci_root = NULL;
+#define PCI_DEVFN(slot, func) ((((slot)&0x1f) << 3) | ((func)&0x07))
+#endif
+
+static U32 counter_overflow[UNCORE_MAX_COUNTERS];
+static U32 counter_port_id;
+static U64 trace_virtual_address;
+
+#if defined(DRV_CHROMEOS)
+/*!
+ * @fn          static VOID get_pci_device_handle(U32   bus_no,
+												  U32   dev_no,
+												  U32   func_no)
+ *
+ * @brief       Get PCI device handle to be able to read/write
+ *
+ * @param       bus_no      - bus number
+ *              dev_no      - device number
+ *              func_no     - function number
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static void get_pci_device_handle(U32 bus_no, U32 dev_no, U32 func_no)
+{
+	if (!pci_root) {
+		pci_root = pci_get_bus_and_slot(bus_no,
+						PCI_DEVFN(dev_no, func_no));
+		if (!pci_root) {
+			SOCPERF_PRINT_DEBUG("Unable to get pci device handle");
+		}
+	}
+}
+#endif
+
+/*!
+ * @fn          static VOID write_To_Register(U32   bus_no,
+											  U32   dev_no,
+											  U32   func_no,
+											  U32   port_id,
+											  U32   op_code,
+											  U64   mmio_offset,
+											  ULONG value)
+ *
+ * @brief       Reads Uncore programming
+ *
+ * @param       bus_no      - bus number
+ *              dev_no      - device number
+ *              func_no     - function number
+ *              port_id     - port id
+ *              op_code     - operation code
+ *              mmio_offset - mmio offset
+ *              value       - data to be written to the register
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static void write_To_Register(U32 bus_no, U32 dev_no, U32 func_no, U32 port_id,
+			      U32 op_code, U64 mmio_offset, ULONG value)
+{
+	U32 cmd = 0;
+	U32 mmio_offset_lo;
+	U32 mmio_offset_hi;
+#if !defined(DRV_CHROMEOS) && !defined(PCI_HELPERS_API)
+	U32 pci_address;
+#endif
+
+	mmio_offset_hi = mmio_offset & SOC_UNCORE_OFFSET_HI_MASK;
+	mmio_offset_lo = mmio_offset & SOC_UNCORE_OFFSET_LO_MASK;
+	cmd = (op_code << SOC_UNCORE_OP_CODE_SHIFT) +
+	      (port_id << SOC_UNCORE_PORT_ID_SHIFT) + (mmio_offset_lo << 8) +
+	      (SOC_UNCORE_BYTE_ENABLES << 4);
+	SOCPERF_PRINT_DEBUG("write off=%llx value=%x\n", mmio_offset, value);
+
+#if defined(PCI_HELPERS_API)
+	intel_mid_msgbus_write32_raw_ext(cmd, mmio_offset_hi, value);
+#elif defined(DRV_CHROMEOS)
+	if (!pci_root) {
+		get_pci_device_handle(bus_no, dev_no, func_no);
+	}
+	pci_write_config_dword(pci_root, SOC_UNCORE_MDR_REG_OFFSET, value);
+	pci_write_config_dword(pci_root, SOC_UNCORE_MCRX_REG_OFFSET,
+			       mmio_offset_hi);
+	pci_write_config_dword(pci_root, SOC_UNCORE_MCR_REG_OFFSET, cmd);
+#else
+	pci_address = FORM_PCI_ADDR(bus_no, dev_no, func_no,
+				    SOC_UNCORE_MDR_REG_OFFSET);
+	SOCPERF_PCI_Write_Ulong((ULONG)pci_address, (ULONG)value);
+	pci_address = FORM_PCI_ADDR(bus_no, dev_no, func_no,
+				    SOC_UNCORE_MCRX_REG_OFFSET);
+	SOCPERF_PCI_Write_Ulong((ULONG)pci_address, mmio_offset_hi);
+	pci_address = FORM_PCI_ADDR(bus_no, dev_no, func_no,
+				    SOC_UNCORE_MCR_REG_OFFSET);
+	SOCPERF_PCI_Write_Ulong((ULONG)pci_address, cmd);
+#endif
+}
+
+/*!
+ * @fn          static ULONG read_From_Register(U32 bus_no,
+												U32 dev_no,
+												U32 func_no,
+												U32 port_id,
+												U32 op_code,
+												U64 mmio_offset)
+ *
+ * @brief       Reads Uncore programming info
+ *
+ * @param       bus_no      - bus number
+ *              dev_no      - device number
+ *              func_no     - function number
+ *              port_id     - port id
+ *              op_code     - operation code
+ *              mmio_offset - mmio offset
+ *
+ * @return      data from the counter
+ *
+ * <I>Special Notes:</I>
+ */
+static void read_From_Register(U32 bus_no, U32 dev_no, U32 func_no, U32 port_id,
+			       U32 op_code, U64 mmio_offset, U32 *data_val)
+{
+	U32 data = 0;
+	U32 cmd = 0;
+	U32 mmio_offset_hi;
+	U32 mmio_offset_lo;
+#if !defined(DRV_CHROMEOS) && !defined(PCI_HELPERS_API)
+	U32 pci_address;
+#endif
+
+	mmio_offset_hi = mmio_offset & SOC_UNCORE_OFFSET_HI_MASK;
+	mmio_offset_lo = mmio_offset & SOC_UNCORE_OFFSET_LO_MASK;
+	cmd = (op_code << SOC_UNCORE_OP_CODE_SHIFT) +
+	      (port_id << SOC_UNCORE_PORT_ID_SHIFT) + (mmio_offset_lo << 8) +
+	      (SOC_UNCORE_BYTE_ENABLES << 4);
+
+#if defined(PCI_HELPERS_API)
+	data = intel_mid_msgbus_read32_raw_ext(cmd, mmio_offset_hi);
+#elif defined(DRV_CHROMEOS)
+	if (!pci_root) {
+		get_pci_device_handle(bus_no, dev_no, func_no);
+	}
+	pci_write_config_dword(pci_root, SOC_UNCORE_MCRX_REG_OFFSET,
+			       mmio_offset_hi);
+	pci_write_config_dword(pci_root, SOC_UNCORE_MCR_REG_OFFSET, cmd);
+	pci_read_config_dword(pci_root, SOC_UNCORE_MDR_REG_OFFSET, &data);
+#else
+	pci_address = FORM_PCI_ADDR(bus_no, dev_no, func_no,
+				    SOC_UNCORE_MCRX_REG_OFFSET);
+	SOCPERF_PCI_Write_Ulong((ULONG)pci_address, mmio_offset_hi);
+	pci_address = FORM_PCI_ADDR(bus_no, dev_no, func_no,
+				    SOC_UNCORE_MCR_REG_OFFSET);
+	SOCPERF_PCI_Write_Ulong((ULONG)pci_address, cmd);
+	pci_address = FORM_PCI_ADDR(bus_no, dev_no, func_no,
+				    SOC_UNCORE_MDR_REG_OFFSET);
+	data = SOCPERF_PCI_Read_Ulong(pci_address);
+#endif
+	SOCPERF_PRINT_DEBUG("read off=%llx value=%x\n", mmio_offset, data);
+	if (data_val) {
+		*data_val = data;
+	}
+}
+
+/*!
+ * @fn          static VOID uncore_Reset_Counters(U32 dev_idx)
+ *
+ * @brief       Reset counters
+ *
+ * @param       dev_idx - device index
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Reset_Counters(U32 dev_idx)
+{
+	U32 data_reg = 0;
+
+	if (counter_port_id != 0) {
+		FOR_EACH_PCI_REG_RAW(pecb, i, dev_idx)
+		{
+			if (ECB_entries_reg_type(pecb, i) ==
+			    PMU_REG_EVENT_SELECT) {
+				data_reg =
+					i + ECB_operations_register_len(
+						    pecb, PMU_OPERATION_WRITE);
+				if (ECB_entries_reg_type(pecb, data_reg) ==
+				    PMU_REG_DATA) {
+					write_To_Register(
+						ECB_entries_bus_no(pecb,
+								   data_reg),
+						ECB_entries_dev_no(pecb,
+								   data_reg),
+						ECB_entries_func_no(pecb,
+								    data_reg),
+						counter_port_id,
+						SOC_COUNTER_WRITE_OP_CODE,
+						ECB_entries_reg_offset(
+							pecb, data_reg),
+						(ULONG)0);
+				}
+				write_To_Register(ECB_entries_bus_no(pecb, i),
+						  ECB_entries_dev_no(pecb, i),
+						  ECB_entries_func_no(pecb, i),
+						  counter_port_id,
+						  SOC_COUNTER_WRITE_OP_CODE,
+						  ECB_entries_reg_offset(pecb,
+									 i),
+						  (ULONG)SOC_UNCORE_STOP);
+			}
+		}
+		END_FOR_EACH_PCI_REG_RAW;
+	}
+}
+
+/*!
+ * @fn          static VOID uncore_Write_PMU(VOID*)
+ *
+ * @brief       Initial write of PMU registers
+ *              Walk through the entries and write the value of the register accordingly.
+ *              When current_group = 0, then this is the first time this routine is called,
+ *
+ * @param       param - device index
+ *
+ * @return      None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Write_PMU(VOID *param)
+{
+	U32 dev_idx;
+	ECB pecb;
+	DRV_PCI_DEVICE_ENTRY dpden;
+	U32 pci_address;
+	U32 bar_lo;
+	U64 bar_hi;
+	U64 final_bar;
+	U64 physical_address;
+	U32 dev_index = 0;
+	S32 bar_list[SOC_UNCORE_MAX_PCI_DEVICES];
+	U32 bar_index = 0;
+	U32 map_size = 0;
+	U64 virtual_address = 0;
+	U32 bar_name = 0;
+	DRV_PCI_DEVICE_ENTRY curr_pci_entry = NULL;
+	U32 next_bar_offset = 0;
+	U64 mmio_offset = 0;
+	U64 map_base = 0;
+	U32 i = 0;
+	U32 cur_grp;
+
+	dev_idx = *((U32 *)param);
+	if (device_uncore == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: NULL device_uncore!\n");
+		return;
+	}
+	cur_grp = LWPMU_DEVICE_cur_group(device_uncore);
+
+	pecb = (ECB)LWPMU_DEVICE_PMU_register_data(device_uncore)[cur_grp];
+	if (pecb == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: null pecb!\n");
+		return;
+	}
+
+	for (dev_index = 0; dev_index < SOC_UNCORE_MAX_PCI_DEVICES;
+	     dev_index++) {
+		bar_list[dev_index] = -1;
+	}
+
+	// initialize the per-counter overflow numbers
+	for (i = 0; i < UNCORE_MAX_COUNTERS; i++) {
+		counter_overflow[i] = 0;
+		socperf_pcb[0].last_uncore_count[i] = 0;
+	}
+
+	ECB_pcidev_entry_list(pecb) = (DRV_PCI_DEVICE_ENTRY)(
+		(S8 *)pecb + ECB_pcidev_list_offset(pecb));
+	dpden = ECB_pcidev_entry_list(pecb);
+
+	uncore_Reset_Counters(dev_idx);
+
+	for (dev_index = 0; dev_index < ECB_num_pci_devices(pecb);
+	     dev_index++) {
+		curr_pci_entry = &dpden[dev_index];
+		bar_name = DRV_PCI_DEVICE_ENTRY_bar_name(curr_pci_entry);
+		mmio_offset = DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(
+			curr_pci_entry);
+
+		if (counter_port_id == 0 &&
+		    DRV_PCI_DEVICE_ENTRY_prog_type(curr_pci_entry) ==
+			    UNC_COUNTER) {
+			counter_port_id =
+				DRV_PCI_DEVICE_ENTRY_port_id(curr_pci_entry);
+			uncore_Reset_Counters(dev_idx);
+		}
+		if (DRV_PCI_DEVICE_ENTRY_config_type(curr_pci_entry) ==
+		    UNC_PCICFG) {
+			if (bar_name == UNC_SOCPCI &&
+			    (DRV_PCI_DEVICE_ENTRY_prog_type(curr_pci_entry) ==
+				     UNC_MUX ||
+			     DRV_PCI_DEVICE_ENTRY_prog_type(curr_pci_entry) ==
+				     UNC_COUNTER) &&
+			    DRV_PCI_DEVICE_ENTRY_operation(curr_pci_entry) ==
+				    UNC_OP_WRITE) {
+				SOCPERF_PRINT_DEBUG(
+					"dev_index=%d OFFSET=%x VAL=%x\n",
+					dev_index,
+					DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(
+						curr_pci_entry),
+					DRV_PCI_DEVICE_ENTRY_value(
+						curr_pci_entry));
+				write_To_Register(
+					DRV_PCI_DEVICE_ENTRY_bus_no(
+						curr_pci_entry),
+					DRV_PCI_DEVICE_ENTRY_dev_no(
+						curr_pci_entry),
+					DRV_PCI_DEVICE_ENTRY_func_no(
+						curr_pci_entry),
+					DRV_PCI_DEVICE_ENTRY_port_id(
+						curr_pci_entry),
+					DRV_PCI_DEVICE_ENTRY_op_code(
+						curr_pci_entry),
+					DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(
+						curr_pci_entry),
+					(ULONG)DRV_PCI_DEVICE_ENTRY_value(
+						curr_pci_entry));
+			}
+			continue;
+		}
+		// UNC_MMIO programming
+		if (bar_list[bar_name] != -1) {
+			bar_index = bar_list[bar_name];
+			virtual_address = DRV_PCI_DEVICE_ENTRY_virtual_address(
+				&dpden[bar_index]);
+			DRV_PCI_DEVICE_ENTRY_virtual_address(curr_pci_entry) =
+				DRV_PCI_DEVICE_ENTRY_virtual_address(
+					&dpden[bar_index]);
+			writel(DRV_PCI_DEVICE_ENTRY_value(curr_pci_entry),
+			       (void __iomem *)(((char *)(UIOP)virtual_address) +
+				       mmio_offset));
+			continue;
+		}
+		pci_address = FORM_PCI_ADDR(
+			DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_bar_offset(curr_pci_entry));
+		bar_lo = SOCPERF_PCI_Read_Ulong(pci_address);
+		next_bar_offset =
+			DRV_PCI_DEVICE_ENTRY_bar_offset(curr_pci_entry) +
+			SOC_UNCORE_NEXT_ADDR_OFFSET;
+		pci_address = FORM_PCI_ADDR(
+			DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+			DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+			next_bar_offset);
+		bar_hi = SOCPERF_PCI_Read_Ulong(pci_address);
+		final_bar = (bar_hi << SOC_UNCORE_BAR_ADDR_SHIFT) | bar_lo;
+		final_bar &= SOC_UNCORE_BAR_ADDR_MASK;
+		DRV_PCI_DEVICE_ENTRY_bar_address(curr_pci_entry) = final_bar;
+		physical_address =
+			DRV_PCI_DEVICE_ENTRY_bar_address(curr_pci_entry);
+		if (physical_address) {
+			map_size = SOC_UNCORE_OTHER_BAR_MMIO_PAGE_SIZE;
+			map_base = (mmio_offset / map_size) * map_size;
+			if (mmio_offset > map_size) {
+				physical_address = physical_address + map_base;
+			}
+		}
+	}
+}
+
+/*!
+ * @fn         static VOID uncore_Disable_PMU(PVOID)
+ *
+ * @brief      Unmap the virtual address when sampling/driver stops
+ *
+ * @param      param - device index
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Disable_PMU(PVOID param)
+{
+	U32 dev_idx = *((U32 *)param);
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) ==
+	    DRV_STATE_PREPARE_STOP) {
+		uncore_Reset_Counters(dev_idx);
+	}
+}
+
+/*!
+ * @fn         static VOID uncore_Stop_Mem(VOID)
+ *
+ * @brief      Stop trace
+ *
+ * @param      param - None
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Stop_Mem(VOID)
+{
+	ECB pecb;
+	DRV_PCI_DEVICE_ENTRY dpden;
+	U32 bar_name = 0;
+	DRV_PCI_DEVICE_ENTRY curr_pci_entry = NULL;
+	U64 mmio_offset = 0;
+	U32 dev_index = 0;
+	U32 data_val = 0;
+	U32 cur_grp;
+
+	if (device_uncore == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: NULL device_uncore!\n");
+		return;
+	}
+	cur_grp = LWPMU_DEVICE_cur_group(device_uncore);
+
+	pecb = (ECB)LWPMU_DEVICE_PMU_register_data(device_uncore)[cur_grp];
+	if (pecb == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: null pecb!\n");
+		return;
+	}
+
+	ECB_pcidev_entry_list(pecb) = (DRV_PCI_DEVICE_ENTRY)(
+		(S8 *)pecb + ECB_pcidev_list_offset(pecb));
+	dpden = ECB_pcidev_entry_list(pecb);
+
+	for (dev_index = 0; dev_index < ECB_num_pci_devices(pecb);
+	     dev_index++) {
+		curr_pci_entry = &dpden[dev_index];
+		bar_name = DRV_PCI_DEVICE_ENTRY_bar_name(curr_pci_entry);
+		mmio_offset = DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(
+			curr_pci_entry);
+
+		if (DRV_PCI_DEVICE_ENTRY_prog_type(curr_pci_entry) ==
+			    UNC_STOP &&
+		    DRV_PCI_DEVICE_ENTRY_config_type(curr_pci_entry) ==
+			    UNC_PCICFG &&
+		    bar_name == UNC_SOCPCI &&
+		    DRV_PCI_DEVICE_ENTRY_operation(curr_pci_entry) ==
+			    UNC_OP_READ) {
+			SOCPERF_PRINT_DEBUG(
+				"op=%d port=%d offset=%x val=%x\n",
+				DRV_PCI_DEVICE_ENTRY_op_code(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_port_id(curr_pci_entry),
+				mmio_offset, data_val);
+			read_From_Register(
+				DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_port_id(curr_pci_entry),
+				SOC_COUNTER_READ_OP_CODE, mmio_offset,
+				&data_val);
+			SOCPERF_PRINT_DEBUG(
+				"op=%d port=%d offset=%x val=%x\n",
+				DRV_PCI_DEVICE_ENTRY_op_code(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_port_id(curr_pci_entry),
+				mmio_offset, data_val);
+			write_To_Register(
+				DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_port_id(curr_pci_entry),
+				SOC_COUNTER_WRITE_OP_CODE, mmio_offset,
+				(ULONG)(data_val | 0x2000));
+		}
+	}
+}
+
+/*!
+ * @fn         static VOID uncore_Initialize(PVOID)
+ *
+ * @brief      Initialize any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Initialize(VOID *param)
+{
+	return;
+}
+
+/*!
+ * @fn         static VOID uncore_Clean_Up(PVOID)
+ *
+ * @brief      Reset any registers or addresses
+ *
+ * @param      param
+ *
+ * @return     None
+ *
+ * <I>Special Notes:</I>
+ */
+static VOID uncore_Clean_Up(VOID *param)
+{
+	if (trace_virtual_address) {
+		iounmap((void __iomem *)(UIOP)trace_virtual_address);
+		trace_virtual_address = 0;
+	}
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn uncore_Read_Data()
+ *
+ * @param    None
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the counters
+ *
+ */
+static VOID uncore_Read_Data(PVOID data_buffer)
+{
+	U32 event_id = 0;
+	U64 *data;
+	int data_index;
+	U32 data_val = 0;
+	U32 data_reg = 0;
+	U64 total_count = 0;
+	U32 event_index = 0;
+	U32 cur_grp;
+
+	if (device_uncore == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: NULL device_uncore!\n");
+		return;
+	}
+	cur_grp = LWPMU_DEVICE_cur_group(device_uncore);
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_UNINITIALIZED ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_IDLE ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_RESERVED ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_PREPARE_STOP ||
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_STOPPED) {
+		SOCPERF_PRINT_ERROR("ERROR: RETURING EARLY from Read_Data\n");
+		return;
+	}
+
+	data = data_buffer;
+	data_index = 0;
+
+	preempt_disable();
+
+	// Write GroupID
+	data[data_index] = cur_grp + 1;
+	// Increment the data index as the event id starts from zero
+	data_index++;
+
+	FOR_EACH_PCI_REG_RAW(pecb, i, dev_idx)
+	{
+		if (ECB_entries_reg_type(pecb, i) == PMU_REG_EVENT_SELECT) {
+			write_To_Register(ECB_entries_bus_no(pecb, i),
+					  ECB_entries_dev_no(pecb, i),
+					  ECB_entries_func_no(pecb, i),
+					  counter_port_id,
+					  SOC_COUNTER_WRITE_OP_CODE,
+					  ECB_entries_reg_offset(pecb, i),
+					  (ULONG)SOC_UNCORE_SAMPLE_DATA);
+
+			data_reg = i + ECB_operations_register_len(
+					       pecb, PMU_OPERATION_WRITE);
+			if (ECB_entries_reg_type(pecb, data_reg) ==
+			    PMU_REG_DATA) {
+				read_From_Register(
+					ECB_entries_bus_no(pecb, data_reg),
+					ECB_entries_dev_no(pecb, data_reg),
+					ECB_entries_func_no(pecb, data_reg),
+					counter_port_id,
+					SOC_COUNTER_READ_OP_CODE,
+					ECB_entries_reg_offset(pecb, data_reg),
+					&data_val);
+				if (data_val <
+				    socperf_pcb[0]
+					    .last_uncore_count[event_index]) {
+					counter_overflow[event_index]++;
+				}
+				socperf_pcb[0].last_uncore_count[event_index] =
+					data_val;
+				total_count = data_val +
+					      counter_overflow[event_index] *
+						      UNCORE_MAX_COUNT;
+				event_index++;
+				data[data_index + event_id] = total_count;
+				event_id++;
+			}
+		}
+	}
+	END_FOR_EACH_PCI_REG_RAW;
+
+	preempt_enable();
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn uncore_Create_Mem()
+ *
+ * @param    None
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the counters
+ *
+ */
+static VOID uncore_Create_Mem(U32 memory_size, U64 *trace_buffer)
+{
+	ECB pecb;
+	DRV_PCI_DEVICE_ENTRY dpden;
+	U32 bar_name = 0;
+	DRV_PCI_DEVICE_ENTRY curr_pci_entry = NULL;
+	U64 mmio_offset = 0;
+	U32 dev_index = 0;
+	U32 data_val = 0;
+	U32 reg_index = 0;
+	U64 physical_high = 0;
+	U64 odla_physical_address = 0;
+
+	if (device_uncore == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: NULL device_uncore!\n");
+		return;
+	}
+	pecb = (ECB)LWPMU_DEVICE_PMU_register_data(device_uncore)[0];
+	if (pecb == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: null pecb!\n");
+		return;
+	}
+
+	if (!trace_buffer) {
+		return;
+	}
+
+	ECB_pcidev_entry_list(pecb) = (DRV_PCI_DEVICE_ENTRY)(
+		(S8 *)pecb + ECB_pcidev_list_offset(pecb));
+	dpden = ECB_pcidev_entry_list(pecb);
+
+	for (dev_index = 0; dev_index < ECB_num_pci_devices(pecb);
+	     dev_index++) {
+		curr_pci_entry = &dpden[dev_index];
+		bar_name = DRV_PCI_DEVICE_ENTRY_bar_name(curr_pci_entry);
+		mmio_offset = DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(
+			curr_pci_entry);
+
+		if (DRV_PCI_DEVICE_ENTRY_prog_type(curr_pci_entry) ==
+			    UNC_MEMORY &&
+		    DRV_PCI_DEVICE_ENTRY_config_type(curr_pci_entry) ==
+			    UNC_PCICFG &&
+		    bar_name == UNC_SOCPCI &&
+		    DRV_PCI_DEVICE_ENTRY_operation(curr_pci_entry) ==
+			    UNC_OP_WRITE) {
+			read_From_Register(
+				DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_port_id(curr_pci_entry),
+				SOC_COUNTER_READ_OP_CODE, mmio_offset,
+				&data_val);
+			if (reg_index == 1) {
+				odla_physical_address = data_val;
+			} else if (reg_index == 2) {
+				physical_high = data_val;
+				odla_physical_address = odla_physical_address |
+							(physical_high << 32);
+			}
+			SOCPERF_PRINT_DEBUG(
+				"op=%d port=%d offset=%x val=%x\n",
+				DRV_PCI_DEVICE_ENTRY_op_code(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_port_id(curr_pci_entry),
+				mmio_offset, data_val);
+			reg_index++;
+		}
+		continue;
+	}
+	SOCPERF_PRINT_DEBUG("Physical Address=%llx\n", odla_physical_address);
+	if (odla_physical_address) {
+		trace_virtual_address = (U64)(UIOP)ioremap_nocache(
+			odla_physical_address, 1024 * sizeof(U64));
+		SOCPERF_PRINT_DEBUG("PHY=%llx ODLA VIRTUAL ADDRESS=%llx\n",
+				    odla_physical_address,
+				    trace_virtual_address);
+		if (trace_buffer) {
+			*trace_buffer = odla_physical_address;
+		}
+	}
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn uncore_Check_Status()
+ *
+ * @param    None
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the counters
+ *
+ */
+static VOID uncore_Check_Status(U64 *trace_buffer, U32 *num_entries)
+{
+	U32 dev_index = 0;
+	ECB pecb;
+	DRV_PCI_DEVICE_ENTRY dpden;
+	U32 bar_name = 0;
+	DRV_PCI_DEVICE_ENTRY curr_pci_entry = NULL;
+	U64 mmio_offset = 0;
+	U32 data_val = 0;
+	U32 data_index = 0;
+
+	if (device_uncore == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: NULL device_uncore!\n");
+		return;
+	}
+	pecb = (ECB)LWPMU_DEVICE_PMU_register_data(device_uncore)[0];
+	if (pecb == NULL) {
+		SOCPERF_PRINT_ERROR("ERROR: null pecb!\n");
+		return;
+	}
+	if (!trace_buffer) {
+		return;
+	}
+
+	ECB_pcidev_entry_list(pecb) = (DRV_PCI_DEVICE_ENTRY)(
+		(S8 *)pecb + ECB_pcidev_list_offset(pecb));
+	dpden = ECB_pcidev_entry_list(pecb);
+
+	for (dev_index = 0; dev_index < ECB_num_pci_devices(pecb);
+	     dev_index++) {
+		curr_pci_entry = &dpden[dev_index];
+		bar_name = DRV_PCI_DEVICE_ENTRY_bar_name(curr_pci_entry);
+		mmio_offset = DRV_PCI_DEVICE_ENTRY_base_offset_for_mmio(
+			curr_pci_entry);
+
+		if (DRV_PCI_DEVICE_ENTRY_prog_type(curr_pci_entry) ==
+			    UNC_STATUS &&
+		    DRV_PCI_DEVICE_ENTRY_config_type(curr_pci_entry) ==
+			    UNC_PCICFG &&
+		    bar_name == UNC_SOCPCI &&
+		    DRV_PCI_DEVICE_ENTRY_operation(curr_pci_entry) ==
+			    UNC_OP_READ) {
+			read_From_Register(
+				DRV_PCI_DEVICE_ENTRY_bus_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_dev_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_func_no(curr_pci_entry),
+				DRV_PCI_DEVICE_ENTRY_port_id(curr_pci_entry),
+				SOC_COUNTER_READ_OP_CODE, mmio_offset,
+				&data_val);
+			SOCPERF_PRINT_DEBUG("TRACE STATUS=%x\n", data_val);
+			trace_buffer[data_index] = data_val;
+			data_index++;
+			continue;
+		}
+	}
+
+	if (num_entries) {
+		*num_entries = data_index;
+	}
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn uncore_Read_Mem()
+ *
+ * @param    None
+ *
+ * @return   None     No return needed
+ *
+ * @brief    Read the counters
+ *
+ */
+static VOID uncore_Read_Mem(U64 start_address, U64 *trace_buffer,
+			    U32 num_entries)
+{
+	U32 data_index = 0;
+	U32 data_value = 0;
+
+	if (num_entries == 0 || !trace_buffer) {
+		return;
+	}
+	SOCPERF_PRINT_DEBUG(
+		"Reading memory for num_entries=%d from address=%llx\n",
+		num_entries, trace_virtual_address);
+	for (data_index = 0; data_index < num_entries; data_index++) {
+		if (trace_virtual_address) {
+			data_value = readl(((void __iomem *)((UIOP)trace_virtual_address +
+								data_index)));
+
+			SOCPERF_PRINT_DEBUG("DATA VALUE=%llx\n", data_value);
+			*(trace_buffer + data_index) = data_value;
+		}
+	}
+
+}
+
+/*
+ * Initialize the dispatch table
+ */
+DISPATCH_NODE soc_uncore_dispatch = {
+	.init = uncore_Initialize, // initialize
+	.fini = NULL, // destroy
+	.write = uncore_Write_PMU, // write
+	.freeze = uncore_Disable_PMU, // freeze
+	.restart = NULL, // restart
+	.read_data = NULL, // read
+	.check_overflow = NULL, // check for overflow
+	.swap_group = NULL,
+	.read_lbrs = NULL,
+	.clean_up = uncore_Clean_Up,
+	.hw_errata = NULL,
+	.read_power = NULL,
+	.check_overflow_errata = NULL,
+	.read_counts = NULL, //read_counts
+	.check_overflow_gp_errata = NULL,
+	.read_power = NULL,
+	.platform_info = NULL,
+	.trigger_read = NULL,
+	.read_current_data = uncore_Read_Data,
+	.create_mem = uncore_Create_Mem,
+	.check_status = uncore_Check_Status,
+	.read_mem = uncore_Read_Mem,
+	.stop_mem = uncore_Stop_Mem
+};
diff --git a/drivers/platform/x86/socperf/socperfdrv.c b/drivers/platform/x86/socperf/socperfdrv.c
new file mode 100644
index 000000000000..3a80764bbed4
--- /dev/null
+++ b/drivers/platform/x86/socperf/socperfdrv.c
@@ -0,0 +1,1560 @@
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#include "lwpmudrv_defines.h"
+
+#include <linux/version.h>
+#include <linux/module.h>
+#include <linux/init.h>
+#include <linux/kernel.h>
+#include <linux/slab.h>
+#include <linux/fs.h>
+#include <linux/errno.h>
+#include <linux/types.h>
+#include <asm/page.h>
+#include <linux/cdev.h>
+#include <linux/proc_fs.h>
+#include <linux/fcntl.h>
+#include <linux/device.h>
+#include <linux/sched.h>
+#include <linux/syscalls.h>
+#include <asm/unistd.h>
+#include <linux/compat.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_version.h"
+#include "lwpmudrv_ecb.h"
+#include "lwpmudrv_struct.h"
+#include "lwpmudrv_ioctl.h"
+#include "inc/ecb_iterators.h"
+#include "socperfdrv.h"
+#include "control.h"
+#include "inc/utility.h"
+
+MODULE_AUTHOR("Copyright(C) 2007-2019 Intel Corporation");
+MODULE_VERSION(SOCPERF_NAME "_" SOCPERF_VERSION_STR);
+MODULE_LICENSE("Dual BSD/GPL");
+
+typedef struct LWPMU_DEV_NODE_S LWPMU_DEV_NODE;
+typedef LWPMU_DEV_NODE * LWPMU_DEV;
+
+struct LWPMU_DEV_NODE_S {
+	long buffer;
+	struct semaphore sem;
+	struct cdev cdev;
+};
+
+#define LWPMU_DEV_buffer(dev) ((dev)->buffer)
+#define LWPMU_DEV_sem(dev) ((dev)->sem)
+#define LWPMU_DEV_cdev(dev) ((dev)->cdev)
+
+/* Global variables of the driver */
+SOCPERF_VERSION_NODE socperf_drv_version;
+U64 *read_unc_ctr_info;
+DISPATCH dispatch_uncore;
+DRV_CONFIG socperf_drv_cfg;
+EVENT_CONFIG socperf_global_ec;
+volatile S32 socperf_abnormal_terminate;
+LWPMU_DEV socperf_control;
+
+LWPMU_DEVICE device_uncore;
+CPU_STATE socperf_pcb;
+size_t socperf_pcb_size;
+
+#if defined(DRV_USE_UNLOCKED_IOCTL)
+static struct mutex ioctl_lock;
+#endif
+
+#define PMU_DEVICES 1 // pmu control
+
+static dev_t lwpmu_DevNum; /* the major and minor parts for SOCPERF base */
+
+static struct class *pmu_class;
+
+#define DRV_DEVICE_DELIMITER "!"
+
+#if !defined(DRV_USE_UNLOCKED_IOCTL)
+#define MUTEX_INIT(lock)
+#define MUTEX_LOCK(lock)
+#define MUTEX_UNLOCK(lock)
+#else
+#define MUTEX_INIT(lock) mutex_init(&(lock))
+#define MUTEX_LOCK(lock) mutex_lock(&(lock))
+#define MUTEX_UNLOCK(lock) mutex_unlock(&(lock))
+#endif
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Initialize_State(void)
+ *
+ * @param none
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Allocates the memory needed at load time.  Initializes all the
+ * @brief  necessary state variables with the default values.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Initialize_State(VOID)
+{
+	S32 i, max_cpu_id = 0;
+
+	for_each_possible_cpu(i) {
+		if (cpu_present(i)) {
+			if (i > max_cpu_id) {
+				max_cpu_id = i;
+			}
+		}
+	}
+	max_cpu_id++;
+
+	/*
+	 *  Machine Initializations
+	 *  Abstract this information away into a separate entry point
+	 *
+	 *  Question:  Should we allow for the use of Hot-cpu
+	 *    add/subtract functionality while the driver is executing?
+	 */
+	if (max_cpu_id > num_present_cpus()) {
+		GLOBAL_STATE_num_cpus(socperf_driver_state) = max_cpu_id;
+	} else {
+		GLOBAL_STATE_num_cpus(socperf_driver_state) =
+			num_present_cpus();
+	}
+	GLOBAL_STATE_active_cpus(socperf_driver_state) = num_online_cpus();
+	GLOBAL_STATE_cpu_count(socperf_driver_state) = 0;
+	GLOBAL_STATE_dpc_count(socperf_driver_state) = 0;
+	GLOBAL_STATE_num_em_groups(socperf_driver_state) = 0;
+	GLOBAL_STATE_current_phase(socperf_driver_state) =
+		DRV_STATE_UNINITIALIZED;
+
+	SOCPERF_PRINT_DEBUG(
+		"%s: num_cpus=%d, active_cpus=%d\n",
+		__func__,
+		GLOBAL_STATE_num_cpus(socperf_driver_state),
+		GLOBAL_STATE_active_cpus(socperf_driver_state));
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID SOCPERF_Read_Data
+ *
+ * @brief    Reads counter data
+ *
+ * @param    param   data_buffer - buffer for reading counter data.
+ *
+ * @return  None
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+extern VOID SOCPERF_Read_Data3(PVOID data_buffer)
+{
+	if (dispatch_uncore && dispatch_uncore->read_current_data) {
+		dispatch_uncore->read_current_data(data_buffer);
+	}
+	SOCPERF_PRINT_DEBUG("%s called\n", __func__);
+}
+EXPORT_SYMBOL(SOCPERF_Read_Data3);
+
+/*********************************************************************
+ *  Internal Driver functions
+ *     Should be called only from the lwpmudrv_DeviceControl routine
+ *********************************************************************/
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Version(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_VERSION call.
+ * @brief  Returns the version number of the kernel mode sampling.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Version(IOCTL_ARGS arg)
+{
+	OS_STATUS status;
+
+	// Check if enough space is provided for collecting the data
+	if ((arg->len_drv_to_usr != sizeof(U32)) ||
+	    (arg->buf_drv_to_usr == NULL)) {
+		return OS_FAULT;
+	}
+
+	status = put_user(
+		SOCPERF_VERSION_NODE_socperf_version(&socperf_drv_version),
+		(U32 __user *)arg->buf_drv_to_usr);
+
+	return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static VOID lwpmudrv_Clean_Up(DRV_BOOL)
+ *
+ * @param  DRV_BOOL finish - Flag to call finish
+ *
+ * @return VOID
+ *
+ * @brief  Cleans up the memory allocation.
+ *
+ * <I>Special Notes</I>
+ */
+static VOID lwpmudrv_Clean_Up(DRV_BOOL finish)
+{
+	U32 i = 0;
+
+	if (dispatch_uncore && dispatch_uncore->clean_up) {
+		dispatch_uncore->clean_up((VOID *)&i);
+	}
+
+	if (device_uncore) {
+		EVENT_CONFIG ec;
+
+		if (LWPMU_DEVICE_PMU_register_data(device_uncore)) {
+			ec = LWPMU_DEVICE_ec(device_uncore);
+			for (i = 0; i < EVENT_CONFIG_num_groups_unc(ec); i++) {
+				SOCPERF_Free_Memory(
+					LWPMU_DEVICE_PMU_register_data(
+						device_uncore)[i]);
+			}
+		}
+		LWPMU_DEVICE_pcfg(device_uncore) =
+			SOCPERF_Free_Memory(LWPMU_DEVICE_pcfg(device_uncore));
+		LWPMU_DEVICE_ec(device_uncore) =
+			SOCPERF_Free_Memory(LWPMU_DEVICE_ec(device_uncore));
+		device_uncore = SOCPERF_Free_Memory(device_uncore);
+	}
+
+	socperf_pcb = SOCPERF_Free_Memory(socperf_pcb);
+	socperf_pcb_size = 0;
+	GLOBAL_STATE_num_em_groups(socperf_driver_state) = 0;
+	GLOBAL_STATE_num_descriptors(socperf_driver_state) = 0;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Initialize_Driver(PVOID buf_drv_to_usr, U32 len_drv_to_usr)
+ *
+ * @param  buf_drv_to_usr       - pointer to the input buffer
+ * @param  len_drv_to_usr   - size of the input buffer
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_INIT_DRIVER call.
+ * @brief  Sets up the interrupt handler.
+ * @brief  Set up the output buffers/files needed to make the driver
+ * @brief  operational.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Initialize_Driver(PVOID buf_drv_to_usr,
+					    U32 len_drv_to_usr)
+{
+	if (buf_drv_to_usr == NULL) {
+		SOCPERF_PRINT_ERROR("buf_drv_to_usr ERROR!\n");
+		return OS_FAULT;
+	}
+
+	socperf_drv_cfg = SOCPERF_Allocate_Memory(len_drv_to_usr);
+	if (!socperf_drv_cfg) {
+		SOCPERF_PRINT_ERROR("Memory allocation failure for socperf_drv_cfg!\n");
+		return OS_NO_MEM;
+	}
+
+	if (copy_from_user(socperf_drv_cfg, (void __user *)buf_drv_to_usr, len_drv_to_usr)) {
+		SOCPERF_PRINT_ERROR("Failed to copy from user");
+		return OS_FAULT;
+	}
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS lwpmudrv_Initialize_Uncore(PVOID buf_drv_to_usr, U32 len_drv_to_usr)
+ *
+ * @param  buf_drv_to_usr       - pointer to the input buffer
+ * @param  len_drv_to_usr   - size of the input buffer
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_INIT call.
+ * @brief  Sets up the interrupt handler.
+ * @brief  Set up the output buffers/files needed to make the driver
+ * @brief  operational.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Initialize_Uncore(PVOID buf_drv_to_usr,
+					    U32 len_drv_to_usr)
+{
+	DEV_UNC_CONFIG pcfg_unc;
+	U32 previous_state;
+	U32 i = 0;
+
+	SOCPERF_PRINT_DEBUG("Entered %s\n", __func__);
+	previous_state =
+		cmpxchg(&GLOBAL_STATE_current_phase(socperf_driver_state),
+			DRV_STATE_UNINITIALIZED, DRV_STATE_IDLE);
+
+	if (previous_state != DRV_STATE_UNINITIALIZED) {
+		SOCPERF_PRINT_ERROR("OS_IN_PROGRESS error!\n");
+		return OS_IN_PROGRESS;
+	}
+	/*
+	 *   Program State Initializations:
+	 *   Foreach device, copy over pcfg_unc and configure dispatch table
+	 */
+	if (buf_drv_to_usr == NULL) {
+		SOCPERF_PRINT_ERROR("in_buff ERROR!\n");
+		return OS_FAULT;
+	}
+	if (len_drv_to_usr != sizeof(DEV_UNC_CONFIG_NODE)) {
+		SOCPERF_PRINT_ERROR(
+			"Got len_drv_to_usr=%d, expecting size=%d\n",
+			len_drv_to_usr, (int)sizeof(DEV_UNC_CONFIG_NODE));
+		return OS_FAULT;
+	}
+
+	device_uncore = SOCPERF_Allocate_Memory(sizeof(LWPMU_DEVICE_NODE));
+	if (!device_uncore) {
+		SOCPERF_PRINT_ERROR(
+			"Memory allocation failure for device_uncore!\n");
+		return OS_NO_MEM;
+	}
+	socperf_pcb_size = GLOBAL_STATE_num_cpus(socperf_driver_state) *
+			   sizeof(CPU_STATE_NODE);
+	socperf_pcb = SOCPERF_Allocate_Memory(socperf_pcb_size);
+	if (!socperf_pcb) {
+		SOCPERF_PRINT_ERROR(
+			"Memory allocation failure for socperf_pcb!\n");
+		return OS_NO_MEM;
+	}
+
+	// allocate memory
+	LWPMU_DEVICE_pcfg(device_uncore) =
+		SOCPERF_Allocate_Memory(sizeof(DEV_UNC_CONFIG_NODE));
+	if (!LWPMU_DEVICE_pcfg(device_uncore)) {
+		SOCPERF_PRINT_ERROR(
+			"Memory allocation failure for LWPMU_DEVICE_pcfg(device_uncore)!\n");
+		return OS_NO_MEM;
+	}
+	// copy over pcfg_unc
+	if (copy_from_user(LWPMU_DEVICE_pcfg(device_uncore), (void __user *)buf_drv_to_usr,
+			   len_drv_to_usr)) {
+		SOCPERF_PRINT_ERROR("Failed to copy from user");
+		return OS_FAULT;
+	}
+	// configure dispatch from dispatch_id
+	pcfg_unc = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(device_uncore);
+
+	LWPMU_DEVICE_dispatch(device_uncore) = SOCPERF_UTILITY_Configure_CPU(
+		DEV_UNC_CONFIG_dispatch_id(pcfg_unc));
+	if (LWPMU_DEVICE_dispatch(device_uncore) == NULL) {
+		SOCPERF_PRINT_ERROR("Unable to configure CPU");
+		return OS_FAULT;
+	}
+
+	LWPMU_DEVICE_em_groups_count(device_uncore) = 0;
+	LWPMU_DEVICE_cur_group(device_uncore) = 0;
+	SOCPERF_PRINT_DEBUG(
+		"SocPerf Driver Config : uncore dispatch id   = %d\n",
+		DEV_UNC_CONFIG_dispatch_id(pcfg_unc));
+	dispatch_uncore = LWPMU_DEVICE_dispatch(device_uncore);
+	if (dispatch_uncore && dispatch_uncore->init) {
+		dispatch_uncore->init((VOID *)&i);
+	}
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS socperf_Terminate(void)
+ *
+ * @param  none
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMUDRV_IOCTL_TERMINATE call.
+ * @brief  Cleans up the interrupt handler and resets the PMU state.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS socperf_Terminate(VOID)
+{
+	U32 previous_state;
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) ==
+	    DRV_STATE_UNINITIALIZED) {
+		return OS_SUCCESS;
+	}
+
+	previous_state =
+		cmpxchg(&GLOBAL_STATE_current_phase(socperf_driver_state),
+			DRV_STATE_STOPPED, DRV_STATE_UNINITIALIZED);
+	if (previous_state != DRV_STATE_STOPPED) {
+		SOCPERF_PRINT_ERROR(
+			"%s: Sampling is in progress, cannot terminate.\n", __func__);
+		return OS_IN_PROGRESS;
+	}
+
+	GLOBAL_STATE_current_phase(socperf_driver_state) =
+		DRV_STATE_UNINITIALIZED;
+	lwpmudrv_Clean_Up(TRUE);
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Trigger_Read(void)
+ *
+ * @param - none
+ *
+ * @return - OS_STATUS
+ *
+ * @brief Read the Counter Data.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Trigger_Read(VOID)
+{
+	dispatch_uncore = LWPMU_DEVICE_dispatch(device_uncore);
+	if (dispatch_uncore && dispatch_uncore->trigger_read) {
+		dispatch_uncore->trigger_read();
+	}
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Init_PMU(void)
+ *
+ * @param - none
+ *
+ * @return - OS_STATUS
+ *
+ * @brief Initialize the PMU and the driver state in preparation for data collection.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Init_PMU(VOID)
+{
+	U32 i = 0;
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) !=
+	    DRV_STATE_IDLE) {
+		return OS_IN_PROGRESS;
+	}
+	dispatch_uncore = LWPMU_DEVICE_dispatch(device_uncore);
+	if (dispatch_uncore && dispatch_uncore->write) {
+		dispatch_uncore->write((VOID *)&i);
+	}
+	SOCPERF_PRINT_DEBUG(
+		"%s: IOCTL_Init_PMU - finished initial Write\n", __func__);
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Set_EM_Config_UNC(IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Set the number of em groups in the global state node.
+ * @brief  Also, copy the EVENT_CONFIG struct that has been passed in,
+ * @brief  into a global location for now.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Set_EM_Config_Uncore(IOCTL_ARGS arg)
+{
+	EVENT_CONFIG ec;
+	SOCPERF_PRINT_DEBUG("enter %s\n", __func__);
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) !=
+	    DRV_STATE_IDLE) {
+		return OS_IN_PROGRESS;
+	}
+
+	if (arg->buf_usr_to_drv == NULL || arg->len_usr_to_drv == 0) {
+		return OS_INVALID;
+	}
+	// allocate memory
+	LWPMU_DEVICE_ec(device_uncore) =
+		SOCPERF_Allocate_Memory(sizeof(EVENT_CONFIG_NODE));
+	if (!LWPMU_DEVICE_ec(device_uncore)) {
+		SOCPERF_PRINT_ERROR(
+			"Memory allocation failure for LWPMU_DEVICE_ec(device_uncore)!\n");
+		return OS_NO_MEM;
+	}
+	if (copy_from_user(LWPMU_DEVICE_ec(device_uncore), (void __user *)arg->buf_usr_to_drv,
+			   arg->len_usr_to_drv)) {
+		return OS_FAULT;
+	}
+	// configure num_groups from ec of the specific device
+	ec = (EVENT_CONFIG)LWPMU_DEVICE_ec(device_uncore);
+	LWPMU_DEVICE_PMU_register_data(device_uncore) = SOCPERF_Allocate_Memory(
+		EVENT_CONFIG_num_groups_unc(ec) * sizeof(VOID *));
+	if (!LWPMU_DEVICE_PMU_register_data(device_uncore)) {
+		SOCPERF_PRINT_ERROR(
+			"Memory allocation failure for LWPMU_DEVICE_PMU_register_data(device_uncore)!\n");
+		return OS_NO_MEM;
+	}
+	LWPMU_DEVICE_em_groups_count(device_uncore) = 0;
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS socperf_Configure_Events_Uncore (IOCTL_ARGS arg)
+ *
+ * @param arg - pointer to the IOCTL_ARGS structure
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Make a copy of the uncore registers that need to be programmed
+ * @brief  for the next event set used for event multiplexing
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS socperf_Configure_Events_Uncore(IOCTL_ARGS arg)
+{
+	VOID **PMU_register_data_unc;
+	S32 em_groups_count_unc;
+	ECB ecb;
+	EVENT_CONFIG ec_unc;
+	U32 group_id = 0;
+	ECB in_ecb = NULL;
+
+	if (GLOBAL_STATE_current_phase(socperf_driver_state) !=
+	    DRV_STATE_IDLE) {
+		return OS_IN_PROGRESS;
+	}
+
+	em_groups_count_unc = LWPMU_DEVICE_em_groups_count(device_uncore);
+	PMU_register_data_unc = LWPMU_DEVICE_PMU_register_data(device_uncore);
+	ec_unc = LWPMU_DEVICE_ec(device_uncore);
+
+	if (ec_unc == NULL) {
+		SOCPERF_PRINT_ERROR(
+			"%s: ec_unc is NULL!\n", __func__);
+		return OS_INVALID;
+	}
+
+	if (em_groups_count_unc >= (S32)EVENT_CONFIG_num_groups_unc(ec_unc)) {
+		SOCPERF_PRINT_ERROR(
+			"%s: Number of Uncore EM groups exceeded the initial configuration.", __func__);
+		return OS_INVALID;
+	}
+	if (arg->buf_usr_to_drv == NULL ||
+	    arg->len_usr_to_drv < sizeof(ECB_NODE)) {
+		SOCPERF_PRINT_ERROR(
+			"%s: args are invalid.", __func__);
+		return OS_INVALID;
+	}
+	//       size is in len_usr_to_drv, data is pointed to by buf_usr_to_drv
+	//
+	in_ecb = SOCPERF_Allocate_Memory(arg->len_usr_to_drv);
+	if (!in_ecb) {
+		SOCPERF_PRINT_ERROR(
+			"%s: ECB memory allocation failed\n", __func__);
+		return OS_NO_MEM;
+	}
+	if (copy_from_user(in_ecb, (void __user *)arg->buf_usr_to_drv, arg->len_usr_to_drv)) {
+		SOCPERF_PRINT_ERROR(
+			"%s: ECB copy failed\n", __func__);
+		in_ecb = SOCPERF_Free_Memory(in_ecb);
+		return OS_NO_MEM;
+	}
+
+	group_id = ECB_group_id(in_ecb);
+	if (group_id >= EVENT_CONFIG_num_groups_unc(ec_unc)) {
+		SOCPERF_PRINT_ERROR(
+			"%s: group_id is larger than total number of groups\n", __func__);
+		in_ecb = SOCPERF_Free_Memory(in_ecb);
+		return OS_INVALID;
+	}
+
+	PMU_register_data_unc[group_id] = in_ecb;
+	if (!PMU_register_data_unc[group_id]) {
+		SOCPERF_PRINT_ERROR(
+			"%s: ECB memory allocation failed\n", __func__);
+		in_ecb = SOCPERF_Free_Memory(in_ecb);
+		return OS_NO_MEM;
+	}
+
+	//
+	// Make a copy of the data for global use.
+	//
+	if (copy_from_user(PMU_register_data_unc[group_id], (void __user *)arg->buf_usr_to_drv,
+			   arg->len_usr_to_drv)) {
+		SOCPERF_PRINT_ERROR(
+			"%s: ECB copy failed\n", __func__);
+		in_ecb = SOCPERF_Free_Memory(in_ecb);
+		return OS_NO_MEM;
+	}
+
+	// at this point, we know the number of uncore events for this device,
+	// so allocate the results buffer per thread for uncore only for event based uncore counting
+	if (em_groups_count_unc == 0) {
+		ecb = PMU_register_data_unc[0];
+		if (ecb == NULL) {
+			in_ecb = SOCPERF_Free_Memory(in_ecb);
+			return OS_INVALID;
+		}
+		LWPMU_DEVICE_num_events(device_uncore) = ECB_num_events(ecb);
+	}
+	LWPMU_DEVICE_em_groups_count(device_uncore) = group_id + 1;
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS socperf_Start(void)
+ *
+ * @param none
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMU_IOCTL_START call.
+ * @brief  Set up the OS hooks for process/thread/load notifications.
+ * @brief  Write the initial set of MSRs.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS socperf_Start(VOID)
+{
+	OS_STATUS status = OS_SUCCESS;
+	U32 previous_state;
+	U32 i = 0;
+
+	/*
+	 * To Do: Check for state == STATE_IDLE and only then enable sampling
+	 */
+	previous_state =
+		cmpxchg(&GLOBAL_STATE_current_phase(socperf_driver_state),
+			DRV_STATE_IDLE, DRV_STATE_RUNNING);
+	if (previous_state != DRV_STATE_IDLE) {
+		SOCPERF_PRINT_ERROR(
+			"%s: Unable to start sampling - State is %d\n",
+			__func__,
+			GLOBAL_STATE_current_phase(socperf_driver_state));
+		return OS_IN_PROGRESS;
+	}
+
+	if (dispatch_uncore && dispatch_uncore->restart) {
+		dispatch_uncore->restart((VOID *)&i);
+	}
+
+	return status;
+}
+
+/*
+ * @fn lwpmudrv_Prepare_Stop();
+ *
+ * @param        NONE
+ * @return       OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMUDRV_IOCTL_STOP call.
+ * @brief  Cleans up the interrupt handler.
+ */
+static OS_STATUS socperf_Prepare_Stop(VOID)
+{
+	U32 i = 0;
+	U32 current_state = GLOBAL_STATE_current_phase(socperf_driver_state);
+
+	SOCPERF_PRINT_DEBUG("%s: About to stop sampling\n", __func__);
+	GLOBAL_STATE_current_phase(socperf_driver_state) =
+		DRV_STATE_PREPARE_STOP;
+
+	if (current_state == DRV_STATE_UNINITIALIZED) {
+		return OS_SUCCESS;
+	}
+
+	if (dispatch_uncore && dispatch_uncore->freeze) {
+		dispatch_uncore->freeze((VOID *)&i);
+	}
+
+	return OS_SUCCESS;
+}
+
+/*
+ * @fn socperf_Finish_Stop();
+ *
+ * @param  NONE
+ * @return OS_STATUS
+ *
+ * @brief  Local function that handles the LWPMUDRV_IOCTL_STOP call.
+ * @brief  Cleans up the interrupt handler.
+ */
+static OS_STATUS socperf_Finish_Stop(VOID)
+{
+	OS_STATUS status = OS_SUCCESS;
+
+	GLOBAL_STATE_current_phase(socperf_driver_state) = DRV_STATE_STOPPED;
+
+	return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Pause(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Pause the collection
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Pause(VOID)
+{
+	U32 previous_state;
+	U32 i = 0;
+
+	previous_state =
+		cmpxchg(&GLOBAL_STATE_current_phase(socperf_driver_state),
+			DRV_STATE_RUNNING, DRV_STATE_PAUSED);
+	if (previous_state == DRV_STATE_RUNNING) {
+		dispatch_uncore = LWPMU_DEVICE_dispatch(device_uncore);
+		if (dispatch_uncore && dispatch_uncore->freeze) {
+			dispatch_uncore->freeze((VOID *)&i);
+		}
+	} else {
+		if (previous_state == DRV_STATE_PAUSED) {
+			return VT_SAMP_IN_PAUSE_STATE;
+		}
+		SOCPERF_PRINT_ERROR(
+			"There is no sampling collection running at this time\n");
+		return VT_SAMP_IN_STOP_STATE;
+	}
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static NTSTATUS lwpmudrv_Resume(void)
+ *
+ * @param - none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Resume the sampling after a pause.  Assumption, the pause duration
+ * @brief will be long enough for all interrupts to be processed and no
+ * @brief active sampling to occur.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Resume(VOID)
+{
+	U32 previous_state;
+	U32 i = 0;
+
+	previous_state =
+		cmpxchg(&GLOBAL_STATE_current_phase(socperf_driver_state),
+			DRV_STATE_PAUSED, DRV_STATE_RUNNING);
+
+	if (previous_state == DRV_STATE_PAUSED) {
+		dispatch_uncore = LWPMU_DEVICE_dispatch(device_uncore);
+		if (dispatch_uncore && dispatch_uncore->restart) {
+			dispatch_uncore->restart((VOID *)&i);
+		}
+		SOCPERF_PRINT_DEBUG("Resuming the sampling collection...\n");
+	} else {
+		SOCPERF_PRINT_DEBUG(
+			"There is no paused sampling collection at this time.\n");
+	}
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Read_Uncore_Counts(void buf_usr_to_drv, U32 len_usr_to_drv)
+ *
+ * @param - buf_usr_to_drv       - output buffer
+ *          len_usr_to_drv   - output buffer length
+ *
+ * @return - OS_STATUS
+ *
+ * @brief    Read the Counter Data.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Read_Uncore_Counts(PVOID buf_usr_to_drv,
+					     U32 len_usr_to_drv)
+{
+	if (buf_usr_to_drv == NULL) {
+		SOCPERF_PRINT_ERROR(
+			"%s: counter buffer is NULL\n", __func__);
+		return OS_FAULT;
+	}
+
+	if (dispatch_uncore && dispatch_uncore->read_current_data) {
+		dispatch_uncore->read_current_data(buf_usr_to_drv);
+	}
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static OS_STATUS SOCPERF_Switch_Group(void)
+ *
+ * @param none
+ *
+ * @return OS_STATUS
+ *
+ * @brief Switch the current uncore group that is being collected.
+ *
+ * <I>Special Notes</I>
+ *     This routine is called from the user mode code to handle the multiple uncore group
+ *     situation.  4 distinct steps are taken:
+ *     Step 1: Pause the sampling
+ *     Step 2: Increment the current uncore group count
+ *     Step 3: Write the new group to the uncore PMU
+ *     Step 4: Resume sampling
+ */
+extern OS_STATUS
+SOCPERF_Switch_Group3(VOID)
+{
+	OS_STATUS status = OS_SUCCESS;
+	U32 current_state = GLOBAL_STATE_current_phase(socperf_driver_state);
+	U32 i = 0;
+	DEV_UNC_CONFIG pcfg_unc;
+
+	SOCPERF_PRINT_DEBUG("Switching Uncore Group...\n");
+	if (current_state != DRV_STATE_RUNNING &&
+	    current_state != DRV_STATE_PAUSED) {
+		return status;
+	}
+	status = lwpmudrv_Pause();
+	LWPMU_DEVICE_cur_group(device_uncore)++;
+	LWPMU_DEVICE_cur_group(device_uncore) %=
+		LWPMU_DEVICE_em_groups_count(device_uncore);
+	dispatch_uncore = LWPMU_DEVICE_dispatch(device_uncore);
+	if (dispatch_uncore && dispatch_uncore->write) {
+		dispatch_uncore->write((VOID *)&i);
+	}
+
+	pcfg_unc = (DEV_UNC_CONFIG)LWPMU_DEVICE_pcfg(device_uncore);
+	if (pcfg_unc && (DRV_CONFIG_start_paused(socperf_drv_cfg) == FALSE)) {
+		status = lwpmudrv_Resume();
+	}
+
+	return status;
+}
+EXPORT_SYMBOL(SOCPERF_Switch_Group3);
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Create_Mem(IOCTL_ARGS arg)
+ *
+ * @param - none
+ *
+ * @return - OS_STATUS
+ *
+ * @brief Read the Counter Data.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Create_Mem(IOCTL_ARGS arg)
+{
+	U32 memory_size = 0;
+	U64 trace_phys_address = 0;
+
+	if (arg->buf_usr_to_drv == NULL || arg->len_usr_to_drv == 0) {
+		SOCPERF_PRINT_ERROR(
+			"%s: Counter buffer is NULL\n", __func__);
+		return OS_FAULT;
+	}
+
+	if (copy_from_user(&memory_size, (U32 __user *)arg->buf_usr_to_drv,
+			   sizeof(U32))) {
+		return OS_FAULT;
+	}
+
+	if (arg->buf_drv_to_usr == NULL || arg->len_drv_to_usr == 0) {
+		SOCPERF_PRINT_ERROR(
+			"%s: output buffer is NULL\n", __func__);
+		return OS_FAULT;
+	}
+	SOCPERF_PRINT_DEBUG("Read size=%llx\n", arg->len_drv_to_usr);
+	SOCPERF_PRINT_DEBUG("Write size=%llx\n", arg->len_usr_to_drv);
+	if (arg->len_drv_to_usr != sizeof(U64)) {
+		return OS_FAULT;
+	}
+
+	dispatch_uncore = LWPMU_DEVICE_dispatch(device_uncore);
+	if (dispatch_uncore && dispatch_uncore->create_mem) {
+		dispatch_uncore->create_mem(memory_size, &trace_phys_address);
+	} else {
+		SOCPERF_PRINT_ERROR("dispatch table could not be called\n");
+	}
+
+	if (copy_to_user((void __user *)arg->buf_drv_to_usr, &trace_phys_address,
+			 sizeof(U64))) {
+		return OS_FAULT;
+	}
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Check_Status( IOCTL_ARGS arg)
+ *
+ * @param - none
+ *
+ * @return - OS_STATUS
+ *
+ * @brief Read the Counter Data.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Check_Status(IOCTL_ARGS arg)
+{
+	U32 num_entries = 0;
+	U64 *status_data = 0;
+
+	if ((arg->len_drv_to_usr == 0) || (arg->buf_drv_to_usr == NULL)) {
+		return OS_FAULT;
+	}
+
+	status_data = SOCPERF_Allocate_Memory(arg->len_drv_to_usr);
+	if (dispatch_uncore && dispatch_uncore->check_status) {
+		dispatch_uncore->check_status(status_data, &num_entries);
+	}
+
+	if (copy_to_user((void __user *)arg->buf_drv_to_usr, status_data,
+			 num_entries * sizeof(U64))) {
+		SOCPERF_Free_Memory(status_data);
+		return OS_FAULT;
+	}
+	SOCPERF_Free_Memory(status_data);
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static OS_STATUS lwpmudrv_Read_Mem( IOCTL_ARGS arg)
+ *
+ * @param - none
+ *
+ * @return - OS_STATUS
+ *
+ * @brief Read the Counter Data.
+ *
+ * <I>Special Notes</I>
+ */
+static OS_STATUS lwpmudrv_Read_Mem(IOCTL_ARGS arg)
+{
+	U64 start_address = 0;
+	U64 *mem_address = NULL;
+	U32 mem_size = 0;
+	U32 num_entries = 0;
+
+	if (arg->buf_usr_to_drv == NULL || arg->len_usr_to_drv == 0) {
+		SOCPERF_PRINT_ERROR(
+			"%s: Counter buffer is NULL\n", __func__);
+		return OS_FAULT;
+	}
+
+	if (copy_from_user(&start_address, (U64 __user *)arg->buf_usr_to_drv,
+			   sizeof(U64))) {
+		return OS_FAULT;
+	}
+
+	if ((arg->len_drv_to_usr == 0) || (arg->buf_drv_to_usr == NULL)) {
+		return OS_FAULT;
+	}
+	mem_size = (U32)arg->len_drv_to_usr;
+	mem_address = SOCPERF_Allocate_Memory(mem_size);
+	if (!mem_address) {
+		return OS_NO_MEM;
+	}
+
+	num_entries = (U32)(mem_size / sizeof(U64));
+	if (dispatch_uncore && dispatch_uncore->read_mem) {
+		dispatch_uncore->read_mem(start_address, mem_address,
+					  num_entries);
+	}
+	if (copy_to_user((void __user *)arg->buf_drv_to_usr, mem_address, mem_size)) {
+		SOCPERF_Free_Memory(mem_address);
+		return OS_FAULT;
+	}
+	SOCPERF_Free_Memory(mem_address);
+
+	return OS_SUCCESS;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn static VOID lwpmudrv_Stop_Mem(void)
+ *
+ * @param - none
+ *
+ * @return - none
+ *
+ * @brief Stop Mem
+ *
+ * <I>Special Notes</I>
+ */
+VOID lwpmudrv_Stop_Mem(VOID)
+{
+	SOCPERF_PRINT_DEBUG("Entered %s\n", __func__);
+
+	if (dispatch_uncore && dispatch_uncore->stop_mem) {
+		dispatch_uncore->stop_mem();
+	}
+
+	SOCPERF_PRINT_DEBUG("Exited %s\n", __func__);
+
+}
+
+/*******************************************************************************
+ *  External Driver functions - Open
+ *      This function is common to all drivers
+ *******************************************************************************/
+
+static int socperf_Open(struct inode *inode, struct file *filp)
+{
+	SOCPERF_PRINT_DEBUG("lwpmu_Open called on maj:%d, min:%d\n",
+			    imajor(inode), iminor(inode));
+	filp->private_data = container_of(inode->i_cdev, LWPMU_DEV_NODE, cdev);
+
+	return 0;
+}
+
+/*******************************************************************************
+ *  External Driver functions
+ *      These functions are registered into the file operations table that
+ *      controls this device.
+ *      Open, Close, Read, Write, Release
+ *******************************************************************************/
+
+static ssize_t socperf_Read(struct file *filp, char __user *buf, size_t count,
+			    loff_t *f_pos)
+{
+	unsigned long retval;
+
+	/* Transferring data to user space */
+	SOCPERF_PRINT_DEBUG("lwpmu_Read dispatched with count=%d\n",
+			    (S32)count);
+	if (copy_to_user((void __user *)buf, &LWPMU_DEV_buffer(socperf_control), 1)) {
+		retval = OS_FAULT;
+		return retval;
+	}
+	/* Changing reading position as best suits */
+	if (*f_pos == 0) {
+		*f_pos += 1;
+		return 1;
+	}
+
+	return 0;
+}
+
+static ssize_t socperf_Write(struct file *filp, const char __user *buf, size_t count,
+			     loff_t *f_pos)
+{
+	unsigned long retval;
+
+	SOCPERF_PRINT_DEBUG("lwpmu_Write dispatched with count=%d\n",
+			    (S32)count);
+	if (copy_from_user(&LWPMU_DEV_buffer(socperf_control), (void __user *)(buf + count - 1),
+			   1)) {
+		retval = OS_FAULT;
+		return retval;
+	}
+
+	return 1;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  extern IOCTL_OP_TYPE socperf_Service_IOCTL(IOCTL_USE_NODE, filp, cmd, arg)
+ *
+ * @param   IOCTL_USE_INODE       - Used for pre 2.6.32 kernels
+ * @param   struct   file   *filp - file pointer
+ * @param   unsigned int     cmd  - IOCTL command
+ * @param   unsigned long    arg  - args to the IOCTL command
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Worker function that handles IOCTL requests from the user mode.
+ *
+ * <I>Special Notes</I>
+ */
+IOCTL_OP_TYPE socperf_Service_IOCTL(IOCTL_USE_INODE struct file *filp,
+					   unsigned int cmd,
+					   IOCTL_ARGS_NODE local_args)
+{
+	int status = OS_SUCCESS;
+
+	switch (cmd) {
+		/*
+		 * Common IOCTL commands
+		 */
+	case DRV_OPERATION_VERSION:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_VERSION\n");
+		status = lwpmudrv_Version(&local_args);
+		break;
+
+	case DRV_OPERATION_RESERVE:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_RESERVE\n");
+		break;
+
+	case DRV_OPERATION_INIT_PMU:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_INIT_PMU\n");
+		status = lwpmudrv_Init_PMU();
+		break;
+
+	case DRV_OPERATION_START:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_START\n");
+		status = socperf_Start();
+		break;
+
+	case DRV_OPERATION_STOP:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_STOP\n");
+		status = socperf_Prepare_Stop();
+		break;
+
+	case DRV_OPERATION_PAUSE:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_PAUSE\n");
+		status = lwpmudrv_Pause();
+		break;
+
+	case DRV_OPERATION_RESUME:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_RESUME\n");
+		status = lwpmudrv_Resume();
+		break;
+
+	case DRV_OPERATION_TERMINATE:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_TERMINATE\n");
+		status = socperf_Terminate();
+		break;
+
+	case DRV_OPERATION_INIT_DRIVER:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_INIT_DRIVER\n");
+		status = lwpmudrv_Initialize_Driver(local_args.buf_usr_to_drv,
+						    local_args.len_usr_to_drv);
+		break;
+
+	case DRV_OPERATION_INIT_UNCORE:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_INIT_UNCORE\n");
+		status = lwpmudrv_Initialize_Uncore(local_args.buf_usr_to_drv,
+						    local_args.len_usr_to_drv);
+		break;
+	case DRV_OPERATION_EM_GROUPS_UNCORE:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_EM_GROUPS_UNC\n");
+		status = lwpmudrv_Set_EM_Config_Uncore(&local_args);
+		break;
+
+	case DRV_OPERATION_EM_CONFIG_NEXT_UNCORE:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_EM_CONFIG_NEXT_UNC\n");
+		status = socperf_Configure_Events_Uncore(&local_args);
+		break;
+
+	case DRV_OPERATION_TIMER_TRIGGER_READ:
+		lwpmudrv_Trigger_Read();
+		break;
+
+	case DRV_OPERATION_READ_UNCORE_DATA:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_READ_UNCORE_DATA\n");
+		status = lwpmudrv_Read_Uncore_Counts(local_args.buf_drv_to_usr,
+						     local_args.len_drv_to_usr);
+		break;
+
+	case DRV_OPERATION_CREATE_MEM:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_CREATE_MEM\n");
+		lwpmudrv_Create_Mem(&local_args);
+		break;
+
+	case DRV_OPERATION_READ_MEM:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_READ_MEM\n");
+		lwpmudrv_Read_Mem(&local_args);
+		break;
+
+	case DRV_OPERATION_CHECK_STATUS:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_CHECK_STATUS\n");
+		lwpmudrv_Check_Status(&local_args);
+		break;
+
+	case DRV_OPERATION_STOP_MEM:
+		SOCPERF_PRINT_DEBUG(" DRV_OPERATION_STOP_MEM\n");
+		lwpmudrv_Stop_Mem();
+		break;
+
+		/*
+		 * if none of the above, treat as unknown/illegal IOCTL command
+		 */
+	default:
+		SOCPERF_PRINT_ERROR("Unknown IOCTL magic:%d number:%d\n",
+				    _IOC_TYPE(cmd), _IOC_NR(cmd));
+		status = OS_ILLEGAL_IOCTL;
+		break;
+	}
+
+	if (cmd == DRV_OPERATION_STOP &&
+	    GLOBAL_STATE_current_phase(socperf_driver_state) ==
+		    DRV_STATE_PREPARE_STOP) {
+		status = socperf_Finish_Stop();
+	}
+
+	return status;
+}
+
+long socperf_Device_Control(IOCTL_USE_INODE struct file *filp,
+				   unsigned int cmd, unsigned long arg)
+{
+	int status = OS_SUCCESS;
+	IOCTL_ARGS_NODE local_args;
+
+#if !defined(DRV_USE_UNLOCKED_IOCTL)
+	SOCPERF_PRINT_DEBUG(
+		"lwpmu_DeviceControl(0x%x) called on inode maj:%d, min:%d\n",
+		cmd, imajor(inode), iminor(inode));
+#endif
+	SOCPERF_PRINT_DEBUG("type: %d, subcommand: %d\n", _IOC_TYPE(cmd),
+			    _IOC_NR(cmd));
+
+	if (_IOC_TYPE(cmd) != LWPMU_IOC_MAGIC) {
+		SOCPERF_PRINT_ERROR("Unknown IOCTL magic:%d\n", _IOC_TYPE(cmd));
+		return OS_ILLEGAL_IOCTL;
+	}
+
+	MUTEX_LOCK(ioctl_lock);
+	if (arg) {
+		status = copy_from_user(&local_args, (void __user *)arg,
+					sizeof(IOCTL_ARGS_NODE));
+	}
+
+	status = socperf_Service_IOCTL(IOCTL_USE_INODE filp, _IOC_NR(cmd),
+				       local_args);
+	MUTEX_UNLOCK(ioctl_lock);
+
+	return status;
+}
+
+#if defined(CONFIG_COMPAT) && defined(DRV_EM64T)
+long socperf_Device_Control_Compat(struct file *filp, unsigned int cmd,
+					  unsigned long arg)
+{
+	int status = OS_SUCCESS;
+	IOCTL_COMPAT_ARGS_NODE local_args_compat;
+	IOCTL_ARGS_NODE local_args;
+
+	memset(&local_args_compat, 0, sizeof(IOCTL_COMPAT_ARGS_NODE));
+	SOCPERF_PRINT_DEBUG("Compat: type: %d, subcommand: %d\n",
+			    _IOC_TYPE(cmd), _IOC_NR(cmd));
+
+	if (_IOC_TYPE(cmd) != LWPMU_IOC_MAGIC) {
+		SOCPERF_PRINT_ERROR("Unknown IOCTL magic:%d\n", _IOC_TYPE(cmd));
+		return OS_ILLEGAL_IOCTL;
+	}
+
+	MUTEX_LOCK(ioctl_lock);
+	if (arg) {
+		status = copy_from_user(&local_args_compat,
+					(void __user *)arg,
+					sizeof(IOCTL_COMPAT_ARGS_NODE));
+	}
+	local_args.len_drv_to_usr = local_args_compat.len_drv_to_usr;
+	local_args.len_usr_to_drv = local_args_compat.len_usr_to_drv;
+	local_args.buf_drv_to_usr =
+		(char *)compat_ptr(local_args_compat.buf_drv_to_usr);
+	local_args.buf_usr_to_drv =
+		(char *)compat_ptr(local_args_compat.buf_usr_to_drv);
+
+	status = socperf_Service_IOCTL(filp, _IOC_NR(cmd), local_args);
+	MUTEX_UNLOCK(ioctl_lock);
+
+	return status;
+}
+#endif
+
+/*
+ * @fn        SOCPERF_Abnormal_Terminate(void)
+ *
+ * @brief     This routine is called from linuxos_Exit_Task_Notify if the user process has
+ *            been killed by an uncatchable signal (example kill -9).  The state variable
+ *            abormal_terminate is set to 1 and the clean up routines are called.  In this
+ *            code path the OS notifier hooks should not be unloaded.
+ *
+ * @param     None
+ *
+ * @return    OS_STATUS
+ *
+ * <I>Special Notes:</I>
+ *     <none>
+ */
+int SOCPERF_Abnormal_Terminate(void)
+{
+	int status = OS_SUCCESS;
+
+	socperf_abnormal_terminate = 1;
+	SOCPERF_PRINT_DEBUG(
+		"Abnormal-Termination: Calling socperf_Prepare_Stop\n");
+	status = socperf_Prepare_Stop();
+	SOCPERF_PRINT_DEBUG(
+		"Abnormal-Termination: Calling socperf_Finish_Stop\n");
+	status = socperf_Finish_Stop();
+	SOCPERF_PRINT_DEBUG(
+		"Abnormal-Termination: Calling lwpmudrv_Terminate\n");
+	status = socperf_Terminate();
+
+	return status;
+}
+
+/*****************************************************************************************
+ *
+ *   Driver Entry / Exit functions that will be called on when the driver is loaded and
+ *   unloaded
+ *
+ ****************************************************************************************/
+
+/*
+ * Structure that declares the usual file access functions
+ * First one is for lwpmu_c, the control functions
+ */
+static struct file_operations socperf_Fops = {
+	.owner = THIS_MODULE,
+	IOCTL_OP = socperf_Device_Control,
+#if defined(CONFIG_COMPAT) && defined(DRV_EM64T)
+	.compat_ioctl = socperf_Device_Control_Compat,
+#endif
+	.read = socperf_Read,
+	.write = socperf_Write,
+	.open = socperf_Open,
+	.release = NULL,
+	.llseek = NULL,
+};
+
+/*!
+ * @fn  static int lwpmudrv_setup_cdev(dev, fops, dev_number)
+ *
+ * @param LWPMU_DEV               dev  - pointer to the device object
+ * @param struct file_operations *fops - pointer to the file operations struct
+ * @param dev_t                   dev_number - major/monor device number
+ *
+ * @return OS_STATUS
+ *
+ * @brief  Set up the device object.
+ *
+ * <I>Special Notes</I>
+ */
+static int lwpmu_setup_cdev(LWPMU_DEV dev, struct file_operations *fops,
+			    dev_t dev_number)
+{
+	cdev_init(&LWPMU_DEV_cdev(dev), fops);
+	LWPMU_DEV_cdev(dev).owner = THIS_MODULE;
+	LWPMU_DEV_cdev(dev).ops = fops;
+
+	return cdev_add(&LWPMU_DEV_cdev(dev), dev_number, 1);
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static int socperf_Load(void)
+ *
+ * @param none
+ *
+ * @return STATUS
+ *
+ * @brief  Load the driver module into the kernel.  Set up the driver object.
+ * @brief  Set up the initial state of the driver and allocate the memory
+ * @brief  needed to keep basic state information.
+ */
+static int socperf_Load(VOID)
+{
+	int num_cpus;
+	OS_STATUS status = OS_SUCCESS;
+
+	SOCPERF_Memory_Tracker_Init();
+
+	/* Get one major device number and one minor number. */
+	/*   The result is formatted as major+minor(0) */
+	/*   One minor number is for control (lwpmu_c), */
+	SOCPERF_PRINT("SocPerf Driver loading...\n");
+	SOCPERF_PRINT("SocPerf Driver about to register chrdev...\n");
+
+	lwpmu_DevNum = MKDEV(0, 0);
+	status = alloc_chrdev_region(&lwpmu_DevNum, 0, PMU_DEVICES,
+				     SOCPERF_DRIVER_NAME);
+	SOCPERF_PRINT("SocPerf Driver: result of alloc_chrdev_region is %d\n",
+		      status);
+	if (status < 0) {
+		SOCPERF_PRINT_ERROR(
+			"SocPerf driver failed to alloc chrdev_region!\n");
+		return status;
+	}
+	SOCPERF_PRINT("SocPerf Driver: major number is %d\n",
+		      MAJOR(lwpmu_DevNum));
+	status = lwpmudrv_Initialize_State();
+	if (status < 0) {
+		SOCPERF_PRINT_ERROR(
+			"SocPerf driver failed to initialize state!\n");
+		return status;
+	}
+	num_cpus = GLOBAL_STATE_num_cpus(socperf_driver_state);
+	SOCPERF_PRINT("SocPerf Driver: detected %d CPUs in lwpmudrv_Load\n",
+		      num_cpus);
+
+	/* Allocate memory for the control structures */
+	socperf_control = SOCPERF_Allocate_Memory(sizeof(LWPMU_DEV_NODE));
+
+	if (!socperf_control) {
+		SOCPERF_Free_Memory(socperf_control);
+		return OS_NO_MEM;
+	}
+
+	/* Register the file operations with the OS */
+
+	SOCPERF_PRINT("SocPerf Driver: creating device %s...\n",
+		      SOCPERF_DRIVER_NAME DRV_DEVICE_DELIMITER "c");
+	pmu_class = class_create(THIS_MODULE, SOCPERF_DRIVER_NAME);
+	if (IS_ERR(pmu_class)) {
+		SOCPERF_PRINT_ERROR(
+			"Error registering SocPerf control class\n");
+	}
+	device_create(pmu_class, NULL, lwpmu_DevNum, NULL,
+		      SOCPERF_DRIVER_NAME DRV_DEVICE_DELIMITER "c");
+
+	status = lwpmu_setup_cdev(socperf_control, &socperf_Fops, lwpmu_DevNum);
+	if (status) {
+		SOCPERF_PRINT_ERROR("Error %d adding lwpmu as char device\n",
+				    status);
+		return status;
+	}
+
+	MUTEX_INIT(ioctl_lock);
+
+	/*
+	 *  Initialize the SocPerf driver version (done once at driver load time)
+	 */
+	SOCPERF_VERSION_NODE_major(&socperf_drv_version) =
+		SOCPERF_MAJOR_VERSION;
+	SOCPERF_VERSION_NODE_minor(&socperf_drv_version) =
+		SOCPERF_MINOR_VERSION;
+	SOCPERF_VERSION_NODE_api(&socperf_drv_version) = SOCPERF_API_VERSION;
+	//
+	// Display driver version information
+	//
+	SOCPERF_PRINT("SocPerf Driver v%d.%d.%d has been loaded.\n",
+		      SOCPERF_VERSION_NODE_major(&socperf_drv_version),
+		      SOCPERF_VERSION_NODE_minor(&socperf_drv_version),
+		      SOCPERF_VERSION_NODE_api(&socperf_drv_version));
+
+	return status;
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn  static int lwpmu_Unload(void)
+ *
+ * @param none
+ *
+ * @return none
+ *
+ * @brief  Remove the driver module from the kernel.
+ */
+static VOID socperf_Unload(VOID)
+{
+	SOCPERF_PRINT("SocPerf Driver unloading...\n");
+
+	socperf_pcb = SOCPERF_Free_Memory(socperf_pcb);
+	socperf_pcb_size = 0;
+
+	unregister_chrdev(MAJOR(lwpmu_DevNum), SOCPERF_DRIVER_NAME);
+	device_destroy(pmu_class, lwpmu_DevNum);
+	device_destroy(pmu_class, lwpmu_DevNum + 1);
+
+	cdev_del(&LWPMU_DEV_cdev(socperf_control));
+	unregister_chrdev_region(lwpmu_DevNum, PMU_DEVICES);
+
+	class_destroy(pmu_class);
+
+	socperf_control = SOCPERF_Free_Memory(socperf_control);
+
+	SOCPERF_Memory_Tracker_Free();
+
+	//
+	// Display driver version information
+	//
+	SOCPERF_PRINT("SocPerf Driver v%d.%d.%d has been unloaded.\n",
+		      SOCPERF_VERSION_NODE_major(&socperf_drv_version),
+		      SOCPERF_VERSION_NODE_minor(&socperf_drv_version),
+		      SOCPERF_VERSION_NODE_api(&socperf_drv_version));
+
+}
+
+/* Declaration of the init and exit functions */
+module_init(socperf_Load);
+module_exit(socperf_Unload);
diff --git a/drivers/platform/x86/socperf/utility.c b/drivers/platform/x86/socperf/utility.c
new file mode 100644
index 000000000000..4d5c783b5a7d
--- /dev/null
+++ b/drivers/platform/x86/socperf/utility.c
@@ -0,0 +1,170 @@
+/************************************************************************
+/* ***********************************************************************************************
+ *
+ * This file is provided under a dual BSD/GPLv2 license.  When using or
+ * redistributing this file, you may do so under either license.
+ *
+ * GPL LICENSE SUMMARY
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of version 2 of the GNU General Public License as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful, but
+ * WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ * General Public License for more details.
+ *
+ * BSD LICENSE
+ *
+ * Copyright(C) 2005-2019 Intel Corporation. All rights reserved.
+ *
+ * Redistribution and use in source and binary forms, with or without
+ * modification, are permitted provided that the following conditions
+ * are met:
+ *
+ *   * Redistributions of source code must retain the above copyright
+ *     notice, this list of conditions and the following disclaimer.
+ *   * Redistributions in binary form must reproduce the above copyright
+ *     notice, this list of conditions and the following disclaimer in
+ *     the documentation and/or other materials provided with the
+ *     distribution.
+ *   * Neither the name of Intel Corporation nor the names of its
+ *     contributors may be used to endorse or promote products derived
+ *     from this software without specific prior written permission.
+ *
+ * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS
+ * "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT
+ * LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR
+ * A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT
+ * OWNER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL,
+ * SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT
+ * LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
+ * DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY
+ * THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
+ * (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
+ * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
+ * ***********************************************************************************************
+ */
+
+
+#include "lwpmudrv_defines.h"
+#include <linux/version.h>
+#include <linux/fs.h>
+#include <asm/msr.h>
+#include <linux/ptrace.h>
+
+#include "lwpmudrv_types.h"
+#include "rise_errors.h"
+#include "lwpmudrv_ecb.h"
+#include "socperfdrv.h"
+#include "utility.h"
+#if defined(DRV_SOFIA)
+#include "noc_uncore.h"
+#elif defined(DRV_BUTTER)
+#include "axi_uncore.h"
+#else
+#include "soc_uncore.h"
+#include "haswellunc_sa.h"
+#include "npk_uncore.h"
+#endif
+
+volatile int config_done;
+
+VOID SOCPERF_UTILITY_Read_TSC(U64 *pTsc)
+{
+	*pTsc = rdtsc_ordered();
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID SOCPERF_UTILITY_Read_Cpuid
+ *
+ * @brief    executes the cpuid_function of cpuid and returns values
+ *
+ * @param  IN   cpuid_function
+ *         OUT  rax  - results of the cpuid instruction in the
+ *         OUT  rbx  - corresponding registers
+ *         OUT  rcx
+ *         OUT  rdx
+ *
+ * @return   none
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ *
+ */
+VOID SOCPERF_UTILITY_Read_Cpuid(U64 cpuid_function, U64 *rax_value,
+				       U64 *rbx_value, U64 *rcx_value,
+				       U64 *rdx_value)
+{
+	U32 function = (U32)cpuid_function;
+	U32 *eax = (U32 *)rax_value;
+	U32 *ebx = (U32 *)rbx_value;
+	U32 *ecx = (U32 *)rcx_value;
+	U32 *edx = (U32 *)rdx_value;
+
+	*eax = function;
+
+	__asm__("cpuid"
+		: "=a"(*eax), "=b"(*ebx), "=c"(*ecx), "=d"(*edx)
+		: "a"(function), "b"(*ebx), "c"(*ecx), "d"(*edx));
+}
+
+/* ------------------------------------------------------------------------- */
+/*!
+ * @fn       VOID SOCPERF_UTILITY_Configure_CPU
+ *
+ * @brief    Reads the CPU information from the hardware
+ *
+ * @param    param   dispatch_id -  The id of the dispatch table.
+ *
+ * @return   Pointer to the correct dispatch table for the CPU architecture
+ *
+ * <I>Special Notes:</I>
+ *              <NONE>
+ */
+DISPATCH SOCPERF_UTILITY_Configure_CPU(U32 dispatch_id)
+{
+	DISPATCH dispatch = NULL;
+
+	switch (dispatch_id) {
+#if defined(DRV_SOFIA)
+	case 1000:
+		SOCPERF_PRINT_DEBUG(
+			"Set up the SoC Uncore NOC dispatch table\n");
+		dispatch = &noc_dispatch;
+		break;
+#elif defined(DRV_BUTTER)
+	case 1100:
+		SOCPERF_PRINT_DEBUG(
+			"Set up the SoC Uncore AXI dispatch table\n");
+		dispatch = &axi_dispatch;
+		break;
+#else
+	case 230:
+		SOCPERF_PRINT_DEBUG("Set up the Haswell SA dispatch table\n");
+		dispatch = &socperf_hswunc_sa_dispatch;
+		break;
+	case 700:
+		SOCPERF_PRINT_DEBUG("Set up the SOC Uncore dispatch table\n");
+		dispatch = &soc_uncore_dispatch;
+		break;
+	case 701:
+		SOCPERF_PRINT_DEBUG(
+			"Set up the SoC Uncore NPK dispatch table\n");
+		dispatch = &npk_dispatch;
+		break;
+#endif
+	default:
+		dispatch = NULL;
+		SOCPERF_PRINT_ERROR(
+			"Architecture not supported (dispatch_id=%d)\n",
+			dispatch_id);
+		break;
+	}
+
+	return dispatch;
+}
-- 
2.17.1

