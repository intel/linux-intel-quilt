From fe82c3da31a167b1828dcbf74c62331c62e69787 Mon Sep 17 00:00:00 2001
From: Shuo A Liu <shuo.a.liu@intel.com>
Date: Thu, 7 May 2020 18:07:37 +0800
Subject: [PATCH 55/91] drm/i915/gvt: change active_hp_work position for code
 cleaning

In INTEL_CONTEXT_SCHEDULE_IN case, whatever enable_context_restore's
value, schedule_work(&gvt->active_hp_work) must be exectued. So we can
make this change for code clean.

Tracked-On: projectacrn/acrn-hypervisor#3918

Signed-off-by: Junming Liu <junming.liu@intel.com>
Reviewed-by: Zhao Yakui <yakui.zhao@intel.com>
---
 drivers/gpu/drm/i915/gvt/scheduler.c | 3 +--
 1 file changed, 1 insertion(+), 2 deletions(-)

diff --git a/drivers/gpu/drm/i915/gvt/scheduler.c b/drivers/gpu/drm/i915/gvt/scheduler.c
index 0dd1815ee772..c6906218cda7 100644
--- a/drivers/gpu/drm/i915/gvt/scheduler.c
+++ b/drivers/gpu/drm/i915/gvt/scheduler.c
@@ -314,8 +314,8 @@ static int shadow_context_status_change(struct notifier_block *nb,
 
 	switch (action) {
 	case INTEL_CONTEXT_SCHEDULE_IN:
+		schedule_work(&gvt->active_hp_work);
 		if (!i915_modparams.enable_context_restore) {
-			schedule_work(&gvt->active_hp_work);
 			atomic_set(&workload->shadow_ctx_active, 1);
 			break;
 		}
@@ -331,7 +331,6 @@ static int shadow_context_status_change(struct notifier_block *nb,
 				      ring_id, workload->vgpu->id);
 		spin_unlock_irqrestore(&scheduler->mmio_context_lock, flags);
 
-		schedule_work(&gvt->active_hp_work);
 		atomic_set(&workload->shadow_ctx_active, 1);
 		break;
 	case INTEL_CONTEXT_SCHEDULE_OUT:
-- 
2.17.1

