From 7355c18196d1f62034d436408448eb8fe591c1c9 Mon Sep 17 00:00:00 2001
From: Ong Boon Leong <boon.leong.ong@intel.com>
Date: Sat, 28 Sep 2019 14:41:15 +0800
Subject: [PATCH 102/108] net: stmmac: add support for XDP_REDIRECT

This makes the driver now support XDP_REDIRECT return bpf action.
Also, the ndo_xdp_xmit is implementation.

XDP_REDIRECT action allows XDP program to redirect frames to other
destination such as another netdev.

Signed-off-by: Ong Boon Leong <boon.leong.ong@intel.com>
Signed-off-by: Voon Weifeng <weifeng.voon@intel.com>
---
 drivers/net/ethernet/stmicro/stmmac/stmmac.h  |  1 +
 .../net/ethernet/stmicro/stmmac/stmmac_main.c | 72 +++++++++++++++++--
 2 files changed, 68 insertions(+), 5 deletions(-)

diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac.h b/drivers/net/ethernet/stmicro/stmmac/stmmac.h
index 5e17015cdd3c..b607ecb9da40 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac.h
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac.h
@@ -323,6 +323,7 @@ int stmmac_resume_main(struct stmmac_priv *priv, struct net_device *ndev);
 #define STMMAC_XDP_PASS		0
 #define STMMAC_XDP_CONSUMED	BIT(0)
 #define STMMAC_XDP_TX		BIT(1)
+#define STMMAC_XDP_REDIR	BIT(2)
 
 static inline bool stmmac_enabled_xdp(struct stmmac_priv *priv)
 {
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
index 5cf29817dc3d..492a49eed141 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
@@ -1633,6 +1633,7 @@ static void free_dma_tx_desc_resources(struct stmmac_priv *priv)
 
 static int alloc_dma_rx_desc_resources_q(struct stmmac_priv *priv, u32 queue)
 {
+	bool is_xdp = stmmac_enabled_xdp(priv);
 	struct stmmac_rx_queue *rx_q = &priv->rx_queue[queue];
 	struct page_pool_params pp_params = { 0 };
 	int ret = -ENOMEM;
@@ -1645,7 +1646,7 @@ static int alloc_dma_rx_desc_resources_q(struct stmmac_priv *priv, u32 queue)
 	pp_params.order = DIV_ROUND_UP(priv->dma_buf_sz, PAGE_SIZE);
 	pp_params.nid = dev_to_node(priv->device);
 	pp_params.dev = priv->device;
-	pp_params.dma_dir = DMA_FROM_DEVICE;
+	pp_params.dma_dir = is_xdp ? DMA_BIDIRECTIONAL : DMA_FROM_DEVICE;
 
 	rx_q->page_pool = page_pool_create(&pp_params);
 	if (IS_ERR(rx_q->page_pool)) {
@@ -4060,7 +4061,9 @@ static inline void stmmac_rx_refill(struct stmmac_priv *priv, u32 queue)
 	int len, dirty = stmmac_rx_dirty(priv, queue);
 	unsigned int entry = rx_q->dirty_rx;
 	unsigned int last_refill = entry;
+	enum dma_data_direction dma_dir;
 
+	dma_dir = page_pool_get_dma_dir(rx_q->page_pool);
 	len = DIV_ROUND_UP(priv->dma_buf_sz, PAGE_SIZE) * PAGE_SIZE;
 
 	while (dirty-- > 0) {
@@ -4096,7 +4099,7 @@ static inline void stmmac_rx_refill(struct stmmac_priv *priv, u32 queue)
 		 * data.
 		 */
 		dma_sync_single_for_device(priv->device, buf->addr, len,
-					   DMA_FROM_DEVICE);
+					   dma_dir);
 
 		stmmac_set_desc_addr(priv, p, buf->addr);
 		stmmac_set_desc_sec_addr(priv, p, buf->sec_addr);
@@ -4202,6 +4205,7 @@ static struct sk_buff *stmmac_run_xdp(struct stmmac_rx_queue *rx_q,
 	struct stmmac_tx_queue *xdp_q;
 	struct bpf_prog *xdp_prog;
 	u32 act;
+	int err;
 
 	rcu_read_lock();
 	xdp_prog = READ_ONCE(rx_q->xdp_prog);
@@ -4219,6 +4223,10 @@ static struct sk_buff *stmmac_run_xdp(struct stmmac_rx_queue *rx_q,
 		xdp_q = &priv->xdp_queue[rx_q->queue_index];
 		result = stmmac_xmit_xdp_tx_queue(xdp, xdp_q);
 		break;
+	case XDP_REDIRECT:
+		err = xdp_do_redirect(priv->dev, xdp, xdp_prog);
+		result = !err ? STMMAC_XDP_REDIR : STMMAC_XDP_CONSUMED;
+		break;
 	default:
 		bpf_warn_invalid_xdp_action(act);
 		/* fall through -- handle default by dropping packet */
@@ -4235,7 +4243,7 @@ static struct sk_buff *stmmac_run_xdp(struct stmmac_rx_queue *rx_q,
 }
 
 /**
- * stmmac_xdp_ring_update_tail - Updates the XDP Tx queue tail register
+ * stmmac_xdp_queue_update_tail - Updates the XDP Tx queue tail register
  * @xdp_q: XDP Tx queue
  *
  * This function updates the XDP Tx queue tail register.
@@ -4275,6 +4283,9 @@ void stmmac_finalize_xdp_rx(struct stmmac_rx_queue *rx_q, unsigned int xdp_res)
 {
 	struct stmmac_priv *priv = rx_q->priv_data;
 
+	if (xdp_res & STMMAC_XDP_REDIR)
+		xdp_do_flush_map();
+
 	if (xdp_res & STMMAC_XDP_TX) {
 		struct stmmac_tx_queue *xdp_q =
 			&priv->xdp_queue[rx_q->queue_index];
@@ -4298,10 +4309,12 @@ static int stmmac_rx(struct stmmac_priv *priv, int limit, u32 queue)
 	unsigned int count = 0, error = 0, len = 0;
 	int status = 0, coe = priv->hw->rx_csum;
 	unsigned int next_entry = rx_q->cur_rx;
+	enum dma_data_direction dma_dir;
 	struct sk_buff *skb = NULL;
 	unsigned int xdp_xmit = 0;
 	struct xdp_buff xdp;
 
+	dma_dir = page_pool_get_dma_dir(rx_q->page_pool);
 	xdp.rxq = &rx_q->xdp_rxq;
 
 	if (netif_msg_rx_status(priv)) {
@@ -4431,7 +4444,7 @@ static int stmmac_rx(struct stmmac_priv *priv, int limit, u32 queue)
 
 			prefetchw(buf->page);
 			dma_sync_single_for_cpu(priv->device, buf->addr,
-						len, DMA_FROM_DEVICE);
+						len, dma_dir);
 
 			xdp.data = page_address(buf->page);
 			xdp.data_meta = xdp.data;
@@ -4443,7 +4456,8 @@ static int stmmac_rx(struct stmmac_priv *priv, int limit, u32 queue)
 			if (IS_ERR(skb)) {
 				unsigned int xdp_res = -PTR_ERR(skb);
 
-				if (xdp_res & STMMAC_XDP_TX) {
+				if (xdp_res & (STMMAC_XDP_TX |
+					       STMMAC_XDP_REDIR)) {
 					/* XDP-TX, update tail pointer later */
 					xdp_xmit |= xdp_res;
 				} else {
@@ -5110,6 +5124,53 @@ static int stmmac_set_mac_address(struct net_device *ndev, void *addr)
 	return ret;
 }
 
+/**
+ * stmmac_xdp_xmit - Implements ndo_xdp_xmit
+ * @dev: netdev
+ * @xdp: XDP buffer
+ **/
+int stmmac_xdp_xmit(struct net_device *dev, int n, struct xdp_frame **frames,
+		    u32 flags)
+{
+	struct stmmac_priv *priv = netdev_priv(dev);
+	unsigned int queue_index = smp_processor_id();
+	struct stmmac_tx_queue *xdp_q;
+	int drops = 0;
+	int i;
+
+	queue_index %= priv->plat->num_queue_pairs;
+
+	if (test_bit(STMMAC_DOWN, &priv->state))
+		return -ENETDOWN;
+
+	if (!stmmac_enabled_xdp(priv))
+		return -ENXIO;
+
+	if (unlikely(flags & ~XDP_XMIT_FLAGS_MASK))
+		return -EINVAL;
+
+	if (!queue_is_xdp(priv, queue_index))
+		return -ENXIO;
+
+	xdp_q = &priv->xdp_queue[queue_index];
+
+	for (i = 0; i < n; i++) {
+		struct xdp_frame *xdpf = frames[i];
+		int err;
+
+		err = stmmac_xmit_xdp_queue(xdpf, xdp_q);
+		if (err != STMMAC_XDP_TX) {
+			xdp_return_frame_rx_napi(xdpf);
+			drops++;
+		}
+	}
+
+	if (unlikely(flags & XDP_XMIT_FLUSH))
+		stmmac_xdp_queue_update_tail(xdp_q);
+
+	return n - drops;
+}
+
 /**
  * stmmac_xdp_setup - add/remove an XDP program
  * @vsi: VSI to changed
@@ -5457,6 +5518,7 @@ static const struct net_device_ops stmmac_netdev_ops = {
 	.ndo_vlan_rx_add_vid = stmmac_vlan_rx_add_vid,
 	.ndo_vlan_rx_kill_vid = stmmac_vlan_rx_kill_vid,
 	.ndo_bpf = stmmac_xdp,
+	.ndo_xdp_xmit = stmmac_xdp_xmit,
 };
 
 static void stmmac_reset_subtask(struct stmmac_priv *priv)
-- 
2.17.1

