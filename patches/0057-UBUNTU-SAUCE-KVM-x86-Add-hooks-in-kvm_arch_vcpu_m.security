From b0fdaf63ae177a69985288cc2d596ab06add80a7 Mon Sep 17 00:00:00 2001
From: Isaku Yamahata <isaku.yamahata@intel.com>
Date: Thu, 12 Sep 2024 20:23:35 +0800
Subject: [PATCH 057/147] UBUNTU: SAUCE: KVM: x86: Add hooks in
 kvm_arch_vcpu_memory_mapping()

BugLink: https://bugs.launchpad.net/bugs/2085104

In the case of TDX, the memory contents needs to be provided to be
encrypted when populating guest memory before running the guest.  Add hooks
in kvm_mmu_map_tdp_page() for KVM_MEMORY_MAPPING before/after calling
kvm_mmu_tdp_page().  TDX KVM will implement the hooks.

Signed-off-by: Isaku Yamahata <isaku.yamahata@intel.com>
(cherry picked from github.com/intel/kernel-downstream commit 941678abd2c8f3264552e5b33fe978a07e8c879d)
Signed-off-by: Thibault Ferrante <thibault.ferrante@canonical.com>
---
 arch/x86/include/asm/kvm-x86-ops.h |  2 ++
 arch/x86/include/asm/kvm_host.h    |  5 +++++
 arch/x86/kvm/x86.c                 | 13 ++++++++++++-
 3 files changed, 19 insertions(+), 1 deletion(-)

diff --git a/arch/x86/include/asm/kvm-x86-ops.h b/arch/x86/include/asm/kvm-x86-ops.h
index 17f42862eeda..fd74c14953bd 100644
--- a/arch/x86/include/asm/kvm-x86-ops.h
+++ b/arch/x86/include/asm/kvm-x86-ops.h
@@ -151,6 +151,8 @@ KVM_X86_OP_OPTIONAL(alloc_apic_backing_page)
 KVM_X86_OP_OPTIONAL_RET0(gmem_prepare)
 KVM_X86_OP_OPTIONAL_RET0(private_max_mapping_level)
 KVM_X86_OP_OPTIONAL(gmem_invalidate)
+KVM_X86_OP_OPTIONAL(pre_memory_mapping);
+KVM_X86_OP_OPTIONAL(post_memory_mapping);
 
 #undef KVM_X86_OP
 #undef KVM_X86_OP_OPTIONAL
diff --git a/arch/x86/include/asm/kvm_host.h b/arch/x86/include/asm/kvm_host.h
index c313b1b5ec86..969ea9a1f974 100644
--- a/arch/x86/include/asm/kvm_host.h
+++ b/arch/x86/include/asm/kvm_host.h
@@ -1873,6 +1873,11 @@ struct kvm_x86_ops {
 	int (*gmem_prepare)(struct kvm *kvm, kvm_pfn_t pfn, gfn_t gfn, int max_order);
 	void (*gmem_invalidate)(kvm_pfn_t start, kvm_pfn_t end);
 	int (*private_max_mapping_level)(struct kvm *kvm, kvm_pfn_t pfn, gfn_t gfn, bool is_private, u8 *max_level);
+	int (*pre_memory_mapping)(struct kvm_vcpu *vcpu,
+				  struct kvm_memory_mapping *mapping,
+				  u64 *error_code, u8 *max_level);
+	void (*post_memory_mapping)(struct kvm_vcpu *vcpu,
+				    struct kvm_memory_mapping *mapping);
 };
 
 struct kvm_x86_nested_ops {
diff --git a/arch/x86/kvm/x86.c b/arch/x86/kvm/x86.c
index d51bca3bedd1..2065773c20af 100644
--- a/arch/x86/kvm/x86.c
+++ b/arch/x86/kvm/x86.c
@@ -5865,10 +5865,21 @@ int kvm_arch_vcpu_memory_mapping(struct kvm_vcpu *vcpu,
 	u8 max_level = KVM_MAX_HUGEPAGE_LEVEL;
 	u64 error_code = PFERR_WRITE_MASK;
 	u8 goal_level = PG_LEVEL_4K;
-	int r;
+	int r = 0;
+
+	if (kvm_x86_ops.pre_memory_mapping)
+		r = static_call(kvm_x86_pre_memory_mapping)(vcpu, mapping, &error_code, &max_level);
+	else {
+		if (mapping->source)
+			r = -EINVAL;
+	}
+	if (r)
+		return r;
 
 	r = kvm_mmu_map_tdp_page(vcpu, gfn_to_gpa(mapping->base_gfn), error_code,
 				 max_level, &goal_level);
+	if (kvm_x86_ops.post_memory_mapping)
+		static_call(kvm_x86_post_memory_mapping)(vcpu, mapping);
 	if (r)
 		return r;
 
-- 
2.34.1

