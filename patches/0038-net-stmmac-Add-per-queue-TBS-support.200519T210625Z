From bc8a9a82fe6adc4ce7ff68cb0ee9f072223847a6 Mon Sep 17 00:00:00 2001
From: "Song, Yoong Siang" <yoong.siang.song@intel.com>
Date: Thu, 30 Apr 2020 04:46:40 +0800
Subject: [PATCH 38/42] net: stmmac: Add per queue TBS support

Add per queue TBS support:
1. By default, half of the Tx Queues will have TBS support.
2. Driver will allocate enhanced descriptor for Tx Queues with
   TBS support.
3. Introduce dwmac5_enable_tbs() call back function to set EDSE
   for Tx Queues with TBS support.
4. Add "tbs" parameter in struct stmmac_tx_queue to check whether
   TBS support is available and enabled.

This patch is partially back-ported from following mainline patch:
  430b383c net: stmmac: tc: Add support for ETF Scheduler using TBS
  579a25a85 net: stmmac: Initial support for TBS

Signed-off-by: Song, Yoong Siang <yoong.siang.song@intel.com>
---
 .../net/ethernet/stmicro/stmmac/dwmac4_dma.c  | 21 ++++-
 drivers/net/ethernet/stmicro/stmmac/hwif.h    |  3 +
 drivers/net/ethernet/stmicro/stmmac/stmmac.h  |  5 +-
 .../net/ethernet/stmicro/stmmac/stmmac_main.c | 85 +++++++++++++------
 .../net/ethernet/stmicro/stmmac/stmmac_pci.c  |  7 ++
 .../net/ethernet/stmicro/stmmac/stmmac_tc.c   | 10 ++-
 .../net/ethernet/stmicro/stmmac/stmmac_xsk.c  |  7 +-
 include/linux/stmmac.h                        |  2 +-
 8 files changed, 104 insertions(+), 36 deletions(-)

diff --git a/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.c b/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.c
index a91aab8fcc26..5386e7f16337 100644
--- a/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.c
+++ b/drivers/net/ethernet/stmicro/stmmac/dwmac4_dma.c
@@ -543,7 +543,7 @@ static void dwmac5_dma_init_tx_chan(void __iomem *ioaddr,
 	u32 value;
 
 	value = readl(ioaddr + DMA_CHAN_TX_CONTROL(chan));
-	value = value | (txpbl << DMA_BUS_MODE_PBL_SHIFT) | DMA_CONTROL_EDSE;
+	value = value | (txpbl << DMA_BUS_MODE_PBL_SHIFT);
 
 	/* Enable OSP to get best performance */
 	value |= DMA_CONTROL_OSP;
@@ -558,6 +558,24 @@ static void dwmac5_dma_init_tx_chan(void __iomem *ioaddr,
 	writel(dma_tx_phy, ioaddr + DMA_CHAN_TX_BASE_ADDR(chan));
 }
 
+static int dwmac5_enable_tbs(void __iomem *ioaddr, bool en, u32 chan)
+{
+	u32 value = readl(ioaddr + DMA_CHAN_TX_CONTROL(chan));
+
+	if (en)
+		value |= DMA_CONTROL_EDSE;
+	else
+		value &= ~DMA_CONTROL_EDSE;
+
+	writel(value, ioaddr + DMA_CHAN_TX_CONTROL(chan));
+
+	value = readl(ioaddr + DMA_CHAN_TX_CONTROL(chan)) & DMA_CONTROL_EDSE;
+	if (en && !value)
+		return -EIO;
+
+	return 0;
+}
+
 const struct stmmac_dma_ops dwmac5_dma_ops = {
 	.reset = dwmac4_dma_reset,
 	.init = dwmac4_dma_init,
@@ -584,4 +602,5 @@ const struct stmmac_dma_ops dwmac5_dma_ops = {
 	.enable_tso = dwmac4_enable_tso,
 	.qmode = dwmac4_qmode,
 	.set_bfsize = dwmac4_set_bfsize,
+	.enable_tbs = dwmac5_enable_tbs,
 };
diff --git a/drivers/net/ethernet/stmicro/stmmac/hwif.h b/drivers/net/ethernet/stmicro/stmmac/hwif.h
index 818eff1fa22c..78f5b8d33ae1 100644
--- a/drivers/net/ethernet/stmicro/stmmac/hwif.h
+++ b/drivers/net/ethernet/stmicro/stmmac/hwif.h
@@ -216,6 +216,7 @@ struct stmmac_dma_ops {
 	void (*qmode)(void __iomem *ioaddr, u32 channel, u8 qmode);
 	void (*set_bfsize)(void __iomem *ioaddr, int bfsize, u32 chan);
 	void (*enable_sph)(void __iomem *ioaddr, bool en, u32 chan);
+	int (*enable_tbs)(void __iomem *ioaddr, bool en, u32 chan);
 };
 
 #define stmmac_reset(__priv, __args...) \
@@ -274,6 +275,8 @@ struct stmmac_dma_ops {
 	stmmac_do_void_callback(__priv, dma, set_bfsize, __args)
 #define stmmac_enable_sph(__priv, __args...) \
 	stmmac_do_void_callback(__priv, dma, enable_sph, __args)
+#define stmmac_enable_tbs(__priv, __args...) \
+	stmmac_do_callback(__priv, dma, enable_tbs, __args)
 
 struct mac_device_info;
 struct net_device;
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac.h b/drivers/net/ethernet/stmicro/stmmac/stmmac.h
index 6bd8f4320869..ee37aed6fc03 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac.h
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac.h
@@ -48,9 +48,13 @@ struct stmmac_tx_info {
 	bool is_jumbo;
 };
 
+#define STMMAC_TBS_AVAIL	BIT(0)
+#define STMMAC_TBS_EN		BIT(1)
+
 /* Frequently used values are kept adjacent for cache effect */
 struct stmmac_tx_queue {
 	u32 tx_count_frames;
+	int tbs;
 	struct timer_list txtimer;
 	u32 queue_index;
 	struct stmmac_priv *priv_data;
@@ -236,7 +240,6 @@ struct stmmac_priv {
 	int tx_lpi_enabled;
 	unsigned int mode;
 	unsigned int chain_mode;
-	int enhanced_tx_desc;
 	int extend_desc;
 	struct hwtstamp_config tstamp_config;
 	struct ptp_clock *ptp_clock;
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
index c9c8cd1da9bd..08cbc44232a8 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_main.c
@@ -1163,7 +1163,7 @@ static void stmmac_display_tx_rings(struct stmmac_priv *priv)
 
 		if (priv->extend_desc)
 			head_tx = (void *)tx_q->dma_etx;
-		else if (priv->enhanced_tx_desc)
+		else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			head_tx = (void *)tx_q->dma_enhtx;
 		else
 			head_tx = (void *)tx_q->dma_tx;
@@ -1243,9 +1243,9 @@ static void stmmac_clear_tx_descriptors(struct stmmac_priv *priv, u32 queue)
 			stmmac_init_tx_desc(priv, &tx_q->dma_etx[i].basic,
 					    priv->mode,
 					    (i == priv->dma_tx_size - 1));
-		else if (priv->enhanced_tx_desc)
+		else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			stmmac_init_tx_desc(priv, &tx_q->dma_enhtx[i].basic,
-					    priv->mode,
+					    STMMAC_ENHANCED_TX_MODE,
 					    (i == priv->dma_tx_size - 1));
 		else
 			stmmac_init_tx_desc(priv, &tx_q->dma_tx[i],
@@ -1573,7 +1573,7 @@ static void init_dma_tx_desc_ring(struct stmmac_priv *priv, u32 queue)
 			stmmac_mode_init(priv, tx_q->dma_etx,
 					 tx_q->dma_tx_phy,
 					 priv->dma_tx_size, 1);
-		else if (priv->enhanced_tx_desc)
+		else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			stmmac_mode_init(priv, tx_q->dma_enhtx,
 					 tx_q->dma_tx_phy,
 					 priv->dma_tx_size, 1);
@@ -1588,7 +1588,7 @@ static void init_dma_tx_desc_ring(struct stmmac_priv *priv, u32 queue)
 
 		if (priv->extend_desc)
 			p = &((tx_q->dma_etx + i)->basic);
-		else if (priv->enhanced_tx_desc)
+		else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			p = &((tx_q->dma_enhtx + i)->basic);
 		else
 			p = tx_q->dma_tx + i;
@@ -1751,7 +1751,7 @@ static void free_dma_tx_desc_resources_q(struct stmmac_priv *priv, u32 queue)
 		dma_free_coherent(priv->device, priv->dma_tx_size *
 					sizeof(struct dma_extended_desc),
 					tx_q->dma_etx, tx_q->dma_tx_phy);
-	else if (priv->enhanced_tx_desc)
+	else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 		dma_free_coherent(priv->device, priv->dma_tx_size *
 					sizeof(struct dma_enhanced_tx_desc),
 					tx_q->dma_enhtx, tx_q->dma_tx_phy);
@@ -1915,7 +1915,7 @@ static int alloc_dma_tx_desc_resources_q(struct stmmac_priv *priv, u32 queue)
 						   GFP_KERNEL);
 		if (!tx_q->dma_etx)
 			goto err_dma;
-	} else if (priv->enhanced_tx_desc) {
+	} else if (tx_q->tbs & STMMAC_TBS_AVAIL) {
 		tx_q->dma_enhtx = dma_alloc_coherent(priv->device,
 						     priv->dma_tx_size *
 						     sizeof(struct
@@ -2225,7 +2225,7 @@ static int stmmac_tx_clean(struct stmmac_priv *priv, int budget, u32 queue)
 
 		if (priv->extend_desc)
 			p = (struct dma_desc *)(tx_q->dma_etx + entry);
-		else if (priv->enhanced_tx_desc)
+		else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			p = &(tx_q->dma_enhtx + entry)->basic;
 		else
 			p = tx_q->dma_tx + entry;
@@ -2327,7 +2327,11 @@ static int stmmac_tx_clean(struct stmmac_priv *priv, int budget, u32 queue)
 			tx_q->xdpf[entry] = NULL;
 		}
 
-		stmmac_release_tx_desc(priv, p, priv->mode);
+		if (tx_q->tbs & STMMAC_TBS_AVAIL)
+			stmmac_release_tx_desc(priv, p,
+					       STMMAC_ENHANCED_TX_MODE);
+		else
+			stmmac_release_tx_desc(priv, p, priv->mode);
 
 		entry = STMMAC_GET_ENTRY(entry, priv->dma_tx_size);
 	}
@@ -3060,6 +3064,14 @@ static int stmmac_hw_setup(struct net_device *dev, bool init_ptp,
 	if (!lock_acquired)
 		rtnl_unlock();
 
+	/* TBS */
+	for (chan = 0; chan < tx_cnt; chan++) {
+		struct stmmac_tx_queue *tx_q = &priv->tx_queue[chan];
+		int enable = tx_q->tbs & STMMAC_TBS_AVAIL;
+
+		stmmac_enable_tbs(priv, priv->ioaddr, enable, chan);
+	}
+
 	/* Start the ball rolling... */
 	stmmac_start_all_dma(priv);
 	stmmac_start_mac_tx(priv, priv->ioaddr);
@@ -3445,6 +3457,20 @@ static int stmmac_open(struct net_device *dev)
 
 	priv->rx_copybreak = STMMAC_RX_COPYBREAK;
 
+	/* Earlier check for TBS */
+	for (chan = 0; chan < priv->plat->tx_queues_to_use; chan++) {
+		struct stmmac_tx_queue *tx_q = &priv->tx_queue[chan];
+		int tbs_en = priv->plat->tx_queues_cfg[chan].tbs_en;
+
+		tx_q->tbs |= tbs_en ? STMMAC_TBS_AVAIL : 0;
+		if (stmmac_enable_tbs(priv, priv->ioaddr, tbs_en, chan)) {
+			tx_q->tbs &= ~STMMAC_TBS_AVAIL;
+			netdev_err(priv->dev,
+				   "%s: TxQ %d TBS enablement failed\n",
+				   __func__, chan);
+		}
+	}
+
 	if (!priv->dma_rx_size)
 		priv->dma_rx_size = DMA_DEFAULT_RX_SIZE;
 	if (!priv->dma_tx_size)
@@ -3619,7 +3645,7 @@ static bool stmmac_vlan_insert(struct stmmac_priv *priv, struct sk_buff *skb,
 
 	tag = skb_vlan_tag_get(skb);
 
-	if (priv->enhanced_tx_desc)
+	if (tx_q->tbs & STMMAC_TBS_AVAIL)
 		p = &tx_q->dma_enhtx[tx_q->cur_tx].basic;
 	else
 		p = tx_q->dma_tx + tx_q->cur_tx;
@@ -3660,7 +3686,7 @@ static void stmmac_tso_allocator(struct stmmac_priv *priv, dma_addr_t des,
 						priv->dma_tx_size);
 		WARN_ON(tx_q->tx_skbuff[tx_q->cur_tx]);
 		/* TSO is not available in DWMAC v3.5  */
-		if (priv->enhanced_tx_desc)
+		if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			desc = &(tx_q->dma_enhtx + tx_q->cur_tx)->basic;
 		else
 			desc = tx_q->dma_tx + tx_q->cur_tx;
@@ -3751,7 +3777,7 @@ static netdev_tx_t stmmac_tso_xmit(struct sk_buff *skb, struct net_device *dev)
 	/* set new MSS value if needed */
 	if (mss != tx_q->mss) {
 		/* TSO is not available in DWMAC v3.5  */
-		if (priv->enhanced_tx_desc)
+		if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			mss_desc = &(tx_q->dma_enhtx + tx_q->cur_tx)->basic;
 		else
 			mss_desc = tx_q->dma_tx + tx_q->cur_tx;
@@ -3775,7 +3801,7 @@ static netdev_tx_t stmmac_tso_xmit(struct sk_buff *skb, struct net_device *dev)
 	first_entry = tx_q->cur_tx;
 	WARN_ON(tx_q->tx_skbuff[first_entry]);
 	/* TSO is not available in DWMAC v3.5  */
-	if (priv->enhanced_tx_desc)
+	if (tx_q->tbs & STMMAC_TBS_AVAIL)
 		desc = &(tx_q->dma_enhtx + first_entry)->basic;
 	else
 		desc = tx_q->dma_tx + first_entry;
@@ -3842,7 +3868,7 @@ static netdev_tx_t stmmac_tso_xmit(struct sk_buff *skb, struct net_device *dev)
 	      priv->hwts_tx_en)) {
 		stmmac_tx_timer_arm(priv, queue);
 	} else {
-		if (priv->enhanced_tx_desc)
+		if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			desc = &(tx_q->dma_enhtx + tx_q->cur_tx)->basic;
 		else
 			desc = tx_q->dma_tx + tx_q->cur_tx;
@@ -3913,7 +3939,7 @@ static netdev_tx_t stmmac_tso_xmit(struct sk_buff *skb, struct net_device *dev)
 				    priv->dma_tx_size, 0);
 
 		/* TSO is not available in DWMAC v3.5  */
-		if (priv->enhanced_tx_desc)
+		if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			stmmac_display_ring(priv, (void *)tx_q->dma_enhtx,
 					    priv->dma_tx_size, 0);
 		else
@@ -3926,7 +3952,7 @@ static netdev_tx_t stmmac_tso_xmit(struct sk_buff *skb, struct net_device *dev)
 	netdev_tx_sent_queue(netdev_get_tx_queue(dev, queue), skb->len);
 
 	/* TSO is not available in DWMAC v3.5  */
-	if (priv->enhanced_tx_desc)
+	if (tx_q->tbs & STMMAC_TBS_AVAIL)
 		tx_q->tx_tail_addr = tx_q->dma_tx_phy +
 					(tx_q->cur_tx *
 					sizeof(struct dma_enhanced_tx_desc));
@@ -4004,7 +4030,7 @@ static netdev_tx_t stmmac_xmit(struct sk_buff *skb, struct net_device *dev)
 
 	if (likely(priv->extend_desc))
 		desc = (struct dma_desc *)(tx_q->dma_etx + entry);
-	else if (priv->enhanced_tx_desc)
+	else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 		desc = &tx_q->dma_enhtx[entry].basic;
 	else
 		desc = tx_q->dma_tx + entry;
@@ -4019,8 +4045,7 @@ static netdev_tx_t stmmac_xmit(struct sk_buff *skb, struct net_device *dev)
 	 * Drop the skb and show warning when launch time value
 	 * is invalid.
 	 */
-	if (priv->plat->tx_queues_cfg[queue].tbs_en && skb->tstamp &&
-	    priv->enhanced_tx_desc) {
+	if (skb->tstamp && (tx_q->tbs & STMMAC_TBS_EN)) {
 		if (stmmac_set_tbs_launchtime(priv, first,
 					      ktime_to_ns(skb->tstamp))) {
 			netdev_warn(priv->dev, "Launch time setting failed\n");
@@ -4049,7 +4074,7 @@ static netdev_tx_t stmmac_xmit(struct sk_buff *skb, struct net_device *dev)
 
 		if (likely(priv->extend_desc))
 			desc = (struct dma_desc *)(tx_q->dma_etx + entry);
-		else if (priv->enhanced_tx_desc)
+		else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			desc = &tx_q->dma_enhtx[entry].basic;
 		else
 			desc = tx_q->dma_tx + entry;
@@ -4088,7 +4113,7 @@ static netdev_tx_t stmmac_xmit(struct sk_buff *skb, struct net_device *dev)
 	} else {
 		if (likely(priv->extend_desc))
 			desc = &tx_q->dma_etx[entry].basic;
-		else if (priv->enhanced_tx_desc)
+		else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			desc = &tx_q->dma_enhtx[entry].basic;
 		else
 			desc = &tx_q->dma_tx[entry];
@@ -4116,7 +4141,7 @@ static netdev_tx_t stmmac_xmit(struct sk_buff *skb, struct net_device *dev)
 
 		if (priv->extend_desc)
 			tx_head = (void *)tx_q->dma_etx;
-		else if (priv->enhanced_tx_desc)
+		else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 			tx_head = (void *)tx_q->dma_enhtx;
 		else
 			tx_head = (void *)tx_q->dma_tx;
@@ -4188,7 +4213,7 @@ static netdev_tx_t stmmac_xmit(struct sk_buff *skb, struct net_device *dev)
 		tx_q->tx_tail_addr = tx_q->dma_tx_phy +
 					(tx_q->cur_tx *
 					sizeof(struct dma_extended_desc));
-	else if (priv->enhanced_tx_desc)
+	else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 		tx_q->tx_tail_addr = tx_q->dma_tx_phy +
 					(tx_q->cur_tx *
 					sizeof(struct dma_enhanced_tx_desc));
@@ -4352,7 +4377,7 @@ static int stmmac_xmit_xdp_queue(struct xdp_frame *xdpf,
 
 	if (likely(priv->extend_desc))
 		desc = (struct dma_desc *)(xdp_q->dma_etx + entry);
-	else if (priv->enhanced_tx_desc)
+	else if (priv->tx_queue[xdp_q->queue_index].tbs & STMMAC_TBS_AVAIL)
 		desc = &xdp_q->dma_enhtx[entry].basic;
 	else
 		desc = xdp_q->dma_tx + entry;
@@ -4454,7 +4479,7 @@ void stmmac_xdp_queue_update_tail(struct stmmac_tx_queue *xdp_q)
 		xdp_q->tx_tail_addr = xdp_q->dma_tx_phy +
 					(xdp_q->cur_tx *
 					sizeof(struct dma_extended_desc));
-	else if (priv->enhanced_tx_desc)
+	else if (priv->tx_queue[xdp_q->queue_index].tbs & STMMAC_TBS_AVAIL)
 		xdp_q->tx_tail_addr = xdp_q->dma_tx_phy +
 					(xdp_q->cur_tx *
 					sizeof(struct dma_enhanced_tx_desc));
@@ -5535,6 +5560,9 @@ static void stmmac_txrx_ch_init(struct stmmac_priv *priv, u16 qid)
 	stmmac_init_tx_chan(priv, priv->ioaddr, priv->plat->dma_cfg,
 			    tx_q->dma_tx_phy, tx_q->queue_index);
 
+	if (tx_q->tbs & STMMAC_TBS_AVAIL)
+		stmmac_enable_tbs(priv, priv->ioaddr, 1, tx_q->queue_index);
+
 	tx_q->tx_tail_addr = tx_q->dma_tx_phy;
 	stmmac_set_tx_tail_ptr(priv, priv->ioaddr,
 			       tx_q->tx_tail_addr, tx_q->queue_index);
@@ -5542,6 +5570,9 @@ static void stmmac_txrx_ch_init(struct stmmac_priv *priv, u16 qid)
 	stmmac_init_tx_chan(priv, priv->ioaddr, priv->plat->dma_cfg,
 			    xdp_q->dma_tx_phy, xdp_q->queue_index);
 
+	if (priv->tx_queue[xdp_q->queue_index].tbs & STMMAC_TBS_AVAIL)
+		stmmac_enable_tbs(priv, priv->ioaddr, 1, xdp_q->queue_index);
+
 	xdp_q->tx_tail_addr = xdp_q->dma_tx_phy;
 	stmmac_set_tx_tail_ptr(priv, priv->ioaddr,
 			       xdp_q->tx_tail_addr,
@@ -5815,7 +5846,7 @@ static int stmmac_rings_status_show(struct seq_file *seq, void *v)
 			seq_printf(seq, "Extended descriptor ring:\n");
 			sysfs_display_ring((void *)tx_q->dma_etx,
 					   priv->dma_tx_size, 1, seq);
-		} else if (priv->enhanced_tx_desc) {
+		} else if (tx_q->tbs & STMMAC_TBS_AVAIL) {
 			seq_printf(seq, "Enhanced descriptor ring:\n");
 			sysfs_display_ring((void *)tx_q->dma_enhtx,
 					   priv->dma_tx_size, 2, seq);
@@ -6468,8 +6499,6 @@ int stmmac_dvr_probe(struct device *device,
 	if (priv->hw->tsn_info.cap.tbs_support && priv->plat->tsn_tbs_en) {
 		stmmac_set_tsn_feat(priv, priv->hw, ndev, TSN_FEAT_ID_TBS,
 				    true);
-		priv->enhanced_tx_desc = 1;
-		priv->mode = STMMAC_ENHANCED_TX_MODE;
 		dev_info(priv->device, "TBS feature enabled\n");
 	}
 
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_pci.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_pci.c
index 820088f84f5c..ec5d867d435e 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_pci.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_pci.c
@@ -230,6 +230,13 @@ static int intel_mgbe_common_data(struct pci_dev *pdev,
 
 		/* Disable Priority config by default */
 		plat->tx_queues_cfg[i].use_prio = false;
+
+		/* Enable per queue TBS support on half of the Tx Queues.
+		 * For examples, if tx_queue_to_use = 8, then Tx Queue 4, 5, 6,
+		 * and 7 will have TBS support.
+		 */
+		if (plat->tsn_tbs_en && i >= (plat->tx_queues_to_use / 2))
+			plat->tx_queues_cfg[i].tbs_en = 1;
 	}
 
 	/* FIFO size is 4096 bytes for 1 tx/rx queue */
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
index f74261b66071..c2941d2b9dba 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_tc.c
@@ -809,7 +809,7 @@ static int tc_setup_taprio(struct stmmac_priv *priv,
 static int tc_setup_etf(struct stmmac_priv *priv,
 			struct tc_etf_qopt_offload *qopt)
 {
-	if (!priv->enhanced_tx_desc)
+	if (!(priv->tx_queue[qopt->queue].tbs & STMMAC_TBS_AVAIL))
 		return -EOPNOTSUPP;
 
 	if (priv->speed == SPEED_10)
@@ -821,7 +821,13 @@ static int tc_setup_etf(struct stmmac_priv *priv,
 		return -EOPNOTSUPP;
 	}
 
-	priv->plat->tx_queues_cfg[qopt->queue].tbs_en = qopt->enable;
+	if (qopt->enable)
+		priv->tx_queue[qopt->queue].tbs |= STMMAC_TBS_EN;
+	else
+		priv->tx_queue[qopt->queue].tbs &= ~STMMAC_TBS_EN;
+
+	netdev_info(priv->dev, "%s ETF for Queue %d\n",
+		    qopt->enable ? "enabled" : "disabled", qopt->queue);
 
 	return 0;
 }
diff --git a/drivers/net/ethernet/stmicro/stmmac/stmmac_xsk.c b/drivers/net/ethernet/stmicro/stmmac/stmmac_xsk.c
index 41d4293fa9f6..5098397d6d1b 100644
--- a/drivers/net/ethernet/stmicro/stmmac/stmmac_xsk.c
+++ b/drivers/net/ethernet/stmicro/stmmac/stmmac_xsk.c
@@ -748,7 +748,8 @@ static bool stmmac_xmit_zc(struct stmmac_tx_queue *xdp_q, unsigned int budget)
 
 		if (likely(priv->extend_desc))
 			tx_desc = (struct dma_desc *)(xdp_q->dma_etx + entry);
-		else if (priv->enhanced_tx_desc)
+		else if (priv->tx_queue[xdp_q->queue_index].tbs &
+			 STMMAC_TBS_AVAIL)
 			tx_desc = &xdp_q->dma_enhtx[entry].basic;
 		else
 			tx_desc = xdp_q->dma_tx + entry;
@@ -762,7 +763,7 @@ static bool stmmac_xmit_zc(struct stmmac_tx_queue *xdp_q, unsigned int budget)
 		stmmac_set_desc_addr(priv, tx_desc, dma);
 
 		if (stmmac_enabled_xdp(priv) &&
-		    priv->plat->tx_queues_cfg[xdp_q->queue_index].tbs_en &&
+		    (priv->tx_queue[xdp_q->queue_index].tbs & STMMAC_TBS_EN) &&
 		    desc.txtime > 0) {
 			if (stmmac_set_tbs_launchtime(priv, tx_desc,
 						      desc.txtime)) {
@@ -815,7 +816,7 @@ static void stmmac_xdp_read_tx_status(struct stmmac_priv *priv, u32 queue,
 
 	if (priv->extend_desc)
 		p = (struct dma_desc *)(tx_q->dma_etx + entry);
-	else if (priv->enhanced_tx_desc)
+	else if (tx_q->tbs & STMMAC_TBS_AVAIL)
 		p = &(tx_q->dma_enhtx + entry)->basic;
 	else
 		p = tx_q->dma_tx + entry;
diff --git a/include/linux/stmmac.h b/include/linux/stmmac.h
index edd09638f966..c36ab84b39c5 100644
--- a/include/linux/stmmac.h
+++ b/include/linux/stmmac.h
@@ -127,7 +127,7 @@ struct stmmac_txq_cfg {
 	u32 low_credit;
 	bool use_prio;
 	u32 prio;
-	bool tbs_en;
+	int tbs_en;
 };
 
 struct plat_stmmacenet_data {
-- 
2.17.1

