From 82f9774800f18441a9770163c804c2b32a22d8eb Mon Sep 17 00:00:00 2001
From: "Li, Fei1" <fei1.li@intel.com>
Date: Fri, 31 Aug 2018 10:59:02 +0800
Subject: [PATCH 063/144] sos: vhm: remove set guest memory map by CMA

We removed CMA Device Manager memory allocation mechanisms and use
hugetlb as the only Device Manager memory allocation mechanism.
So there is no needs to support set guest vm memory by CMA any more.

Signed-off-by: Li, Fei1 <fei1.li@intel.com>
Acked-by: Anthony Xu <anthony.xu@intel.com>
---
 drivers/char/vhm/vhm_dev.c         |  14 --
 drivers/vhm/vhm_mm.c               | 252 ++---------------------------
 include/linux/vhm/acrn_vhm_mm.h    |  13 --
 include/linux/vhm/vhm_ioctl_defs.h |   1 +
 include/linux/vhm/vhm_vm_mngt.h    |   4 -
 5 files changed, 15 insertions(+), 269 deletions(-)

diff --git a/drivers/char/vhm/vhm_dev.c b/drivers/char/vhm/vhm_dev.c
index 4019b4e6e913..ef9ac913912d 100644
--- a/drivers/char/vhm/vhm_dev.c
+++ b/drivers/char/vhm/vhm_dev.c
@@ -110,9 +110,6 @@ static int vhm_dev_open(struct inode *inodep, struct file *filep)
 	vm->vmid = ACRN_INVALID_VMID;
 	vm->dev = vhm_device;
 
-	INIT_LIST_HEAD(&vm->memseg_list);
-	mutex_init(&vm->seg_lock);
-
 	for (i = 0; i < HUGEPAGE_HLIST_ARRAY_SIZE; i++)
 		INIT_HLIST_HEAD(&vm->hugepage_hlist[i]);
 	mutex_init(&vm->hugepage_lock);
@@ -269,16 +266,6 @@ static long vhm_dev_ioctl(struct file *filep,
 		return ret;
 	}
 
-	case IC_ALLOC_MEMSEG: {
-		struct vm_memseg memseg;
-
-		if (copy_from_user(&memseg, (void *)ioctl_param,
-			sizeof(struct vm_memseg)))
-			return -EFAULT;
-
-		return alloc_guest_memseg(vm, &memseg);
-	}
-
 	case IC_SET_MEMSEG: {
 		struct vm_memmap memmap;
 
@@ -560,7 +547,6 @@ static const struct file_operations fops = {
 	.open = vhm_dev_open,
 	.read = vhm_dev_read,
 	.write = vhm_dev_write,
-	.mmap = vhm_dev_mmap,
 	.release = vhm_dev_release,
 	.unlocked_ioctl = vhm_dev_ioctl,
 	.poll = vhm_dev_poll,
diff --git a/drivers/vhm/vhm_mm.c b/drivers/vhm/vhm_mm.c
index bff448208836..3c0c2acbe522 100644
--- a/drivers/vhm/vhm_mm.c
+++ b/drivers/vhm/vhm_mm.c
@@ -76,14 +76,6 @@
 #include <linux/vhm/vhm_vm_mngt.h>
 #include <linux/vhm/vhm_hypercall.h>
 
-struct guest_memseg {
-	struct list_head list;
-	u64 vm0_gpa;
-	size_t len;
-	u64 gpa;
-	long vma_count;
-};
-
 static u64 _alloc_memblk(struct device *dev, size_t len)
 {
 	unsigned int count;
@@ -110,52 +102,6 @@ static bool _free_memblk(struct device *dev, u64 vm0_gpa, size_t len)
 	return dma_release_from_contiguous(dev, page, count);
 }
 
-static int add_guest_memseg(struct vhm_vm *vm, unsigned long vm0_gpa,
-	unsigned long guest_gpa, unsigned long len)
-{
-	struct guest_memseg *seg;
-	int max_gfn;
-
-	seg = kzalloc(sizeof(struct guest_memseg), GFP_KERNEL);
-	if (seg == NULL)
-		return -ENOMEM;
-
-	seg->vm0_gpa = vm0_gpa;
-	seg->gpa = guest_gpa;
-	seg->len = len;
-
-	max_gfn = (seg->gpa + seg->len) >> PAGE_SHIFT;
-	if (vm->max_gfn < max_gfn)
-		vm->max_gfn = max_gfn;
-
-	pr_info("VHM: add memseg with len=0x%lx, vm0_gpa=0x%llx,"
-		" and its guest gpa = 0x%llx, vm max_gfn 0x%x\n",
-		seg->len, seg->vm0_gpa, seg->gpa, vm->max_gfn);
-
-	seg->vma_count = 0;
-	mutex_lock(&vm->seg_lock);
-	list_add(&seg->list, &vm->memseg_list);
-	mutex_unlock(&vm->seg_lock);
-
-	return 0;
-}
-
-int alloc_guest_memseg(struct vhm_vm *vm, struct vm_memseg *memseg)
-{
-	unsigned long vm0_gpa;
-	int ret;
-
-	vm0_gpa = _alloc_memblk(vm->dev, memseg->len);
-	if (vm0_gpa == 0ULL)
-		return -ENOMEM;
-
-	ret = add_guest_memseg(vm, vm0_gpa, memseg->gpa, memseg->len);
-	if (ret < 0)
-		_free_memblk(vm->dev, vm0_gpa, memseg->len);
-
-	return ret;
-}
-
 int _mem_set_memmap(unsigned long vmid, unsigned long guest_gpa,
 	unsigned long host_gpa, unsigned long len,
 	unsigned int mem_type, unsigned int mem_access_right,
@@ -223,7 +169,6 @@ int update_memmap_attr(unsigned long vmid, unsigned long guest_gpa,
 
 int map_guest_memseg(struct vhm_vm *vm, struct vm_memmap *memmap)
 {
-	struct guest_memseg *seg = NULL;
 	unsigned int type;
 	unsigned int mem_type, mem_access_right;
 	unsigned long guest_gpa, host_gpa;
@@ -232,77 +177,31 @@ int map_guest_memseg(struct vhm_vm *vm, struct vm_memmap *memmap)
 	if (memmap->type == VM_MEMMAP_SYSMEM && memmap->using_vma)
 		return hugepage_map_guest(vm, memmap);
 
-	mutex_lock(&vm->seg_lock);
-
-	/* cma or mmio */
-	if (memmap->type == VM_MEMMAP_SYSMEM) {
-		list_for_each_entry(seg, &vm->memseg_list, list) {
-			if (seg->gpa == memmap->gpa
-				&& seg->len == memmap->len)
-				break;
-		}
-		if (&seg->list == &vm->memseg_list) {
-			mutex_unlock(&vm->seg_lock);
-			return -EINVAL;
-		}
-		guest_gpa = seg->gpa;
-		host_gpa = seg->vm0_gpa;
-		mem_type = MEM_TYPE_WB;
-		mem_access_right = (memmap->prot & MEM_ACCESS_RIGHT_MASK);
-		type = MAP_MEM;
-	} else {
-		guest_gpa = memmap->gpa;
-		host_gpa = acrn_hpa2gpa(memmap->hpa);
-		mem_type = MEM_TYPE_UC;
-		mem_access_right = (memmap->prot & MEM_ACCESS_RIGHT_MASK);
-		type = MAP_MMIO;
+	/* mmio */
+	if (memmap->type != VM_MEMMAP_MMIO) {
+		pr_err("vhm: %s invalid memmap type: %d\n",
+			__func__, memmap->type);
+		return -EINVAL;
 	}
+	guest_gpa = memmap->gpa;
+	host_gpa = acrn_hpa2gpa(memmap->hpa);
+	mem_type = MEM_TYPE_UC;
+	mem_access_right = (memmap->prot & MEM_ACCESS_RIGHT_MASK);
+	type = MAP_MMIO;
 
 	if (_mem_set_memmap(vm->vmid, guest_gpa, host_gpa, memmap->len,
 		mem_type, mem_access_right, type) < 0) {
 		pr_err("vhm: failed to set memmap %ld!\n", vm->vmid);
-		mutex_unlock(&vm->seg_lock);
 		return -EFAULT;
 	}
 
-	mutex_unlock(&vm->seg_lock);
-
 	return 0;
 }
 
 void free_guest_mem(struct vhm_vm *vm)
 {
-	struct guest_memseg *seg;
-
 	if (vm->hugetlb_enabled)
 		return hugepage_free_guest(vm);
-
-	mutex_lock(&vm->seg_lock);
-	while (!list_empty(&vm->memseg_list)) {
-		seg = list_first_entry(&vm->memseg_list,
-				struct guest_memseg, list);
-		if (!_free_memblk(vm->dev, seg->vm0_gpa, seg->len))
-			pr_warn("failed to free memblk\n");
-		list_del(&seg->list);
-		kfree(seg);
-	}
-	mutex_unlock(&vm->seg_lock);
-}
-
-int check_guest_mem(struct vhm_vm *vm)
-{
-	struct guest_memseg *seg;
-
-	mutex_lock(&vm->seg_lock);
-	list_for_each_entry(seg, &vm->memseg_list, list) {
-		if (seg->vma_count == 0)
-			continue;
-
-		mutex_unlock(&vm->seg_lock);
-		return -EAGAIN;
-	}
-	mutex_unlock(&vm->seg_lock);
-	return 0;
 }
 
 #define TRUSTY_MEM_GPA_BASE (511UL * 1024UL * 1024UL * 1024UL)
@@ -330,121 +229,17 @@ void deinit_trusty(struct vhm_vm *vm)
 	vm->trusty_host_gpa = 0;
 }
 
-static void guest_vm_open(struct vm_area_struct *vma)
-{
-	struct vhm_vm *vm = vma->vm_file->private_data;
-	struct guest_memseg *seg = vma->vm_private_data;
-
-	mutex_lock(&vm->seg_lock);
-	seg->vma_count++;
-	mutex_unlock(&vm->seg_lock);
-}
-
-static void guest_vm_close(struct vm_area_struct *vma)
-{
-	struct vhm_vm *vm = vma->vm_file->private_data;
-	struct guest_memseg *seg = vma->vm_private_data;
-
-	mutex_lock(&vm->seg_lock);
-	seg->vma_count--;
-	BUG_ON(seg->vma_count < 0);
-	mutex_unlock(&vm->seg_lock);
-}
-
-static const struct vm_operations_struct guest_vm_ops = {
-	.open = guest_vm_open,
-	.close = guest_vm_close,
-};
-
-static int do_mmap_guest(struct file *file,
-		struct vm_area_struct *vma, struct guest_memseg *seg)
-{
-	struct page *page;
-	size_t size = seg->len;
-	unsigned long pfn;
-	unsigned long start_addr;
-
-	vma->vm_flags |= VM_MIXEDMAP | VM_DONTEXPAND | VM_DONTCOPY;
-	pfn = seg->vm0_gpa >> PAGE_SHIFT;
-	start_addr = vma->vm_start;
-	while (size > 0) {
-		page = pfn_to_page(pfn);
-		if (vm_insert_page(vma, start_addr, page))
-			return -EINVAL;
-		size -= PAGE_SIZE;
-		start_addr += PAGE_SIZE;
-		pfn++;
-	}
-	seg->vma_count++;
-	vma->vm_ops = &guest_vm_ops;
-	vma->vm_private_data = (void *)seg;
-
-	pr_info("VHM: mmap for memseg [seg vm0_gpa=0x%llx, gpa=0x%llx] "
-		"to start addr 0x%lx\n",
-		seg->vm0_gpa, seg->gpa, start_addr);
-
-	return 0;
-}
-
-int vhm_dev_mmap(struct file *file, struct vm_area_struct *vma)
-{
-	struct vhm_vm *vm = file->private_data;
-	struct guest_memseg *seg;
-	u64 offset = vma->vm_pgoff << PAGE_SHIFT;
-	size_t len = vma->vm_end - vma->vm_start;
-	int ret;
-
-	if (vm->hugetlb_enabled)
-		return -EINVAL;
-
-	mutex_lock(&vm->seg_lock);
-	list_for_each_entry(seg, &vm->memseg_list, list) {
-		if (seg->gpa != offset || seg->len != len)
-			continue;
-
-		ret = do_mmap_guest(file, vma, seg);
-		mutex_unlock(&vm->seg_lock);
-		return ret;
-	}
-	mutex_unlock(&vm->seg_lock);
-	return -EINVAL;
-}
-
-static void *do_map_guest_phys(struct vhm_vm *vm, u64 guest_phys, size_t size)
-{
-	struct guest_memseg *seg;
-
-	mutex_lock(&vm->seg_lock);
-	list_for_each_entry(seg, &vm->memseg_list, list) {
-		if (seg->gpa > guest_phys ||
-		    guest_phys >= seg->gpa + seg->len)
-			continue;
-
-		if (guest_phys + size > seg->gpa + seg->len) {
-			mutex_unlock(&vm->seg_lock);
-			return NULL;
-		}
-
-		mutex_unlock(&vm->seg_lock);
-		return phys_to_virt(seg->vm0_gpa + guest_phys - seg->gpa);
-	}
-	mutex_unlock(&vm->seg_lock);
-	return NULL;
-}
-
 void *map_guest_phys(unsigned long vmid, u64 guest_phys, size_t size)
 {
 	struct vhm_vm *vm;
-	void *ret;
+	void *ret = NULL;
 
 	vm = find_get_vm(vmid);
 	if (vm == NULL)
-		return NULL;
+		return ret;
 
 	if (vm->hugetlb_enabled)
 		ret = hugepage_map_guest_phys(vm, guest_phys, size);
-	else
-		ret = do_map_guest_phys(vm, guest_phys, size);
 
 	put_vm(vm);
 
@@ -452,38 +247,19 @@ void *map_guest_phys(unsigned long vmid, u64 guest_phys, size_t size)
 }
 EXPORT_SYMBOL(map_guest_phys);
 
-static int do_unmap_guest_phys(struct vhm_vm *vm, u64 guest_phys)
-{
-	struct guest_memseg *seg;
-
-	mutex_lock(&vm->seg_lock);
-	list_for_each_entry(seg, &vm->memseg_list, list) {
-		if (seg->gpa <= guest_phys &&
-			guest_phys < seg->gpa + seg->len) {
-			mutex_unlock(&vm->seg_lock);
-			return 0;
-		}
-	}
-	mutex_unlock(&vm->seg_lock);
-
-	return -ESRCH;
-}
-
 int unmap_guest_phys(unsigned long vmid, u64 guest_phys)
 {
 	struct vhm_vm *vm;
-	int ret;
+	int ret = -ESRCH;
 
 	vm = find_get_vm(vmid);
 	if (vm == NULL) {
 		pr_warn("vm_list corrupted\n");
-		return -ESRCH;
+		return ret;
 	}
 
 	if (vm->hugetlb_enabled)
 		ret = hugepage_unmap_guest_phys(vm, guest_phys);
-	else
-		ret = do_unmap_guest_phys(vm, guest_phys);
 
 	put_vm(vm);
 	return ret;
diff --git a/include/linux/vhm/acrn_vhm_mm.h b/include/linux/vhm/acrn_vhm_mm.h
index 21269e47b26a..645a8a56531e 100644
--- a/include/linux/vhm/acrn_vhm_mm.h
+++ b/include/linux/vhm/acrn_vhm_mm.h
@@ -163,8 +163,6 @@ int update_memmap_attr(unsigned long vmid, unsigned long guest_gpa,
 
 int vhm_dev_mmap(struct file *file, struct vm_area_struct *vma);
 
-int check_guest_mem(struct vhm_vm *vm);
-
 /**
  * free_guest_mem - free memory of guest
  *
@@ -174,17 +172,6 @@ int check_guest_mem(struct vhm_vm *vm);
  */
 void free_guest_mem(struct vhm_vm *vm);
 
-/**
- * alloc_guest_memseg - alloc memory of guest according to pre-defined
- * memory segment info
- *
- * @vm: pointer to guest vm
- * @memseg: pointer to guest memory segment info
- *
- * Return:
- */
-int alloc_guest_memseg(struct vhm_vm *vm, struct vm_memseg *memseg);
-
 /**
  * map_guest_memseg - set guest mmapping of memory according to
  * pre-defined memory mapping info
diff --git a/include/linux/vhm/vhm_ioctl_defs.h b/include/linux/vhm/vhm_ioctl_defs.h
index ad158f8949ba..3b9b4afc7d82 100644
--- a/include/linux/vhm/vhm_ioctl_defs.h
+++ b/include/linux/vhm/vhm_ioctl_defs.h
@@ -91,6 +91,7 @@
 
 /* Guest memory management */
 #define IC_ID_MEM_BASE                  0x40UL
+/* IC_ALLOC_MEMSEG not used */
 #define IC_ALLOC_MEMSEG                 _IC_ID(IC_ID, IC_ID_MEM_BASE + 0x00)
 #define IC_SET_MEMSEG                   _IC_ID(IC_ID, IC_ID_MEM_BASE + 0x01)
 
diff --git a/include/linux/vhm/vhm_vm_mngt.h b/include/linux/vhm/vhm_vm_mngt.h
index 4fed61229ad9..fe0ab90fc425 100644
--- a/include/linux/vhm/vhm_vm_mngt.h
+++ b/include/linux/vhm/vhm_vm_mngt.h
@@ -80,8 +80,6 @@ extern struct mutex vhm_vm_list_lock;
  * @trusty_host_gpa: host physical address of continuous memory for Trusty
  * @ioreq_fallback_client: default ioreq client
  * @refcnt: reference count of guest
- * @seg_lock:  mutex to protect memseg_list
- * @memseg_list: list of memseg
  * @hugepage_lock:  mutex to protect hugepage_hlist
  * @hugepage_hlist: hash list of hugepage
  * @max_gfn: maximum guest page frame number
@@ -98,8 +96,6 @@ struct vhm_vm {
 	unsigned long trusty_host_gpa;
 	int ioreq_fallback_client;
 	long refcnt;
-	struct mutex seg_lock;
-	struct list_head memseg_list;
 	struct mutex hugepage_lock;
 	struct hlist_head hugepage_hlist[HUGEPAGE_HLIST_ARRAY_SIZE];
 	int max_gfn;
-- 
2.17.1

