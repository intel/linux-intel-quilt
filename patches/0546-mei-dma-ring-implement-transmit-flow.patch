From 1966c001c079fa51a58edaf4c563d275656fa1d0 Mon Sep 17 00:00:00 2001
From: Tomas Winkler <tomas.winkler@intel.com>
Date: Wed, 2 Nov 2016 18:18:36 -0400
Subject: [PATCH 0546/2302] mei: dma ring: implement transmit flow

Implement a circular buffer on allocated system memory. Read and write
indices are stored on the control block which is also shared between the
device and the host.
Two new functions are exported from the DMA module: mei_dma_ring_write,
and mei_dma_ring_empty_slots. The former simply copy a packet on the TX
DMA circular buffer and later, returns the number of empty slots on the
TX DMA circular buffer.

Change-Id: I47885e4b989b1425253211c86b5931dc30c5bde6
Signed-off-by: Tomas Winkler <tomas.winkler@intel.com>
Signed-off-by: Alexander Usyskin <alexander.usyskin@intel.com>
Signed-off-by: Tomas Winkler <tomas.winkler@intel.com>
---
 drivers/misc/mei/client.c   | 137 +++++++++++++++++++++++++++++---------------
 drivers/misc/mei/dma-ring.c |  82 ++++++++++++++++++++++++++
 drivers/misc/mei/mei_dev.h  |   2 +
 3 files changed, 174 insertions(+), 47 deletions(-)

diff --git a/drivers/misc/mei/client.c b/drivers/misc/mei/client.c
index e4badcc..81a09e8 100644
--- a/drivers/misc/mei/client.c
+++ b/drivers/misc/mei/client.c
@@ -1513,6 +1513,22 @@ int mei_cl_read_start(struct mei_cl *cl, size_t length, const struct file *fp)
 	return rets;
 }
 
+static inline void mei_msg_hdr_init(struct mei_msg_hdr *mei_hdr,
+				    struct mei_cl_cb *cb)
+{
+	mei_hdr->host_addr = mei_cl_host_addr(cb->cl);
+	mei_hdr->me_addr = mei_cl_me_id(cb->cl);
+	mei_hdr->reserved = 0;
+	mei_hdr->msg_complete = 0;
+	mei_hdr->dma_ring = 0;
+	mei_hdr->internal = cb->internal;
+}
+
+struct mei_msg_hdr_ext {
+	struct mei_msg_hdr hdr;
+	u32 dma_len;
+};
+
 /**
  * mei_cl_irq_write - write a message to device
  *	from the interrupt thread context
@@ -1528,12 +1544,15 @@ int mei_cl_irq_write(struct mei_cl *cl, struct mei_cl_cb *cb,
 {
 	struct mei_device *dev;
 	struct mei_msg_data *buf;
-	struct mei_msg_hdr mei_hdr;
+	struct mei_msg_hdr_ext ext_hdr;
+	struct mei_msg_hdr *mei_hdr = &ext_hdr.hdr;
 	size_t len;
 	u32 msg_slots;
-	int slots;
+	u32 dr_slots;
+	int hbuf_slots;
 	int rets;
 	bool first_chunk;
+	const void *data;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
@@ -1553,41 +1572,48 @@ int mei_cl_irq_write(struct mei_cl *cl, struct mei_cl_cb *cb,
 		return 0;
 	}
 
-	slots = mei_hbuf_empty_slots(dev);
+	mei_msg_hdr_init(mei_hdr, cb);
+
+	hbuf_slots = mei_hbuf_empty_slots(dev);
+	dr_slots = mei_dma_ring_empty_slots(dev);
 	len = buf->size - cb->buf_idx;
+	data = buf->data + cb->buf_idx;
 	msg_slots = mei_data2slots(len);
 
-	mei_hdr.host_addr = mei_cl_host_addr(cl);
-	mei_hdr.me_addr = mei_cl_me_id(cl);
-	mei_hdr.reserved = 0;
-	mei_hdr.dma_ring = 0;
-	mei_hdr.internal = cb->internal;
-
-	if (slots >= msg_slots) {
-		mei_hdr.length = len;
-		mei_hdr.msg_complete = 1;
-	/* Split the message only if we can write the whole host buffer */
-	} else if (slots == dev->hbuf_depth) {
-		msg_slots = slots;
-		len = (slots * sizeof(u32)) - sizeof(struct mei_msg_hdr);
-		mei_hdr.length = len;
-		mei_hdr.msg_complete = 0;
+	if (hbuf_slots >= msg_slots) {
+		mei_hdr->length = len;
+		mei_hdr->msg_complete = 1;
+	} else if (dev->hbm_f_dr_supported && hbuf_slots > sizeof(ext_hdr) &&
+		   dr_slots) {
+		if (msg_slots < dr_slots)
+			mei_hdr->msg_complete = 1;
+		else
+			len = mei_slots2data(dr_slots);
+
+		mei_hdr->dma_ring = 1;
+		mei_hdr->length = sizeof(ext_hdr.dma_len);
+		ext_hdr.dma_len = len;
+		data = &ext_hdr.dma_len;
+
+	} else if (hbuf_slots == dev->hbuf_depth) {
+		len = mei_hbuf_max_len(dev);
+		mei_hdr->length = len;
 	} else {
 		/* wait for next time the host buffer is empty */
 		return 0;
 	}
 
-	cl_dbg(dev, cl, "buf: size = %zu idx = %zu\n",
-			cb->buf.size, cb->buf_idx);
+	if (mei_hdr->dma_ring)
+		mei_dma_ring_write(dev, buf->data + cb->buf_idx, len);
 
-	rets = mei_write_message(dev, &mei_hdr, buf->data + cb->buf_idx);
+	rets = mei_write_message(dev, mei_hdr, data);
 	if (rets)
 		goto err;
 
 	cl->status = 0;
 	cl->writing_state = MEI_WRITING;
-	cb->buf_idx += mei_hdr.length;
-	cb->completed = mei_hdr.msg_complete == 1;
+	cb->buf_idx += len;
+	cb->completed = mei_hdr->msg_complete == 1;
 
 	if (first_chunk) {
 		if (mei_cl_tx_flow_ctrl_creds_reduce(cl)) {
@@ -1596,7 +1622,7 @@ int mei_cl_irq_write(struct mei_cl *cl, struct mei_cl_cb *cb,
 		}
 	}
 
-	if (mei_hdr.msg_complete)
+	if (mei_hdr->msg_complete)
 		list_move_tail(&cb->list, &dev->write_waiting_list);
 
 	return 0;
@@ -1620,10 +1646,13 @@ int mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb)
 {
 	struct mei_device *dev;
 	struct mei_msg_data *buf;
-	struct mei_msg_hdr mei_hdr;
-	int size;
+	struct mei_msg_hdr_ext ext_hdr;
+	struct mei_msg_hdr *mei_hdr = &ext_hdr.hdr;
 	int rets;
 	bool blocking;
+	size_t len;
+	u32 hbuf_slots, dr_slots, msg_slots;
+	const void *data;
 
 	if (WARN_ON(!cl || !cl->dev))
 		return -ENODEV;
@@ -1634,10 +1663,11 @@ int mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb)
 	dev = cl->dev;
 
 	buf = &cb->buf;
-	size = buf->size;
+	len = buf->size;
+	data = buf->data;
 	blocking = cb->blocking;
 
-	cl_dbg(dev, cl, "size=%d\n", size);
+	cl_dbg(dev, cl, "size = %zu\n", len);
 
 	rets = pm_runtime_get(dev->dev);
 	if (rets < 0 && rets != -EINPROGRESS) {
@@ -1649,12 +1679,7 @@ int mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb)
 	cb->buf_idx = 0;
 	cl->writing_state = MEI_IDLE;
 
-	mei_hdr.host_addr = mei_cl_host_addr(cl);
-	mei_hdr.me_addr = mei_cl_me_id(cl);
-	mei_hdr.reserved = 0;
-	mei_hdr.msg_complete = 0;
-	mei_hdr.dma_ring = 0;
-	mei_hdr.internal = cb->internal;
+	mei_msg_hdr_init(mei_hdr, cb);
 
 	rets = mei_cl_tx_flow_ctrl_creds(cl);
 	if (rets < 0)
@@ -1662,25 +1687,41 @@ int mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb)
 
 	if (rets == 0) {
 		cl_dbg(dev, cl, "No flow control credentials: not sending.\n");
-		rets = size;
 		goto out;
 	}
+
 	if (!mei_hbuf_acquire(dev)) {
 		cl_dbg(dev, cl, "Cannot acquire the host buffer: not sending.\n");
-		rets = size;
 		goto out;
 	}
 
-	/* Check for a maximum length */
-	if (size > mei_hbuf_max_len(dev)) {
-		mei_hdr.length = mei_hbuf_max_len(dev);
-		mei_hdr.msg_complete = 0;
+	hbuf_slots = mei_hbuf_empty_slots(dev);
+	dr_slots = mei_dma_ring_empty_slots(dev);
+	msg_slots = mei_data2slots(len);
+
+	if (hbuf_slots >= msg_slots) {
+		mei_hdr->length = len;
+		mei_hdr->msg_complete = 1;
+	} else if (dev->hbm_f_dr_supported && hbuf_slots > sizeof(ext_hdr) &&
+		   dr_slots) {
+		if (msg_slots < dr_slots)
+			mei_hdr->msg_complete = 1;
+		else
+			len = mei_slots2data(dr_slots);
+
+		mei_hdr->dma_ring = 1;
+		mei_hdr->length = sizeof(ext_hdr.dma_len);
+		ext_hdr.dma_len = len;
+		data = &ext_hdr.dma_len;
 	} else {
-		mei_hdr.length = size;
-		mei_hdr.msg_complete = 1;
+		len = mei_hbuf_max_len(dev);
+		mei_hdr->length = len;
 	}
 
-	rets = mei_write_message(dev, &mei_hdr, buf->data);
+	if (mei_hdr->dma_ring)
+		mei_dma_ring_write(dev, buf->data, len);
+
+	rets = mei_write_message(dev, mei_hdr, data);
 	if (rets)
 		goto err;
 
@@ -1689,11 +1730,13 @@ int mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb)
 		goto err;
 
 	cl->writing_state = MEI_WRITING;
-	cb->buf_idx = mei_hdr.length;
-	cb->completed = mei_hdr.msg_complete == 1;
+	cb->buf_idx = len;
+	cb->completed = mei_hdr->msg_complete == 1;
 
+	/* reset len to the original size for a function return value */
+	len = buf->size;
 out:
-	if (mei_hdr.msg_complete)
+	if (mei_hdr->msg_complete)
 		list_add_tail(&cb->list, &dev->write_waiting_list);
 	else
 		list_add_tail(&cb->list, &dev->write_list);
@@ -1718,7 +1761,7 @@ int mei_cl_write(struct mei_cl *cl, struct mei_cl_cb *cb)
 		}
 	}
 
-	rets = size;
+	rets = len;
 err:
 	cl_dbg(dev, cl, "rpm: autosuspend\n");
 	pm_runtime_mark_last_busy(dev->dev);
diff --git a/drivers/misc/mei/dma-ring.c b/drivers/misc/mei/dma-ring.c
index 9c580a0..f841b9f 100644
--- a/drivers/misc/mei/dma-ring.c
+++ b/drivers/misc/mei/dma-ring.c
@@ -121,6 +121,18 @@ static size_t mei_dma_copy_from(struct mei_device *dev, unsigned char *buf,
 	return b_n;
 }
 
+static size_t mei_dma_copy_to(struct mei_device *dev, unsigned char *buf,
+			      u32 offset, u32 n)
+{
+	unsigned char *hbuf = dev->dr_dscr[DMA_DSCR_HOST].vaddr;
+
+	size_t b_offset = offset << 2;
+	size_t b_n = n << 2;
+
+	memcpy(hbuf + b_offset, buf, b_n);
+
+	return b_n;
+}
 void mei_dma_ring_read(struct mei_device *dev, unsigned char *buf, u32 len)
 {
 	struct hbm_dma_ring_ctrl *ctrl = mei_dma_ring_ctrl(dev);
@@ -149,3 +161,73 @@ void mei_dma_ring_read(struct mei_device *dev, unsigned char *buf, u32 len)
 out:
 	WRITE_ONCE(ctrl->dbuf_rd_idx, ctrl->dbuf_rd_idx + slots);
 }
+
+static inline u32 mei_dma_ring_hbuf_depth(struct mei_device *dev)
+{
+	return dev->dr_dscr[DMA_DSCR_HOST].size >> 2;
+}
+
+/**
+ * mei_dma_ring_empty_slots - calaculate number of empty slots in dma ring
+ *
+ * @dev: mei_device
+ *
+ * Return: number of empty slots
+ */
+u32 mei_dma_ring_empty_slots(struct mei_device *dev)
+{
+	struct hbm_dma_ring_ctrl *ctrl = mei_dma_ring_ctrl(dev);
+	u32 wr_idx, rd_idx, hbuf_depth, empty;
+
+	if (!mei_dma_ring_is_allocated(dev))
+		return 0;
+
+	if (WARN_ON(!ctrl))
+		return 0;
+
+	/* easier to work in slots */
+	hbuf_depth = mei_dma_ring_hbuf_depth(dev);
+	rd_idx = READ_ONCE(ctrl->hbuf_rd_idx);
+	wr_idx = READ_ONCE(ctrl->hbuf_wr_idx);
+
+	if (rd_idx > wr_idx)
+		empty = rd_idx - wr_idx;
+	else
+		empty = hbuf_depth - (wr_idx - rd_idx);
+
+	return empty;
+}
+
+/**
+ * mei_dma_ring_write - write data to dma ring host buffer
+ *
+ * @dev: mei_device
+ * @buf: data will be written
+ * @len: data length
+ */
+void mei_dma_ring_write(struct mei_device *dev, unsigned char *buf, u32 len)
+{
+	struct hbm_dma_ring_ctrl *ctrl = mei_dma_ring_ctrl(dev);
+	u32 hbuf_depth;
+	u32 wr_idx, rem, slots;
+
+	if (WARN_ON(!ctrl))
+		return;
+
+	dev_dbg(dev->dev, "writing to dma %u bytes\n", len);
+	hbuf_depth = mei_dma_ring_hbuf_depth(dev);
+	wr_idx = READ_ONCE(ctrl->hbuf_wr_idx) & (hbuf_depth - 1);
+	slots = DIV_ROUND_UP(len, MEI_DMA_SLOT_SIZE);
+
+	if (wr_idx + slots > hbuf_depth) {
+		buf += mei_dma_copy_to(dev, buf, wr_idx, hbuf_depth - wr_idx);
+		rem = slots - (hbuf_depth - wr_idx);
+		wr_idx = 0;
+	} else {
+		rem = slots;
+	}
+
+	mei_dma_copy_to(dev, buf, wr_idx, rem);
+
+	WRITE_ONCE(ctrl->hbuf_wr_idx, ctrl->hbuf_wr_idx + slots);
+}
diff --git a/drivers/misc/mei/mei_dev.h b/drivers/misc/mei/mei_dev.h
index 1b5dd9c..2fa5659 100644
--- a/drivers/misc/mei/mei_dev.h
+++ b/drivers/misc/mei/mei_dev.h
@@ -561,6 +561,8 @@ void mei_dmam_ring_free(struct mei_device *dev);
 bool mei_dma_ring_is_allocated(struct mei_device *dev);
 void mei_dma_ring_reset(struct mei_device *dev);
 void mei_dma_ring_read(struct mei_device *dev, unsigned char *buf, u32 len);
+void mei_dma_ring_write(struct mei_device *dev, unsigned char *buf, u32 len);
+u32 mei_dma_ring_empty_slots(struct mei_device *dev);
 
 /*
  *  MEI interrupt functions prototype
-- 
2.7.4

