From 7dddd7d5b9b6f6b2f5e142bf4f87f2102ebf5e22 Mon Sep 17 00:00:00 2001
From: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Date: Wed, 8 Sep 2021 19:03:41 +0200
Subject: [PATCH 13/25] drm/i915/gt: Use spin_lock_irq() instead of
 local_irq_disable() + spin_lock()

execlists_dequeue() is invoked from a function which uses
local_irq_disable() to disable interrupts so the spin_lock() behaves
like spin_lock_irq().
This breaks PREEMPT_RT because local_irq_disable() + spin_lock() is not
the same as spin_lock_irq().

execlists_dequeue_irq() and execlists_dequeue() has each one caller
only. If intel_engine_cs::active::lock is acquired and released with the
_irq suffix then it behaves almost as if execlists_dequeue() would be
invoked with disabled interrupts. The difference is the last part of the
function which is then invoked with enabled interrupts.
I can't tell if this makes a difference. From looking at it, it might
work to move the last unlock at the end of the function as I didn't find
anything that would acquire the lock again.

Reported-by: Clark Williams <williams@redhat.com>
Signed-off-by: Sebastian Andrzej Siewior <bigeasy@linutronix.de>
Reviewed-by: Maarten Lankhorst <maarten.lankhorst@linux.intel.com>
Signed-off-by: Junxiao Chang <junxiao.chang@intel.com>
---
 .../drm/i915/gt/intel_execlists_submission.c  | 22 +++++++++++++++++++
 1 file changed, 22 insertions(+)

diff --git a/drivers/gpu/drm/i915/gt/intel_execlists_submission.c b/drivers/gpu/drm/i915/gt/intel_execlists_submission.c
index 72090f52fb850..f8086634729c5 100644
--- a/drivers/gpu/drm/i915/gt/intel_execlists_submission.c
+++ b/drivers/gpu/drm/i915/gt/intel_execlists_submission.c
@@ -1303,7 +1303,11 @@ static void execlists_dequeue(struct intel_engine_cs *engine)
 	 * and context switches) submission.
 	 */
 
+#ifdef CONFIG_PREEMPT_RT
+	spin_lock_irq(&sched_engine->lock);
+#else
 	spin_lock(&sched_engine->lock);
+#endif
 
 	/*
 	 * If the queue is higher priority than the last
@@ -1403,7 +1407,11 @@ static void execlists_dequeue(struct intel_engine_cs *engine)
 				 * Even if ELSP[1] is occupied and not worthy
 				 * of timeslices, our queue might be.
 				 */
+#ifdef CONFIG_PREEMPT_RT
+				spin_unlock_irq(&sched_engine->lock);
+#else
 				spin_unlock(&sched_engine->lock);
+#endif
 				return;
 			}
 		}
@@ -1429,7 +1437,11 @@ static void execlists_dequeue(struct intel_engine_cs *engine)
 
 		if (last && !can_merge_rq(last, rq)) {
 			spin_unlock(&ve->base.sched_engine->lock);
+#ifdef CONFIG_PREEMPT_RT
+			spin_unlock_irq(&engine->sched_engine->lock);
+#else
 			spin_unlock(&engine->sched_engine->lock);
+#endif
 			return; /* leave this for another sibling */
 		}
 
@@ -1591,7 +1603,11 @@ static void execlists_dequeue(struct intel_engine_cs *engine)
 	 */
 	sched_engine->queue_priority_hint = queue_prio(sched_engine);
 	i915_sched_engine_reset_on_empty(sched_engine);
+#ifdef CONFIG_PREEMPT_RT
+	spin_unlock_irq(&sched_engine->lock);
+#else
 	spin_unlock(&sched_engine->lock);
+#endif
 
 	/*
 	 * We can skip poking the HW if we ended up with exactly the same set
@@ -1617,12 +1633,14 @@ static void execlists_dequeue(struct intel_engine_cs *engine)
 	}
 }
 
+#ifndef CONFIG_PREEMPT_RT
 static void execlists_dequeue_irq(struct intel_engine_cs *engine)
 {
 	local_irq_disable(); /* Suspend interrupts across request submission */
 	execlists_dequeue(engine);
 	local_irq_enable(); /* flush irq_work (e.g. breadcrumb enabling) */
 }
+#endif
 
 static void clear_ports(struct i915_request **ports, int count)
 {
@@ -2478,7 +2496,11 @@ static void execlists_submission_tasklet(struct tasklet_struct *t)
 	}
 
 	if (!engine->execlists.pending[0]) {
+#ifdef CONFIG_PREEMPT_RT
+		execlists_dequeue(engine);
+#else
 		execlists_dequeue_irq(engine);
+#endif
 		start_timeslice(engine);
 	}
 
-- 
2.25.1

